{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7c9db2",
   "metadata": {
    "id": "af7c9db2",
    "papermill": {
     "duration": 0.123947,
     "end_time": "2022-02-13T03:48:50.443026",
     "exception": false,
     "start_time": "2022-02-13T03:48:50.319079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#a7d5ed;font-size:170%;\n",
    "            font-family:Nexa;letter-spacing:4.5px;\">    \n",
    "    <h1 style=\"padding:15px;color:black;text-align: center\"> Feature Engineering </h1> \n",
    "</div>\n",
    "\n",
    "![](img/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df1cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T21:07:28.068848Z",
     "start_time": "2021-12-17T21:07:28.056849Z"
    },
    "id": "17df1cf4",
    "papermill": {
     "duration": 0.072795,
     "end_time": "2022-02-13T03:48:50.607818",
     "exception": false,
     "start_time": "2022-02-13T03:48:50.535023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> OBJETIVO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed77c8",
   "metadata": {
    "id": "95ed77c8",
    "papermill": {
     "duration": 0.072412,
     "end_time": "2022-02-13T03:48:50.753402",
     "exception": false,
     "start_time": "2022-02-13T03:48:50.680990",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "O objetivo neste notebook é criação novas variáveis (features) que possam ajudar na identificação de novos padrões, com a finalidade de bater a baseline estabelecida no notebook anterior de RMSE 247.78 com XGBoost na competição. \n",
    "\n",
    "![](img/01-rank.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f8d9e",
   "metadata": {
    "id": "0c6f8d9e",
    "papermill": {
     "duration": 0.072397,
     "end_time": "2022-02-13T03:48:50.897545",
     "exception": false,
     "start_time": "2022-02-13T03:48:50.825148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 1. IMPORTAÇÕES </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d25b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T20:49:34.792594Z",
     "start_time": "2021-12-17T20:49:34.785596Z"
    },
    "id": "283d25b5",
    "papermill": {
     "duration": 0.071893,
     "end_time": "2022-02-13T03:48:51.042107",
     "exception": false,
     "start_time": "2022-02-13T03:48:50.970214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a8fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:06:45.492071Z",
     "start_time": "2022-07-04T22:06:45.461074Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:48:51.210862Z",
     "iopub.status.busy": "2022-02-13T03:48:51.210191Z",
     "iopub.status.idle": "2022-02-13T03:49:00.128309Z",
     "shell.execute_reply": "2022-02-13T03:49:00.127697Z",
     "shell.execute_reply.started": "2022-02-13T00:29:02.882517Z"
    },
    "executionInfo": {
     "elapsed": 74771,
     "status": "ok",
     "timestamp": 1655826420198,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "f71a8fd8",
    "outputId": "c19202e4-f491-44b6-c667-5a0d1ff5a9a1",
    "papermill": {
     "duration": 9.008148,
     "end_time": "2022-02-13T03:49:00.128456",
     "exception": false,
     "start_time": "2022-02-13T03:48:51.120308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pub.towardsai.net/use-google-colab-like-a-pro-39a97184358d\n",
    "COLAB = 'google.colab' in str(get_ipython()) \n",
    "\n",
    "if COLAB:        \n",
    "    !pip install --q scikit-plot\n",
    "    !pip install --q category_encoders\n",
    "    !pip install --q shap\n",
    "    !pip install --q inflection    \n",
    "    !pip install --q optbinning\n",
    "    !pip install --q optuna  \n",
    "    !pip install --q catboost\n",
    "    !pip install --q pandas-profiling\n",
    "    !pip install --q feature_engine\n",
    "    #!pip install --q pycaret\n",
    "        \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f785108",
   "metadata": {
    "id": "2f785108",
    "papermill": {
     "duration": 0.073951,
     "end_time": "2022-02-13T03:49:00.427074",
     "exception": false,
     "start_time": "2022-02-13T03:49:00.353123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa56e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:21.112669Z",
     "start_time": "2022-07-04T22:06:46.857262Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:00.577906Z",
     "iopub.status.busy": "2022-02-13T03:49:00.577228Z",
     "iopub.status.idle": "2022-02-13T03:49:02.735090Z",
     "shell.execute_reply": "2022-02-13T03:49:02.734379Z",
     "shell.execute_reply.started": "2022-02-13T00:29:11.961770Z"
    },
    "executionInfo": {
     "elapsed": 5547,
     "status": "ok",
     "timestamp": 1655826425739,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "dbfa56e0",
    "papermill": {
     "duration": 2.23593,
     "end_time": "2022-02-13T03:49:02.735247",
     "exception": false,
     "start_time": "2022-02-13T03:49:00.499317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import sklearn.exceptions\n",
    "import datetime\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508135c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:31.608513Z",
     "start_time": "2022-07-04T22:07:21.114676Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:02.900615Z",
     "iopub.status.busy": "2022-02-13T03:49:02.899960Z",
     "iopub.status.idle": "2022-02-13T03:49:03.173267Z",
     "shell.execute_reply": "2022-02-13T03:49:03.172121Z",
     "shell.execute_reply.started": "2022-02-13T00:29:11.971454Z"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1655826438292,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "508135c8",
    "papermill": {
     "duration": 0.357843,
     "end_time": "2022-02-13T03:49:03.173421",
     "exception": false,
     "start_time": "2022-02-13T03:49:02.815578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn           as sns\n",
    "import joblib            as jb\n",
    "import scipy.stats       as stats\n",
    "import statsmodels.api   as sm\n",
    "import xgboost           as xgb\n",
    "import scikitplot        as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea73f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:31.624280Z",
     "start_time": "2022-07-04T22:07:31.611281Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:03.342248Z",
     "iopub.status.busy": "2022-02-13T03:49:03.341660Z",
     "iopub.status.idle": "2022-02-13T03:49:03.567639Z",
     "shell.execute_reply": "2022-02-13T03:49:03.568076Z",
     "shell.execute_reply.started": "2022-02-13T00:29:11.983460Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826438589,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "32ea73f4",
    "papermill": {
     "duration": 0.311288,
     "end_time": "2022-02-13T03:49:03.568250",
     "exception": false,
     "start_time": "2022-02-13T03:49:03.256962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing   import StandardScaler, MinMaxScaler, RobustScaler \n",
    "from sklearn.preprocessing   import MaxAbsScaler, QuantileTransformer \n",
    "from sklearn.preprocessing   import PowerTransformer, Normalizer\n",
    "from sklearn.preprocessing   import LabelBinarizer, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn                 import metrics\n",
    "from sklearn.metrics         import ConfusionMatrixDisplay, confusion_matrix\n",
    "from datetime                import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa0346",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:31.640278Z",
     "start_time": "2022-07-04T22:07:31.628281Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1655826438875,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "13fa0346"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster         import KMeans\n",
    "from sklearn.decomposition   import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9c315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:31.720430Z",
     "start_time": "2022-07-04T22:07:31.643280Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826439117,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "8fd9c315"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble        import VotingRegressor\n",
    "from sklearn.compose         import TransformedTargetRegressor\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from scipy.stats             import skew, norm\n",
    "from scipy.stats             import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087a0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:38.729851Z",
     "start_time": "2022-07-04T22:07:31.722279Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:03.724284Z",
     "iopub.status.busy": "2022-02-13T03:49:03.723481Z",
     "iopub.status.idle": "2022-02-13T03:49:03.927969Z",
     "shell.execute_reply": "2022-02-13T03:49:03.927434Z",
     "shell.execute_reply.started": "2022-02-13T00:29:11.992133Z"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1655826440077,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "d087a0ec",
    "papermill": {
     "duration": 0.286499,
     "end_time": "2022-02-13T03:49:03.928094",
     "exception": false,
     "start_time": "2022-02-13T03:49:03.641595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster        import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from scipy                      import stats\n",
    "from scipy.cluster              import hierarchy as hc\n",
    "from math                       import factorial\n",
    "from scipy.stats                import mode\n",
    "from collections                import Counter\n",
    "from sklearn.neighbors          import KNeighborsClassifier\n",
    "from optbinning                 import OptimalBinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e59de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:38.886118Z",
     "start_time": "2022-07-04T22:07:38.736854Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826440424,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "26e59de9"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor       import ResidualsPlot\n",
    "from yellowbrick.regressor       import PredictionError\n",
    "from yellowbrick.model_selection import ValidationCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc6200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.021335Z",
     "start_time": "2022-07-04T22:07:38.888123Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826440674,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "38cc6200"
   },
   "outputs": [],
   "source": [
    "from lightgbm                        import LGBMRegressor\n",
    "from sklearn.linear_model            import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble                import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble                import AdaBoostRegressor\n",
    "from sklearn.linear_model            import LinearRegression\n",
    "from sklearn.kernel_ridge            import KernelRidge\n",
    "from itertools                       import product\n",
    "from sklearn.linear_model            import Ridge\n",
    "from sklearn.neighbors               import KNeighborsRegressor\n",
    "from sklearn.ensemble                import ExtraTreesRegressor \n",
    "from catboost                        import CatBoostRegressor\n",
    "#from pycaret.regression              import * \n",
    "from sklearn.ensemble                import IsolationForest\n",
    "from sklearn.covariance              import EllipticEnvelope\n",
    "from sklearn.preprocessing           import FunctionTransformer\n",
    "#from feature_engine.outlier_removers import Winsoriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179cf1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.036177Z",
     "start_time": "2022-07-04T22:07:43.024129Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose      import TransformedTargetRegressor\n",
    "from sklearn.pipeline     import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.base         import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c25312",
   "metadata": {
    "id": "44c25312",
    "papermill": {
     "duration": 0.071787,
     "end_time": "2022-02-13T03:49:04.073443",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.001656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c3e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.179162Z",
     "start_time": "2022-07-04T22:07:43.045128Z"
    },
    "code_folding": [
     0,
     7,
     52,
     71,
     116,
     139,
     182,
     224,
     246,
     249,
     257,
     262,
     275,
     299,
     307,
     315,
     326,
     341,
     383,
     396,
     412,
     431
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:04.235486Z",
     "iopub.status.busy": "2022-02-13T03:49:04.233853Z",
     "iopub.status.idle": "2022-02-13T03:49:04.236048Z",
     "shell.execute_reply": "2022-02-13T03:49:04.236480Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.001803Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826441227,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "068c3e54",
    "papermill": {
     "duration": 0.091139,
     "end_time": "2022-02-13T03:49:04.236630",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.145491",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ultil():\n",
    "    \n",
    "    import sklearn.exceptions\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def jupyter_setting():\n",
    "    \n",
    "        %matplotlib inline\n",
    "\n",
    "        #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "        #plt.style.use('bmh') \n",
    "        #plt.rcParams['figure.figsize'] = [20,15]\n",
    "        #plt.rcParams['font.size']      = 13\n",
    "\n",
    "        pd.options.display.max_columns = None\n",
    "        #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        warnings.simplefilter('ignore')\n",
    "        warnings.filterwarnings('ignore')\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "        pd.set_option('display.max_rows', 200)\n",
    "        pd.set_option('display.max_columns', 500)\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "        icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "        #sns.palplot(sns.color_palette(icecream))\n",
    "\n",
    "        colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "              \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "              \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "              \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "\n",
    "        # Colors\n",
    "        dark_red   = \"#b20710\"\n",
    "        black      = \"#221f1f\"\n",
    "        green      = \"#009473\"\n",
    "        myred      = '#CD5C5C'\n",
    "        myblue     = '#6495ED'\n",
    "        mygreen    = '#90EE90'    \n",
    "        color_cols = [myred, myblue,mygreen]\n",
    "\n",
    "        return icecream, colors, color_cols\n",
    "\n",
    "    def missing_zero_values_table(df):\n",
    "        mis_val         = df.isnull().sum()\n",
    "        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n",
    "        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n",
    "                                                     0 : 'Valores ausentes', \n",
    "                                                     1 : '% de valores totais'})\n",
    "        \n",
    "        mz_table['Tipo de dados'] = df.dtypes\n",
    "        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n",
    "                                     sort_values('% de valores totais', ascending=False)\n",
    "        \n",
    "        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n",
    "              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n",
    "            \n",
    "        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n",
    "        \n",
    "        return mz_table.reset_index()\n",
    "    \n",
    "    def reduce_memory_usage(df, verbose=True):\n",
    "    \n",
    "        numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "        start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            col_type = df[col].dtypes\n",
    "\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "        end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                    end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def graf_label(ax, total):\n",
    "\n",
    "         for i in ax.patches:\n",
    "            # get_width pulls left or right; get_y pushes up or down\n",
    "            width, height = i.get_width() -.2 , i.get_height()\n",
    "\n",
    "            x, y  = i.get_xy()  \n",
    "            color = 'white'\n",
    "            alt   = .5\n",
    "            soma  = 0 \n",
    "\n",
    "            if height < 70:\n",
    "                color = 'black'\n",
    "                alt   = 1\n",
    "                soma  = 10\n",
    "\n",
    "            ax.annotate(str(round((i.get_height() * 100.0 / total), 1) )+'%', \n",
    "                        (i.get_x()+.3*width, \n",
    "                         i.get_y()+soma + alt*height),\n",
    "                         color   = color,\n",
    "                         weight = 'bold',\n",
    "                         size   = 14)\n",
    "            \n",
    "    def graf_bar(df, col, title, xlabel, ylabel, tol = 0):\n",
    "    \n",
    "        #ax    = df.groupby(['churn_cat'])['churn_cat'].count()\n",
    "        ax     = df    \n",
    "        colors = col\n",
    "\n",
    "        if tol == 0: \n",
    "            total  = sum(ax)\n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           color   = colors, \n",
    "                           grid    = False)\n",
    "        else:\n",
    "            total  = tol     \n",
    "\n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           figsize = (10,6),\n",
    "                           color   = colors,\n",
    "                           grid    = False)\n",
    "\n",
    "        #ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "        #y_fmt = tick.FormatStrFormatter('%.0f') \n",
    "        #ax.yaxis.set_major_formatter(y_fmt)\n",
    "\n",
    "        title   = title #+ ' \\n'\n",
    "        xlabel  = '\\n ' + xlabel \n",
    "        ylabel  = ylabel + ' \\n'\n",
    "\n",
    "        ax.set_title(title  , fontsize=22)\n",
    "        ax.set_xlabel(xlabel, fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)    \n",
    "\n",
    "        min = [0,23000000]\n",
    "        #ax.set_ylim(min)\n",
    "\n",
    "        graf_label(ax, total)\n",
    "\n",
    "    def graf_fature_corr(df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                         print_graf_=True, mask_=True, title_=''):\n",
    "\n",
    "        df = df_.corr(method ='pearson').round(5)\n",
    "\n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "\n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot=annot_, \n",
    "                             mask=mask, \n",
    "                             cmap=\"RdBu\", \n",
    "                             annot_kws={\"weight\": \"bold\", \"fontsize\":13}\n",
    "                            )\n",
    "\n",
    "            ax.set_title(\"\\n Correlação das variável {} \\n\".format(title_), fontsize=17)\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\")\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\")\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                \n",
    "    def describe(df):\n",
    "        var = df.columns\n",
    "\n",
    "        # Medidas de tendência central, média e mediana \n",
    "        ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "        ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "        # Dispensão - str, min , max range skew, kurtosis\n",
    "        d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "        d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "        d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "        d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "        d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "        d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "        d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "        # concatenete \n",
    "        m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "        m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "\n",
    "        return m\n",
    "\n",
    "    def graf_outlier(df, feature):\n",
    "        col = [(0,4), (5,9)]\n",
    "\n",
    "        df_plot = ((df[feature] - df[feature].min())/\n",
    "                   (df[feature].max() - df[feature].min()))\n",
    "\n",
    "        fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "        for i, (x) in enumerate(col): \n",
    "            sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); \n",
    "\n",
    "    def diff(t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "\n",
    "    def free_gpu_cache():\n",
    "\n",
    "        # https://www.kaggle.com/getting-started/140636\n",
    "        #print(\"Initial GPU Usage\")\n",
    "        #gpu_usage()                             \n",
    "\n",
    "        #cuda.select_device(0)\n",
    "        #cuda.close()\n",
    "        #cuda.select_device(0)   \n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def graf_eval():\n",
    "\n",
    "        results     = model.evals_result()\n",
    "        ntree_limit = model.best_ntree_limit\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "\n",
    "        for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "\n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "            plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "            plt.axvline(ntree_limit, \n",
    "                        color=\"gray\", \n",
    "                        label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "\n",
    "\n",
    "            title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "            plt.title(title_name)\n",
    "            plt.xlabel(\"Número de árvores\")\n",
    "            plt.ylabel(error)\n",
    "            plt.legend();\n",
    "\n",
    "    def linear_fit_slope(y):\n",
    "        \"\"\"Return the slope of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return slope\n",
    "\n",
    "    def linear_fit_intercept(y):\n",
    "        \"\"\"Return the intercept of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return intercept\n",
    "\n",
    "    def cromer_v(x, y):\n",
    "        cm       = pd.crosstab(x, y).to_numpy()        \n",
    "        n        = cm.sum()\n",
    "        r, k     = cm.shape\n",
    "        chi2     = stats.chi2_contingency(cm)[0]\n",
    "        chi2corr = max(0, chi2 - (k-1) * (r-1) /(n-1))\n",
    "        kcorr    = k - (k-1) **2/(n-1)\n",
    "        rcorr    = r - (r-1) **2/(n-1)    \n",
    "        v        = np.sqrt((chi2corr/n) / (min(kcorr-1, rcorr-1)))        \n",
    "        return v  \n",
    "\n",
    "    def generate_category_table(data):\n",
    "\n",
    "        cols    = data.select_dtypes(include='object').columns\n",
    "        dataset = pd.DataFrame()\n",
    "\n",
    "        for i in cols:\n",
    "            corr = []\n",
    "            for x in cols: \n",
    "                corr.append(Ultil.cromer_v(data[i],data[x]))\n",
    "\n",
    "            aux     = pd.DataFrame({i:corr})\n",
    "            dataset = pd.concat([dataset, aux], axis=1) \n",
    "\n",
    "        return dataset.set_index(dataset.columns)\n",
    "            \n",
    "    def graf_feature_corr(df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                          print_graf_=True, mask_=True, title_=''):\n",
    "\n",
    "        df = df_.corr(method ='pearson').round(5)\n",
    "\n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "\n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot=annot_, \n",
    "                             mask=mask, \n",
    "                             cmap=\"RdBu\", \n",
    "                             annot_kws={\"weight\": \"bold\", \"fontsize\":13}\n",
    "                            )\n",
    "\n",
    "            ax.set_title(\"\\n Correlação das variável {} \\n\".format(title_), fontsize=17)\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\")\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\")\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "\n",
    "    def plot_roc_curve(fpr, tpr, label=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "        ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for FLAI 08')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "\n",
    "    def feature_engineering(df_):\n",
    "\n",
    "        var_f27 = ''\n",
    "        for col in df_['f_27']: \n",
    "            var_f27 +=col\n",
    "\n",
    "        var_f27 = list(set(var_f27))\n",
    "        var_f27.sort()\n",
    "\n",
    "        df_[\"fe_f_27_unique\"] = df_[\"f_27\"].apply(lambda x: len(set(x)))\n",
    "\n",
    "        for letra in var_f27:             \n",
    "            df_['fe_' + letra.lower() + '_count'] = df2_train[\"f_27\"].str.count(letra)\n",
    "\n",
    "        return df_ \n",
    "\n",
    "    def identifies_outliers(df):\n",
    "\n",
    "        cols_num = df.select_dtypes(np.number).columns\n",
    "\n",
    "        for col in cols_num: \n",
    "            if col != 'unnamed':            \n",
    "                Q1  = df[col].quantile(0.25)\n",
    "                Q3  = df[col].quantile(0.75)\n",
    "                IQR = Q3-Q1\n",
    "                lowqe_bound=Q1 - 1.5 * IQR\n",
    "                upper_bound=Q3 + 1.5 * IQR\n",
    "\n",
    "                df['outliers_'+ col] = 0\n",
    "                df['outliers_'+ col][(df[col]<=lowqe_bound)|(df[col]>=upper_bound)] = 1    \n",
    "\n",
    "                df[col] = np.where(df[col] > df[col].quantile(0.95),\n",
    "                                                df[col].median(),\n",
    "                                                df[col])\n",
    "\n",
    "    def evaluation(y_, predictions_):\n",
    "        mae  = metrics.mean_absolute_error(y_, predictions_)\n",
    "        mse  = metrics.mean_squared_error(y_, predictions_)\n",
    "        rmse = metrics.mean_squared_error(y_, predictions_, squared=False) \n",
    "        mape = metrics.mean_absolute_percentage_error(y_, predictions_)\n",
    "        r2   = metrics.r2_score(y_, predictions_)    \n",
    "        return rmse, mae, mse, mape, r2\n",
    "\n",
    "icecream, colors, color_cols = Ultil.jupyter_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4551d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.195126Z",
     "start_time": "2022-07-04T22:07:43.181129Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:04.407736Z",
     "iopub.status.busy": "2022-02-13T03:49:04.405990Z",
     "iopub.status.idle": "2022-02-13T03:49:04.408334Z",
     "shell.execute_reply": "2022-02-13T03:49:04.408777Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.024081Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826442468,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "f7b4551d",
    "papermill": {
     "duration": 0.093407,
     "end_time": "2022-02-13T03:49:04.408925",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.315518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    \n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        col_type = df[col].dtypes\n",
    "        \n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db9c97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.211152Z",
     "start_time": "2022-07-04T22:07:43.198125Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:04.597966Z",
     "iopub.status.busy": "2022-02-13T03:49:04.595671Z",
     "iopub.status.idle": "2022-02-13T03:49:04.602519Z",
     "shell.execute_reply": "2022-02-13T03:49:04.604138Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.043512Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826442468,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "b5db9c97",
    "papermill": {
     "duration": 0.123013,
     "end_time": "2022-02-13T03:49:04.604345",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.481332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def missing_zero_values_table(df):\n",
    "        mis_val         = df.isnull().sum()\n",
    "        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n",
    "        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n",
    "                                                     0 : 'Valores ausentes', \n",
    "                                                     1 : '% de valores totais'})\n",
    "        \n",
    "        mz_table['Tipo de dados'] = df.dtypes\n",
    "        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n",
    "                                     sort_values('% de valores totais', ascending=False)\n",
    "        \n",
    "        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n",
    "              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n",
    "            \n",
    "        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n",
    "        \n",
    "        return mz_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951f472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.227163Z",
     "start_time": "2022-07-04T22:07:43.213162Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1655826442717,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "e951f472"
   },
   "outputs": [],
   "source": [
    "def graf_label(ax, total):\n",
    "    \n",
    "     for i in ax.patches:\n",
    "        # get_width pulls left or right; get_y pushes up or down\n",
    "        width, height = i.get_width() -.2 , i.get_height()\n",
    "        \n",
    "        x, y  = i.get_xy()  \n",
    "        color = 'white'\n",
    "        alt   = .5\n",
    "        soma  = 0 \n",
    "\n",
    "        if height < 70:\n",
    "            color = 'black'\n",
    "            alt   = 1\n",
    "            soma  = 10\n",
    "\n",
    "        ax.annotate(str(round((i.get_height() * 100.0 / total), 1) )+'%', \n",
    "                    (i.get_x()+.3*width, \n",
    "                     i.get_y()+soma + alt*height),\n",
    "                     color   = color,\n",
    "                     weight = 'bold',\n",
    "                     size   = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5fb87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.243127Z",
     "start_time": "2022-07-04T22:07:43.230128Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:04.873015Z",
     "iopub.status.busy": "2022-02-13T03:49:04.872156Z",
     "iopub.status.idle": "2022-02-13T03:49:04.874383Z",
     "shell.execute_reply": "2022-02-13T03:49:04.873755Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.055372Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826443068,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3bb5fb87",
    "papermill": {
     "duration": 0.134386,
     "end_time": "2022-02-13T03:49:04.874552",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.740166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scaler_MaxAbsScaler_StandardScaler(df):    \n",
    "    sc_mm = MaxAbsScaler()\n",
    "    sc_st = StandardScaler()     \n",
    "    col = df.columns\n",
    "    df  = sc_mm.fit_transform(df)\n",
    "    df  = pd.DataFrame(sc_st.fit_transform(df), columns=col)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a26463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.259162Z",
     "start_time": "2022-07-04T22:07:43.245125Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:05.121380Z",
     "iopub.status.busy": "2022-02-13T03:49:05.119648Z",
     "iopub.status.idle": "2022-02-13T03:49:05.122222Z",
     "shell.execute_reply": "2022-02-13T03:49:05.122682Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.065523Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826443371,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "a3a26463",
    "papermill": {
     "duration": 0.128676,
     "end_time": "2022-02-13T03:49:05.122818",
     "exception": false,
     "start_time": "2022-02-13T03:49:04.994142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diff(t_a, t_b):\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7adda72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.275155Z",
     "start_time": "2022-07-04T22:07:43.262129Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:05.277126Z",
     "iopub.status.busy": "2022-02-13T03:49:05.276184Z",
     "iopub.status.idle": "2022-02-13T03:49:05.278455Z",
     "shell.execute_reply": "2022-02-13T03:49:05.278879Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.073875Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826444169,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "d7adda72",
    "papermill": {
     "duration": 0.079941,
     "end_time": "2022-02-13T03:49:05.279027",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.199086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    \n",
    "    # https://www.kaggle.com/getting-started/140636\n",
    "    #print(\"Initial GPU Usage\")\n",
    "    #gpu_usage()                             \n",
    "\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b690171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.291127Z",
     "start_time": "2022-07-04T22:07:43.277125Z"
    },
    "code_folding": [
     1
    ],
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1655826444565,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "6b690171",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def graf_feature_corr(df_, annot_=False, threshold_=.8, print_var_=False, print_graf_=True, mask_=True, title_=''):\n",
    "    \n",
    "    df = df_.corr(method ='pearson').round(5)\n",
    "\n",
    "    if print_graf_: \n",
    "        # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "        mask = np.zeros_like(df)\n",
    "        mask[np.triu_indices_from(mask)] = mask_\n",
    "\n",
    "        # Making a plot\n",
    "        ax = sns.heatmap(df, annot=annot_, \n",
    "                         mask=mask, \n",
    "                         cmap=\"RdBu\", \n",
    "                         annot_kws={\"weight\": \"bold\", \"fontsize\":13}\n",
    "                        )\n",
    "\n",
    "        ax.set_title(\"\\n Correlação das variável {} \\n\".format(title_), fontsize=17)\n",
    "\n",
    "        plt.setp(ax.get_xticklabels(), \n",
    "                 rotation      = 90, \n",
    "                 ha            = \"right\",\n",
    "                 rotation_mode = \"anchor\", \n",
    "                 weight        = \"normal\")\n",
    "\n",
    "        plt.setp(ax.get_yticklabels(), \n",
    "                 weight        = \"normal\",\n",
    "                 rotation_mode = \"anchor\", \n",
    "                 rotation      = 0, \n",
    "                 ha            = \"right\")\n",
    "                \n",
    "        plt.show();\n",
    "\n",
    "    if print_var_:         \n",
    "        df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "        if len(df_corr)>0:            \n",
    "            print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "            df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "            display(df_corr)\n",
    "        else: \n",
    "            print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77218594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.307125Z",
     "start_time": "2022-07-04T22:07:43.293126Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1655826444869,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "77218594"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for {}'.format(label))\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176ca85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.323123Z",
     "start_time": "2022-07-04T22:07:43.310126Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826445183,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "8176ca85"
   },
   "outputs": [],
   "source": [
    "def evaluation(y_, predictions_):\n",
    "    mae  = metrics.mean_absolute_error(y_, predictions_)\n",
    "    mse  = metrics.mean_squared_error(y_, predictions_)\n",
    "    rmse = metrics.mean_squared_error(y_, predictions_, squared=False) \n",
    "    mape = metrics.mean_absolute_percentage_error(y_, predictions_)\n",
    "    r2   = metrics.r2_score(y_, predictions_)    \n",
    "    return rmse, mae, mse, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df6edb",
   "metadata": {
    "id": "a0df6edb",
    "papermill": {
     "duration": 0.071953,
     "end_time": "2022-02-13T03:49:05.424578",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.352625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.4. Criar estrutura de pasta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb822f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.338162Z",
     "start_time": "2022-07-04T22:07:43.325127Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:06.016730Z",
     "iopub.status.busy": "2022-02-13T03:49:06.015877Z",
     "iopub.status.idle": "2022-02-13T03:49:06.017698Z",
     "shell.execute_reply": "2022-02-13T03:49:06.018120Z",
     "shell.execute_reply.started": "2022-02-13T00:29:14.904585Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826446858,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "efb822f4",
    "papermill": {
     "duration": 0.07893,
     "end_time": "2022-02-13T03:49:06.018259",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.939329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path        = '/content/drive/MyDrive/Flai/09/' if COLAB else ''   \n",
    "path_data   = 'Data/'  \n",
    "target      = 'aluguéis'\n",
    "path_automl = 'automl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc821f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.433186Z",
     "start_time": "2022-07-04T22:07:43.340124Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:05.575275Z",
     "iopub.status.busy": "2022-02-13T03:49:05.574704Z",
     "iopub.status.idle": "2022-02-13T03:49:05.577106Z",
     "shell.execute_reply": "2022-02-13T03:49:05.577541Z",
     "shell.execute_reply.started": "2022-02-13T00:29:12.081730Z"
    },
    "executionInfo": {
     "elapsed": 3411,
     "status": "ok",
     "timestamp": 1655826450266,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "dbc821f4",
    "papermill": {
     "duration": 0.080815,
     "end_time": "2022-02-13T03:49:05.577674",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.496859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'Data/tunning', \n",
    "         'model', 'model/preds', 'model/optuna','model/preds/test', 'Data/shap',\n",
    "         'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n",
    "         'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n",
    "         'model/preds/train/n3', 'model/preds/param', 'model/mdl', 'model/preds/folds' ]\n",
    "\n",
    "for p in paths:\n",
    "    try:\n",
    "        os.mkdir(path + p)       \n",
    "    except:\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af184251",
   "metadata": {
    "id": "af184251",
    "papermill": {
     "duration": 0.072314,
     "end_time": "2022-02-13T03:49:05.722879",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.650565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.5. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e3e7f",
   "metadata": {
    "id": "400e3e7f",
    "papermill": {
     "duration": 0.072353,
     "end_time": "2022-02-13T03:49:05.867236",
     "exception": false,
     "start_time": "2022-02-13T03:49:05.794883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.5.2. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d2bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T22:07:43.545126Z",
     "start_time": "2022-07-04T22:07:43.437141Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:06.168402Z",
     "iopub.status.busy": "2022-02-13T03:49:06.167889Z",
     "iopub.status.idle": "2022-02-13T03:49:41.715117Z",
     "shell.execute_reply": "2022-02-13T03:49:41.715570Z",
     "shell.execute_reply.started": "2022-02-13T00:29:20.745029Z"
    },
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1655826451000,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3d9d2bd0",
    "outputId": "da741efc-9531-464e-fc6a-df84ccc6ef20",
    "papermill": {
     "duration": 35.625187,
     "end_time": "2022-02-13T03:49:41.715722",
     "exception": false,
     "start_time": "2022-02-13T03:49:06.090535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_train     = pd.read_csv(path + path_data + 'treino.csv')\n",
    "df1_test      = pd.read_csv(path + path_data + 'teste.csv')\n",
    "df_submission = pd.DataFrame({target: np.zeros(df1_test.shape[0])})\n",
    "df1_train.shape, df1_test.shape, df_submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfe6b0",
   "metadata": {
    "id": "71cfe6b0",
    "papermill": {
     "duration": 0.072473,
     "end_time": "2022-02-13T03:49:41.860923",
     "exception": false,
     "start_time": "2022-02-13T03:49:41.788450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.5.3. Visualizar os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99710704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:46.335768Z",
     "start_time": "2022-07-03T03:00:46.186920Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:42.009378Z",
     "iopub.status.busy": "2022-02-13T03:49:42.008594Z",
     "iopub.status.idle": "2022-02-13T03:49:42.190181Z",
     "shell.execute_reply": "2022-02-13T03:49:42.190682Z",
     "shell.execute_reply.started": "2022-02-13T00:32:36.910466Z"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1655826562577,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "99710704",
    "outputId": "96496413-ae56-412e-e33b-3d1343961dee",
    "papermill": {
     "duration": 0.257336,
     "end_time": "2022-02-13T03:49:42.190857",
     "exception": false,
     "start_time": "2022-02-13T03:49:41.933521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a9aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:47.032772Z",
     "start_time": "2022-07-03T03:00:47.017764Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:42.405284Z",
     "iopub.status.busy": "2022-02-13T03:49:42.395359Z",
     "iopub.status.idle": "2022-02-13T03:49:42.533525Z",
     "shell.execute_reply": "2022-02-13T03:49:42.533939Z",
     "shell.execute_reply.started": "2022-02-13T00:32:37.391051Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1655826563444,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "ec5a9aa6",
    "outputId": "179af779-91cd-491a-b647-9e66e150caa5",
    "papermill": {
     "duration": 0.257532,
     "end_time": "2022-02-13T03:49:42.534077",
     "exception": false,
     "start_time": "2022-02-13T03:49:42.276545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a18f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:48.571810Z",
     "start_time": "2022-07-03T03:00:48.211091Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1655826564890,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "90a18f25",
    "outputId": "0a102ced-c806-44cb-a7f0-d019717c5f91"
   },
   "outputs": [],
   "source": [
    "df1_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d549a77",
   "metadata": {
    "id": "6d549a77",
    "papermill": {
     "duration": 0.079208,
     "end_time": "2022-02-13T03:49:42.692351",
     "exception": false,
     "start_time": "2022-02-13T03:49:42.613143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 2. PROCESSAMENTO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643ba74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:50.400902Z",
     "start_time": "2022-07-03T03:00:50.393906Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:42.853256Z",
     "iopub.status.busy": "2022-02-13T03:49:42.852120Z",
     "iopub.status.idle": "2022-02-13T03:49:43.099052Z",
     "shell.execute_reply": "2022-02-13T03:49:43.099642Z",
     "shell.execute_reply.started": "2022-02-13T00:32:38.686356Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826565346,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "7643ba74",
    "outputId": "390fba40-8495-4a1a-fcef-53396905b09c",
    "papermill": {
     "duration": 0.329418,
     "end_time": "2022-02-13T03:49:43.099806",
     "exception": false,
     "start_time": "2022-02-13T03:49:42.770388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2_train = df1_train.copy()\n",
    "df2_test  = df1_test.copy()\n",
    "\n",
    "df2_train.shape, df2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209943d8",
   "metadata": {
    "id": "209943d8",
    "papermill": {
     "duration": 0.078107,
     "end_time": "2022-02-13T03:49:43.257059",
     "exception": false,
     "start_time": "2022-02-13T03:49:43.178952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1. Tratar variável visibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4bf80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:52.441798Z",
     "start_time": "2022-07-03T03:00:52.433796Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-13T03:49:43.624746Z",
     "iopub.status.busy": "2022-02-13T03:49:43.623986Z",
     "iopub.status.idle": "2022-02-13T03:49:43.626452Z",
     "shell.execute_reply": "2022-02-13T03:49:43.626905Z",
     "shell.execute_reply.started": "2022-02-13T00:32:42.532210Z"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1655826567248,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "e9a4bf80",
    "papermill": {
     "duration": 0.291756,
     "end_time": "2022-02-13T03:49:43.627056",
     "exception": false,
     "start_time": "2022-02-13T03:49:43.335300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_visibilidade(df_):    \n",
    "    list_visibilidade = []\n",
    "    for c in df_['visibilidade'].values: \n",
    "        list_visibilidade.append(np.float64( c.replace('%', '')))        \n",
    "    df_['visibilidade']= list_visibilidade    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a88d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:53.347499Z",
     "start_time": "2022-07-03T03:00:53.329496Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826568693,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "65a88d14"
   },
   "outputs": [],
   "source": [
    "df2_train = convert_visibilidade(df2_train.copy())\n",
    "df2_test  = convert_visibilidade(df2_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d911c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:54.547862Z",
     "start_time": "2022-07-03T03:00:54.516862Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1655826571892,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "cd8d911c",
    "outputId": "6eb973f5-a24e-45c4-da7a-671bb2a32e27"
   },
   "outputs": [],
   "source": [
    "df2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db58fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:55.612202Z",
     "start_time": "2022-07-03T03:00:55.585204Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826572635,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "36db58fc",
    "outputId": "a88813d4-d9e6-4ec4-e7f3-ebcf277f5b7b"
   },
   "outputs": [],
   "source": [
    "df2_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b425d",
   "metadata": {
    "id": "305b425d",
    "papermill": {
     "duration": 0.079393,
     "end_time": "2022-02-13T03:50:21.332626",
     "exception": false,
     "start_time": "2022-02-13T03:50:21.253233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 3. FEATURE ENGINEERING </h1>    \n",
    "</div>\n",
    "\n",
    "Nesta parte do processo vamos criar diversas variávies com a finalidade de ajudar o modelo a identificar novos padrões e consequentemente melhor o desempenho, como padrão vamos criar todas as variáveis com inicial **fe_**, a cada criação de novas variáveis vamos treinar um conjunto de  modelos e analisar a performance das novas variáveis na identifição de novos padrões.\n",
    "\n",
    "Vamos criar três datasets para treinar os classficadores, são eles os seguintes: \n",
    "1. **dataset misto** com variáveis categóricas que foram transformadas em dammi e ordinal; \n",
    "2. **dataset ordinal** com todas as variáveis categóricas como ordinal; \n",
    "3. **dataset dammy** com todas as variáveis categóricas transformadas em dammi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde3eeda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:00:57.875205Z",
     "start_time": "2022-07-03T03:00:57.858205Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826573331,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "dde3eeda"
   },
   "outputs": [],
   "source": [
    "df3_train = df2_train.copy()\n",
    "df3_test  = df2_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b2f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:01:33.698365Z",
     "start_time": "2022-07-03T03:01:33.677345Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826573576,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "941b2f6c",
    "outputId": "833ac17b-3f7c-4dc8-80b0-bae0bb0e1ac0"
   },
   "outputs": [],
   "source": [
    "feature_all   = df3_test.columns.to_list()\n",
    "feature_float = df3_test.select_dtypes(np.number).columns.to_list()\n",
    "feature_cat   = df3_test.select_dtypes(object).columns.to_list()\n",
    "\n",
    "print('Variáveis Númericas')\n",
    "print(feature_float,)\n",
    "print()\n",
    "print('Variáveis Categóricas')\n",
    "print(feature_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a20339",
   "metadata": {
    "id": "b0a20339"
   },
   "source": [
    "## 3.1. Variáveis Qualitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b8aac",
   "metadata": {
    "id": "714b8aac"
   },
   "source": [
    "Vamos criar uma função para tratamento e geração das novas variáveis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0eb5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:01:51.940821Z",
     "start_time": "2022-07-03T03:01:51.924813Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826575249,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "b6e0eb5b",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_binarizer(df_tr_, df_vl_, df_ts_, features_ohe_=None, feature_ord_=None):\n",
    "\n",
    "    if features_ohe_ is not None:\n",
    "        for col in features_ohe_:         \n",
    "            lb   = OneHotEncoder(sparse=False) # LabelBinarizer() OneHotEncoder\n",
    "            cols = df_tr_[col].unique().tolist() \n",
    "\n",
    "            cols_fe = []\n",
    "            for x in df_tr_[col].unique().tolist(): \n",
    "                cols_fe.append('fe_'+ col + '_' +str(x) )\n",
    "\n",
    "            df_lb_tr = pd.DataFrame(lb.fit_transform (df_tr_[[col]]), columns=cols_fe)\n",
    "            df_lb_vl = pd.DataFrame(lb.transform (df_vl_[[col]]), columns=cols_fe)\n",
    "            df_lb_ts = pd.DataFrame(lb.transform (df_ts_[[col]]), columns=cols_fe)\n",
    "            \n",
    "            df_lb_tr[cols_fe]= df_lb_tr[cols_fe].astype(int)\n",
    "            df_lb_vl[cols_fe]= df_lb_vl[cols_fe].astype(int)\n",
    "            df_lb_ts[cols_fe]= df_lb_ts[cols_fe].astype(int)\n",
    "\n",
    "            df_lb_tr.index =  df_tr_.index\n",
    "            df_lb_vl.index =  df_vl_.index\n",
    "            df_lb_ts.index =  df_ts_.index\n",
    "\n",
    "            df_tr_ = pd.concat([df_tr_, df_lb_tr], axis=1)\n",
    "            df_vl_ = pd.concat([df_vl_, df_lb_vl], axis=1)\n",
    "            df_ts_ = pd.concat([df_ts_, df_lb_ts], axis=1)\n",
    "\n",
    "            df_tr_.drop(col, axis=1, inplace=True)\n",
    "            df_vl_.drop(col, axis=1, inplace=True)\n",
    "            df_ts_.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    col     = ''\n",
    "    cols_fe = ''\n",
    "\n",
    "    if feature_ord_ is not None:\n",
    "        for col in feature_ord_:\n",
    "            ordEncoder = OrdinalEncoder()            \n",
    "            cols = df_tr_[col].unique().tolist() \n",
    "\n",
    "            cols_fe = []\n",
    "            for x in df_tr_[col].unique().tolist(): \n",
    "                cols_fe.append('fe_'+ col + '_' +str(x) )\n",
    "                \n",
    "            df_tr_[col] = ordEncoder.fit_transform(df_tr_[[col]])\n",
    "            df_vl_[col] = ordEncoder.transform (df_vl_[[col]])\n",
    "            df_ts_[col] = ordEncoder.transform (df_ts_[[col]])\n",
    "\n",
    "    return df_tr_, df_vl_, df_ts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc3c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:01:52.982167Z",
     "start_time": "2022-07-03T03:01:52.811484Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655826576189,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "bbcc3c7f"
   },
   "outputs": [],
   "source": [
    "cols_oho_01 = ['estação','feriado'] \n",
    "cols_ord_01 = ['dia']\n",
    "cols_oho_02 = [] \n",
    "cols_ord_02 = ['dia', 'estação','feriado']\n",
    "cols_oho_03 = ['dia', 'estação','feriado'] \n",
    "cols_ord_03 = []\n",
    "\n",
    "\n",
    "df3_tr_01_mista, _, df3_ts_01_mista = \\\n",
    "    feature_binarizer(df3_train.copy(), df3_train.copy(), df3_test.copy(), cols_oho_01, cols_ord_01)\n",
    "\n",
    "df3_tr_02_ord_Encoder, _, df3_ts_02_ord_Encoder = \\\n",
    "    feature_binarizer(df3_train.copy(), df3_train.copy(), df3_test.copy(),cols_oho_02, cols_ord_02)\n",
    "\n",
    "df3_tr_03_one_hot, _, df3_ts_03_one_hot = \\\n",
    "    feature_binarizer(df3_train.copy(), df3_train.copy(), df3_test.copy(),cols_oho_03, cols_ord_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966b6d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:01:57.736417Z",
     "start_time": "2022-07-03T03:01:53.794848Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3908,
     "status": "ok",
     "timestamp": 1655826580711,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "b966b6d2",
    "outputId": "fe48ed17-2d17-4e46-ba9b-d280cb4feba3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df    = [df3_tr_01_mista, df3_tr_02_ord_Encoder, df3_tr_03_one_hot]\n",
    "title = ['- df misto', '- df ordinal', ' - df one hot']\n",
    "\n",
    "for i, df_ in enumerate(df): \n",
    "    plt.figure(figsize=(15,10))\n",
    "    Ultil.graf_feature_corr(df_         = df_.copy(), \n",
    "                            annot_      = True, \n",
    "                            threshold_  = .7, \n",
    "                            print_var_  = True, \n",
    "                            print_graf_ = True, \n",
    "                            mask_       = False,\n",
    "                            title_      = title[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9457152",
   "metadata": {
    "id": "a9457152"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "    \n",
    "Nos datasets criados temos variáveis com correlação acima de 70%, negativa ou positiva, neste primeiro momento vamos deixa essa variáveis, no processo de seleção das variáveis (**feature selection**) podemos fazer a remoção de algumas variáveis, caso alguma das variáveis não seja necessária na modelagem.         \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274002e",
   "metadata": {
    "id": "5274002e"
   },
   "source": [
    "### 3.1.1. Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69af6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:02:22.374134Z",
     "start_time": "2022-07-03T03:02:22.355165Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1655826580712,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3b69af6f"
   },
   "outputs": [],
   "source": [
    " def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a1919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:02:23.171345Z",
     "start_time": "2022-07-03T03:02:23.154296Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1655826583291,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "4d3a1919",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_, y_pred_test_, score_, \n",
    "                    seed_, level_='1', target_='target', cutoff_value_=.6, gera_submission_=True):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_)  + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        \n",
    "        delete_files(model_name_)\n",
    "        \n",
    "        jb.dump(y_pred_train_prob_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        jb.dump(model_, path_name_model)\n",
    "                \n",
    "        if gera_submission_:\n",
    "            df_submission[target] = y_pred_test_\n",
    "            df_submission.to_csv(path + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfbb85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:02:23.799897Z",
     "start_time": "2022-07-03T03:02:23.782882Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655826583523,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "13dfbb85",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_winsorize_target(y_tr_, perc_lower_limit_=.05, perc_upper_limit_=.99):\n",
    "      \n",
    "    if perc_lower_limit_ is not None:\n",
    "        lower_limit_ = y_tr_.quantile(perc_lower_limit_)\n",
    "        y_tr_[y_tr_<lower_limit_]  = lower_limit_                \n",
    "\n",
    "    if perc_upper_limit_ is not None:\n",
    "        upper_limit_ = y_tr_.quantile(perc_upper_limit_)\n",
    "        y_tr_[y_tr_>upper_limit_]  = upper_limit_\n",
    "\n",
    "    return y_tr_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b858e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:02:24.366647Z",
     "start_time": "2022-07-03T03:02:24.341612Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1655854241265,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "e96b858e",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def model_fit(models_, datasets_, target_, path_, feature_drop_cor_=[], scalers_=[None], \n",
    "              seed_=12359, transf_target_=None, winsorize_=False, perc_lower_limit_=None,\n",
    "              perc_upper_limit_=None, feature_scaler_=None, test_size_=0.2):\n",
    "    \n",
    "    df_pred_final = pd.DataFrame()\n",
    "    \n",
    "    scaler_best    = None\n",
    "    model_best     = None\n",
    "    count_datase_1 = 0\n",
    "    count_datase_2 = 0\n",
    "    count_datase_3 = 0\n",
    "    score_best     = np.mean(datasets_[0][0][target_])\n",
    "\n",
    "    \n",
    "    for ii , mdl in enumerate(models_):\n",
    "        \n",
    "        model      = mdl[0]\n",
    "        model_name = mdl[1]\n",
    "        type_model = mdl[2]\n",
    "               \n",
    "        for i, df in enumerate(datasets_): \n",
    "            \n",
    "            clf_name    = model.__class__.__name__\n",
    "            df_tr       = datasets_[i][0]\n",
    "            df_ts       = datasets_[i][1]\n",
    "            df_name     = datasets_[i][2]   \n",
    "            num_dataset = datasets_[i][3]   \n",
    "\n",
    "            model_name_ = model_name + '_' + str(i)\n",
    "            \n",
    "            delete_files(model_name_)\n",
    "\n",
    "            X      = df_tr.drop(target_, axis=1).copy()\n",
    "            X      = X.drop(feature_drop_cor_, axis=1).copy()\n",
    "            y      = df_tr[target_]\n",
    "            X_test = df_ts.drop(feature_drop_cor_, axis=1).copy()\n",
    "\n",
    "            X_train, X_valid, y_train, y_valid = \\\n",
    "                train_test_split(X, y, \n",
    "                                 test_size    = test_size_,\n",
    "                                 shuffle      = True, \n",
    "                                 #stratify     = y, \n",
    "                                 random_state = seed_)   \n",
    "            \n",
    "            model_baseline = model\n",
    "            cols           = X_valid.columns.to_list()  \n",
    "            n_estimators   = 0 if type_model>1 else int(model.get_params()['n_estimators']*.1)\n",
    "\n",
    "            print('Model: {} -> {}'.format(model.__class__.__name__, df_name))\n",
    "\n",
    "            \n",
    "            if winsorize_:                   \n",
    "                y_train = feature_winsorize_target(y_tr_            = y_train, \n",
    "                                                   perc_lower_limit_= perc_lower_limit_, \n",
    "                                                   perc_upper_limit_= perc_upper_limit_)\n",
    "                \n",
    "            for i , scaler in enumerate(scalers_):\n",
    "                \n",
    "                X_train_s = X_train.copy() \n",
    "                X_valid_s = X_valid.copy()\n",
    "                X_test_s  = X_test.copy()      \n",
    "                \n",
    "                if scaler!=None:      \n",
    "                    scaler.fit(X_train_s[cols])\n",
    "                    X_train_s[cols] = scaler.transform(X_train_s[cols])\n",
    "                    X_valid_s[cols] = scaler.transform(X_valid_s[cols])\n",
    "                    X_test_s[cols]  = scaler.transform(X_test[cols])\n",
    "                                \n",
    "                y_train_nor = y_train\n",
    "                y_valid_nor = y_valid        \n",
    "                \n",
    "                if transf_target_ is not None:                     \n",
    "                    transf_target_.fit(y_train_nor.values.reshape(-1,1))\n",
    "                    y_train_nor = transf_target_.transform(y_train_nor.values.reshape(-1,1))\n",
    "                    y_valid_nor = transf_target_.transform(y_valid_nor.values.reshape(-1,1)) \n",
    "                    \n",
    "                if type_model==1:\n",
    "                    eval_set = [(X_train_s, y_train_nor), (X_valid_s, y_valid_nor)]\n",
    "                    model.fit(X_train_s, \n",
    "                              y_train_nor, \n",
    "                              #eval_metric           = 'rmse', \n",
    "                              eval_set              = eval_set,                                               \n",
    "                              verbose               = False,                                                       \n",
    "                              early_stopping_rounds = n_estimators)\n",
    "                \n",
    "                if type_model==2: \n",
    "                    model.fit(X_train_s, y_train_nor) \n",
    "                    \n",
    "                if type_model==3:                     \n",
    "                    model.fit(X_train_s, \n",
    "                              y_train_nor, \n",
    "                              #eval_metric = 'RMSE', \n",
    "                              eval_set       = [(X_train_s, y_train_nor), (X_valid_s, y_valid_nor)],                                               \n",
    "                              verbose        = False,                           \n",
    "                              use_best_model = True, \n",
    "                              )\n",
    "                     \n",
    "                # \n",
    "\n",
    "                y_pred_tr = abs(model.predict(X_train_s))\n",
    "                y_pred_vl = abs(model.predict(X_valid_s)) #, ntree_limit=model.best_ntree_limit) # model_best.best_ntree_limit\n",
    "                y_pred_ts = abs(model.predict(X_test_s)) # , ntree_limit=model.best_ntree_limit)\n",
    "                \n",
    "                #y_pred_vl = np.clip(y_pred_vl, y_train.min(), y_train.max())\n",
    "\n",
    "                if transf_target_ is not None:                       \n",
    "                    y_pred_vl = transf_target_.inverse_transform(pd.DataFrame(y_pred_vl))\n",
    "                    y_pred_ts = transf_target_.inverse_transform(pd.DataFrame(y_pred_ts))\n",
    "                \n",
    "                y_pred_tr = np.int64(y_pred_tr)\n",
    "                y_pred_vl = np.int64(y_pred_vl) \n",
    "                y_pred_ts = np.int64(y_pred_ts)\n",
    "                \n",
    "                rmse, mae, mse, mape, r_squared = Ultil.evaluation(y_valid, y_pred_vl)   \n",
    "                rmse_tr, _, _, _, _ = Ultil.evaluation(y_train, y_pred_tr)   \n",
    "\n",
    "                msg = 'RMSE: {:2.2f} - MAE: {:2.2f} - MSE: {:2.2f} '\n",
    "                msg = msg + '- MAPE: {:2.2f} - R2: {:2.2f} - TR RMSE: {:2.2f} => {}'     \n",
    "\n",
    "                print(msg.format(rmse, mae, mse, mape, r_squared, rmse_tr, scaler))\n",
    "\n",
    "                if score_best>rmse:        \n",
    "                    score_best    = rmse\n",
    "                    mdl_name_best = clf_name\n",
    "                    dataset_best  = df_name\n",
    "                    scaler_best   = scaler                    \n",
    "                    y_valid_best  = y_pred_vl\n",
    "                    model_best    = model_baseline\n",
    "\n",
    "                    if num_dataset==1: \n",
    "                        count_datase_1 +=1\n",
    "                    \n",
    "                    if num_dataset==2: \n",
    "                        count_datase_2 +=1\n",
    "\n",
    "                    if num_dataset==3: \n",
    "                        count_datase_3 +=1\n",
    "                     \n",
    "                name_file_sub         = model_name_ + '_{:2.2f}_{}_{}.csv'.format(rmse, df_name,str(scaler).lower()[:4])\n",
    "                df_submission[target] = y_pred_ts         \n",
    "                df_submission.to_csv(path_ + 'Data/submission/' + name_file_sub, index=False)\n",
    "\n",
    "                scaler_name = scaler.__class__.__name__\n",
    "\n",
    "                df_pred = pd.DataFrame({'model'   : clf_name,\n",
    "                                        'df_name' : df_name,\n",
    "                                        'scaler'  : scaler_name, \n",
    "                                        'y'       : y_valid, \n",
    "                                        'y_pred'  : np.squeeze(y_valid_best)})    \n",
    "\n",
    "                df_pred['residuals'] = df_pred['y'] - df_pred['y_pred']\n",
    "                df_pred['score']     =  np.round(rmse, 2)\n",
    "                df_pred_final        = pd.concat([df_pred_final,df_pred], axis=0)\n",
    "\n",
    "                Ultil.free_gpu_cache()\n",
    "\n",
    "            print()\n",
    "\n",
    "    print()\n",
    "    print('The Best')  \n",
    "    print('Model  : {}'.format(mdl_name_best))  \n",
    "    print('Dataset: {}'.format(dataset_best))  \n",
    "    print('Scaler : {}'.format(scaler_best))    \n",
    "    print('Score  : {:2.2f}'.format(score_best))\n",
    "    print()\n",
    "    print('RESUMO DATASET')\n",
    "    print('df 1   : {}'.format(count_datase_1))\n",
    "    print('df 2   : {}'.format(count_datase_2))\n",
    "    print('df 3   : {}'.format(count_datase_3))\n",
    "    print()\n",
    "\n",
    "    return df_pred_final, model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02851",
   "metadata": {
    "id": "49c02851"
   },
   "source": [
    "#### 3.1.1.1. Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0949c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:03:33.798562Z",
     "start_time": "2022-07-03T03:03:33.627797Z"
    },
    "code_folding": [
     1,
     11,
     14,
     23,
     31,
     36,
     49,
     60
    ],
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1655856222480,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "c0949c21",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "seed       = 12359\n",
    "params_xgb = {'objective'        : 'reg:squarederror',                \n",
    "              'eval_metric'      : 'rmse', \n",
    "              'n_estimators'     : 2000,         \n",
    "              'max_depth'        : 7, \n",
    "              'learning_rate'    : .01, \n",
    "              'subsample'        : 0.7, \n",
    "              'colsample_bytree' : 0.8, \n",
    "              'reg_alpha'        : 0.9,               \n",
    "              'random_state'     : seed}\n",
    "\n",
    "if torch.cuda.is_available():           \n",
    "    params_xgb.update({'tree_method': 'gpu_hist','predictor': 'gpu_predictor'})\n",
    "\n",
    "params_lgbm = {'n_estimators'     : 2000, \n",
    "               'colsample_bytree' : 0.7,\n",
    "               'learning_rate'    : 0.01, \n",
    "               'max_depth'        : 7,                                              \n",
    "               'subsample'        : 0.7,\n",
    "               'reg_alpha'        : 0.9,\n",
    "               'random_state'     : seed               \n",
    "              }\n",
    "\n",
    "params_rf = {'n_estimators'      : 2000,\n",
    "             #'max_features'      : 10, \n",
    "             #'min_samples_split' : 4,\n",
    "             #'min_samples_leaf'  : 4, \n",
    "             #'bootstrap'         : True, \n",
    "             'random_state'      : seed               \n",
    "              }\n",
    "\n",
    "params_ext = {'n_estimators' : 2000,\n",
    "              'max_depth'    : 7,                \n",
    "              'n_jobs'       : -1, \n",
    "              'random_state' : seed}\n",
    "\n",
    "param_catb = {'iterations'    : 2000,\n",
    "              'learning_rate' : 0.05,\n",
    "              'depth'         : 7,\n",
    "              'eval_metric'   : 'RMSE',\n",
    "              'random_seed'   : seed,               \n",
    "               #task_type=\"GPU\",\n",
    "               #devices='0:1'\n",
    "               #bagging_temperature = 0.2,\n",
    "               #od_type='Iter',\n",
    "               # metric_period = 50,\n",
    "               #od_wait=20\n",
    "               }\n",
    "\n",
    "params_gbr = {'criterion'         : 'squared_error',\n",
    "              'n_estimators'      : 2000, \n",
    "              'learning_rate'     : 0.05,\n",
    "              'max_depth'         : 7, \n",
    "              'max_features'      : 'sqrt',\n",
    "              'min_samples_leaf'  : 15, \n",
    "              'min_samples_split' : 10, \n",
    "              'loss'              : 'huber', \n",
    "              'random_state'      : seed\n",
    "              } \n",
    "\n",
    "params_ada = {\n",
    "              'n_estimators'      : 2000, \n",
    "              'learning_rate'     : 0.05,\n",
    "              'loss'              : 'huber', \n",
    "              'random_state'      : seed\n",
    "              } \n",
    "\n",
    "params_knn = {'n_neighbors': 4}\n",
    "param_rid  = {'alpha' : 0.001, 'kernel': 'polynomial'}\n",
    "\n",
    "# https://www.analyticsvidhya.com/blog/2021/04/how-to-use-catboost-for-mental-fatigue-score-prediction/\n",
    "# https://pub.towardsai.net/knn-algorithm-for-classification-and-regression-hands-on-with-scikit-learn-4c5ec558cdba\n",
    "\n",
    "model_xgb   = xgb.XGBRegressor(**params_xgb)\n",
    "model_lgb   = LGBMRegressor(**params_lgbm)\n",
    "model_rf    = RandomForestRegressor(**params_rf)\n",
    "model_knn   = KNeighborsRegressor(**params_knn)  \n",
    "model_ext   = ExtraTreesRegressor(**params_ext)\n",
    "model_lasso = KernelRidge(**param_rid )\n",
    "model_catb  = CatBoostRegressor(**param_catb)\n",
    "model_gbr   = GradientBoostingRegressor(**params_gbr)\n",
    "model_ada   = AdaBoostRegressor(**params_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08894836",
   "metadata": {
    "id": "08894836"
   },
   "source": [
    "#### 3.1.1.2. Treinamento do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6699d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:06:36.269657Z",
     "start_time": "2022-07-03T03:03:35.514021Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80460,
     "status": "ok",
     "timestamp": 1655856813036,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "f6699d91",
    "outputId": "2c278afc-c1c5-4f52-f781-eea8daeed48c"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "scalers = [None]\n",
    "df11    = (df3_tr_01_mista, df3_ts_01_mista, 'df_mista', 1, 'dataset base')\n",
    "df12    = (df3_tr_02_ord_Encoder, df3_ts_02_ord_Encoder, 'df_ord_Encoder', 2)\n",
    "df13    = (df3_tr_03_one_hot, df3_ts_03_one_hot, 'df_one_hot', 3) \n",
    "dfs_01  = [df11, df12, df13]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)]\n",
    "\n",
    "df_preds, model_best = model_fit(models_          = models,                     \n",
    "                                 datasets_        = dfs_01,                      \n",
    "                                 target_          = target, \n",
    "                                 path_            = path, \n",
    "                                 feature_drop_cor_= [], \n",
    "                                 scalers_         = scalers,    \n",
    "                                 seed_            = seed)\n",
    "\n",
    "# RMSE: 242.81 - MAE: 140.37 - MSE: 58958.17 - MAPE: 1.56 - R2: 0.85 - RMSE Trn: 0.98149293 => None\n",
    "# 235.19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A7ysL_1UKZe3",
   "metadata": {
    "id": "A7ysL_1UKZe3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "    \n",
    "Como podemos observar, o melhor dataset neste primeiro momento é **df3_train_fe_03_one_hot_encoder**, que teve todas as variáveis codificadas como **one hot encoder** com o classificador **CatBoostRegressor**. O XGBoost teve um bom desempenho neste dataset, batendo o resultado anterior.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7a83b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T22:02:14.464613Z",
     "start_time": "2022-06-16T22:02:13.565141Z"
    },
    "id": "63d7a83b"
   },
   "source": [
    "#### 3.1.1.3. Real x Predito\n",
    "vamos dar uma olhada nas previsões do **CatBoostRegressor** que teve o melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52245f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:09:02.187163Z",
     "start_time": "2022-07-03T03:09:02.180159Z"
    },
    "id": "e52245f2"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab59fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:09:35.533041Z",
     "start_time": "2022-07-03T03:09:34.984060Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "executionInfo": {
     "elapsed": 1398,
     "status": "ok",
     "timestamp": 1655857634510,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "eab59fea",
    "outputId": "04b53bda-67a8-4a4f-c673-3897c90fb1ad"
   },
   "outputs": [],
   "source": [
    "sample     = 200\n",
    "model_name = 'CatBoostRegressor'\n",
    "df         = df_preds[df_preds['model']==model_name].sample(sample)\n",
    "x_ax       = range(len(df[:sample]))\n",
    "y_nor      = df.y\n",
    "y_pred     = df.y_pred\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_ax, y_nor,  label=\"original\")\n",
    "plt.plot(x_ax, y_pred, label=\"predicted\")\n",
    "plt.title(\"Previsão em dados de validação - {}\".format(model_name))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(x_ax, y_nor, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, y_pred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "\n",
    "\n",
    "sns.scatterplot(x=df['y'], y=df['y_pred'],  ) # hue=df['y_pred']\n",
    "sns.scatterplot(x=df['y'], y=df['y'])\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del df, x_ax, y_nor, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453fce4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T22:36:43.973099Z",
     "start_time": "2022-06-16T22:36:43.650279Z"
    },
    "id": "f453fce4"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Observando os gráficos acima, identificamos que o modelo tem dificuldade em prever os valores acima de 1200 e nas previsões temos valores negativos, sendo que nos dados de treino e validação não temos valores negativos.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100af66",
   "metadata": {
    "id": "c100af66"
   },
   "source": [
    "## 3.2. Variáveis Quantitativas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f4f53",
   "metadata": {
    "id": "2b5f4f53"
   },
   "source": [
    "### 3.2.1. Outliers\n",
    "Outliers são observações que estão distantes de outras observações. Eles podem ser devido a erros ou ser observações genuínas. Seja qual for o motivo, é importante identificá-los porque os modelos de aprendizado de máquina são sensíveis ao intervalo e à distribuição de valores, sendo assim, vamos aplicar algumas técnicas de identificação de outliers e fazer alguns tratamentos como: \n",
    "1. __Univariado__\n",
    "    - Intervalo interquartil\n",
    "    - Z-score\n",
    "\n",
    "2. __Multivariado__    \n",
    "    - Envelope Elíptico \n",
    "    - Isolation Forest \n",
    "    - Winsorizer <p>\n",
    "\n",
    "    \n",
    "**REFERÊNCIAS**: \n",
    "- https://leportella.com/pt-br/outliers-i/\n",
    "- https://leportella.com/pt-br/outliers-ii/\n",
    "- https://github.com/leportella/outlier-analysis\n",
    "- https://github.com/brunobro/deteccao-remocao-de-outliers\n",
    "- https://towardsdatascience.com/creating-custom-transformers-using-scikit-learn-5f9db7d7fdb5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc5273",
   "metadata": {
    "id": "3afc5273"
   },
   "source": [
    "#### 3.2.1.1. Idendificação dos Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a2d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:09:52.276278Z",
     "start_time": "2022-07-03T03:09:51.652751Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1655857675550,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "c11a2d96",
    "outputId": "1923c96b-68fe-4f69-95d0-f8e4258c0bfd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "feature_outliers = feature_float.copy()\n",
    "feature_outliers.append(target)\n",
    "\n",
    "df_outliers = df3_tr_03_one_hot[feature_outliers]\n",
    "\n",
    "row = int(len(feature_outliers)/3 +1) \n",
    "\n",
    "for i, col in enumerate(feature_outliers): \n",
    "    plt.subplot(row,3,i+1)\n",
    "    sns.boxplot(data=df_outliers,  y=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VaLTfTjni0RT",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:10:54.021261Z",
     "start_time": "2022-07-03T03:10:53.540236Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1655857676094,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "VaLTfTjni0RT",
    "outputId": "3919d2e3-5917-4be0-8eb2-56b44c461e9d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "Ultil.graf_feature_corr(df_           = df_outliers, \n",
    "                        annot_      = True, \n",
    "                        threshold_  = .7, \n",
    "                        print_var_  = False, \n",
    "                        print_graf_ = True, \n",
    "                        mask_       = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceRt0iNLLq5x",
   "metadata": {
    "id": "ceRt0iNLLq5x"
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "    \n",
    "Temos quatro variáveis com outliers: **chuva, sol, vento e aluguéis**, neste primeiro momento vamos trabalhar apenas com as três primeiras variáveis, observamos que a correlação dessas variáveis são baixa com a variável alvo.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oMLXgf2uNODn",
   "metadata": {
    "id": "oMLXgf2uNODn"
   },
   "source": [
    "#### 3.2.1.1. Intervalo interquartil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd8124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:10:56.942844Z",
     "start_time": "2022-07-03T03:10:56.923817Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1655857677062,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "42cd8124"
   },
   "outputs": [],
   "source": [
    "def outlier_create_feature_check(df_train_, df_test_, cols_outlirs_=[], qt_inferior_=.25, \n",
    "                                 qt_superior_=.75, zero_outliers_=True, flg_ts_=True):\n",
    "    \n",
    "    col_oltlier = 'fe_outlier'\n",
    "\n",
    "    if zero_outliers_:\n",
    "        df_train_[col_oltlier] = 0 \n",
    "        df_test_[col_oltlier]  = 0 \n",
    "\n",
    "    for c in cols_outlirs_:\n",
    "        \n",
    "        percentil25 = df_train_[c].quantile(qt_inferior_)\n",
    "        percentil75 = df_train_[c].quantile(qt_superior_)\n",
    "\n",
    "        iqr= percentil75 - percentil25 \n",
    "\n",
    "        limite_inferior = percentil25 - 1.5 * iqr\n",
    "        limite_superior = percentil75 + 1.5 * iqr\n",
    "\n",
    "        df_train_[col_oltlier][df_train_[c]>limite_superior] = -1\n",
    "        df_train_[col_oltlier][df_train_[c]<limite_inferior] = -1\n",
    "\n",
    "        if flg_ts_:\n",
    "            df_test_[col_oltlier][df_test_[c]>limite_superior] = -1\n",
    "            df_test_[col_oltlier][df_test_[c]<limite_inferior] = -1\n",
    "\n",
    "        print('Com a variável {}'.format(c))\n",
    "        print(df_train_[col_oltlier].value_counts())\n",
    "        print()\n",
    "        \n",
    "    return df_train_, df_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f292aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:10:57.945294Z",
     "start_time": "2022-07-03T03:10:57.877260Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655857677357,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "7f292aca",
    "outputId": "803f266d-829a-43dc-fd1f-3da13d1f44d5"
   },
   "outputs": [],
   "source": [
    "df3_tr_01_mista_02       = df3_tr_01_mista.copy()\n",
    "df3_ts_01_mista_02       = df3_ts_01_mista.copy()\n",
    "df3_tr_02_ord_Encoder_02 = df3_tr_02_ord_Encoder.copy() \n",
    "df3_ts_02_ord_Encoder_02 = df3_ts_02_ord_Encoder.copy()\n",
    "df3_tr_03_one_hot_02     = df3_tr_03_one_hot.copy()\n",
    "df3_ts_03_one_hot_02     = df3_ts_03_one_hot.copy()\n",
    "\n",
    "df21   = (df3_tr_01_mista_02, df3_ts_01_mista_02, 'df_mista', 1, 'dataset base')\n",
    "df22   = (df3_tr_02_ord_Encoder_02, df3_ts_02_ord_Encoder_02, 'df_ord_Encoder', 2)\n",
    "df23   = (df3_tr_03_one_hot_02, df3_ts_03_one_hot_02, 'df3_one_hot', 3) \n",
    "dfs_02 = [df21, df22, df23]\n",
    "\n",
    "for i, df_ in enumerate(dfs_02):   \n",
    "    df_tr = df_[0]\n",
    "    df_ts = df_[1] \n",
    "    df_tr, df_ts = \\\n",
    "        outlier_create_feature_check(df_train_      = df_tr, \n",
    "                                     df_test_       = df_ts, \n",
    "                                     cols_outlirs_  = ['vento'], # 'sol', 'chuva',  vento\n",
    "                                     qt_inferior_   = .25, \n",
    "                                     qt_superior_   = .75, \n",
    "                                     zero_outliers_ = True, \n",
    "                                     flg_ts_ = False\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vyeflFQMzu-a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:14:06.930561Z",
     "start_time": "2022-07-03T03:11:06.018188Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234317,
     "status": "ok",
     "timestamp": 1655857912645,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "vyeflFQMzu-a",
    "outputId": "9a067a8f-fd1e-4ae1-9111-a631eeb76205"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds, model_best = model_fit(models_          = models,                     \n",
    "                                 datasets_        = dfs_02,                      \n",
    "                                 target_          = target, \n",
    "                                 path_            = path, \n",
    "                                 feature_drop_cor_= [], \n",
    "                                 scalers_         = scalers,                      \n",
    "                                 seed_            = seed)\n",
    "\n",
    "# The Best\n",
    "# Model  : CatBoostRegressor\n",
    "# Dataset: df3_train_fe_03_one_hot_encoder\n",
    "# Scaler : StandardScaler()\n",
    "# Score  : 236.29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0849bece",
   "metadata": {
    "id": "0849bece"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Com a criação da variável que identifica os outliers com a técnica de **intervalo interquartil**, tivemos uma pequena melhoria no score da maioria dos modelos, entre as três variáveis: vento, sol, chuva, a variável que teve melhor desempenho foi a variável **vento**. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bq4LkxrAZG_H",
   "metadata": {
    "id": "Bq4LkxrAZG_H"
   },
   "source": [
    "#### 3.2.1.2. Z-score\n",
    "Z-score  é uma medida relacionada a distância que um ponto está da média, em função do desvio padrão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961938d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:16:44.819748Z",
     "start_time": "2022-07-03T03:16:44.810742Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1655857912645,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3961938d"
   },
   "outputs": [],
   "source": [
    "def feature_zscore(df_tr_, df_ts_, feature_):         \n",
    "    md = np.mean(df_tr_[feature_])\n",
    "    dp = np.std(df_tr_[feature_])    \n",
    "    df_tr_['fe_outlier_zscore'] = (df_tr_[feature_]-md)/dp\n",
    "    df_ts_['fe_outlier_zscore'] = (df_ts_[feature_]-md)/dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c68561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:20:35.535859Z",
     "start_time": "2022-07-03T03:16:45.659548Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241007,
     "status": "ok",
     "timestamp": 1655858153646,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "b5c68561",
    "outputId": "59c7b4c2-5508-415f-dd75-021890cadefc"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df3_tr_01_mista_03       = df3_tr_01_mista.copy()\n",
    "df3_ts_01_mista_03       = df3_ts_01_mista.copy()\n",
    "df3_tr_02_ord_Encoder_03 = df3_tr_02_ord_Encoder.copy() \n",
    "df3_ts_02_ord_Encoder_03 = df3_ts_02_ord_Encoder.copy()\n",
    "df3_tr_03_one_hot_03     = df3_tr_03_one_hot.copy()\n",
    "df3_ts_03_one_hot_03     = df3_ts_03_one_hot.copy()\n",
    "\n",
    "df31   = (df3_tr_01_mista_03, df3_ts_01_mista_03, 'df3_tr_01_mista', 1, 'Z-score')\n",
    "df32   = (df3_tr_02_ord_Encoder_03, df3_ts_02_ord_Encoder_03, 'df3_tr_02_ord_Encoder', 2)\n",
    "df33   = (df3_tr_03_one_hot_03, df3_ts_03_one_hot_03, 'df3_tr_03_one_hot', 3)\n",
    "dfs_03 = [df31, df32, df33]\n",
    "\n",
    "for df_ in dfs_03: \n",
    "    feature_zscore(df_[0], df_[1], 'sol') # 'sol', 'chuva',  vento\n",
    "    \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds, model = model_fit(models_          = models,                     \n",
    "                            datasets_        = dfs_03,                      \n",
    "                            target_          = target, \n",
    "                            path_            = path, \n",
    "                            feature_drop_cor_= [], \n",
    "                            scalers_         = scalers,                      \n",
    "                            seed_            = seed)\n",
    "\n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 235.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd89825d",
   "metadata": {
    "id": "dd89825d"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Não tivemos uma melhoria. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TnJ5IMv-ZXWe",
   "metadata": {
    "id": "TnJ5IMv-ZXWe"
   },
   "source": [
    "#### 3.2.1.3. Envelope Elíptico\n",
    "É uma técnica relacionada ao Determinante de Covariância Mínima, que é um estimador altamente robusto para estimação de dispersão multivariada.\n",
    "\n",
    "* Supõe uma distribuição Gaussiana\n",
    "\n",
    "Em síntese, emprega a ideia de uma hiperesfera (hiperelipse) no espaço de entrada, com uma distribuição Gaussiana. Aquelas amostras que estão fora desta hiperesfera são consideradas Outliers.\n",
    "\n",
    "Referência: https://arxiv.org/pdf/1709.07045.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331aee7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:25:48.472021Z",
     "start_time": "2022-07-03T03:21:48.053484Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234609,
     "status": "ok",
     "timestamp": 1655858388245,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "d331aee7",
    "outputId": "63963d74-94bc-4348-9738-dd5550cbed6a"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "cols_feature = ['vento'] # 'chuva', 'sol', 'vento'\n",
    "\n",
    "df_outliers_tr = pd.DataFrame(df3_tr_03_one_hot[cols_feature] )\n",
    "df_outliers_ts = pd.DataFrame(df3_ts_03_one_hot[cols_feature])\n",
    "\n",
    "model_e_eliptico = EllipticEnvelope(contamination=0.1)\n",
    "model_e_eliptico.fit(df_outliers_tr)\n",
    "\n",
    "out_EE_tr = model_e_eliptico.predict(df_outliers_tr)\n",
    "out_EE_ts = model_e_eliptico.predict(df_outliers_ts)\n",
    "\n",
    "df3_tr_01_mista_04       = df3_tr_01_mista.copy()\n",
    "df3_ts_01_mista_04       = df3_ts_01_mista.copy()\n",
    "df3_tr_02_ord_Encoder_04 = df3_tr_02_ord_Encoder.copy() \n",
    "df3_ts_02_ord_Encoder_04 = df3_ts_02_ord_Encoder.copy()\n",
    "df3_tr_03_one_hot_04     = df3_tr_03_one_hot.copy()\n",
    "df3_ts_03_one_hot_04     = df3_ts_03_one_hot.copy()\n",
    "\n",
    "df41 = (df3_tr_01_mista_04, df3_ts_01_mista_04, 'df3_tr_01_mista', 1, 'Envelope Elíptico')\n",
    "df42 = (df3_tr_02_ord_Encoder_04, df3_ts_02_ord_Encoder_04, 'df3_tr_02_ord_Encoder', 2)\n",
    "df43 = (df3_tr_03_one_hot_04, df3_ts_03_one_hot_04, 'df3_tr_03_one_hot', 3) \n",
    "\n",
    "dfs_04 = [df41, df42, df43]\n",
    "\n",
    "for df_ in dfs_04:\n",
    "    df_[0]['fe_outlier_env_eliptico'] = out_EE_tr\n",
    "    df_[1]['fe_outlier_env_eliptico'] = out_EE_ts\n",
    "    \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds = model_fit(models_          = models,                     \n",
    "                     datasets_        = dfs_04,                      \n",
    "                     target_          = target, \n",
    "                     path_            = path, \n",
    "                     feature_drop_cor_= [], \n",
    "                     scalers_         = scalers,                      \n",
    "                     seed_            = seed)\n",
    "   \n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 235.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d31c9",
   "metadata": {
    "id": "381d31c9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Não tivemos uma melhoria. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zG5VBJgnZy3h",
   "metadata": {
    "id": "zG5VBJgnZy3h"
   },
   "source": [
    "#### 3.2.1.4. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9b600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:29:28.153225Z",
     "start_time": "2022-07-03T03:29:28.141277Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1655858388246,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "47a9b600"
   },
   "outputs": [],
   "source": [
    "def outlier_IsolationForest(df_tr_, df_ts_, feature_):\n",
    "    # https://www.analyticsvidhya.com/blog/2021/07/anomaly-detection-using-isolation-forest-a-complete-guide/\n",
    "    #Retorna -1 se a amostra é Outlier e 1 caso contrário\n",
    "\n",
    "    X_tr = df_tr_[feature_].values.reshape(-1, 1)\n",
    "    X_ts = df_ts_[feature_].values.reshape(-1, 1)\n",
    "\n",
    "    model_if = IsolationForest( n_estimators  = 1000,                                 \n",
    "                                contamination = float(.15),\n",
    "                                n_jobs        = -1, \n",
    "                                random_state  = seed, \n",
    "                                verbose       = 0)\n",
    "    \n",
    "    model_if.fit(X_tr)\n",
    "\n",
    "    out_IF_tr = model_if.predict(X_tr)\n",
    "    out_IF_ts = model_if.predict(X_ts)\n",
    "\n",
    "    return out_IF_tr , out_IF_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mYqU873L1SM1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:33:31.532927Z",
     "start_time": "2022-07-03T03:29:29.675834Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240139,
     "status": "ok",
     "timestamp": 1655858628380,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "mYqU873L1SM1",
    "outputId": "571af7e9-2534-4432-eda6-78cf852103fc"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df3_tr_01_mista_05       = df3_tr_01_mista.copy()\n",
    "df3_ts_01_mista_05       = df3_ts_01_mista.copy()\n",
    "df3_tr_02_ord_Encoder_05 = df3_tr_02_ord_Encoder.copy() \n",
    "df3_ts_02_ord_Encoder_05 = df3_ts_02_ord_Encoder.copy()\n",
    "df3_tr_03_one_hot_05     = df3_tr_03_one_hot.copy()\n",
    "df3_ts_03_one_hot_05     = df3_ts_03_one_hot.copy()\n",
    "\n",
    "out_IF_tr , out_IF_ts = outlier_IsolationForest(df3_tr_01_mista_05, \n",
    "                                                df3_ts_01_mista_05,\n",
    "                                                'sol')  # chuva, sol, vento\n",
    "\n",
    "df51   = (df3_tr_01_mista_05, df3_ts_01_mista_05, 'df3_tr_01_mista', 1, 'Envelope Elíptico')\n",
    "df52   = (df3_tr_02_ord_Encoder_05, df3_ts_02_ord_Encoder_05, 'df3_tr_02_ord_Encoder', 2)\n",
    "df53   = (df3_tr_03_one_hot_05, df3_ts_03_one_hot_05, 'df3_tr_03_one_hot', 3) \n",
    "dfs_05 = [df51, df52, df53]\n",
    "\n",
    "for df_ in dfs_05:\n",
    "    df_[0]['fe_outlier_iso_forest'] = out_IF_tr\n",
    "    df_[1]['fe_outlier_iso_forest'] = out_IF_ts\n",
    "    \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds = model_fit(models_          = models,                     \n",
    "                     datasets_        = dfs_05,                      \n",
    "                     target_          = target, \n",
    "                     path_            = path, \n",
    "                     feature_drop_cor_= [], \n",
    "                     scalers_         = scalers,                      \n",
    "                     seed_            = seed)\n",
    "   \n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 235.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b04af",
   "metadata": {
    "id": "8c8b04af"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Não tivemos melhoria, a melhor técnica com as três variáveis foi **Intervalo interquartil** com score de 235.12 utilizando o **GradientBoostingRegressor** no dataset **df3_train_fe_03_one_hot_encoder**.\n",
    " \n",
    "Nos próximos passos vamos utilizar  o conjunto de datasets da variável **dfs_02**, que teve o melhor desempenho até agora. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed0eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:38:24.247503Z",
     "start_time": "2022-07-03T03:38:24.219469Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1655858628381,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "cfed0eb5",
    "outputId": "40238988-1b0f-48b1-af8a-b07ee6c6154a"
   },
   "outputs": [],
   "source": [
    "dfs_02[2][0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a52717",
   "metadata": {
    "id": "b1a52717"
   },
   "source": [
    "### 3.3.2. Feature Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449aac84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:38:24.216468Z",
     "start_time": "2022-07-03T03:33:31.566931Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250048,
     "status": "ok",
     "timestamp": 1655858878420,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "449aac84",
    "outputId": "bce9a9a9-d86a-492c-f39d-8eacd8ef88b6"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "def create_feature_Statistic(df_, feature_):\n",
    "    df_['fe_mean'] = df_[feature_].mean(axis=1) #/ 1000    \n",
    "    #df_['hora']    = df_['hora'] / 24\n",
    "    \n",
    "df3_tr_01_mista_06       = dfs_02[0][0].copy()\n",
    "df3_ts_01_mista_06       = dfs_02[0][1].copy()\n",
    "df3_tr_02_ord_Encoder_06 = dfs_02[1][0].copy() \n",
    "df3_ts_02_ord_Encoder_06 = dfs_02[1][1].copy()\n",
    "df3_tr_03_one_hot_06     = dfs_02[2][0].copy()\n",
    "df3_ts_03_one_hot_06     = dfs_02[2][1].copy()\n",
    "\n",
    "df61   = (df3_tr_01_mista_06, df3_ts_01_mista_06, 'df3_tr_01_mista', 1, 'Isolation Forest')\n",
    "df62   = (df3_tr_02_ord_Encoder_06, df3_ts_02_ord_Encoder_06, 'df3_tr_02_ord_Encoder', 2)\n",
    "df63   = (df3_tr_03_one_hot_06, df3_ts_03_one_hot_06, 'df3_tr_03_one_hot', 3) \n",
    "dfs_06 = [df61, df62, df63]\n",
    "\n",
    "feature_statistic = ['temperatura', 'chuva', 'umidade', 'vento', 'sol', 'visibilidade']\n",
    " \n",
    "for df_ in dfs_06:\n",
    "    create_feature_Statistic(df_[0], feature_statistic)\n",
    "    create_feature_Statistic(df_[1], feature_statistic)\n",
    "        \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds, model = model_fit(models_          = models,                     \n",
    "                            datasets_        = dfs_06,                      \n",
    "                            target_          = target, \n",
    "                            path_            = path, \n",
    "                            feature_drop_cor_= [], \n",
    "                            scalers_         = scalers,                                  \n",
    "                            seed_            = seed)\n",
    "\n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 235.00 234.24 233.50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d66bf9",
   "metadata": {},
   "source": [
    "## 3.3. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa5e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:38:24.485503Z",
     "start_time": "2022-07-03T03:38:24.249484Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pca_tr   = dfs_02[2][0].drop(target, axis=1)\n",
    "df_pca_ts   = dfs_02[2][1]\n",
    "feature_pca = df_pca_tr.columns.to_list()\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(df_pca_tr)\n",
    "\n",
    "df_pca_tr = pd.DataFrame(scaler.fit_transform(df_pca_tr), columns=feature_pca)\n",
    "df_pca_ts = pd.DataFrame(scaler.fit_transform(df_pca_ts), columns=feature_pca)\n",
    "\n",
    "pca             = PCA(random_state=12359)\n",
    "df3_4_train_pca = pca.fit_transform(df_pca_tr)\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca, figsize=(8,6));\n",
    "# .783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f5bd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:38:24.708523Z",
     "start_time": "2022-07-03T03:38:24.488468Z"
    }
   },
   "outputs": [],
   "source": [
    "features = range(pca.n_components_)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(features[:15], pca.explained_variance_[:15], color='lightskyblue')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(features[:15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120a9e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:38:24.740510Z",
     "start_time": "2022-07-03T03:38:24.711471Z"
    }
   },
   "outputs": [],
   "source": [
    "n_components  = 3\n",
    "pca           = PCA(n_components=n_components, random_state=123)\n",
    "pca_feats     = [f'fe_pca_{i}' for i in range(n_components)]\n",
    "\n",
    "df_pca_tr[pca_feats] = pca.fit_transform(df_pca_tr)\n",
    "df_pca_ts[pca_feats] = pca.transform(df_pca_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c4e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:39:20.761081Z",
     "start_time": "2022-07-03T03:39:20.723096Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pca_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ca832",
   "metadata": {
    "id": "6a7ca832"
   },
   "source": [
    "## 3.4. Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e15eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:39:23.685075Z",
     "start_time": "2022-07-03T03:39:22.547514Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "visualizer_1 = KElbowVisualizer(KMeans(random_state=12359), k=(2,10))\n",
    "visualizer_1.fit(df_pca_tr[pca_feats])\n",
    "visualizer_1.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7204c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:39:34.369524Z",
     "start_time": "2022-07-03T03:39:34.107529Z"
    }
   },
   "outputs": [],
   "source": [
    "model_kmeans = KMeans(n_clusters=4, random_state=12359)\n",
    "model_kmeans.fit(df_pca_tr[pca_feats]);\n",
    "\n",
    "clusters_train = model_kmeans.predict(df_pca_tr[pca_feats])\n",
    "clusters_test  = model_kmeans.predict(df_pca_ts[pca_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0381c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:44:13.571986Z",
     "start_time": "2022-07-03T03:39:43.067968Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "error",
     "timestamp": 1655860022292,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "80e0381c",
    "outputId": "3e6a8f04-5c04-4f94-e96f-d29cdea9dd35"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "def create_feature_Statistic(df_, feature_):\n",
    "    df_['fe_mean'] = df_[feature_].mean(axis=1) #/ 1000    \n",
    "    \n",
    "    \n",
    "df3_tr_01_mista_07       = dfs_02[0][0].copy()\n",
    "df3_ts_01_mista_07       = dfs_02[0][1].copy()\n",
    "df3_tr_02_ord_Encoder_07 = dfs_02[1][0].copy() \n",
    "df3_ts_02_ord_Encoder_07 = dfs_02[1][1].copy()\n",
    "df3_tr_03_one_hot_07     = dfs_02[2][0].copy()\n",
    "df3_ts_03_one_hot_07     = dfs_02[2][1].copy()\n",
    "\n",
    "df71   = (df3_tr_01_mista_07, df3_ts_01_mista_07, 'df3_tr_01_mista', 1, 'Isolation Forest')\n",
    "df72   = (df3_tr_02_ord_Encoder_07, df3_ts_02_ord_Encoder_07, 'df3_tr_02_ord_Encoder', 2)\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df3_tr_03_one_hot', 3) \n",
    "dfs_07 = [df71, df72, df73]\n",
    "\n",
    "feature_statistic = ['temperatura', 'chuva', 'umidade', 'vento', 'sol', 'visibilidade']\n",
    " \n",
    "for df_ in dfs_07:\n",
    "    create_feature_Statistic(df_[0], feature_statistic)\n",
    "    create_feature_Statistic(df_[1], feature_statistic)\n",
    "    df_[0]['fe_cluster'] = clusters_train\n",
    "    df_[1]['fe_cluster'] = clusters_test\n",
    "    \n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds, model = model_fit(models_          = models,                     \n",
    "                            datasets_        = dfs_07,                      \n",
    "                            target_          = target, \n",
    "                            path_            = path, \n",
    "                            feature_drop_cor_= [], \n",
    "                            scalers_         = scalers,                                  \n",
    "                            seed_            = seed)\n",
    "\n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 233.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b54af3",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "Model: XGBRegressor -> df3_tr_01_mista\n",
    "  RMSE: 242.62 - MAE: 140.10 - MSE: 58864.09 - MAPE: 1.55 - R2: 0.85 - TR RMSE: 88.54 => None\n",
    "  RMSE: 240.57 - MAE: 140.04 - MSE: 57871.57 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 61.25 => None\n",
    "* RMSE: 238.92 - MAE: 136.85 - MSE: 57082.50 - MAPE: 1.51 - R2: 0.86 - TR RMSE: 58.47 => None\n",
    "\n",
    "  RMSE: 242.25 - MAE: 139.47 - MSE: 58686.34 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 58.61 => None\n",
    "  RMSE: 242.11 - MAE: 141.45 - MSE: 58618.24 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 100.04 => None\n",
    "* RMSE: 240.90 - MAE: 138.34 - MSE: 58034.39 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 61.39 => None\n",
    "                        \n",
    "* RMSE: 241.72 - MAE: 139.01 - MSE: 58427.56 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 60.60 => None\n",
    "  RMSE: 242.15 - MAE: 142.01 - MSE: 58636.55 - MAPE: 1.53 - R2: 0.85 - TR RMSE: 79.97 => None\n",
    "  RMSE: 241.89 - MAE: 138.97 - MSE: 58511.62 - MAPE: 1.56 - R2: 0.85 - TR RMSE: 61.94 => None\n",
    "\n",
    "  RMSE: 242.20 - MAE: 139.68 - MSE: 58661.55 - MAPE: 1.54 - R2: 0.85 - TR RMSE: 65.60 => None\n",
    "  RMSE: 242.11 - MAE: 141.45 - MSE: 58615.50 - MAPE: 1.52 - R2: 0.85 - TR RMSE: 74.89 => None\n",
    "* RMSE: 242.03 - MAE: 138.81 - MSE: 58576.25 - MAPE: 1.55 - R2: 0.85 - TR RMSE: 59.45 => None\n",
    "\n",
    "  RMSE: 242.78 - MAE: 139.78 - MSE: 58942.79 - MAPE: 1.53 - R2: 0.85 - TR RMSE: 61.90 => None\n",
    "* RMSE: 241.49 - MAE: 141.17 - MSE: 58316.41 - MAPE: 1.52 - R2: 0.85 - TR RMSE: 65.79 => None\n",
    "  RMSE: 241.67 - MAE: 138.46 - MSE: 58403.59 - MAPE: 1.55 - R2: 0.85 - TR RMSE: 61.03 => None\n",
    "\n",
    "  RMSE: 237.66 - MAE: 138.77 - MSE: 56482.07 - MAPE: 1.44 - R2: 0.86 - TR RMSE: 56.76 => None\n",
    "* RMSE: 237.05 - MAE: 138.33 - MSE: 56193.53 - MAPE: 1.45 - R2: 0.86 - TR RMSE: 60.69 => None\n",
    "  RMSE: 238.10 - MAE: 137.41 - MSE: 56689.73 - MAPE: 1.47 - R2: 0.86 - TR RMSE: 56.10 => None\n",
    "\n",
    "  RMSE: 238.77 - MAE: 139.41 - MSE: 57008.96 - MAPE: 1.48 - R2: 0.86 - TR RMSE: 102.47 => None\n",
    "  RMSE: 238.00 - MAE: 138.18 - MSE: 56646.36 - MAPE: 1.44 - R2: 0.86 - TR RMSE: 56.37 => None\n",
    "* RMSE: 235.44 - MAE: 136.42 - MSE: 55432.42 - MAPE: 1.41 - R2: 0.86 - TR RMSE: 55.65 => None\n",
    "\n",
    "ok \n",
    "\n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "Model: LGBMRegressor -> df3_tr_01_mista\n",
    "* RMSE: 248.51 - MAE: 147.48 - MSE: 61756.55 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 193.38 => None\n",
    "  RMSE: 248.94 - MAE: 148.26 - MSE: 61970.16 - MAPE: 1.65 - R2: 0.84 - TR RMSE: 197.68 => None\n",
    "  RMSE: 249.79 - MAE: 146.90 - MSE: 62395.38 - MAPE: 1.66 - R2: 0.84 - TR RMSE: 214.58 => None\n",
    "\n",
    "  RMSE: 248.63 - MAE: 147.50 - MSE: 61818.39 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 198.71 => None\n",
    "  RMSE: 248.84 - MAE: 147.67 - MSE: 61920.55 - MAPE: 1.69 - R2: 0.84 - TR RMSE: 208.89 => None\n",
    "* RMSE: 247.65 - MAE: 145.71 - MSE: 61330.07 - MAPE: 1.68 - R2: 0.85 - TR RMSE: 214.93 => None\n",
    "\n",
    "  RMSE: 249.21 - MAE: 148.84 - MSE: 62107.12 - MAPE: 1.68 - R2: 0.84 - TR RMSE: 217.19 => None\n",
    "  RMSE: 250.18 - MAE: 148.65 - MSE: 62591.79 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 211.69 => None\n",
    "* RMSE: 248.26 - MAE: 146.80 - MSE: 61632.67 - MAPE: 1.69 - R2: 0.84 - TR RMSE: 215.92 => None\n",
    "\n",
    "  RMSE: 248.98 - MAE: 147.58 - MSE: 61991.29 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 199.18 => None\n",
    "  RMSE: 249.55 - MAE: 147.90 - MSE: 62277.64 - MAPE: 1.68 - R2: 0.84 - TR RMSE: 212.49 => None\n",
    "* RMSE: 248.72 - MAE: 146.64 - MSE: 61859.49 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 216.31 => None\n",
    "\n",
    "  RMSE: 249.95 - MAE: 148.85 - MSE: 62477.43 - MAPE: 1.68 - R2: 0.84 - TR RMSE: 217.50 => None  \n",
    "  RMSE: 248.91 - MAE: 147.38 - MSE: 61955.04 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 206.80 => None\n",
    "* RMSE: 248.91 - MAE: 146.65 - MSE: 61955.27 - MAPE: 1.67 - R2: 0.84 - TR RMSE: 217.99 => None\n",
    "\n",
    "  RMSE: 243.36 - MAE: 145.12 - MSE: 59226.33 - MAPE: 1.52 - R2: 0.85 - TR RMSE: 167.51 => None\n",
    "  RMSE: 245.33 - MAE: 146.22 - MSE: 60187.72 - MAPE: 1.56 - R2: 0.85 - TR RMSE: 176.86 => None\n",
    "* RMSE: 242.71 - MAE: 142.83 - MSE: 58906.36 - MAPE: 1.52 - R2: 0.85 - TR RMSE: 166.66 => None\n",
    "\n",
    "* RMSE: 243.66 - MAE: 144.08 - MSE: 59372.60 - MAPE: 1.57 - R2: 0.85 - TR RMSE: 176.02 => None\n",
    "  RMSE: 244.89 - MAE: 145.81 - MSE: 59969.55 - MAPE: 1.55 - R2: 0.85 - TR RMSE: 170.15 => None\n",
    "  RMSE: 244.94 - MAE: 143.65 - MSE: 59993.85 - MAPE: 1.55 - R2: 0.85 - TR RMSE: 195.66 => None\n",
    "                        \n",
    "df63   = (df3_tr_03_one_hot_06, df3_ts_03_one_hot_06, 'df3_tr_03_one_hot', 3) \n",
    "                        \n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "Model: CatBoostRegressor -> df3_tr_01_mista\n",
    "  RMSE: 240.24 - MAE: 141.82 - MSE: 57716.52 - MAPE: 1.39 - R2: 0.85 - TR RMSE: 98.85 => None\n",
    "  RMSE: 246.36 - MAE: 146.00 - MSE: 60695.31 - MAPE: 1.43 - R2: 0.85 - TR RMSE: 123.38 => None\n",
    "* RMSE: 235.93 - MAE: 140.13 - MSE: 55663.33 - MAPE: 1.44 - R2: 0.86 - TR RMSE: 86.49 => None\n",
    "\n",
    "  RMSE: 243.51 - MAE: 145.31 - MSE: 59295.16 - MAPE: 1.43 - R2: 0.85 - TR RMSE: 90.67 => None\n",
    "  RMSE: 244.39 - MAE: 144.66 - MSE: 59728.50 - MAPE: 1.51 - R2: 0.85 - TR RMSE: 176.27 => None\n",
    "* RMSE: 235.15 - MAE: 138.54 - MSE: 55296.89 - MAPE: 1.43 - R2: 0.86 - TR RMSE: 95.87 => None\n",
    "\n",
    "  RMSE: 241.91 - MAE: 142.11 - MSE: 58521.45 - MAPE: 1.44 - R2: 0.85 - TR RMSE: 89.37 => None\n",
    "  RMSE: 246.39 - MAE: 145.03 - MSE: 60707.93 - MAPE: 1.47 - R2: 0.85 - TR RMSE: 103.37 => None\n",
    "* RMSE: 235.87 - MAE: 137.78 - MSE: 55634.42 - MAPE: 1.42 - R2: 0.86 - TR RMSE: 104.10 => None\n",
    "\n",
    "  RMSE: 243.13 - MAE: 144.77 - MSE: 59112.05 - MAPE: 1.43 - R2: 0.85 - TR RMSE: 93.18 => None\n",
    "  RMSE: 244.58 - MAE: 146.07 - MSE: 59819.96 - MAPE: 1.47 - R2: 0.85 - TR RMSE: 150.44 => None\n",
    "* RMSE: 234.93 - MAE: 138.43 - MSE: 55191.45 - MAPE: 1.39 - R2: 0.86 - TR RMSE: 84.79 => None\n",
    "\n",
    "  RMSE: 243.00 - MAE: 143.88 - MSE: 59050.65 - MAPE: 1.46 - R2: 0.85 - TR RMSE: 136.60 => None\n",
    "  RMSE: 244.12 - MAE: 143.57 - MSE: 59592.49 - MAPE: 1.48 - R2: 0.85 - TR RMSE: 141.87 => None\n",
    "* RMSE: 235.37 - MAE: 138.21 - MSE: 55401.16 - MAPE: 1.40 - R2: 0.86 - TR RMSE: 105.28 => None\n",
    "\n",
    "  RMSE: 235.03 - MAE: 139.62 - MSE: 55238.33 - MAPE: 1.30 - R2: 0.86 - TR RMSE: 85.23 => None\n",
    "  RMSE: 237.71 - MAE: 140.55 - MSE: 56507.48 - MAPE: 1.28 - R2: 0.86 - TR RMSE: 86.69 => None\n",
    "* RMSE: 232.80 - MAE: 137.42 - MSE: 54197.84 - MAPE: 1.26 - R2: 0.86 - TR RMSE: 78.28 => None\n",
    "\n",
    "  RMSE: 238.13 - MAE: 141.30 - MSE: 56703.80 - MAPE: 1.31 - R2: 0.86 - TR RMSE: 83.52 => None\n",
    "  RMSE: 236.48 - MAE: 141.16 - MSE: 55923.40 - MAPE: 1.32 - R2: 0.86 - TR RMSE: 82.23 => None\n",
    "* RMSE: 231.38 - MAE: 137.73 - MSE: 53537.12 - MAPE: 1.28 - R2: 0.87 - TR RMSE: 98.47 => None\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df3_tr_03_one_hot', 3) \n",
    "                        \n",
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "Model: GradientBoostingRegressor -> df3_tr_01_mista\n",
    "  RMSE: 239.08 - MAE: 139.45 - MSE: 57161.07 - MAPE: 1.54 - R2: 0.86 - TR RMSE: 143.16 => None\n",
    "  RMSE: 242.76 - MAE: 140.98 - MSE: 58932.04 - MAPE: 1.67 - R2: 0.85 - TR RMSE: 144.38 => None\n",
    "* RMSE: 238.03 - MAE: 138.05 - MSE: 56659.60 - MAPE: 1.53 - R2: 0.86 - TR RMSE: 146.66 => None\n",
    "                        \n",
    "  RMSE: 242.51 - MAE: 140.24 - MSE: 58811.01 - MAPE: 1.59 - R2: 0.85 - TR RMSE: 143.22 => None\n",
    "  RMSE: 241.16 - MAE: 140.34 - MSE: 58160.27 - MAPE: 1.60 - R2: 0.85 - TR RMSE: 141.03 => None\n",
    "* RMSE: 234.72 - MAE: 136.83 - MSE: 55094.61 - MAPE: 1.54 - R2: 0.86 - TR RMSE: 145.81 => None\n",
    "    \n",
    "* RMSE: 238.74 - MAE: 138.66 - MSE: 56995.17 - MAPE: 1.57 - R2: 0.86 - TR RMSE: 143.03 => None\n",
    "  RMSE: 242.43 - MAE: 140.35 - MSE: 58774.21 - MAPE: 1.63 - R2: 0.85 - TR RMSE: 143.52 => None\n",
    "  RMSE: 241.68 - MAE: 139.77 - MSE: 58409.57 - MAPE: 1.60 - R2: 0.85 - TR RMSE: 143.58 => None\n",
    "         \n",
    "  RMSE: 241.29 - MAE: 143.29 - MSE: 58219.54 - MAPE: 1.56 - R2: 0.85 - TR RMSE: 141.69 => None\n",
    "  RMSE: 240.83 - MAE: 139.64 - MSE: 58000.98 - MAPE: 1.64 - R2: 0.85 - TR RMSE: 144.11 => None\n",
    "* RMSE: 236.44 - MAE: 138.27 - MSE: 55904.70 - MAPE: 1.52 - R2: 0.86 - TR RMSE: 145.86 => None\n",
    "         \n",
    "  RMSE: 241.27 - MAE: 140.61 - MSE: 58212.39 - MAPE: 1.58 - R2: 0.85 - TR RMSE: 143.16 => None\n",
    "  RMSE: 240.93 - MAE: 140.41 - MSE: 58046.95 - MAPE: 1.63 - R2: 0.85 - TR RMSE: 143.31 => None\n",
    "* RMSE: 237.89 - MAE: 137.04 - MSE: 56590.51 - MAPE: 1.57 - R2: 0.86 - TR RMSE: 146.12 => None\n",
    "     \n",
    "  RMSE: 240.13 - MAE: 140.34 - MSE: 57664.12 - MAPE: 1.51 - R2: 0.85 - TR RMSE: 135.71 => None\n",
    "  RMSE: 240.59 - MAE: 138.69 - MSE: 57881.59 - MAPE: 1.51 - R2: 0.85 - TR RMSE: 142.54 => None\n",
    "* RMSE: 233.96 - MAE: 136.28 - MSE: 54736.34 - MAPE: 1.46 - R2: 0.86 - TR RMSE: 142.68 => None\n",
    "\n",
    "  RMSE: 239.25 - MAE: 140.44 - MSE: 57241.89 - MAPE: 1.48 - R2: 0.86 - TR RMSE: 133.82 => None\n",
    "  RMSE: 237.39 - MAE: 138.99 - MSE: 56352.55 - MAPE: 1.48 - R2: 0.86 - TR RMSE: 138.55 => None\n",
    "* RMSE: 233.93 - MAE: 138.00 - MSE: 54724.62 - MAPE: 1.45 - R2: 0.86 - TR RMSE: 139.81 => None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a644c2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T04:00:29.310647Z",
     "start_time": "2022-07-03T03:56:41.185117Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# xgb \n",
    "# RMSE: 235.44\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df3_tr_03_one_hot', 3) \n",
    "\n",
    "# LGBMRegressor\n",
    "df63   = (df3_tr_03_one_hot_06, df3_ts_03_one_hot_06, 'df3_tr_03_one_hot', 3) \n",
    "\n",
    "# CatBoostRegressor \n",
    "# RMSE: 231.38\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df3_tr_03_one_hot', 3) \n",
    "\n",
    "# GradientBoostingRegressor \n",
    "# RMSE: 233.93\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df3_tr_03_one_hot', 3)\n",
    "\n",
    "\n",
    "dfs_08 = [df63, df73]\n",
    "\n",
    "scalers = [None]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "df_preds, model = model_fit(models_          = models,                     \n",
    "                            datasets_        = dfs_07,                      \n",
    "                            target_          = target, \n",
    "                            path_            = path, \n",
    "                            feature_drop_cor_= [], \n",
    "                            scalers_         = scalers,                                  \n",
    "                            seed_            = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedcb5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T21:56:09.643362Z",
     "start_time": "2022-06-26T21:56:09.622326Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = ['catb_2_231.38_df3_tr_03_one_hot_none.csv', 'gbr_2_233.93_df3_tr_03_one_hot_none.csv', \n",
    "         'lgb_0_243.66_df3_tr_01_mista_none.csv', 'xgb_2_235.44_df3_tr_03_one_hot_none.csv'\n",
    "        ]\n",
    "\n",
    "df  = pd.DataFrame()\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(path + 'Data/Submission/'+ file)\n",
    "    df = pd.concat([df, df1], axis=1)\n",
    "\n",
    "pd.DataFrame(df.mean(axis=1).astype(np.int64), columns=['aluguéis']).to_csv(path + 'Data/Submission/sub_09.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df020bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T21:48:02.330918Z",
     "start_time": "2022-06-26T21:48:02.317920Z"
    }
   },
   "outputs": [],
   "source": [
    "0        951.000000\n",
    "1        433.000000\n",
    "2        192.666667\n",
    "3        464.666667\n",
    "4       2205.000000\n",
    "           ...     \n",
    "2995     415.333333\n",
    "2996     142.666667\n",
    "2997     270.333333\n",
    "2998     236.666667\n",
    "2999     114.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082f54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:43.974118Z",
     "start_time": "2022-06-26T19:23:40.569682Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_s   = dfs_06[2][0].drop(target, axis=1)\n",
    "explainer   = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e37817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:44.352722Z",
     "start_time": "2022-06-26T19:23:44.056567Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train_s, plot_type=\"bar\", max_display=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7400fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:45.765289Z",
     "start_time": "2022-06-26T19:23:44.597792Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train_s, max_display=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bb98d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Com a criação da variável cluster, tivemos uma melhora no score e a variável se posicionou entre as 10. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e48ea",
   "metadata": {
    "id": "862e48ea"
   },
   "source": [
    "## 3.5. Variável Alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95ff44",
   "metadata": {
    "id": "5c95ff44"
   },
   "source": [
    "##### 3.2.1.5.1. Análise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdbdd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T21:59:25.438664Z",
     "start_time": "2022-06-26T21:59:25.412667Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1655745835783,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "7dbdbdd0",
    "outputId": "1dba78fb-c870-4d54-f003-e7d1306f5e84"
   },
   "outputs": [],
   "source": [
    "perc_inferior  = dfs_06[2][0][target].quantile(.01)\n",
    "perc_superior  = dfs_06[2][0][target].quantile(.99)\n",
    "filtro_outlier = (df3_train[target]>perc_inferior) & (df3_train[target]<perc_superior)\n",
    "\n",
    "vlr_inferior    = df3_train[df3_train[target]< perc_inferior][target]\n",
    "vlr_superior    = df3_train[df3_train[target]>=perc_superior][target]\n",
    "vlr_sem_outlier = df3_train[filtro_outlier][target]\n",
    "\n",
    "print('Valor inferior: {:2.2f} -> Quantidade: {}'.format(perc_inferior, len(vlr_inferior)))\n",
    "print('Valor superior: {:2.2f} -> Quantidade: {}'.format(perc_superior, len(vlr_superior)))\n",
    "print()\n",
    "print('Dataset Normal')\n",
    "print(df3_train[target].describe())\n",
    "print()\n",
    "print('Sem Outliers')\n",
    "print(vlr_sem_outlier.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264c09f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T21:59:28.106999Z",
     "start_time": "2022-06-26T21:59:26.108184Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "error",
     "timestamp": 1655859903030,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "5264c09f",
    "outputId": "8a39e655-dc7e-4f93-dde3-7924142f74df",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "power  = PowerTransformer(method='box-cox') # \n",
    "y_ori  = dfs_02[2][0][target]  \n",
    "y_log  = np.log1p(y_ori)\n",
    "y_sqr  = np.sqrt(y_ori)\n",
    "y_bcox = pd.DataFrame(power.fit_transform(pd.DataFrame(y_ori)), columns=['y'])['y']\n",
    "label  = ['Sem transformação','Log','Raiz quandrada', 'Box-Cox']\n",
    "\n",
    "list_feature_trans = [y_ori, y_log, y_sqr, y_bcox]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "msg = 'Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'\n",
    "\n",
    "for i, v in enumerate(list_feature_trans):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    (mu, sigma) = norm.fit(v)        \n",
    "    sns.distplot(v, kde=True, hist=True, fit=norm)\n",
    "    plt.legend([msg.format(mu, sigma)],loc='best')\n",
    "    plt.xlabel('')\n",
    "    plt.title('{}'.format(label[i]), fontsize=16)\n",
    "    \n",
    "    plt.subplot(3,4,i+5)\n",
    "    sns.boxplot(y=v)\n",
    "    \n",
    "    plt.subplot(3,4,i+9)\n",
    "    res = stats.probplot(v, plot=plt)\n",
    "    plt.xlabel('')\n",
    "    plt.title('')\n",
    "\n",
    "plt.suptitle('Transformação da variável alvo ({})'.format(target), fontsize=20);\n",
    "plt.tight_layout(pad=3.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0f3c4",
   "metadata": {
    "id": "c8a0f3c4"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632d24b",
   "metadata": {
    "id": "8632d24b"
   },
   "source": [
    "##### 3.2.1.5.2. Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d19ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T02:32:03.084526Z",
     "start_time": "2022-06-26T02:32:02.994349Z"
    }
   },
   "outputs": [],
   "source": [
    "df3_tr_03_one_hot_07.corr(method='pearson').sort_values(target, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c548d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T22:01:32.252830Z",
     "start_time": "2022-06-26T21:59:51.715490Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "executionInfo": {
     "elapsed": 966,
     "status": "error",
     "timestamp": 1655746773061,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "78c548d5",
    "outputId": "82cb5b30-9eca-4f9e-c30a-7e79397d94da",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df3_tr_01_mista_07       = dfs_06[0][0].copy()\n",
    "df3_ts_01_mista_07       = dfs_06[0][1].copy()\n",
    "df3_tr_02_ord_Encoder_07 = dfs_06[1][0].copy() \n",
    "df3_ts_02_ord_Encoder_07 = dfs_06[1][1].copy()\n",
    "df3_tr_03_one_hot_07     = dfs_06[2][0].copy()\n",
    "df3_ts_03_one_hot_07     = dfs_06[2][1].copy()\n",
    "\n",
    "df71   = (df3_tr_01_mista_07, df3_ts_01_mista_07, 'df_mista', 1, 'Target')\n",
    "df72   = (df3_tr_02_ord_Encoder_07, df3_ts_02_ord_Encoder_07, 'df_ord_Encoder', 2)\n",
    "df73   = (df3_tr_03_one_hot_07, df3_ts_03_one_hot_07, 'df_one_hot', 3) \n",
    "dfs_07 = [#df71, df72, \n",
    "          df73]\n",
    "\n",
    "transformer = FunctionTransformer(np.sqrt, validate=True) \n",
    "\n",
    "scalers = [None#, StandardScaler(), MinMaxScaler()\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1) ,\n",
    "          (model_lgb, 'lgb', 1),           \n",
    "          (model_catb, 'catb', 3),\n",
    "          (model_gbr, 'gbr', 2)\n",
    "         ]\n",
    "\n",
    "\n",
    "transf_sqrt = FunctionTransformer(func=np.sqrt, inverse_func=lambda x:x**2, validate=True, check_inverse=True)\n",
    "transf_cbrt = FunctionTransformer(func=np.cbrt, inverse_func=lambda x:x**3, validate=True, check_inverse=True)\n",
    "transf_cbrt_ = FunctionTransformer(func=lambda x:x*(1/3), inverse_func=lambda x:x*3, validate=True, check_inverse=True)\n",
    "transf_log  = FunctionTransformer(func=np.log,  inverse_func=np.exp, validate=True, check_inverse=True)\n",
    "transf_bcox = PowerTransformer(method='box-cox')\n",
    "\n",
    "df_preds, model = model_fit(models_          = models,                     \n",
    "                            datasets_        = dfs_08,                      \n",
    "                            target_          = target, \n",
    "                            path_            = path, \n",
    "                            feature_drop_cor_= [], \n",
    "                            scalers_         = scalers,                      \n",
    "                            seed_            = seed, \n",
    "                            #transf_target_   = transf_sqrt, \n",
    "                            winsorize_       = True,                     \n",
    "                            perc_upper_limit_= .98, \n",
    "                            test_size_= .02# .001\n",
    "                            )\n",
    "   \n",
    "# The Best\n",
    "# Model  : GradientBoostingRegressor\n",
    "# Dataset: df3_train_fe_03_one_hot_encoder\n",
    "# Scaler : StandardScaler()\n",
    "# Score  : 179.95 => RMSE: 179.95 - MAE: 106.62 - MSE: 32381.52 - MAPE: 0.32 - R2: 0.86 => StandardScaler()\n",
    "# https://www.analyticsvidhya.com/blog/2020/10/getting-started-with-feature-engineering/\n",
    "\n",
    "# The Best\n",
    "# Model  : CatBoostRegressor\n",
    "# Dataset: df3_tr_03_one_hot\n",
    "# Scaler : None\n",
    "# Score  : 231.93 226.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc93f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T22:09:02.684568Z",
     "start_time": "2022-06-26T22:09:02.637532Z"
    }
   },
   "outputs": [],
   "source": [
    "files = ['catb_2_231.38_df3_tr_03_one_hot_none.csv', 'gbr_2_233.93_df3_tr_03_one_hot_none.csv', \n",
    "         'lgb_0_243.66_df3_tr_01_mista_none.csv', 'xgb_2_235.44_df3_tr_03_one_hot_none.csv', \n",
    "         'catb_1_211.56_df3_tr_03_one_hot_none.csv', 'gbr_0_221.40_df3_tr_03_one_hot_none.csv', \n",
    "         'lgb_0_234.36_df3_tr_03_one_hot_none.csv', 'xgb_1_230.11_df3_tr_03_one_hot_none.csv'\n",
    "        ]\n",
    "\n",
    "df  = pd.DataFrame()\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(path + 'Data/Submission/'+ file)\n",
    "    df = pd.concat([df, df1], axis=1)\n",
    "\n",
    "pd.DataFrame(df.mean(axis=1).astype(np.int64), columns=['aluguéis']).to_csv(path + 'Data/Submission/sub_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6161e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:46:37.266014Z",
     "start_time": "2022-06-26T03:46:37.254007Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@df_preds[#(df_preds['y_pred']<0) & \n",
    "#@         (df_preds['model'] =='CatBoostRegressor') & \n",
    "#@         (df_preds['df_name'] =='df_one_hot')\n",
    "#@        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eaa86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:11:13.108329Z",
     "start_time": "2022-06-26T03:11:13.088293Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models_          = models                    \n",
    "datasets_        = dfs_07                      \n",
    "target_          = target \n",
    "path_            = path \n",
    "feature_drop_cor_= [] \n",
    "scalers_         = scalers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e9bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:11:13.769135Z",
     "start_time": "2022-06-26T03:11:13.731100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_preds = len(models_) * len(datasets_) *len(scalers_) \n",
    "\n",
    "for i, df in enumerate(datasets_): \n",
    "    \n",
    "    tr_num_row = df[0].shape[0]\n",
    "    ts_num_row = df[1].shape[0]\n",
    "    \n",
    "    preds_train = np.zeros((tr_num_row, num_preds))\n",
    "    preds_test  = np.zeros((ts_num_row, num_preds))       \n",
    "    \n",
    "    # preds_valid = np.zeros(len(X_test_)) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61aac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:11:14.414779Z",
     "start_time": "2022-06-26T03:11:14.394740Z"
    }
   },
   "outputs": [],
   "source": [
    "col_df = []\n",
    "for model in models:\n",
    "    model_name = model[1] \n",
    "    for df in datasets_:        \n",
    "        for sc in scalers_:\n",
    "            col_name = model_name + '_' + df[2] + '_'+ sc.__class__.__name__\n",
    "            col_df.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2089ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:11:15.750512Z",
     "start_time": "2022-06-26T03:11:15.726517Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preds_train, columns=col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1495206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T22:05:21.671967Z",
     "start_time": "2022-06-25T22:05:21.637969Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preds_test, columns=col_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf1fb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T01:51:59.802370Z",
     "start_time": "2022-06-20T01:51:59.797369Z"
    },
    "id": "aeaf1fb9"
   },
   "source": [
    "##### 3.2.1.5.3. Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52719861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:10:44.227197Z",
     "start_time": "2022-06-26T03:10:43.667451Z"
    },
    "id": "52719861",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample     = 200\n",
    "model_name = 'GradientBoostingRegressor'\n",
    "df         = df_preds[df_preds['model']==model_name]\n",
    "x_ax       = range(len(df[:sample]))\n",
    "\n",
    "df_sample = df.sample(sample)\n",
    "y_nor  = df_sample.y\n",
    "y_pred = df_sample.y_pred\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(x_ax, y_nor,  label=\"original\")\n",
    "plt.plot(x_ax, y_pred, label=\"predicted\")\n",
    "plt.title(\"Previsão em dados de validação - {}\".format(model_name))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(x_ax, y_nor, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, y_pred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.scatterplot(x=df['y'], y=df['y_pred']) #hue=df['y_pred']\n",
    "sns.scatterplot(x=df['y'], y=df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d5094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T13:23:40.230112Z",
     "start_time": "2022-06-20T13:23:40.223109Z"
    },
    "id": "089d5094"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "    \n",
    "A técnica não funcionou, o score na submissão foi para 241.20\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e403ddc8",
   "metadata": {
    "heading_collapsed": true,
    "id": "e403ddc8",
    "papermill": {
     "duration": 0.147716,
     "end_time": "2022-02-13T03:52:22.682969",
     "exception": false,
     "start_time": "2022-02-13T03:52:22.535253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1.1. Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f37535",
   "metadata": {
    "hidden": true,
    "id": "87f37535",
    "papermill": {
     "duration": 0.083149,
     "end_time": "2022-02-13T03:53:55.337296",
     "exception": false,
     "start_time": "2022-02-13T03:53:55.254147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.1.2. Validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d85ab20",
   "metadata": {
    "heading_collapsed": true,
    "id": "3d85ab20",
    "papermill": {
     "duration": 0.096957,
     "end_time": "2022-02-13T04:04:27.587495",
     "exception": false,
     "start_time": "2022-02-13T04:04:27.490538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3. Adicionando decâmeros\n",
    "\n",
    "Conforme explicado na EDA do @AMBROSM, há um número diferente de decâmeros na amostra devido ao processo descrito no artigo \"Analysis of Identification Method for Bacterial Species and Antibiotic Resistance Genes Using Optical Data From DNA Oligomers\" (https://www.frontiersin.org/articles/10.3389/fmicb.2020.00257/full). Queremos adicionar também este recurso para testar se é informativo.\n",
    "\n",
    "Consulte este notebook https://www.kaggle.com/ambrosm/tpsfeb22-01-eda-which-makes-sense para obter o código original e vote-o se achar útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef2d60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916ac68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0733f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eb3ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T04:24:24.584330Z",
     "start_time": "2022-06-25T04:24:24.572323Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, df_, y_pred_test_prob_, y_pred_test_subm_, score_, \n",
    "                    seed_, level_='1', target_='target', cutoff_value_=.6, gera_submission_=True):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        \n",
    "        delete_files(model_name_)\n",
    "        \n",
    "        jb.dump(df_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        jb.dump(model_, path_name_model)\n",
    "                \n",
    "        if gera_submission_:\n",
    "            model_name_ = model_name_.format(score_, seed_)\n",
    "            df_submission[target] = y_pred_test_subm_\n",
    "            df_submission.to_csv(path_ + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000192a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T04:24:24.600324Z",
     "start_time": "2022-06-25T04:24:24.588328Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, df_, y_pred_test_prob_, y_pred_test_subm_, score_, \n",
    "                    seed_, level_='1', target_='target', cutoff_value_=.6, gera_submission_=True):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        \n",
    "        delete_files(model_name_)\n",
    "        \n",
    "        jb.dump(df_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        jb.dump(model_, path_name_model)\n",
    "                \n",
    "        if gera_submission_:\n",
    "            model_name_ = model_name_.format(score_, seed_)\n",
    "            df_submission[target] = y_pred_test_subm_\n",
    "            df_submission.to_csv(path_ + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62196dcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T04:24:24.616358Z",
     "start_time": "2022-06-25T04:24:24.603325Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def df_return_preds_stacking(model_name_=None, path_='', target_='target', level=1): \n",
    "\n",
    "    if level==1: \n",
    "        level_ = 'n1'\n",
    "    else: \n",
    "        if level==2:\n",
    "            level_ = 'n2'\n",
    "        else: \n",
    "            level_ = 'n3'\n",
    "\n",
    "    paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n",
    "\n",
    "    if model_name_==None: \n",
    "        model_name_=''\n",
    "\n",
    "    for i, p in enumerate(paths): \n",
    "\n",
    "        p = path_ + p \n",
    "\n",
    "        name_file_pkl     = glob.glob(p + '/'+ model_name_ + '*.pkl.z')\n",
    "        dic_preds_mdl_pkl = dict()    \n",
    "\n",
    "        for p_name in name_file_pkl:    \n",
    "            y_model_pkl_name_col  = p_name.replace(p + '\\\\', '').replace('.pkl.z','') \n",
    "            #y_model_pkl           = jb.load(p_name)\n",
    "            df_pkl =jb.load(p_name)\n",
    "\n",
    "            if i==0: \n",
    "                x_proba = df_pkl\n",
    "            else: \n",
    "                x_proba = df_pkl['y_proba']        \n",
    "\n",
    "            dic_preds_mdl_pkl[y_model_pkl_name_col] = x_proba\n",
    "\n",
    "        if i==0:\n",
    "            df_ts = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "        else: \n",
    "            df_tr = pd.DataFrame(dic_preds_mdl_pkl) \n",
    "            df_tr[target_] = df_pkl['y_proba']\n",
    "            \n",
    "    return df_tr, df_ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930d921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T05:05:35.402542Z",
     "start_time": "2022-06-25T05:05:35.365514Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_model(model_, model_name_, X_, y_, X_test_, target_, scalers_, lb_, fold_=5, path_='',  \n",
    "                    seed_=12359, feature_scaler_=None, print_report_=False, save_submission_=False, \n",
    "                    save_predict_=False, level_='1', cutoff_value_save_=.6, \n",
    "                    train_with_created_folds_=False, type_model_=1, transf_target_=None):\n",
    "    \n",
    "    n_estimators    = model_.get_params()['n_estimators']             \n",
    "    valid_preds     = {}\n",
    "    taco            = 76 \n",
    "    acc_best        = 0  \n",
    "    df_preds        = pd.DataFrame()\n",
    "    feature_imp     = pd.DataFrame()\n",
    "    test_preds      = []\n",
    "    preds           = []\n",
    "    model           = []\n",
    "    folds           = []\n",
    "    cols_sencond_level = ['fold', 'idx_fold', 'y', 'y_pred', 'residuo']\n",
    "    \n",
    "    # Recuperar os indices do kf \n",
    "    if train_with_created_folds_:\n",
    "        for i in range(fold_):         \n",
    "            folds.append(jb.load(path + 'model/preds/folds/kf_folds_{}_{}.pkl.z'.format(fold_, i+1)))\n",
    "    else:\n",
    "        folds = KFold(n_splits=fold_, shuffle=True, random_state=12359)\n",
    "        #folds = StratifiedKFold(n_splits=fold_, shuffle=True, random_state=12359)\n",
    "        folds = folds.split(X_, y_)\n",
    "        \n",
    "\n",
    "    for i, scaler_ in enumerate(scalers_): \n",
    "\n",
    "        time_start  = datetime.now()\n",
    "        score     = [] \n",
    "        score_mae = []\n",
    "                \n",
    "        if scaler_!=None:            \n",
    "            string_scaler = str(scaler_)        \n",
    "            string_scaler = string_scaler[:string_scaler.index('(')]\n",
    "        else:\n",
    "            string_scaler = None \n",
    "            \n",
    "        y_pred_test = np.zeros(len(X_test_))        \n",
    "        \n",
    "        print('='*taco)\n",
    "        print('Scaler: {} - n_estimators: {}'.format(string_scaler, n_estimators))\n",
    "        print('='*taco)\n",
    "        \n",
    "        y_pred_test_oof = 0      \n",
    "        second_level    = np.zeros((X_.shape[0], 5))        \n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds): \n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "            \n",
    "            if train_with_created_folds_:\n",
    "                trn_idx = folds[fold][trn_idx]\n",
    "                val_idx = folds[fold][val_idx]\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Separar dados para treino \n",
    "            # ----------------------------------------------------     \n",
    "            X_trn, X_val = X_.iloc[trn_idx], X_.iloc[val_idx]\n",
    "            y_trn, y_val = y_.iloc[trn_idx], y_.iloc[val_idx] \n",
    "                      \n",
    "            if transf_target_ is not None:                     \n",
    "                transf_target_.fit(y_trn.values.reshape(-1,1))\n",
    "                y_trn       = transf_target_.transform(y_trn.values.reshape(-1,1))\n",
    "                y_val_trasf = transf_target_.transform(y_val.values.reshape(-1,1)) \n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Processamento \n",
    "            # ---------------------------------------------------- \n",
    "            X_tst = X_test_.copy()\n",
    "            \n",
    "            if scaler_!=None: \n",
    "                if feature_scaler_!=None:                     \n",
    "                    X_trn[feature_scaler_] = scaler_.fit_transform(X_trn[feature_scaler_])\n",
    "                    X_val[feature_scaler_] = scaler_.transform(X_val[feature_scaler_])                      \n",
    "                    X_tst[feature_scaler_] = scaler_.transform(X_tst[feature_scaler_])\n",
    "                else:            \n",
    "                    X_trn = scaler_.fit_transform(X_trn)\n",
    "                    X_val = scaler_.transform(X_val)\n",
    "                    X_tst = scaler_.transform(X_tst.copy())\n",
    "                \n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------     \n",
    "            if type_model_==1:\n",
    "                model_.fit(X_trn, y_trn,\n",
    "                           eval_set              = [(X_trn, y_trn), (X_val, y_val_trasf)],          \n",
    "                           early_stopping_rounds = int(n_estimators*.1),\n",
    "                           verbose               = False)\n",
    "                \n",
    "            if type_model_==2: \n",
    "                model_.fit(X_trn, y_trn,) \n",
    "                    \n",
    "            if type_model_==3:    \n",
    "                model_.fit(X_trn, y_trn,\n",
    "                           eval_set       = [(X_trn, y_trn), (X_val, y_val_trasf)],      \n",
    "                           use_best_model = True,                            \n",
    "                           verbose        = False)\n",
    "                                        \n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------                 \n",
    "            y_pred_val       = model_.predict(X_val) #, ntree_limit=model_.best_ntree_limit)\n",
    "            y_pred_test_oof += model_.predict(X_tst) / fold_\n",
    "                       \n",
    "            if transf_target_ is not None:                       \n",
    "                y_pred_val = transf_target_.inverse_transform(pd.DataFrame(y_pred_val))\n",
    "                #y_pred_ts = transf_target_.inverse_transform(pd.DataFrame(y_pred_ts))\n",
    "\n",
    "            #y_pred_vl = np.int64(y_pred_vl) \n",
    "            #y_pred_ts = np.int64(y_pred_ts)\n",
    "                \n",
    "                \n",
    "            second_level[val_idx, 0] = fold+1 \n",
    "            second_level[val_idx, 1] = val_idx \n",
    "            second_level[val_idx, 2] = val_idx #y_val.values\n",
    "            second_level[val_idx, 3] = val_idx # y_pred_val \n",
    "            second_level[val_idx, 4] = val_idx #np.int64(y_val.values - y_pred_val) \n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ----------------------------------------------------                         \n",
    "            rmse, mae, mse, mape, r_squared = evaluation(y_val, y_pred_val)  \n",
    "                       \n",
    "            score.append(rmse)     \n",
    "            score_mae.append(mae)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_.columns,\n",
    "                                    data    = model_.feature_importances_,\n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['rmse_'+str(fold+1)] = rmse\n",
    "            feature_imp = pd.concat([feature_imp, feat_imp], axis=1)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())\n",
    "            msg = '[Fold {}] RMSE: {:2.2f} - MAE: {:2.2f} - MAPE: {:2.2f}  - {}'\n",
    "            print(msg.format(fold+1, rmse, mae, mape, time_fold_end))\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Salvar o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler' : scaler_, \n",
    "                         'fold'   : fold+1, \n",
    "                         'model'  : model_ }\n",
    "            \n",
    "            model.append(dic_model)\n",
    "        \n",
    "        df_preds           = pd.DataFrame(second_level, columns=cols_sencond_level)\n",
    "        df_preds['scaler'] = string_scaler\n",
    "        \n",
    "        for col in ['fold', 'idx_fold', 'y', 'y_pred']:\n",
    "            df_preds[col] = df_preds[col].astype(np.int)\n",
    "        \n",
    "        score_mean     = np.mean(score) \n",
    "        score_std      = np.std(score)\n",
    "        score_mae_mean = np.mean(score_mae)\n",
    "        \n",
    "        if score_mean > acc_best:     \n",
    "            acc_best    = score_mean           \n",
    "            model_best  = model_    \n",
    "            scaler_best = scaler_\n",
    "\n",
    "        time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        msg ='[Mean Fold] RMSE: {:2.2f} std: {:2.2f} - MAE {:2.2f} - {}'\n",
    "        \n",
    "        print('-'*taco)        \n",
    "        print(msg.format(score_mean,score_std, score_mae_mean, time_end))\n",
    "        print('='*taco)\n",
    "        print()\n",
    "                                         \n",
    "        # Salvar as predições\n",
    "        if save_submission_:        \n",
    "            y_pred_test_oof = np.int64(y_pred_test_oof)\n",
    "            save_data_model(model_             = model_, \n",
    "                            model_name_        = model_name_+'_score_{:2.5f}_seed_{}_'+str(scaler_).lower()[:4], \n",
    "                            path_              = path_,                             \n",
    "                            df_                = df_preds,          # stacking\n",
    "                            y_pred_test_prob_  = y_pred_test_oof,   # stacking \n",
    "                            y_pred_test_subm_  = y_pred_test_oof,   # sumission \n",
    "                            score_             = score_mean, \n",
    "                            seed_              = seed_, \n",
    "                            level_             = level_, \n",
    "                            target_            = target_, \n",
    "                            cutoff_value_      = cutoff_value_save_) \n",
    "            \n",
    "    print('-'*taco)\n",
    "    print('Scaler Best: {}'.format(scaler_best))\n",
    "    print('Score      : {:2.2f}'.format(acc_best))\n",
    "    print('-'*taco)\n",
    "    print()\n",
    "    \n",
    "    free_gpu_cache()\n",
    "    \n",
    "    return model, df_preds , feature_imp , val_idx, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76f1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T05:02:28.570652Z",
     "start_time": "2022-06-25T05:02:28.563628Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_kfolds(folds, X_, y_):\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=12359)\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=12359)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kf.split(X_, y_)):   \n",
    "        idx  = {'trn_idx': trn_idx, 'val_idx': val_idx}\n",
    "        file = path + 'model/preds/folds/kf_folds_{}_{}.pkl.z'.format(folds,fold+1)\n",
    "        jb.dump(idx, file)\n",
    "        print('Fold: {}'.format(fold+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c9401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T05:02:28.933616Z",
     "start_time": "2022-06-25T05:02:28.900647Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "create_kfolds(5, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5cdff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T05:10:53.968221Z",
     "start_time": "2022-06-25T05:10:53.940224Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs_07[2][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a19af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T13:34:54.936944Z",
     "start_time": "2022-06-25T13:34:54.916982Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X      = dfs_06[2][0].drop(target, axis=1)\n",
    "y      = dfs_06[2][0][target]\n",
    "X_test = dfs_06[2][1]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size    = 0.2,\n",
    "                                                      shuffle      = True, \n",
    "                                                      random_state = 12359)\n",
    "X.shape, y.shape,  X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76123953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T14:40:39.611825Z",
     "start_time": "2022-06-25T14:38:45.146747Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed        = 12359\n",
    "eval_metric = ['rmse']                 \n",
    "scalers = [None \n",
    "           #QuantileTransformer(output_distribution='normal', random_state=0),\n",
    "           #StandardScaler(),\n",
    "           #RobustScaler(), \n",
    "           #MinMaxScaler(), \n",
    "           #MaxAbsScaler(),                     \n",
    "          ]               \n",
    "\n",
    "model_name = 'xgb_02_cv_05_folds'\n",
    "\n",
    "delete_files(model_name)\n",
    "\n",
    "model, df_preds, feature_imp, val_idx, y_val = \\\n",
    "    cross_val_model(model_           = model_gbr,\n",
    "                    model_name_      = model_name,\n",
    "                    X_               = X,\n",
    "                    y_               = y,\n",
    "                    X_test_          = X_test,\n",
    "                    target_          = target,\n",
    "                    scalers_         = scalers,\n",
    "                    fold_            = 30,\n",
    "                    lb_              = None,\n",
    "                    path_            = path,\n",
    "                    seed_            = seed, \n",
    "                    feature_scaler_  = None,                     \n",
    "                    save_submission_ = True, \n",
    "                    type_model_      = 2,\n",
    "                    transf_target_   = transf_sqrt,\n",
    "                    #train_with_created_folds_ = True\n",
    "                   )\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd602852",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = [(model_xgb, 'xgb_04_fe', 1), \n",
    "          (model_lgb, 'lgb_05_fe', 1),\n",
    "          (model_rf, 'rf_06_fe', 2), \n",
    "          (model_ext, 'ext_07_fe', 2),\n",
    "          (model_knn, 'knn_08_fe', 2), \n",
    "          (model_catb, 'ext_09_fe', 3),\n",
    "          (model_lasso, 'lasso_10_fe', 2), \n",
    "          (model_gbr, 'gbr_11_fe', 2)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7863e06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T13:40:23.206140Z",
     "start_time": "2022-06-25T13:40:23.193139Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, RepeatedKFold, KFold, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca767db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T18:29:09.255309Z",
     "start_time": "2022-06-25T18:06:04.868571Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fold_ = 50\n",
    "X_= X \n",
    "y_= y\n",
    "X_test_ = X_test\n",
    "model_  = model_gbr\n",
    "\n",
    "\n",
    "folds = KFold(n_splits=fold_, shuffle=True, random_state=12359)\n",
    "#folds = StratifiedKFold(n_splits=fold_, shuffle=True, random_state=12359)\n",
    "\n",
    "y_pred_test_oof = 0      \n",
    "second_level    = np.zeros((X_.shape[0], 5))        \n",
    "\n",
    "y_pred_test_oof = 0      \n",
    "second_level    = np.zeros((X_.shape[0], 5))  \n",
    "y_pred_test     = np.zeros(len(X_test_))   \n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_)): \n",
    "\n",
    "    X_trn, X_val = X_.iloc[trn_idx], X_.iloc[val_idx]\n",
    "    y_trn, y_val = y_.iloc[trn_idx], y_.iloc[val_idx] \n",
    "    \n",
    "    model_.fit(X_trn, y_trn,) \n",
    "    \n",
    "    y_pred_val = model_.predict(X_val) \n",
    "    \n",
    "    rmse = metrics.mean_squared_error(y_val, y_pred_val, squared=False) \n",
    "    \n",
    "    y_pred_test_oof+=rmse\n",
    "    print('RMSE: {:2.2f}'.format(rmse))\n",
    "    \n",
    "print('M. RMSE: {:2.2f}'.format(y_pred_test_oof/fold_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e358ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T18:05:52.294299Z",
     "start_time": "2022-06-25T18:05:52.283368Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dd1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T18:05:37.252591Z",
     "start_time": "2022-06-25T18:05:37.242629Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mae_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb306c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explicação_variância'\n",
    "\n",
    "metrics.explained_variance_score\n",
    "\n",
    "'max_error'\n",
    "\n",
    "metrics.max_error\n",
    "\n",
    "'neg_mean_absolute_error'\n",
    "\n",
    "metrics.mean_absolute_error\n",
    "\n",
    "neg_mean_squared_error'\n",
    "neg_mean_squared_error\n",
    "\n",
    "metrics.mean_squared_error\n",
    "\n",
    "'neg_root_mean_squared_error'\n",
    "\n",
    "metrics.mean_squared_error\n",
    "\n",
    "'neg_mean_squared_log_error'\n",
    "\n",
    "metrics.mean_squared_log_error\n",
    "\n",
    "'neg_median_absolute_error'\n",
    "\n",
    "metrics.median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6030da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:33:13.642267Z",
     "start_time": "2022-06-26T03:33:13.613284Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "      \n",
    "                      \n",
    "            if transf_target_ is not None:                     \n",
    "                transf_target_.fit(y_trn.values.reshape(-1,1))\n",
    "                y_trn       = transf_target_.transform(y_trn.values.reshape(-1,1))\n",
    "                y_val_trasf = transf_target_.transform(y_val.values.reshape(-1,1)) \n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Processamento \n",
    "            # ---------------------------------------------------- \n",
    "            X_tst = X_test_.copy()\n",
    "            \n",
    "            if scaler_!=None: \n",
    "                if feature_scaler_!=None:                     \n",
    "                    X_trn[feature_scaler_] = scaler_.fit_transform(X_trn[feature_scaler_])\n",
    "                    X_val[feature_scaler_] = scaler_.transform(X_val[feature_scaler_])                      \n",
    "                    X_tst[feature_scaler_] = scaler_.transform(X_tst[feature_scaler_])\n",
    "                else:            \n",
    "                    X_trn = scaler_.fit_transform(X_trn)\n",
    "                    X_val = scaler_.transform(X_val)\n",
    "                    X_tst = scaler_.transform(X_tst.copy())\n",
    "                \n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------     \n",
    "            if type_model_==1:\n",
    "                model_.fit(X_trn, y_trn,\n",
    "                           eval_set              = [(X_trn, y_trn), (X_val, y_val_trasf)],          \n",
    "                           early_stopping_rounds = int(n_estimators*.1),\n",
    "                           verbose               = False)\n",
    "                \n",
    "            if type_model_==2: \n",
    "                model_.fit(X_trn, y_trn,) \n",
    "                    \n",
    "            if type_model_==3:    \n",
    "                model_.fit(X_trn, y_trn,\n",
    "                           eval_set       = [(X_trn, y_trn), (X_val, y_val_trasf)],      \n",
    "                           use_best_model = True,                            \n",
    "                           verbose        = False)\n",
    "                                        \n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------                 \n",
    "            y_pred_val       = model_.predict(X_val) #, ntree_limit=model_.best_ntree_limit)\n",
    "            y_pred_test_oof += model_.predict(X_tst) / fold_\n",
    "                       \n",
    "            if transf_target_ is not None:                       \n",
    "                y_pred_val = transf_target_.inverse_transform(pd.DataFrame(y_pred_val))\n",
    "                #y_pred_ts = transf_target_.inverse_transform(pd.DataFrame(y_pred_ts))\n",
    "\n",
    "            #y_pred_vl = np.int64(y_pred_vl) \n",
    "            #y_pred_ts = np.int64(y_pred_ts)\n",
    "                \n",
    "                \n",
    "            second_level[val_idx, 0] = fold+1 \n",
    "            second_level[val_idx, 1] = val_idx \n",
    "            second_level[val_idx, 2] = val_idx #y_val.values\n",
    "            second_level[val_idx, 3] = val_idx # y_pred_val \n",
    "            second_level[val_idx, 4] = val_idx #np.int64(y_val.values - y_pred_val) \n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ----------------------------------------------------                         \n",
    "            rmse, mae, mse, mape, r_squared = evaluation(y_val, y_pred_val)  \n",
    "                       \n",
    "            score.append(rmse)     \n",
    "            score_mae.append(mae)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_.columns,\n",
    "                                    data    = model_.feature_importances_,\n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['rmse_'+str(fold+1)] = rmse\n",
    "            feature_imp = pd.concat([feature_imp, feat_imp], axis=1)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())\n",
    "            msg = '[Fold {}] RMSE: {:2.2f} - MAE: {:2.2f} - MAPE: {:2.2f}  - {}'\n",
    "            print(msg.format(fold+1, rmse, mae, mape, time_fold_end))\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Salvar o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler' : scaler_, \n",
    "                         'fold'   : fold+1, \n",
    "                         'model'  : model_ }\n",
    "            \n",
    "            model.append(dic_model)\n",
    "        \n",
    "        df_preds           = pd.DataFrame(second_level, columns=cols_sencond_level)\n",
    "        df_preds['scaler'] = string_scaler\n",
    "        \n",
    "        for col in ['fold', 'idx_fold', 'y', 'y_pred']:\n",
    "            df_preds[col] = df_preds[col].astype(np.int)\n",
    "        \n",
    "        score_mean     = np.mean(score) \n",
    "        score_std      = np.std(score)\n",
    "        score_mae_mean = np.mean(score_mae)\n",
    "        \n",
    "        if score_mean > acc_best:     \n",
    "            acc_best    = score_mean           \n",
    "            model_best  = model_    \n",
    "            scaler_best = scaler_\n",
    "\n",
    "        time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        msg ='[Mean Fold] RMSE: {:2.2f} std: {:2.2f} - MAE {:2.2f} - {}'\n",
    "        \n",
    "        print('-'*taco)        \n",
    "        print(msg.format(score_mean,score_std, score_mae_mean, time_end))\n",
    "        print('='*taco)\n",
    "        print()\n",
    "                                         \n",
    "        # Salvar as predições\n",
    "        if save_submission_:        \n",
    "            y_pred_test_oof = np.int64(y_pred_test_oof)\n",
    "            save_data_model(model_             = model_, \n",
    "                            model_name_        = model_name_+'_score_{:2.5f}_seed_{}_'+str(scaler_).lower()[:4], \n",
    "                            path_              = path_,                             \n",
    "                            df_                = df_preds,          # stacking\n",
    "                            y_pred_test_prob_  = y_pred_test_oof,   # stacking \n",
    "                            y_pred_test_subm_  = y_pred_test_oof,   # sumission \n",
    "                            score_             = score_mean, \n",
    "                            seed_              = seed_, \n",
    "                            level_             = level_, \n",
    "                            target_            = target_, \n",
    "                            cutoff_value_      = cutoff_value_save_) \n",
    "            \n",
    "    print('-'*taco)\n",
    "    print('Scaler Best: {}'.format(scaler_best))\n",
    "    print('Score      : {:2.2f}'.format(acc_best))\n",
    "    print('-'*taco)\n",
    "    print()\n",
    "    \n",
    "    free_gpu_cache()\n",
    "    \n",
    "    return model, df_preds , feature_imp , val_idx, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4642e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd32e433",
   "metadata": {},
   "source": [
    "# nEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b36f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:36:22.594663Z",
     "start_time": "2022-06-26T03:36:22.581666Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf197c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T03:37:36.039976Z",
     "start_time": "2022-06-26T03:37:36.019978Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59eded8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T04:04:26.641473Z",
     "start_time": "2022-06-26T03:59:46.422530Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df3_tr_03_one_hot_07     = dfs_06[2][0].copy()\n",
    "df3_ts_03_one_hot_07     = dfs_06[2][1].copy()\n",
    "\n",
    "X = df3_tr_03_one_hot_07.drop(target, axis=1)\n",
    "y = df3_tr_03_one_hot_07[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "y_train = feature_winsorize_target(y_tr_= y_train, perc_upper_limit_= .98)\n",
    "\n",
    "\n",
    "models = []\n",
    "#models.append((\"Lasso\", linear_model.Lasso(alpha=0.1)))\n",
    "\n",
    "models.append((\"XGB\", model_xgb))\n",
    "models.append((\"LGBM\", model_lgb))\n",
    "models.append((\"Catboost\", model_catb))\n",
    "\n",
    "#models.append((\"GradientBoosting\", GradientBoostingRegressor()))\n",
    "\n",
    "\n",
    "\n",
    "estimators = [('xgb', model_xgb),\n",
    "              ('lgbm', model_lgb),\n",
    "              ('catb', model_catb), \n",
    "              ('gbr', model_gbr)]\n",
    "\n",
    "models = [(model_xgb, 'xgb', 1), \n",
    "          (model_lgb, 'lgb', 1),\n",
    "          (model_catb, 'cat', 3), \n",
    "          (model_gbr, 'gbr', 2)\n",
    "          \n",
    "models.append((\"StackingRegressor\", StackingRegressor(estimators=estimators, final_estimator=model_lgb)))\n",
    "\n",
    "results = []\n",
    "names   = []\n",
    "          \n",
    "for name,model in models:\n",
    "          \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    result = metrics.mean_squared_error(y_test, y_pred, squared=False) \n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "\n",
    "for i in range(len(names)):    \n",
    "    print(names[i],results[i].mean())\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f487073",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model: XGBRegressor              RMSE: 230.11 \n",
    "Model: LGBMRegressor             RMSE: 235.07 \n",
    "Model: CatBoostRegressor         RMSE: 211.56 \n",
    "Model: GradientBoostingRegressor RMSE: 224.58 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5194d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T04:55:49.502716Z",
     "start_time": "2022-06-26T04:55:49.473716Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f723a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T04:56:25.169026Z",
     "start_time": "2022-06-26T04:56:25.152028Z"
    }
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def rmse_cv(modelo):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=12359).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69335dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:16:18.713795Z",
     "start_time": "2022-06-26T04:56:25.714545Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "rmse = rmse_cv(model_catb)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e0bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:16:18.729796Z",
     "start_time": "2022-06-26T05:16:18.717796Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    # we define clones of the original models to fit the data in\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        return np.mean(predictions, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e6e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:16:18.761797Z",
     "start_time": "2022-06-26T05:16:18.732802Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb6ac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:16:18.792795Z",
     "start_time": "2022-06-26T05:16:18.765797Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "averaged_models = AveragingModels(models = (model_xgb, model_lgb, model_catb, model_gbr))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f}n\".format(score.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeaa8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T05:16:18.808795Z",
     "start_time": "2022-06-26T05:16:18.795800Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "stacked_averaged_models = StackingAveragedModels(base_models=(model_xgb, model_lgb, model_catb, model_gbr),\n",
    "                                                 meta_model =model_gbr)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd6f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efedcd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8fbfb0dc",
    "4e0c4c3e",
    "e403ddc8",
    "3bb4d222",
    "6ccf4873",
    "87f37535",
    "8f3f951a",
    "94e98bd9",
    "a2a11987",
    "8119e582",
    "df14f604",
    "3d85ab20",
    "f1aa2d3d",
    "602980ad",
    "e4f16aa2",
    "4ab4607b",
    "ae48fe99",
    "544e5ba5",
    "1695b88b",
    "fcccc9c4",
    "12c44033"
   ],
   "machine_shape": "hm",
   "name": "02 - Features Engineering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "pt-br"
   ],
   "hotkey": "",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt-br",
   "useGoogleTranslate": true
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1855.87013,
   "end_time": "2022-02-13T04:19:37.763339",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-13T03:48:41.893209",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
