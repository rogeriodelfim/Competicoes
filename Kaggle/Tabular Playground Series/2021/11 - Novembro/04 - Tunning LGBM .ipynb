{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFogj-Cdi34f"
   },
   "source": [
    "<h1 div class='alert alert-success'><center> Tunning Hyperparameters LGBM\n",
    "    \n",
    "\n",
    " </center></h1>\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKJFMrjqi34j"
   },
   "source": [
    "# <div class=\"alert alert-success\">  1. INSTALAÇÕES </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12667,
     "status": "ok",
     "timestamp": 1638138532742,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "U2CKimxvi34k",
    "outputId": "6b6d6c52-b74c-4c51-e130-ec79e77733f6"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet optuna\n",
    "!pip install --q GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opkjnk7KXBEL"
   },
   "source": [
    "## 1.1. Preparar ambiente para LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16632,
     "status": "ok",
     "timestamp": 1638138557867,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "0AN-U-kEW_wr",
    "outputId": "2f966a35-e68e-4c4c-d64b-4089754a312f"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/58707252/get-lightgbm-lgbm-run-with-gpu-on-google-colabratory\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82858,
     "status": "ok",
     "timestamp": 1638138694547,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "pBcwOzaYXnaz",
    "outputId": "eab2213b-7d0f-410e-92cd-1f4173ebb250"
   },
   "outputs": [],
   "source": [
    "%cd LightGBM\n",
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ../../LightGBM\n",
    "!make -j4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16444,
     "status": "ok",
     "timestamp": 1638138710964,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "buK0JQGIYYx1",
    "outputId": "175d43ab-45ce-46bf-fb63-1ee394d0ed60"
   },
   "outputs": [],
   "source": [
    "!git clone --recursive https://github.com/Microsoft/LightGBM.git\n",
    "%cd LightGBM/python-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96367,
     "status": "ok",
     "timestamp": 1638138814752,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "AOs3wRVDSKGF",
    "outputId": "eb27fab8-0d3c-424c-c4f4-732b4db75a5f"
   },
   "outputs": [],
   "source": [
    "!python3 setup.py install --gpu\n",
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15522,
     "status": "ok",
     "timestamp": 1638138830073,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Q0FLVEmxRce2",
    "outputId": "152de40f-5e66-413f-dca5-885a75e6f978"
   },
   "outputs": [],
   "source": [
    "! git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LQl7exNRdiL",
    "outputId": "8a412df2-35b5-477b-bf08-a645feec5b7a"
   },
   "outputs": [],
   "source": [
    "! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvzaUsMGSm6V"
   },
   "source": [
    "# 1.1. IMPORTAÇÕES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckrEOEuUi34l"
   },
   "source": [
    "## 0.1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:22:44.534193Z",
     "start_time": "2021-11-29T00:22:36.892148Z"
    },
    "id": "icBhRH0Si34m"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import glob\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:22:45.701191Z",
     "start_time": "2021-11-29T00:22:45.443193Z"
    },
    "id": "OjwX36f3i34m"
   },
   "outputs": [],
   "source": [
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import matplotlib.pyplot    as plt \n",
    "import seaborn              as sns\n",
    "import joblib               as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:04.485193Z",
     "start_time": "2021-11-29T00:22:46.596194Z"
    },
    "id": "xyxT1_-ei34n"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn             as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:06.448192Z",
     "start_time": "2021-11-29T00:23:04.488192Z"
    },
    "id": "me4iqeW8i34o"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm             as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:06.479193Z",
     "start_time": "2021-11-29T00:23:06.450192Z"
    },
    "id": "RM2RI3_ti34p"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection       import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing         import QuantileTransformer,  KBinsDiscretizer, StandardScaler\n",
    "from sklearn.preprocessing         import RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn                       import metrics\n",
    "from sklearn.feature_selection     import SelectKBest, SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:06.510194Z",
     "start_time": "2021-11-29T00:23:06.482193Z"
    },
    "id": "IMnB1bcOi34p"
   },
   "outputs": [],
   "source": [
    "from optuna.samplers               import TPESampler\n",
    "from optuna.visualization          import plot_edf\n",
    "from optuna.visualization          import plot_optimization_history\n",
    "from optuna.visualization          import plot_parallel_coordinate\n",
    "from optuna.visualization          import plot_param_importances\n",
    "from optuna.visualization          import plot_slice\n",
    "from optuna.visualization          import plot_intermediate_values\n",
    "from optuna.visualization          import plot_contour\n",
    "from optuna.pruners                import MedianPruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.552192Z",
     "start_time": "2021-11-29T00:23:06.512192Z"
    },
    "id": "rxIrWu38i34q"
   },
   "outputs": [],
   "source": [
    "from GPUtil                        import showUtilization as gpu_usage\n",
    "from numba                         import cuda\n",
    "from sklearn.ensemble              import IsolationForest\n",
    "from psutil                        import virtual_memory\n",
    "from datetime                      import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwyizAfdi34r"
   },
   "source": [
    "## 0.2. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.583192Z",
     "start_time": "2021-11-29T00:23:07.554193Z"
    },
    "id": "1vHZjDzgi34r"
   },
   "outputs": [],
   "source": [
    "def jupyter_setting():\n",
    "    \n",
    "    %matplotlib inline\n",
    "     \n",
    "    pd.options.display.max_columns = None\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "      \n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    warnings.simplefilter('ignore')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    #pd.set_option('display.max_rows', 150)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "    #sns.palplot(sns.color_palette(icecream))\n",
    "    \n",
    "    return icecream\n",
    "\n",
    "icecream = jupyter_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.599194Z",
     "start_time": "2021-11-29T00:23:07.585193Z"
    },
    "id": "m-u-wKS5i34s"
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.663196Z",
     "start_time": "2021-11-29T00:23:07.601195Z"
    },
    "id": "oT4xvNQxi34t"
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision Recall vs threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.678193Z",
     "start_time": "2021-11-29T00:23:07.666191Z"
    },
    "id": "OzJVgUuTi34u"
   },
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n",
    "    \n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision vs recall')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.725192Z",
     "start_time": "2021-11-29T00:23:07.681194Z"
    },
    "id": "51KsDDGLi34u"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for TPS 09')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.820193Z",
     "start_time": "2021-11-29T00:23:07.727194Z"
    },
    "id": "3gf0D8QLi34u"
   },
   "outputs": [],
   "source": [
    "def graf_corr(df):\n",
    "    \n",
    "    df = df.corr().round(5)\n",
    "\n",
    "    # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "    mask = np.zeros_like(df)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Making a plot\n",
    "    plt.figure(figsize=(16,16))\n",
    "    ax = sns.heatmap(df, annot=True, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n",
    "\n",
    "    ax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), \n",
    "             rotation      = 90, \n",
    "             ha            = \"right\",\n",
    "             rotation_mode = \"anchor\", \n",
    "             weight        = \"normal\")\n",
    "\n",
    "    plt.setp(ax.get_yticklabels(), \n",
    "             weight        = \"normal\",\n",
    "             rotation_mode = \"anchor\", \n",
    "             rotation      = 0, \n",
    "             ha            = \"right\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.836193Z",
     "start_time": "2021-11-29T00:23:07.822191Z"
    },
    "executionInfo": {
     "elapsed": 7794,
     "status": "ok",
     "timestamp": 1638141560894,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "YYXsmuJwi34u"
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "\n",
    "    col_corr    = set()  # Conjunto de todos os nomes de colunas correlacionadas\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold: # estamos interessados no valor coeficiente absoluto\n",
    "                colname = corr_matrix.columns[i]        # obtendo o nome da coluna\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:07.851192Z",
     "start_time": "2021-11-29T00:23:07.838192Z"
    },
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1638141562131,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "GuS0Lh52i34v"
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    \n",
    "    # https://www.kaggle.com/getting-started/140636\n",
    "    #print(\"Initial GPU Usage\")\n",
    "    #gpu_usage()                             \n",
    "\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)   \n",
    "    gc.enable()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puAI82JpDOJO"
   },
   "source": [
    "## 0.3. GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iISld6GaDyRM"
   },
   "source": [
    "### 0.3.1. Informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:08.635196Z",
     "start_time": "2021-11-29T00:23:07.853192Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 398,
     "status": "ok",
     "timestamp": 1638139202638,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Je1LG7eeDL1s",
    "outputId": "12ce5da7-525c-4f5a-f1ba-d0e2217759e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 28 21:23:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.06       Driver Version: 510.06       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   65C    P8    N/A /  N/A |   1008MiB /  4096MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1228    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A      4352    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      5884    C+G   ...afe Family\\SafeFamily.exe    N/A      |\n",
      "|    0   N/A  N/A     10768    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     11696    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11744    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     11788    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     11944    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14364    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     14816    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     21772    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     29184    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     34236    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     44072    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     64072    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     94492    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWJ4r84ZEAIM"
   },
   "source": [
    "## 0.3.2. Memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:08.651198Z",
     "start_time": "2021-11-29T00:23:08.637194Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1638139204167,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OVohZ_xSD33t",
    "outputId": "5d7b0bdf-1cba-44c9-de98-57d53fdbc1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 17.0 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "ram_gb = virtual_memory().total / 1e9\n",
    "\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_PfcxeGi34v"
   },
   "source": [
    "## 0.4. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178930,
     "status": "ok",
     "timestamp": 1638139538586,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "D_QC_2_bprhF",
    "outputId": "e1fda8cd-3b03-4b32-d37b-4efa2cbeff3d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:08.667196Z",
     "start_time": "2021-11-29T00:23:08.654191Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1638139543228,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "UaT5Rgjli34v"
   },
   "outputs": [],
   "source": [
    "path   = '/content/drive/MyDrive/kaggle/Tabular Playground Series/2021/11 - Novembro/'\n",
    "path   = ''\n",
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:25.988286Z",
     "start_time": "2021-11-29T00:23:09.596191Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8061,
     "status": "ok",
     "timestamp": 1638139551284,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Ar5Fty2Ei34v",
    "outputId": "a2bfa2b0-bc33-49c5-a6ca-6e8e3e3a7145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 111), (540000, 110), (540000, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train     = jb.load(path + 'Data/pkl/df2_nb_02_train.pkl.z')\n",
    "df3_test      = jb.load(path + 'Data/pkl/df2_nb_02_test.pkl.z')\n",
    "df_submission = pd.read_csv(path + 'Data/sample_submission.csv')\n",
    "\n",
    "df3_train.shape, df3_test.shape, df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:26.576287Z",
     "start_time": "2021-11-29T00:23:25.997285Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1638139551710,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "-qfjHtY0i34w",
    "outputId": "f36faaab-5205-4586-c4e1-7408b8d12d82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>f78</th>\n",
       "      <th>f79</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>f88</th>\n",
       "      <th>f89</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>target</th>\n",
       "      <th>fe_cluster_0</th>\n",
       "      <th>fe_cluster_1</th>\n",
       "      <th>fe_cluster_2</th>\n",
       "      <th>fe_cluster_3</th>\n",
       "      <th>fe_cluster_4</th>\n",
       "      <th>fe_mean</th>\n",
       "      <th>fe_median</th>\n",
       "      <th>fe_min</th>\n",
       "      <th>fe_max</th>\n",
       "      <th>fe_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106628</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>132.7500</td>\n",
       "      <td>3.183594</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>1.188477</td>\n",
       "      <td>3.732422</td>\n",
       "      <td>2.265625</td>\n",
       "      <td>2.099609</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>1.607422</td>\n",
       "      <td>-0.318115</td>\n",
       "      <td>0.560059</td>\n",
       "      <td>2.806641</td>\n",
       "      <td>1.351562</td>\n",
       "      <td>2.535156</td>\n",
       "      <td>0.197510</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>1.990234</td>\n",
       "      <td>-3.841797</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.230347</td>\n",
       "      <td>3.330078</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>3.050781</td>\n",
       "      <td>1.303711</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>-0.018280</td>\n",
       "      <td>2.748047</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>-0.036285</td>\n",
       "      <td>-0.049866</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>3.898438</td>\n",
       "      <td>11.289062</td>\n",
       "      <td>1.137695</td>\n",
       "      <td>3.367188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>2.113281</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>0.789551</td>\n",
       "      <td>1.113281</td>\n",
       "      <td>1.491211</td>\n",
       "      <td>2.439453</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.053680</td>\n",
       "      <td>1.701172</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.094910</td>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>4.445312</td>\n",
       "      <td>1.586914</td>\n",
       "      <td>-0.068665</td>\n",
       "      <td>-0.108276</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.046112</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>-0.027557</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>-0.048828</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>3.728516</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>0.167603</td>\n",
       "      <td>0.039764</td>\n",
       "      <td>2.042969</td>\n",
       "      <td>-0.016617</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>3.507812</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>-0.097046</td>\n",
       "      <td>5.394531</td>\n",
       "      <td>0.244507</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>0.113098</td>\n",
       "      <td>-0.015472</td>\n",
       "      <td>4.207031</td>\n",
       "      <td>4.105469</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>-0.118835</td>\n",
       "      <td>0.067078</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>-0.011719</td>\n",
       "      <td>0.052765</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>1.978516</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.240479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650391</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-3.841797</td>\n",
       "      <td>132.7500</td>\n",
       "      <td>9.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.673828</td>\n",
       "      <td>76.5625</td>\n",
       "      <td>3.378906</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.275391</td>\n",
       "      <td>-0.471436</td>\n",
       "      <td>4.546875</td>\n",
       "      <td>0.037720</td>\n",
       "      <td>0.331787</td>\n",
       "      <td>0.325195</td>\n",
       "      <td>0.062042</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>-0.224976</td>\n",
       "      <td>0.233643</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>1.903320</td>\n",
       "      <td>0.067871</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.006134</td>\n",
       "      <td>2.603516</td>\n",
       "      <td>0.103455</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>4.753906</td>\n",
       "      <td>1.855469</td>\n",
       "      <td>-0.181885</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>3.166016</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.117126</td>\n",
       "      <td>0.315186</td>\n",
       "      <td>24.484375</td>\n",
       "      <td>1.671875</td>\n",
       "      <td>-0.409180</td>\n",
       "      <td>4.953125</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>2.603516</td>\n",
       "      <td>1.955078</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>3.289062</td>\n",
       "      <td>2.564453</td>\n",
       "      <td>0.817871</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>4.617188</td>\n",
       "      <td>1.575195</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.183472</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>2.746094</td>\n",
       "      <td>0.835449</td>\n",
       "      <td>0.188232</td>\n",
       "      <td>4.960938</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>-0.015266</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.064575</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>0.093628</td>\n",
       "      <td>0.963867</td>\n",
       "      <td>0.630371</td>\n",
       "      <td>4.308594</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>-0.036346</td>\n",
       "      <td>3.617188</td>\n",
       "      <td>3.103516</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.924805</td>\n",
       "      <td>0.123291</td>\n",
       "      <td>-0.022675</td>\n",
       "      <td>1.547852</td>\n",
       "      <td>-0.010399</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>3.662109</td>\n",
       "      <td>-0.118408</td>\n",
       "      <td>2.357422</td>\n",
       "      <td>-0.009109</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>4.097656</td>\n",
       "      <td>3.533203</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.121399</td>\n",
       "      <td>0.109985</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.124878</td>\n",
       "      <td>0.154053</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>-0.267822</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>-0.020874</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.136719</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>-0.471436</td>\n",
       "      <td>76.5625</td>\n",
       "      <td>8.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036316</td>\n",
       "      <td>1.497070</td>\n",
       "      <td>233.5000</td>\n",
       "      <td>2.195312</td>\n",
       "      <td>0.026917</td>\n",
       "      <td>3.126953</td>\n",
       "      <td>5.058594</td>\n",
       "      <td>3.849609</td>\n",
       "      <td>1.801758</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.328613</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>5.308594</td>\n",
       "      <td>1.354492</td>\n",
       "      <td>-0.261963</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.480469</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>-0.008804</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>1.683594</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>3.572266</td>\n",
       "      <td>0.120605</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>2.234375</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.502930</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>1.417969</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>3.222656</td>\n",
       "      <td>2.121094</td>\n",
       "      <td>3.082031</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>-0.006821</td>\n",
       "      <td>-0.390869</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>3.701172</td>\n",
       "      <td>-0.033600</td>\n",
       "      <td>1.578125</td>\n",
       "      <td>0.051971</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>2.691406</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>0.111389</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>-0.324951</td>\n",
       "      <td>-0.019943</td>\n",
       "      <td>3.455078</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.009811</td>\n",
       "      <td>-0.010628</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>-0.048920</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>1.865234</td>\n",
       "      <td>2.404297</td>\n",
       "      <td>0.411621</td>\n",
       "      <td>0.057739</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>2.167969</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>4.949219</td>\n",
       "      <td>-0.010979</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>0.266846</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>3.847656</td>\n",
       "      <td>-0.121460</td>\n",
       "      <td>3.740234</td>\n",
       "      <td>0.147095</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>0.614746</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>0.979980</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>0.085205</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>0.116089</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.520020</td>\n",
       "      <td>2.140625</td>\n",
       "      <td>0.124451</td>\n",
       "      <td>0.148193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.814453</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>-0.520020</td>\n",
       "      <td>233.5000</td>\n",
       "      <td>9.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014076</td>\n",
       "      <td>0.245972</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>1.890625</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>2.697266</td>\n",
       "      <td>4.515625</td>\n",
       "      <td>4.503906</td>\n",
       "      <td>0.123474</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>4.871094</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>2.498047</td>\n",
       "      <td>1.238281</td>\n",
       "      <td>2.347656</td>\n",
       "      <td>0.175415</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>2.029297</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>1.651367</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>4.238281</td>\n",
       "      <td>-0.032837</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>0.097473</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>25.375000</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>2.025391</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>1.085938</td>\n",
       "      <td>1.710938</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>0.034637</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>71.437500</td>\n",
       "      <td>3.035156</td>\n",
       "      <td>0.092224</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.029221</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.164307</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.110901</td>\n",
       "      <td>0.026840</td>\n",
       "      <td>2.931641</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.495117</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>2.242188</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>-0.139282</td>\n",
       "      <td>4.742188</td>\n",
       "      <td>3.292969</td>\n",
       "      <td>0.117859</td>\n",
       "      <td>0.065613</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>-0.058044</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>0.068542</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>4.070312</td>\n",
       "      <td>-0.008835</td>\n",
       "      <td>3.896484</td>\n",
       "      <td>0.913574</td>\n",
       "      <td>-0.163208</td>\n",
       "      <td>3.074219</td>\n",
       "      <td>4.355469</td>\n",
       "      <td>-0.048889</td>\n",
       "      <td>4.917969</td>\n",
       "      <td>0.069946</td>\n",
       "      <td>-0.015350</td>\n",
       "      <td>3.474609</td>\n",
       "      <td>-0.017105</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.044861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.859375</td>\n",
       "      <td>0.180420</td>\n",
       "      <td>-0.495117</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>9.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003260</td>\n",
       "      <td>3.714844</td>\n",
       "      <td>156.1250</td>\n",
       "      <td>2.148438</td>\n",
       "      <td>0.018280</td>\n",
       "      <td>2.097656</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>3.371094</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.711426</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>3.710938</td>\n",
       "      <td>5.464844</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>2.617188</td>\n",
       "      <td>1.383789</td>\n",
       "      <td>0.074890</td>\n",
       "      <td>-0.010544</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>2.275391</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>4.359375</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>4.054688</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>3.402344</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>1.635742</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>4.019531</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>5.289062</td>\n",
       "      <td>4.117188</td>\n",
       "      <td>0.072144</td>\n",
       "      <td>2.751953</td>\n",
       "      <td>3.171875</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>-0.105835</td>\n",
       "      <td>3.320312</td>\n",
       "      <td>0.090698</td>\n",
       "      <td>0.112915</td>\n",
       "      <td>4.621094</td>\n",
       "      <td>0.126831</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>4.707031</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>2.972656</td>\n",
       "      <td>0.115356</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.075562</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>-0.042297</td>\n",
       "      <td>0.047974</td>\n",
       "      <td>-0.294189</td>\n",
       "      <td>5.066406</td>\n",
       "      <td>1.049805</td>\n",
       "      <td>0.034027</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.263672</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>-0.023300</td>\n",
       "      <td>5.617188</td>\n",
       "      <td>0.086243</td>\n",
       "      <td>0.157593</td>\n",
       "      <td>3.726562</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.086609</td>\n",
       "      <td>0.607422</td>\n",
       "      <td>1.411133</td>\n",
       "      <td>2.060547</td>\n",
       "      <td>-0.023148</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.914551</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>0.375732</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>1.910156</td>\n",
       "      <td>-0.042938</td>\n",
       "      <td>0.105591</td>\n",
       "      <td>0.125122</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>1.075195</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>0.072815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949219</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>-0.294189</td>\n",
       "      <td>156.1250</td>\n",
       "      <td>9.710938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.106628  3.593750  132.7500  3.183594  0.081970  1.188477  3.732422   \n",
       "1  0.125000  1.673828   76.5625  3.378906  0.099426  5.093750  1.275391   \n",
       "2  0.036316  1.497070  233.5000  2.195312  0.026917  3.126953  5.058594   \n",
       "3 -0.014076  0.245972  780.0000  1.890625  0.006947  1.531250  2.697266   \n",
       "4 -0.003260  3.714844  156.1250  2.148438  0.018280  2.097656  4.156250   \n",
       "\n",
       "         f7        f8        f9       f10       f11       f12       f13  \\\n",
       "0  2.265625  2.099609  0.012329  1.607422 -0.318115  0.560059  2.806641   \n",
       "1 -0.471436  4.546875  0.037720  0.331787  0.325195  0.062042  2.261719   \n",
       "2  3.849609  1.801758  0.057007  0.328613  2.968750  0.105225  2.070312   \n",
       "3  4.515625  4.503906  0.123474  1.002930  4.871094  0.058411  2.498047   \n",
       "4 -0.038239  3.371094  0.034180  0.711426  0.770020  0.057556  0.957031   \n",
       "\n",
       "        f14       f15       f16       f17       f18       f19       f20  \\\n",
       "0  1.351562  2.535156  0.197510  0.676270  1.990234 -3.841797  0.037384   \n",
       "1  4.339844 -0.224976  0.233643  3.380859  1.903320  0.067871 -0.051270   \n",
       "2  5.308594  1.354492 -0.261963  1.378906  1.480469  0.020538 -0.008804   \n",
       "3  1.238281  2.347656  0.175415  1.609375  2.029297  0.042084  0.005142   \n",
       "4  3.710938  5.464844  0.287109  2.617188  1.383789  0.074890 -0.010544   \n",
       "\n",
       "        f21       f22       f23       f24       f25       f26       f27  \\\n",
       "0  0.230347  3.330078  0.009399  0.144775  3.050781  1.303711  0.033234   \n",
       "1  0.006134  2.603516  0.103455  0.067627  4.753906  1.855469 -0.181885   \n",
       "2  0.109375  1.683594  0.038177  0.123718  1.112305  3.572266  0.120605   \n",
       "3  0.076477  1.651367  0.111816  0.121643  0.589355  4.238281 -0.032837   \n",
       "4  0.109131  2.275391  0.008026  0.045227  4.359375  5.074219 -0.009377   \n",
       "\n",
       "        f28       f29       f30       f31       f32       f33       f34  \\\n",
       "0 -0.018280  2.748047 -0.009293 -0.036285 -0.049866  0.019485  3.898438   \n",
       "1  0.008362  3.166016  0.011848  0.022293  0.069336  0.117126  0.315186   \n",
       "2  0.082092  2.234375  0.002270  0.045197  0.014404  0.011597 -0.502930   \n",
       "3  0.058167  0.712891  0.097473  0.072754  0.000324  0.063354  4.062500   \n",
       "4  0.528809  4.054688  0.020004  0.106812  0.051300  0.045929  3.402344   \n",
       "\n",
       "         f35       f36       f37       f38       f39       f40       f41  \\\n",
       "0  11.289062  1.137695  3.367188  4.945312 -0.105774  2.113281  3.453125   \n",
       "1  24.484375  1.671875 -0.409180  4.953125  0.092346  2.603516  1.955078   \n",
       "2  33.750000  1.417969  1.071289  3.222656  2.121094  3.082031  0.637695   \n",
       "3  25.375000  0.576660  2.025391  2.968750  1.085938  1.710938  1.372070   \n",
       "4  15.562500  1.635742  0.047028  4.019531  0.155762  5.289062  4.117188   \n",
       "\n",
       "        f42       f43        f44       f45       f46       f47       f48  \\\n",
       "0  0.789551  1.113281   1.491211  2.439453  0.041809  3.355469  0.053680   \n",
       "1  0.005898  3.289062   2.564453  0.817871  0.026001  4.617188  1.575195   \n",
       "2 -0.006821 -0.390869  17.343750  3.701172 -0.033600  1.578125  0.051971   \n",
       "3  0.034637  0.722656  71.437500  3.035156  0.092224  3.453125  0.044830   \n",
       "4  0.072144  2.751953   3.171875  0.693359 -0.105835  3.320312  0.090698   \n",
       "\n",
       "        f49       f50       f51       f52       f53       f54       f55  \\\n",
       "0  1.701172  0.908691  0.094910  0.030212  0.597168  4.445312  1.586914   \n",
       "1  0.066101  0.681641  0.025253  0.183472  0.110046  2.746094  0.835449   \n",
       "2 -0.002005  2.691406  0.018372 -0.030472  0.111389  2.187500 -0.324951   \n",
       "3  0.027191  4.082031  0.046967  0.063721  0.029221  0.671875  0.185303   \n",
       "4  0.112915  4.621094  0.126831  0.142700  0.055725  4.707031 -0.055115   \n",
       "\n",
       "        f56       f57       f58       f59       f60       f61       f62  \\\n",
       "0 -0.068665 -0.108276  0.061035  0.046112  0.017105 -0.027557  0.019485   \n",
       "1  0.188232  4.960938  0.136108 -0.008492 -0.015266 -0.010841  0.064575   \n",
       "2 -0.019943  3.455078  0.068115 -0.009811 -0.010628  0.027573 -0.007122   \n",
       "3  0.164307  3.804688  0.062317 -0.021408  0.009468  0.110901  0.026840   \n",
       "4  0.523926  2.972656  0.115356  0.125244  0.067444  0.075562  0.032104   \n",
       "\n",
       "        f63       f64       f65       f66       f67       f68       f69  \\\n",
       "0 -0.048828  0.050751  3.728516  5.015625  4.187500  0.063354  0.121033   \n",
       "1  0.102539  0.093628  0.963867  0.630371  4.308594  0.091309 -0.036346   \n",
       "2 -0.048920 -0.002575  1.865234  2.404297  0.411621  0.057739  0.525391   \n",
       "3  2.931641  0.068115 -0.495117  1.345703  2.242188  0.035614 -0.139282   \n",
       "4 -0.042297  0.047974 -0.294189  5.066406  1.049805  0.034027  0.024612   \n",
       "\n",
       "        f70       f71       f72       f73       f74       f75       f76  \\\n",
       "0  1.372070  4.015625  0.167603  0.039764  2.042969 -0.016617  0.107666   \n",
       "1  3.617188  3.103516  0.000657  0.051300  1.924805  0.123291 -0.022675   \n",
       "2  2.167969  0.828125  0.089844  0.093750  4.949219 -0.010979  0.076660   \n",
       "3  4.742188  3.292969  0.117859  0.065613  0.556641 -0.058044  0.070496   \n",
       "4  3.125000  2.263672  0.082458 -0.023300  5.617188  0.086243  0.157593   \n",
       "\n",
       "        f77       f78       f79       f80       f81       f82       f83  \\\n",
       "0  3.507812  0.013657 -0.097046  5.394531  0.244507  3.492188  0.113098   \n",
       "1  1.547852 -0.010399  0.058319  3.662109 -0.118408  2.357422 -0.009109   \n",
       "2  0.266846  0.038696  0.382812  3.847656 -0.121460  3.740234  0.147095   \n",
       "3  1.101562  0.068542  0.162964  4.070312 -0.008835  3.896484  0.913574   \n",
       "4  3.726562  0.061249  0.086609  0.607422  1.411133  2.060547 -0.023148   \n",
       "\n",
       "        f84       f85       f86       f87       f88       f89       f90  \\\n",
       "0 -0.015472  4.207031  4.105469  0.037231 -0.118835  0.067078  0.010742   \n",
       "1  0.178711  4.097656  3.533203  0.005245  0.121399  0.109985  0.135864   \n",
       "2 -0.016571  0.614746  2.125000  0.078857  0.979980  0.026764  0.117310   \n",
       "3 -0.163208  3.074219  4.355469 -0.048889  4.917969  0.069946 -0.015350   \n",
       "4  0.011238  2.156250  0.914551  0.044525  0.375732  0.134399  0.013779   \n",
       "\n",
       "        f91       f92       f93       f94       f95       f96       f97  \\\n",
       "0  1.098633  0.013329 -0.011719  0.052765  0.065430  4.210938  1.978516   \n",
       "1  3.460938  0.017059  0.124878  0.154053  0.606934 -0.267822  2.578125   \n",
       "2  4.882812  0.085205  0.032410  0.116089 -0.001689 -0.520020  2.140625   \n",
       "3  3.474609 -0.017105 -0.008102  0.062012  0.041199  0.511719  1.968750   \n",
       "4  1.910156 -0.042938  0.105591  0.125122  0.037506  1.043945  1.075195   \n",
       "\n",
       "        f98       f99  target  fe_cluster_0  fe_cluster_1  fe_cluster_2  \\\n",
       "0  0.085999  0.240479       0             1             0             0   \n",
       "1 -0.020874  0.024719       0             1             0             0   \n",
       "2  0.124451  0.148193       0             0             0             0   \n",
       "3  0.040009  0.044861       0             0             0             1   \n",
       "4 -0.012817  0.072815       1             1             0             0   \n",
       "\n",
       "   fe_cluster_3  fe_cluster_4   fe_mean  fe_median    fe_min    fe_max  \\\n",
       "0             0             0  2.650391   0.242432 -3.841797  132.7500   \n",
       "1             0             0  2.136719   0.145020 -0.471436   76.5625   \n",
       "2             0             1  3.814453   0.124084 -0.520020  233.5000   \n",
       "3             0             0  9.859375   0.180420 -0.495117  780.0000   \n",
       "4             0             0  2.949219   0.149170 -0.294189  156.1250   \n",
       "\n",
       "    fe_skew  \n",
       "0  9.687500  \n",
       "1  8.429688  \n",
       "2  9.609375  \n",
       "3  9.867188  \n",
       "4  9.710938  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:27.115284Z",
     "start_time": "2021-11-29T00:23:26.580280Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1638139551711,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "_JUntp99QiWX",
    "outputId": "61050dc1-0f46-4262-e031-4d900f0aeec5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>f32</th>\n",
       "      <th>f33</th>\n",
       "      <th>f34</th>\n",
       "      <th>f35</th>\n",
       "      <th>f36</th>\n",
       "      <th>f37</th>\n",
       "      <th>f38</th>\n",
       "      <th>f39</th>\n",
       "      <th>f40</th>\n",
       "      <th>f41</th>\n",
       "      <th>f42</th>\n",
       "      <th>f43</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>f65</th>\n",
       "      <th>f66</th>\n",
       "      <th>f67</th>\n",
       "      <th>f68</th>\n",
       "      <th>f69</th>\n",
       "      <th>f70</th>\n",
       "      <th>f71</th>\n",
       "      <th>f72</th>\n",
       "      <th>f73</th>\n",
       "      <th>f74</th>\n",
       "      <th>f75</th>\n",
       "      <th>f76</th>\n",
       "      <th>f77</th>\n",
       "      <th>f78</th>\n",
       "      <th>f79</th>\n",
       "      <th>f80</th>\n",
       "      <th>f81</th>\n",
       "      <th>f82</th>\n",
       "      <th>f83</th>\n",
       "      <th>f84</th>\n",
       "      <th>f85</th>\n",
       "      <th>f86</th>\n",
       "      <th>f87</th>\n",
       "      <th>f88</th>\n",
       "      <th>f89</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>target</th>\n",
       "      <th>fe_cluster_0</th>\n",
       "      <th>fe_cluster_1</th>\n",
       "      <th>fe_cluster_2</th>\n",
       "      <th>fe_cluster_3</th>\n",
       "      <th>fe_cluster_4</th>\n",
       "      <th>fe_mean</th>\n",
       "      <th>fe_median</th>\n",
       "      <th>fe_min</th>\n",
       "      <th>fe_max</th>\n",
       "      <th>fe_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106628</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>132.7500</td>\n",
       "      <td>3.183594</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>1.188477</td>\n",
       "      <td>3.732422</td>\n",
       "      <td>2.265625</td>\n",
       "      <td>2.099609</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>1.607422</td>\n",
       "      <td>-0.318115</td>\n",
       "      <td>0.560059</td>\n",
       "      <td>2.806641</td>\n",
       "      <td>1.351562</td>\n",
       "      <td>2.535156</td>\n",
       "      <td>0.197510</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>1.990234</td>\n",
       "      <td>-3.841797</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.230347</td>\n",
       "      <td>3.330078</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>3.050781</td>\n",
       "      <td>1.303711</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>-0.018280</td>\n",
       "      <td>2.748047</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>-0.036285</td>\n",
       "      <td>-0.049866</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>3.898438</td>\n",
       "      <td>11.289062</td>\n",
       "      <td>1.137695</td>\n",
       "      <td>3.367188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>2.113281</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>0.789551</td>\n",
       "      <td>1.113281</td>\n",
       "      <td>1.491211</td>\n",
       "      <td>2.439453</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.053680</td>\n",
       "      <td>1.701172</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.094910</td>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>4.445312</td>\n",
       "      <td>1.586914</td>\n",
       "      <td>-0.068665</td>\n",
       "      <td>-0.108276</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.046112</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>-0.027557</td>\n",
       "      <td>0.019485</td>\n",
       "      <td>-0.048828</td>\n",
       "      <td>0.050751</td>\n",
       "      <td>3.728516</td>\n",
       "      <td>5.015625</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>0.167603</td>\n",
       "      <td>0.039764</td>\n",
       "      <td>2.042969</td>\n",
       "      <td>-0.016617</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>3.507812</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>-0.097046</td>\n",
       "      <td>5.394531</td>\n",
       "      <td>0.244507</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>0.113098</td>\n",
       "      <td>-0.015472</td>\n",
       "      <td>4.207031</td>\n",
       "      <td>4.105469</td>\n",
       "      <td>0.037231</td>\n",
       "      <td>-0.118835</td>\n",
       "      <td>0.067078</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>-0.011719</td>\n",
       "      <td>0.052765</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>1.978516</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.240479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650391</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-3.841797</td>\n",
       "      <td>132.7500</td>\n",
       "      <td>9.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.673828</td>\n",
       "      <td>76.5625</td>\n",
       "      <td>3.378906</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>1.275391</td>\n",
       "      <td>-0.471436</td>\n",
       "      <td>4.546875</td>\n",
       "      <td>0.037720</td>\n",
       "      <td>0.331787</td>\n",
       "      <td>0.325195</td>\n",
       "      <td>0.062042</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>-0.224976</td>\n",
       "      <td>0.233643</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>1.903320</td>\n",
       "      <td>0.067871</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>0.006134</td>\n",
       "      <td>2.603516</td>\n",
       "      <td>0.103455</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>4.753906</td>\n",
       "      <td>1.855469</td>\n",
       "      <td>-0.181885</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>3.166016</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.117126</td>\n",
       "      <td>0.315186</td>\n",
       "      <td>24.484375</td>\n",
       "      <td>1.671875</td>\n",
       "      <td>-0.409180</td>\n",
       "      <td>4.953125</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>2.603516</td>\n",
       "      <td>1.955078</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>3.289062</td>\n",
       "      <td>2.564453</td>\n",
       "      <td>0.817871</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>4.617188</td>\n",
       "      <td>1.575195</td>\n",
       "      <td>0.066101</td>\n",
       "      <td>0.681641</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.183472</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>2.746094</td>\n",
       "      <td>0.835449</td>\n",
       "      <td>0.188232</td>\n",
       "      <td>4.960938</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>-0.015266</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.064575</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>0.093628</td>\n",
       "      <td>0.963867</td>\n",
       "      <td>0.630371</td>\n",
       "      <td>4.308594</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>-0.036346</td>\n",
       "      <td>3.617188</td>\n",
       "      <td>3.103516</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.924805</td>\n",
       "      <td>0.123291</td>\n",
       "      <td>-0.022675</td>\n",
       "      <td>1.547852</td>\n",
       "      <td>-0.010399</td>\n",
       "      <td>0.058319</td>\n",
       "      <td>3.662109</td>\n",
       "      <td>-0.118408</td>\n",
       "      <td>2.357422</td>\n",
       "      <td>-0.009109</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>4.097656</td>\n",
       "      <td>3.533203</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.121399</td>\n",
       "      <td>0.109985</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>3.460938</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.124878</td>\n",
       "      <td>0.154053</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>-0.267822</td>\n",
       "      <td>2.578125</td>\n",
       "      <td>-0.020874</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.136719</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>-0.471436</td>\n",
       "      <td>76.5625</td>\n",
       "      <td>8.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036316</td>\n",
       "      <td>1.497070</td>\n",
       "      <td>233.5000</td>\n",
       "      <td>2.195312</td>\n",
       "      <td>0.026917</td>\n",
       "      <td>3.126953</td>\n",
       "      <td>5.058594</td>\n",
       "      <td>3.849609</td>\n",
       "      <td>1.801758</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>0.328613</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>5.308594</td>\n",
       "      <td>1.354492</td>\n",
       "      <td>-0.261963</td>\n",
       "      <td>1.378906</td>\n",
       "      <td>1.480469</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>-0.008804</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>1.683594</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>3.572266</td>\n",
       "      <td>0.120605</td>\n",
       "      <td>0.082092</td>\n",
       "      <td>2.234375</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.502930</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>1.417969</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>3.222656</td>\n",
       "      <td>2.121094</td>\n",
       "      <td>3.082031</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>-0.006821</td>\n",
       "      <td>-0.390869</td>\n",
       "      <td>17.343750</td>\n",
       "      <td>3.701172</td>\n",
       "      <td>-0.033600</td>\n",
       "      <td>1.578125</td>\n",
       "      <td>0.051971</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>2.691406</td>\n",
       "      <td>0.018372</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>0.111389</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>-0.324951</td>\n",
       "      <td>-0.019943</td>\n",
       "      <td>3.455078</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.009811</td>\n",
       "      <td>-0.010628</td>\n",
       "      <td>0.027573</td>\n",
       "      <td>-0.007122</td>\n",
       "      <td>-0.048920</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>1.865234</td>\n",
       "      <td>2.404297</td>\n",
       "      <td>0.411621</td>\n",
       "      <td>0.057739</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>2.167969</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>4.949219</td>\n",
       "      <td>-0.010979</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>0.266846</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>3.847656</td>\n",
       "      <td>-0.121460</td>\n",
       "      <td>3.740234</td>\n",
       "      <td>0.147095</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>0.614746</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.078857</td>\n",
       "      <td>0.979980</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>0.085205</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>0.116089</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.520020</td>\n",
       "      <td>2.140625</td>\n",
       "      <td>0.124451</td>\n",
       "      <td>0.148193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.814453</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>-0.520020</td>\n",
       "      <td>233.5000</td>\n",
       "      <td>9.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014076</td>\n",
       "      <td>0.245972</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>1.890625</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>2.697266</td>\n",
       "      <td>4.515625</td>\n",
       "      <td>4.503906</td>\n",
       "      <td>0.123474</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>4.871094</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>2.498047</td>\n",
       "      <td>1.238281</td>\n",
       "      <td>2.347656</td>\n",
       "      <td>0.175415</td>\n",
       "      <td>1.609375</td>\n",
       "      <td>2.029297</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>1.651367</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.589355</td>\n",
       "      <td>4.238281</td>\n",
       "      <td>-0.032837</td>\n",
       "      <td>0.058167</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>0.097473</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>25.375000</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>2.025391</td>\n",
       "      <td>2.968750</td>\n",
       "      <td>1.085938</td>\n",
       "      <td>1.710938</td>\n",
       "      <td>1.372070</td>\n",
       "      <td>0.034637</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>71.437500</td>\n",
       "      <td>3.035156</td>\n",
       "      <td>0.092224</td>\n",
       "      <td>3.453125</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>4.082031</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.029221</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.185303</td>\n",
       "      <td>0.164307</td>\n",
       "      <td>3.804688</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-0.021408</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.110901</td>\n",
       "      <td>0.026840</td>\n",
       "      <td>2.931641</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.495117</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>2.242188</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>-0.139282</td>\n",
       "      <td>4.742188</td>\n",
       "      <td>3.292969</td>\n",
       "      <td>0.117859</td>\n",
       "      <td>0.065613</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>-0.058044</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>1.101562</td>\n",
       "      <td>0.068542</td>\n",
       "      <td>0.162964</td>\n",
       "      <td>4.070312</td>\n",
       "      <td>-0.008835</td>\n",
       "      <td>3.896484</td>\n",
       "      <td>0.913574</td>\n",
       "      <td>-0.163208</td>\n",
       "      <td>3.074219</td>\n",
       "      <td>4.355469</td>\n",
       "      <td>-0.048889</td>\n",
       "      <td>4.917969</td>\n",
       "      <td>0.069946</td>\n",
       "      <td>-0.015350</td>\n",
       "      <td>3.474609</td>\n",
       "      <td>-0.017105</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>0.062012</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>0.044861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.859375</td>\n",
       "      <td>0.180420</td>\n",
       "      <td>-0.495117</td>\n",
       "      <td>780.0000</td>\n",
       "      <td>9.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003260</td>\n",
       "      <td>3.714844</td>\n",
       "      <td>156.1250</td>\n",
       "      <td>2.148438</td>\n",
       "      <td>0.018280</td>\n",
       "      <td>2.097656</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>3.371094</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.711426</td>\n",
       "      <td>0.770020</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>3.710938</td>\n",
       "      <td>5.464844</td>\n",
       "      <td>0.287109</td>\n",
       "      <td>2.617188</td>\n",
       "      <td>1.383789</td>\n",
       "      <td>0.074890</td>\n",
       "      <td>-0.010544</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>2.275391</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>4.359375</td>\n",
       "      <td>5.074219</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>4.054688</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>3.402344</td>\n",
       "      <td>15.562500</td>\n",
       "      <td>1.635742</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>4.019531</td>\n",
       "      <td>0.155762</td>\n",
       "      <td>5.289062</td>\n",
       "      <td>4.117188</td>\n",
       "      <td>0.072144</td>\n",
       "      <td>2.751953</td>\n",
       "      <td>3.171875</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>-0.105835</td>\n",
       "      <td>3.320312</td>\n",
       "      <td>0.090698</td>\n",
       "      <td>0.112915</td>\n",
       "      <td>4.621094</td>\n",
       "      <td>0.126831</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>4.707031</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>0.523926</td>\n",
       "      <td>2.972656</td>\n",
       "      <td>0.115356</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>0.067444</td>\n",
       "      <td>0.075562</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>-0.042297</td>\n",
       "      <td>0.047974</td>\n",
       "      <td>-0.294189</td>\n",
       "      <td>5.066406</td>\n",
       "      <td>1.049805</td>\n",
       "      <td>0.034027</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>2.263672</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>-0.023300</td>\n",
       "      <td>5.617188</td>\n",
       "      <td>0.086243</td>\n",
       "      <td>0.157593</td>\n",
       "      <td>3.726562</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.086609</td>\n",
       "      <td>0.607422</td>\n",
       "      <td>1.411133</td>\n",
       "      <td>2.060547</td>\n",
       "      <td>-0.023148</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.914551</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>0.375732</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>1.910156</td>\n",
       "      <td>-0.042938</td>\n",
       "      <td>0.105591</td>\n",
       "      <td>0.125122</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>1.075195</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>0.072815</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949219</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>-0.294189</td>\n",
       "      <td>156.1250</td>\n",
       "      <td>9.710938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0        f1        f2        f3        f4        f5        f6  \\\n",
       "0  0.106628  3.593750  132.7500  3.183594  0.081970  1.188477  3.732422   \n",
       "1  0.125000  1.673828   76.5625  3.378906  0.099426  5.093750  1.275391   \n",
       "2  0.036316  1.497070  233.5000  2.195312  0.026917  3.126953  5.058594   \n",
       "3 -0.014076  0.245972  780.0000  1.890625  0.006947  1.531250  2.697266   \n",
       "4 -0.003260  3.714844  156.1250  2.148438  0.018280  2.097656  4.156250   \n",
       "\n",
       "         f7        f8        f9       f10       f11       f12       f13  \\\n",
       "0  2.265625  2.099609  0.012329  1.607422 -0.318115  0.560059  2.806641   \n",
       "1 -0.471436  4.546875  0.037720  0.331787  0.325195  0.062042  2.261719   \n",
       "2  3.849609  1.801758  0.057007  0.328613  2.968750  0.105225  2.070312   \n",
       "3  4.515625  4.503906  0.123474  1.002930  4.871094  0.058411  2.498047   \n",
       "4 -0.038239  3.371094  0.034180  0.711426  0.770020  0.057556  0.957031   \n",
       "\n",
       "        f14       f15       f16       f17       f18       f19       f20  \\\n",
       "0  1.351562  2.535156  0.197510  0.676270  1.990234 -3.841797  0.037384   \n",
       "1  4.339844 -0.224976  0.233643  3.380859  1.903320  0.067871 -0.051270   \n",
       "2  5.308594  1.354492 -0.261963  1.378906  1.480469  0.020538 -0.008804   \n",
       "3  1.238281  2.347656  0.175415  1.609375  2.029297  0.042084  0.005142   \n",
       "4  3.710938  5.464844  0.287109  2.617188  1.383789  0.074890 -0.010544   \n",
       "\n",
       "        f21       f22       f23       f24       f25       f26       f27  \\\n",
       "0  0.230347  3.330078  0.009399  0.144775  3.050781  1.303711  0.033234   \n",
       "1  0.006134  2.603516  0.103455  0.067627  4.753906  1.855469 -0.181885   \n",
       "2  0.109375  1.683594  0.038177  0.123718  1.112305  3.572266  0.120605   \n",
       "3  0.076477  1.651367  0.111816  0.121643  0.589355  4.238281 -0.032837   \n",
       "4  0.109131  2.275391  0.008026  0.045227  4.359375  5.074219 -0.009377   \n",
       "\n",
       "        f28       f29       f30       f31       f32       f33       f34  \\\n",
       "0 -0.018280  2.748047 -0.009293 -0.036285 -0.049866  0.019485  3.898438   \n",
       "1  0.008362  3.166016  0.011848  0.022293  0.069336  0.117126  0.315186   \n",
       "2  0.082092  2.234375  0.002270  0.045197  0.014404  0.011597 -0.502930   \n",
       "3  0.058167  0.712891  0.097473  0.072754  0.000324  0.063354  4.062500   \n",
       "4  0.528809  4.054688  0.020004  0.106812  0.051300  0.045929  3.402344   \n",
       "\n",
       "         f35       f36       f37       f38       f39       f40       f41  \\\n",
       "0  11.289062  1.137695  3.367188  4.945312 -0.105774  2.113281  3.453125   \n",
       "1  24.484375  1.671875 -0.409180  4.953125  0.092346  2.603516  1.955078   \n",
       "2  33.750000  1.417969  1.071289  3.222656  2.121094  3.082031  0.637695   \n",
       "3  25.375000  0.576660  2.025391  2.968750  1.085938  1.710938  1.372070   \n",
       "4  15.562500  1.635742  0.047028  4.019531  0.155762  5.289062  4.117188   \n",
       "\n",
       "        f42       f43        f44       f45       f46       f47       f48  \\\n",
       "0  0.789551  1.113281   1.491211  2.439453  0.041809  3.355469  0.053680   \n",
       "1  0.005898  3.289062   2.564453  0.817871  0.026001  4.617188  1.575195   \n",
       "2 -0.006821 -0.390869  17.343750  3.701172 -0.033600  1.578125  0.051971   \n",
       "3  0.034637  0.722656  71.437500  3.035156  0.092224  3.453125  0.044830   \n",
       "4  0.072144  2.751953   3.171875  0.693359 -0.105835  3.320312  0.090698   \n",
       "\n",
       "        f49       f50       f51       f52       f53       f54       f55  \\\n",
       "0  1.701172  0.908691  0.094910  0.030212  0.597168  4.445312  1.586914   \n",
       "1  0.066101  0.681641  0.025253  0.183472  0.110046  2.746094  0.835449   \n",
       "2 -0.002005  2.691406  0.018372 -0.030472  0.111389  2.187500 -0.324951   \n",
       "3  0.027191  4.082031  0.046967  0.063721  0.029221  0.671875  0.185303   \n",
       "4  0.112915  4.621094  0.126831  0.142700  0.055725  4.707031 -0.055115   \n",
       "\n",
       "        f56       f57       f58       f59       f60       f61       f62  \\\n",
       "0 -0.068665 -0.108276  0.061035  0.046112  0.017105 -0.027557  0.019485   \n",
       "1  0.188232  4.960938  0.136108 -0.008492 -0.015266 -0.010841  0.064575   \n",
       "2 -0.019943  3.455078  0.068115 -0.009811 -0.010628  0.027573 -0.007122   \n",
       "3  0.164307  3.804688  0.062317 -0.021408  0.009468  0.110901  0.026840   \n",
       "4  0.523926  2.972656  0.115356  0.125244  0.067444  0.075562  0.032104   \n",
       "\n",
       "        f63       f64       f65       f66       f67       f68       f69  \\\n",
       "0 -0.048828  0.050751  3.728516  5.015625  4.187500  0.063354  0.121033   \n",
       "1  0.102539  0.093628  0.963867  0.630371  4.308594  0.091309 -0.036346   \n",
       "2 -0.048920 -0.002575  1.865234  2.404297  0.411621  0.057739  0.525391   \n",
       "3  2.931641  0.068115 -0.495117  1.345703  2.242188  0.035614 -0.139282   \n",
       "4 -0.042297  0.047974 -0.294189  5.066406  1.049805  0.034027  0.024612   \n",
       "\n",
       "        f70       f71       f72       f73       f74       f75       f76  \\\n",
       "0  1.372070  4.015625  0.167603  0.039764  2.042969 -0.016617  0.107666   \n",
       "1  3.617188  3.103516  0.000657  0.051300  1.924805  0.123291 -0.022675   \n",
       "2  2.167969  0.828125  0.089844  0.093750  4.949219 -0.010979  0.076660   \n",
       "3  4.742188  3.292969  0.117859  0.065613  0.556641 -0.058044  0.070496   \n",
       "4  3.125000  2.263672  0.082458 -0.023300  5.617188  0.086243  0.157593   \n",
       "\n",
       "        f77       f78       f79       f80       f81       f82       f83  \\\n",
       "0  3.507812  0.013657 -0.097046  5.394531  0.244507  3.492188  0.113098   \n",
       "1  1.547852 -0.010399  0.058319  3.662109 -0.118408  2.357422 -0.009109   \n",
       "2  0.266846  0.038696  0.382812  3.847656 -0.121460  3.740234  0.147095   \n",
       "3  1.101562  0.068542  0.162964  4.070312 -0.008835  3.896484  0.913574   \n",
       "4  3.726562  0.061249  0.086609  0.607422  1.411133  2.060547 -0.023148   \n",
       "\n",
       "        f84       f85       f86       f87       f88       f89       f90  \\\n",
       "0 -0.015472  4.207031  4.105469  0.037231 -0.118835  0.067078  0.010742   \n",
       "1  0.178711  4.097656  3.533203  0.005245  0.121399  0.109985  0.135864   \n",
       "2 -0.016571  0.614746  2.125000  0.078857  0.979980  0.026764  0.117310   \n",
       "3 -0.163208  3.074219  4.355469 -0.048889  4.917969  0.069946 -0.015350   \n",
       "4  0.011238  2.156250  0.914551  0.044525  0.375732  0.134399  0.013779   \n",
       "\n",
       "        f91       f92       f93       f94       f95       f96       f97  \\\n",
       "0  1.098633  0.013329 -0.011719  0.052765  0.065430  4.210938  1.978516   \n",
       "1  3.460938  0.017059  0.124878  0.154053  0.606934 -0.267822  2.578125   \n",
       "2  4.882812  0.085205  0.032410  0.116089 -0.001689 -0.520020  2.140625   \n",
       "3  3.474609 -0.017105 -0.008102  0.062012  0.041199  0.511719  1.968750   \n",
       "4  1.910156 -0.042938  0.105591  0.125122  0.037506  1.043945  1.075195   \n",
       "\n",
       "        f98       f99  target  fe_cluster_0  fe_cluster_1  fe_cluster_2  \\\n",
       "0  0.085999  0.240479       0             1             0             0   \n",
       "1 -0.020874  0.024719       0             1             0             0   \n",
       "2  0.124451  0.148193       0             0             0             0   \n",
       "3  0.040009  0.044861       0             0             0             1   \n",
       "4 -0.012817  0.072815       1             1             0             0   \n",
       "\n",
       "   fe_cluster_3  fe_cluster_4   fe_mean  fe_median    fe_min    fe_max  \\\n",
       "0             0             0  2.650391   0.242432 -3.841797  132.7500   \n",
       "1             0             0  2.136719   0.145020 -0.471436   76.5625   \n",
       "2             0             1  3.814453   0.124084 -0.520020  233.5000   \n",
       "3             0             0  9.859375   0.180420 -0.495117  780.0000   \n",
       "4             0             0  2.949219   0.149170 -0.294189  156.1250   \n",
       "\n",
       "    fe_skew  \n",
       "0  9.687500  \n",
       "1  8.429688  \n",
       "2  9.609375  \n",
       "3  9.867188  \n",
       "4  9.710938  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQ6DBwBLi34z"
   },
   "source": [
    "# <div class=\"alert alert-success\"> 1.  TUNNING </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cJfauA3i34z"
   },
   "source": [
    "## 1.0. Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:23:34.040206Z",
     "start_time": "2021-11-29T00:23:27.122282Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1638139561392,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "7slBPAVpX0dZ",
    "outputId": "b50c0678-eae5-4e74-f35e-dc7a84f93652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480000, 110), (480000,), (120000, 110), (120000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X      = df3_train.drop([target], axis=1)    \n",
    "y      = df3_train[target].copy()\n",
    "X_test = df3_test\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size    = 0.2,\n",
    "                                                      shuffle      = True, \n",
    "                                                      stratify     = y,\n",
    "                                                      random_state = 0)\n",
    "\n",
    "del df3_train , df3_test\n",
    "\n",
    "free_gpu_cache() \n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l1vmUmRi340"
   },
   "source": [
    "## 1.1. Classe Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:26:33.239631Z",
     "start_time": "2021-11-29T00:26:32.863103Z"
    },
    "code_folding": [
     4,
     23,
     59
    ],
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 1987,
     "status": "ok",
     "timestamp": 1638143302894,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "LpYUOrRpi340"
   },
   "outputs": [],
   "source": [
    "class TunningModels(nn.Module):\n",
    "    \n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    \n",
    "    def __init__(self, name_model_, X_trn_, y_trn_, X_ts_, feature_=None, \n",
    "                 seed_=12359, scaler_=StandardScaler(), feature_bin_=None, \n",
    "                 target_='target', path_='', level_='1', save_predict_=True):\n",
    "        \n",
    "        super(TunningModels,self).__init__() \n",
    "\n",
    "        self.name_clf     = name_model\n",
    "        self.X_trn        = X_trn_\n",
    "        self.y_trn        = y_trn_\n",
    "        self.X_ts         = X_ts_         \n",
    "        self.feature      = feature_\n",
    "        self.seed         = seed_\n",
    "        self.scaler       = scaler_\n",
    "        self.feature_bin  = feature_bin_ \n",
    "        self.target       = target_\n",
    "        self.path         = path_\n",
    "        self.level        = level_\n",
    "        self.save_predict = save_predict_\n",
    "\n",
    "    def recover_prediction_first_level():\n",
    "        \n",
    "        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n",
    "        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n",
    "        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n",
    "\n",
    "        df_train1     = []\n",
    "        scores_traint = dict()\n",
    "\n",
    "        for p_name in preds_train1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n",
    "            df_train1.append(p_df)    \n",
    "            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n",
    "\n",
    "        df_val1     = [] \n",
    "        scores_val1 = dict()\n",
    "        for p_name in preds_val1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n",
    "            df_val1.append(p_df)    \n",
    "            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n",
    "\n",
    "        df_test     = [] \n",
    "        scores_test = dict()\n",
    "        for p_name in preds_test:    \n",
    "            p         = jb.load(p_name)\n",
    "            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n",
    "            df_test.append(p_df_test)\n",
    "\n",
    "        df_train1 = pd.concat(df_train1, axis=1)\n",
    "        df_val1   = pd.concat(df_val1, axis=1)\n",
    "        df_test   = pd.concat(df_test, axis=1)\n",
    "\n",
    "        return df_train1, df_val1, df_test.shape\n",
    "        \n",
    "    def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))\n",
    " \n",
    "    def logging_callback(study, frozen_trail):\n",
    "        prev_best = study.user_attrs.get('prev_best', None)\n",
    "        if prev_best != study.best_value:\n",
    "            study.set_user_attr('prev_best', study.best_value)\n",
    "            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n",
    "\n",
    "    def df_return_preds_tunning(model_name=None, level=1, target_='target', \n",
    "                                train_shape_row=0, test_shape_row=0): \n",
    "    \n",
    "        if level==1: \n",
    "            level_ = 'n1'\n",
    "        else: \n",
    "            if level==2:\n",
    "                level_ = 'n2'\n",
    "            else: \n",
    "                level_ = 'n3'\n",
    "        \n",
    "        paths = ['model/preds/test/n1', 'model/preds/train/' + level_ ]    \n",
    "\n",
    "        if model_name==None: \n",
    "            model_name=''\n",
    "            \n",
    "        for i, path in enumerate(paths): \n",
    "\n",
    "            name_file_pkl     = glob.glob(path + '/'+ model_name + '*.pkl.z')\n",
    "            dic_preds_mdl_pkl = dict()\n",
    "\n",
    "            for p_name in name_file_pkl:    \n",
    "                y_model_pkl_name_col  = p_name.replace(path + '\\\\', '').replace('.pkl.z','') \n",
    "                y_model_pkl           = jb.load(p_name)   \n",
    "\n",
    "                if i==0:\n",
    "                    if len(y_model_pkl)==test_shape_row:\n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "                        \n",
    "                if i==1:\n",
    "                    if len(y_model_pkl)==train_shape_row:                        \n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "                \n",
    "                gc.collect()\n",
    "\n",
    "            if i==0:         \n",
    "                X_test_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "            else:\n",
    "                X_train_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        X_train_pred_nivel_1[target_] = y\n",
    "        \n",
    "        return X_train_pred_nivel_1, X_test_pred_nivel_1\n",
    "    \n",
    "    def feature_select(mdl, feature=[], best_score=0):\n",
    "    \n",
    "        best_feature = ''\n",
    "\n",
    "        for col in df_train1.columns:\n",
    "\n",
    "            if col not in feature:\n",
    "                Xtr  = df_train1[feature+[col]].copy()\n",
    "                Xval = df_val1[feature+[col]].copy()                \n",
    "\n",
    "                mdl.fit(Xtr, y_train1)\n",
    "\n",
    "                p = mdl.predict(Xval)\n",
    "                c = f1_score(y_val1, p)\n",
    "\n",
    "                if c > best_score:\n",
    "                    best_score = c\n",
    "                    best_feature = col \n",
    "\n",
    "        return best_score, best_feature\n",
    "\n",
    "    def permutation_test(mdl, feature_selected):\n",
    "\n",
    "        dist = []\n",
    "\n",
    "        for seed in range(100):\n",
    "\n",
    "            Xtr  = df_train1[feature_selected].copy()\n",
    "            Xval = df_val1[feature_selected].copy()\n",
    "\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            Xtr['random']  = np.random.permutation(Xtr.iloc[:, -1].values)\n",
    "            Xval['random'] = np.random.permutation(Xval.iloc[:, -1].values)\n",
    "\n",
    "            mdl.fit(Xtr, y_train1)\n",
    "\n",
    "            p = mdl.predict(Xval)\n",
    "            c = f1_score(y_val1, p)\n",
    "\n",
    "            dist.append(c)\n",
    "\n",
    "        dist = np.array(dist)\n",
    "\n",
    "        return dist.max()\n",
    "\n",
    "    def feature_selected_model(model = RidgeClassifier(alpha=1.) ):\n",
    "   \n",
    "        score_feature, best_feature =  TunningModels.feature_select(model)\n",
    "        print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        feature_selected = []\n",
    "        feature_selected.append(best_feature)\n",
    "\n",
    "        loop = True\n",
    "\n",
    "        while loop:\n",
    "\n",
    "            best_score = TunningModels.permutation_test(model, feature_selected) \n",
    "            best_score = best_score + 1e-4\n",
    "\n",
    "            score_feature, best_feature = TunningModels.feature_select(model, feature=feature_selected, best_score=best_score)\n",
    "            \n",
    "\n",
    "            if score_feature <= best_score:  \n",
    "                print('Fim')\n",
    "                loop= False\n",
    "            else: \n",
    "                feature_selected.append(best_feature)\n",
    "                print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        return feature_selected\n",
    "    \n",
    "    def model_of_diversity_feature_group(model, name_model_, X_, y_, X_ts_, scaler_=None, feature_bin_= None, \n",
    "                                         feature_imp_num=5, seed_=12359):\n",
    "\n",
    "        TunningModels.delete_files(name_model_)\n",
    "    \n",
    "        mdl ,score , y_hat = TunningModels.cross_valid( model        = model, \n",
    "                                                        model_name_  = name_model_, \n",
    "                                                        X_           = X_, \n",
    "                                                        y_           = y_, \n",
    "                                                        X_test_      = X_ts_, \n",
    "                                                        type_model   = 1, \n",
    "                                                        feature      = None,\n",
    "                                                        seed         = seed_, \n",
    "                                                        tunning      = 1, \n",
    "                                                        scaler       = scaler_,\n",
    "                                                        print_result = False, \n",
    "                                                        feature_bin  = feature_bin_, \n",
    "                                                        save_predict = False,\n",
    "                                                        n_splits     = 2\n",
    "                                                        )\n",
    "        \n",
    "        df               = pd.DataFrame()\n",
    "        df[\"feature\"]    = X_.columns.to_list()\n",
    "        df[\"importance\"] = mdl.feature_importances_\n",
    "        \n",
    "        df.sort_values(\"importance\", axis=0, ascending=False, inplace=True)\n",
    "\n",
    "        feature_import = df[:feature_imp_num]['feature'].to_list()\n",
    "        \n",
    "        print(feature_import)\n",
    "        print()\n",
    "\n",
    "        for feature_imp in  feature_import:\n",
    "\n",
    "            score_                =  0.09\n",
    "            feature_best          = []\n",
    "            feature               = X_ts_.columns            \n",
    "            feature               = [s for s in feature if s not in feature_import]\n",
    "            feature_number        = len(feature)\n",
    "            feature_select_number = np.round(np.sqrt(len(feature)))\n",
    "            feature_number_sample = int(np.round((feature_number/feature_select_number)))\n",
    "            feature_sample        = []\n",
    "\n",
    "            print('='*60)\n",
    "            print(' Divercidade de Grupos de Features => ({})'.format(feature_imp))\n",
    "            print('='*60)\n",
    "\n",
    "            for i in  range(0,5):\n",
    "\n",
    "                feature            = [s for s in feature if s not in feature_sample]\n",
    "                feature_sample     = pd.Series(feature).sample(feature_number_sample).to_list() \n",
    "                name_model_xgb_div = name_model_ + '_' + str(i+1)   \n",
    "\n",
    "                feature_sample.append(feature_imp)\n",
    "\n",
    "                feature_sample_bin = []\n",
    "\n",
    "                for x in feature_sample: \n",
    "                    if x in feature_bin_: \n",
    "                        feature_sample_bin.append(x)\n",
    "\n",
    "                if len(feature_sample_bin)==0:\n",
    "                    feature_sample_bin = None\n",
    "                \n",
    "                mdl ,score , y_hat = TunningModels.cross_valid( model        = model, \n",
    "                                                                model_name_  = name_model_xgb_div, \n",
    "                                                                X_           = X_, \n",
    "                                                                y_           = y_, \n",
    "                                                                X_test_      = X_ts_, \n",
    "                                                                type_model   = 2, \n",
    "                                                                feature      = feature_sample,\n",
    "                                                                seed         = seed_, \n",
    "                                                                tunning      = 1, \n",
    "                                                                scaler       = scaler_,\n",
    "                                                                print_result = False, \n",
    "                                                                feature_bin  = feature_sample_bin, \n",
    "                                                                save_predict = True,\n",
    "                                                                n_splits     = 3\n",
    "                                                                )\n",
    "                \n",
    "                if score >=.6:\n",
    "                    create = '*'\n",
    "                else: \n",
    "                    create = ' '\n",
    "            \n",
    "                feature_best.append(feature)\n",
    "                print('Score: {:2.5f} => {} Gr.Feature: {} {}'.format(score, create, i+1, feature_sample))\n",
    "\n",
    "            print('')\n",
    "            \n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "        \n",
    "    def model_of_diversity_feature_one_(model, name_model,  X_, y_, X_test_,  scaler_=None, feature_bin_=None, seed_=12359):\n",
    "\n",
    "        score_       =  0.09\n",
    "        feature_best = []\n",
    "\n",
    "        print('')\n",
    "        print('Feature apenas uma')\n",
    "        print('-'*20)\n",
    "        print()\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        for feature in X_train.columns:\n",
    "\n",
    "            name_model_xgb_div = name_model + feature \n",
    "\n",
    "            mdl ,score , y_hat = TunningModels.cross_valid(model       = model, \n",
    "                                              model_name_  = name_model_xgb_div, \n",
    "                                              X_           = X_, \n",
    "                                              y_           = y_, \n",
    "                                              X_test_      = X_test_, \n",
    "                                              type_model   = 1, \n",
    "                                              feature      = feature,\n",
    "                                              seed         = seed_, \n",
    "                                              tunning      = 1, \n",
    "                                              scaler       = scaler_,\n",
    "                                              print_result = False, \n",
    "                                              feature_bin  = feature_bin_, \n",
    "                                              save_predict = True,\n",
    "                                              n_splits     = 3\n",
    "                                              )\n",
    "    \n",
    "            if score >.6:\n",
    "                create = '*'\n",
    "            else: \n",
    "                create = ' '\n",
    "                \n",
    "            if score > score_:\n",
    "                score_ = np.abs(score)\n",
    "                feature_best.append(feature)\n",
    "                print('F1-score: {:2.5f} => {} feature: {}'.format(score, create, feature ))        \n",
    "\n",
    "        print('')\n",
    "        print('Feature dupla')\n",
    "        print('-'*20)\n",
    "\n",
    "        for feature in feature_best:\n",
    "\n",
    "            for feature_ in feature_best:\n",
    "                if feature != feature_:            \n",
    "                    name_model_xgb_div = name_model + feature + '_' + feature_     \n",
    "                            \n",
    "                    mdl ,score , y_hat = TunningModels.cross_valid( model       = model, \n",
    "                                                                    model_name_  = name_model_xgb_div, \n",
    "                                                                    X_           = X_, \n",
    "                                                                    y_           = y_, \n",
    "                                                                    X_test_      = X_test_, \n",
    "                                                                    type_model   = 1, \n",
    "                                                                    feature      = [feature, feature_],\n",
    "                                                                    seed         = seed_, \n",
    "                                                                    tunning      = 1, \n",
    "                                                                    scaler       = scaler_,\n",
    "                                                                    print_result = False, \n",
    "                                                                    feature_bin  = feature_bin_, \n",
    "                                                                    save_predict = True,\n",
    "                                                                    n_splits     = 3\n",
    "                                                                    )\n",
    "            \n",
    "                    if score >.59:\n",
    "                        create = '*'\n",
    "                    else: \n",
    "                        create = ' '\n",
    "\n",
    "                    print('F1-score: {:.4f} => {} feature: {} | {}'.format(score*100, create,  feature, feature_ )) \n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "         \n",
    "    def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_,\n",
    "                     score_, seed_, level_='1', target_='target'):\n",
    "        \n",
    "        level_ = 'n'+ level_ + '/'\n",
    "\n",
    "        if score_>.6:          \n",
    "\n",
    "            path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_)\n",
    "            path_name_train = path_ + 'model/preds/train/' + level_ + model_name_.format(score_, seed_)\n",
    "            path_name_test  = path_ + 'model/preds/test/'  + level_ + model_name_.format(score_, seed_)    \n",
    "            path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)    \n",
    "\n",
    "            jb.dump(y_pred_train_prob_, path_name_train)\n",
    "            jb.dump(y_pred_test_prob_, path_name_test)\n",
    "            jb.dump(model_, path_name_model)\n",
    "            jb.dump(pd.DataFrame([model_.get_params()]), path_name_param)   \n",
    "\n",
    "            if score_>.6:\n",
    "                # Gerar o arquivo de submissão \n",
    "                df_submission[target_] = y_pred_test_prob_\n",
    "                name_file_sub =  path_ + 'Data/submission/tunning/' + model_name_.format(score_, seed_) + '.csv'\n",
    "                df_submission.to_csv(name_file_sub, index = False)\n",
    "                \n",
    "    def diff(t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def feature_scaler(df_, scaler_=None, feature_bin_=None):\n",
    "    \n",
    "        if scaler_!=None: \n",
    "            \n",
    "            if feature_bin_!=None:\n",
    "                disc = KBinsDiscretizer(n_bins=50, encode='ordinal', strategy='uniform')\n",
    "                df_[feature_bin_] = disc.fit_transform(df_[feature_bin_])\n",
    "\n",
    "            df_ = pd.DataFrame(scaler_.fit_transform(df_), columns=df_.columns)\n",
    "    \n",
    "        return df_\n",
    "\n",
    "    def cross_valid(model_, model_name_, X_train_, y_train_, X_test_, fold_=5, target_='target', \n",
    "                    path_='', level_='1', save_predict_=True, print_result_=True, seed_=12359, \n",
    "                    feature_=None, feature_bin_=None, scaler_=StandardScaler(), threshold=.5):\n",
    "        \n",
    "        if feature_!=None: \n",
    "            X_train_ = X_train_[feature_]\n",
    "            X_test_  = X_test_[feature_]\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Scorpo de variáveis\n",
    "        #--------------------------------------------------------\n",
    "\n",
    "        time_pred_start    = datetime.now()\n",
    "        preds_valid_f      = {}\n",
    "        preds_test         = []\n",
    "        total_auc          = []\n",
    "        f_scores           = []\n",
    "        auc_mean           = []\n",
    "        f1_mean            = []\n",
    "        lloss_mean         = []\n",
    "        preds_test_prob    = 0    \n",
    "        df_score_history   = pd.DataFrame()\n",
    "        df_train_pred_fold = pd.DataFrame()\n",
    "        random             = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_        = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'\n",
    "        clf_name           = model_.__class__.__name__\n",
    "        pri_result         = 92\n",
    "        learning_rate      = model_.learning_rate \n",
    "        feature_imp_values = np.zeros(X_train.shape[1])\n",
    "        out_of_fold        = np.zeros(X_train.shape[0]) \n",
    "        \n",
    "        # Lists for recording validation and training scores\n",
    "        valid_scores = []\n",
    "        train_scores = []\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Início do process de varilidação\n",
    "        #--------------------------------------------------------\n",
    "        have_observation=''\n",
    "\n",
    "        #if dropout_>0: \n",
    "        #    is_dropout='*'\n",
    "\n",
    "        if print_result_:\n",
    "            num_parallel_tree = 1 #model_.get_params()['num_parallel_tree']\n",
    "            learning_rate     = model_.learning_rate\n",
    "            n_estimators      = model_.n_estimators * num_parallel_tree  \n",
    "            max_depth         = model_.max_depth \n",
    "            msg               = 'Training model: {} - seed {} - n_estimators: {} - max_depth: {} {:2.5f}'\n",
    "\n",
    "            print('='*pri_result)            \n",
    "            print(msg.format(clf_name, seed_, n_estimators, max_depth, learning_rate))\n",
    "            print('='*pri_result)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=fold_, random_state=seed_, shuffle=True)\n",
    "\n",
    "        for fold,(idx_train, idx_val) in enumerate(kf.split(X_train_, y_train_, groups=y_train_)):\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Seleção dos dados\n",
    "            #--------------------------------------------------------\n",
    "            X_trn, X_val = X_train_.iloc[idx_train], X_train_.iloc[idx_val]\n",
    "            y_trn, y_val = y_train_.iloc[idx_train], y_train_.iloc[idx_val]\n",
    "            index_valid  = X_val.index.tolist() \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Processamento\n",
    "            #--------------------------------------------------------        \n",
    "            X_trn = TunningModels.feature_scaler(X_trn, scaler_, feature_bin_) \n",
    "            X_val = TunningModels.feature_scaler(X_val, scaler_, feature_bin_) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Modelo\n",
    "            #--------------------------------------------------------\n",
    "            #model = model_.fit(X_trn, y_trn, )\n",
    "\n",
    "            eval_set     = [(X_trn, y_trn), (X_val, y_val)]   \n",
    "            model = model_.fit(X_trn, y_trn, \n",
    "                               eval_set              = eval_set,\n",
    "                               eval_names            = ['valid', 'train'],\n",
    "                               early_stopping_rounds = int(n_estimators * .1), \n",
    "                               verbose               = False)\n",
    "            \n",
    "            best_iteration      = model.best_iteration_\n",
    "            feature_imp_values += model.feature_importances_ / fold_\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # oof\n",
    "            #--------------------------------------------------------\n",
    "            preds_valid_proba  = model.predict_proba(X_val, num_iteration = best_iteration)[:, 1]\n",
    "            y_pred_valid       = (preds_valid_proba>.5).astype(int)\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Obtenha os valores médios de cada fold para a previsão\n",
    "            #--------------------------------------------------------        \n",
    "            preds_test_prob += model.predict_proba(X_test_, num_iteration = best_iteration)[:, 1] / fold_\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Métricas \n",
    "            #--------------------------------------------------------\n",
    "            auc   = metrics.roc_auc_score(y_val, y_pred_valid)\n",
    "            f1    = metrics.f1_score(y_val, y_pred_valid)\n",
    "            lloss = metrics.log_loss(y_val, preds_valid_proba) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Concatenar validação e predição\n",
    "            #--------------------------------------------------------        \n",
    "            df_val_pred_fold = pd.DataFrame({'fold'       : fold+1,\n",
    "                                            'index'       : index_valid, \n",
    "                                            'auc'         : auc, \n",
    "                                            'f1'          : f1,\n",
    "                                            'lloss'       : lloss,\n",
    "                                            'pred_val'    : preds_valid_proba, \n",
    "                                            'train_score' : model.best_score_['train']['auc'], \n",
    "                                            'valid_score' : model.best_score_['valid']['auc'],\n",
    "                                            'target'      : y_val})\n",
    "            \n",
    "            df_train_pred_fold = pd.concat([df_train_pred_fold, df_val_pred_fold], axis=0)\n",
    "\n",
    "            auc_mean.append(auc)   \n",
    "            f1_mean.append(f1)    \n",
    "            lloss_mean.append(lloss) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Print resultado Fold\n",
    "            #--------------------------------------------------------\n",
    "            if print_result_:\n",
    "                msg = 'Fold: {} - AUC: {:2.5f} - F1-score: {:2.5f} - L.Loss: {:2.5f} - {}'\n",
    "                time_fold_start_end = TunningModels.diff(time_fold_start, datetime.now())\n",
    "                print(msg.format(fold+1, auc, f1, lloss, time_fold_start_end))\n",
    "\n",
    "            free_gpu_cache() \n",
    "\n",
    "        del X_trn, y_trn, X_val, y_val\n",
    "\n",
    "        df_train_pred_fold.sort_values(\"index\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Salvar predição em disco\n",
    "        #--------------------------------------------------------\n",
    "        X_train_prob      = df_train_pred_fold['pred_val'].to_list()\n",
    "        score             = np.mean(auc_mean)\n",
    "        y_pred_test_prob_ = preds_test_prob \n",
    "\n",
    "        if save_predict_:\n",
    "            TunningModels.save_data_model(model_             = model_, \n",
    "                                            model_name_        = model_name_, \n",
    "                                            path_              = path_, \n",
    "                                            y_pred_train_prob_ = X_train_prob, \n",
    "                                            y_pred_test_prob_  = y_pred_test_prob_, \n",
    "                                            score_             = score, \n",
    "                                            seed_              = seed_, \n",
    "                                            level_             = level_, \n",
    "                                            target_            = target_\n",
    "                                            )  \n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Print média dos Folds\n",
    "        #--------------------------------------------------------\n",
    "        time_pred_end = TunningModels.diff(time_pred_start, datetime.now())\n",
    "\n",
    "        if print_result_:\n",
    "            msg = '[Mean Fold]  AUC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - L. Loss: {:.5f}  {}'        \n",
    "            print('-'*pri_result)            \n",
    "            print(msg.format(np.mean(auc_mean),np.std(auc_mean) , np.mean(f1_mean), np.mean(lloss_mean), time_pred_end))\n",
    "            print('='*pri_result)\n",
    "            print()\n",
    "\n",
    "        free_gpu_cache() \n",
    "\n",
    "        return model, score, y_pred_test_prob_, df_train_pred_fold\n",
    "        \n",
    "    def lgbm(self, trial):\n",
    "        \n",
    "        # https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n",
    "        # https://buildmedia.readthedocs.org/media/pdf/optuna/stable/optuna.pdf\n",
    "        # https://medium.com/@am.sharma/lgbm-on-colab-with-gpu-c1c09e83f2af\n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['binary']),     \n",
    "                  'metric'            : trial.suggest_categorical('metric', ['auc']),                   \n",
    "                  'boosting_type'     : trial.suggest_categorical('boosting_type', ['gbdt']),  \n",
    "                  'importance_type'   : trial.suggest_categorical('importance_type', ['gain']),  \n",
    "                  'class_weight'      : trial.suggest_categorical('class_weight', ['balanced']),                   \n",
    "                  'learning_rate'     : trial.suggest_float('learning_rate', 0.0095, 0.11),               \n",
    "                  'max_depth'         : trial.suggest_int('max_depth', 2, 8),\n",
    "                  'n_estimators'      : trial.suggest_int('n_estimators', 100, 4000),\n",
    "                  'min_child_samples' : trial.suggest_int('min_child_samples', 180, 250),\n",
    "                  'extra_trees'       : trial.suggest_categorical('extra_trees', ['True']),  \n",
    "                  'extra_seed'        : trial.suggest_int('extra_seed', self.seed, self.seed),\n",
    "                  'max_delta_step'    : trial.suggest_float('max_delta_step', .75, .89), \n",
    "                  'reg_lambda'        : trial.suggest_float('reg_lambda', .95, 1.05), \n",
    "                  'subsample'         : trial.suggest_float('subsample', .59, .95),\n",
    "                  'seed'              : trial.suggest_int('random_state', self.seed, self.seed),                  \n",
    "                  'verbosity'         : trial.suggest_int('verbosity', -1, -1),\n",
    "                  'n_jobs'            : trial.suggest_int('n_jobs', -1, -1),\n",
    "                }\n",
    "    \n",
    "        if torch.cuda.is_available():       \n",
    "            params.update({'device': trial.suggest_categorical('device', ['gpu'])})\n",
    "                      \n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc', valid_name='valid_1')\n",
    "       \n",
    "        mdl = lgbm.LGBMClassifier(**params) #, callbacks=[pruning_callback])\n",
    "                \n",
    "        _, score, _, _  = TunningModels.cross_valid(model_         = mdl, \n",
    "                                                    model_name_    = self.name_clf, \n",
    "                                                    X_train_       = self.X_trn, \n",
    "                                                    y_train_       = self.y_trn, \n",
    "                                                    X_test_        = self.X_ts,            \n",
    "                                                    target_        = self.target,\n",
    "                                                    path_          = self.path,\n",
    "                                                    level_         = self.level,            \n",
    "                                                    seed_          = self.seed,\n",
    "                                                    feature_       = self.feature, \n",
    "                                                    feature_bin_   = self.feature_bin,\n",
    "                                                    scaler_        = self.scaler, \n",
    "                                                    save_predict_  = self.save_predict\n",
    "                                                    )\n",
    "        \n",
    "        print('param = {}'.format(params))\n",
    "        print()\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDUypJOfi345"
   },
   "source": [
    "## 1.2. LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:26:36.496560Z",
     "start_time": "2021-11-29T00:26:35.951562Z"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1638139932848,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "G1FuoNZEX0de"
   },
   "outputs": [],
   "source": [
    "feature_int      = X_test.filter(regex=r'f[0-9]').columns.to_list()\n",
    "feature_cluster  = X_test.filter(regex=r'fe_clu').columns.to_list()\n",
    "feature_static   = X_test.filter(regex=r'fe_[m-s]').columns.to_list()\n",
    "feature_         = X[feature_int + ['fe_cluster_1', 'fe_cluster_3']].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-29T00:38:02.196720Z",
     "start_time": "2021-11-29T00:26:38.364623Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "executionInfo": {
     "elapsed": 4475,
     "status": "error",
     "timestamp": 1638143378060,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "mdOnxd5jX0dg",
    "outputId": "e6be183a-5e55-4802-b27d-cdb754ef5b77",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "============================================================================================\n",
      "Training model: LGBMClassifier - seed 12359 - n_estimators: 1200 - max_depth: 4 0.01000\n",
      "============================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (110,) (102,) (110,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_48716/2123200869.py\u001b[0m in \u001b[0;36mcross_valid\u001b[1;34m(model_, model_name_, X_train_, y_train_, X_test_, fold_, target_, path_, level_, save_predict_, print_result_, seed_, feature_, feature_bin_, scaler_, threshold)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             \u001b[0mbest_iteration\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             \u001b[0mfeature_imp_values\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfold_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;31m#--------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (110,) (102,) (110,) "
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "SEED   = 12359  \n",
    "params = {'objective'         : 'binary',     \n",
    "          'metric'            : 'auc',                   \n",
    "          'boosting_type'     : 'gbdt',  \n",
    "          'importance_type'   : 'gain',  \n",
    "          'class_weight'      : 'balanced',                   \n",
    "          'learning_rate'     : 0.01,        # [.1, .11]       \n",
    "          'max_depth'         : 4,           # [4, 9]\n",
    "          'n_estimators'      : 1200,        # [1000, 5000 ]\n",
    "          'min_child_samples' : 200,         # [180, 250]\n",
    "          'extra_trees'       : True,\n",
    "          'extra_seed'        : SEED,\n",
    "          'max_delta_step'    : .8,          # [.75, 89]\n",
    "          'reg_lambda'        : 1.0,         # [.95, 1.04]                   \n",
    "          'subsample'         : .6,          # [.59, 95]\n",
    "          'device'            : 'gpu',  \n",
    "          'verbosity'         : -1, \n",
    "          'seed'              : SEED\n",
    "          }\n",
    "\n",
    "scalers = [#None, \n",
    "           StandardScaler(), \n",
    "           #RobustScaler(), \n",
    "           #MinMaxScaler(), \n",
    "           #MaxAbsScaler(), \n",
    "           #QuantileTransformer(output_distribution='normal', random_state=SEED)\n",
    "           ]\n",
    "\n",
    "score_best     = 0 \n",
    "name_model_clf = 'lgbm_' \n",
    "name_model     = name_model_clf + '001_scaler_' \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "\n",
    "for scaler in scalers: \n",
    "    \n",
    "    print(scaler)\n",
    "     \n",
    "    X_test_scaler = TunningModels.feature_scaler(df_          = X_test.copy(), \n",
    "                                                 scaler_      = scaler, \n",
    "                                                 feature_bin_ = None)\n",
    "        \n",
    "    name_mdl            = name_model + str(scaler).lower()[:4]\n",
    "    model, score, yp,df = TunningModels.cross_valid(model_         = lgbm.LGBMClassifier(**params), \n",
    "                                                    model_name_    = name_mdl, \n",
    "                                                    X_train_       = X.head(3000), \n",
    "                                                    y_train_       = y.head(3000), \n",
    "                                                    X_test_        = X_test_scaler, \n",
    "                                                    fold_          = 5, \n",
    "                                                    target_        = 'target',\n",
    "                                                    path_          = path,\n",
    "                                                    level_         = '1',\n",
    "                                                    save_predict_  = False, \n",
    "                                                    print_result_  = True,\n",
    "                                                    seed_          = SEED,\n",
    "                                                    feature_       = feature_, \n",
    "                                                    feature_bin_   = None, \n",
    "                                                    scaler_        = scaler, \n",
    "                                                    threshold      =.5                                                      \n",
    "                                                    )\n",
    "    \n",
    "    if score > score_best: \n",
    "        score_best  = score\n",
    "        scaler_best = scaler\n",
    "       \n",
    "print()\n",
    "print('Scaler best: {}'.format(scaler_best))\n",
    "print('Score      : {:2.5f}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5fsZ-O5i345"
   },
   "source": [
    "### 1.2.1. Tunning \n",
    "Nesta etapa de modelagem, vamos criar 20 modelos e salvá-los para a nossa `Stacking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yNlljM6i345",
    "outputId": "8bc42f24-1ce3-4683-a7cc-9c9c1d957fe0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "name_model = name_model_clf + '002_tunning_' \n",
    "n_trials_  = 20\n",
    "\n",
    "scaler_best = StandardScaler() \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "    \n",
    "modelOpt = TunningModels(name_model_     = name_model, \n",
    "                         X_trn_          = X, \n",
    "                         y_trn_          = y, \n",
    "                         X_ts_           = X_test_scaler,                                     \n",
    "                         feature_        = feature_,  \n",
    "                         scaler_         = scaler_best, \n",
    "                         seed_           = SEED, \n",
    "                         feature_bin_    = None, \n",
    "                         target_         = 'target', \n",
    "                         path_           = path, \n",
    "                         level_          = '1', \n",
    "                         save_predict_   = True)\n",
    "\n",
    "pruner = MedianPruner(n_startup_trials = 5,\n",
    "                      n_warmup_steps   = 0,\n",
    "                      interval_steps   = 1,\n",
    "                      n_min_trials     = 5,\n",
    "                      )\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize',\n",
    "                            sampler   = optuna.samplers.TPESampler(seed=SEED),\n",
    "                            pruner    = optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "                            #pruner    = pruner,\n",
    "                            study_name= 'lgbm_tuning'\n",
    "                            ) \n",
    "\n",
    "study.optimize(modelOpt.lgbm, n_trials=n_trials_)\n",
    "\n",
    "score_seed = study.best_value \n",
    "params     = study.best_params \n",
    "path_name  = path + 'model/optuna/' + name_model + '_{:2.5f}.pkl.z'.format(score_seed) \n",
    "  \n",
    "seed_best   = SEED\n",
    "score_best  = score_seed \n",
    "params_best = params\n",
    "\n",
    "print()\n",
    "print('-'*110)\n",
    "print('Best score: {:2.5f}'.format(scare_best))\n",
    "print('Seed      : {}'.format(SEED))\n",
    "print('Parameters:\\n\\n{}'.format(params_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRDDC2LJX0dh"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "**`NOTA:`** <br>\n",
    "    \n",
    "Com os melhores parametros gerei uma nova submissão e obtive a AUC de 0.68785.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEQa44wEi346"
   },
   "source": [
    "### Análise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "error",
     "timestamp": 1638138429519,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "RD2yIoWTi346",
    "outputId": "a0c6518b-3caf-4875-c0f6-11c02ec3c496"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Plot functions\n",
    "# --------------\n",
    "# Visualize the optimization history. See :func:`~optuna.visualization.plot_optimization_history` for the details.\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbL1Cd57i347"
   },
   "outputs": [],
   "source": [
    "#plot_intermediate_values(study)\n",
    "###################################################################################################\n",
    "# Visualize the learning curves of the trials. See :func:`~optuna.visualization.plot_intermediate_values` for the details.\n",
    "#plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIOk6e4Li347"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize high-dimensional parameter relationships. See :func:`~optuna.visualization.plot_parallel_coordinate` for the details.\n",
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgZlJAMvi347"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Select parameters to visualize.\n",
    "plot_parallel_coordinate(study, params=['max_depth', 'subsample','learning_rate', 'n_estimators' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3DA8PfAmSZY"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize hyperparameter relationships. See :func:`~optuna.visualization.plot_contour` for the details.\n",
    "#plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYBgMW9OmVVc"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Select parameters to visualize.\n",
    "plot_contour(study, params=[ 'max_depth', 'subsample','learning_rate', 'n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7ssQ77NmXBQ"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize individual hyperparameters as slice plot. See :func:`~optuna.visualization.plot_slice` for the details.\n",
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRiuCit3ndh0"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Select parameters to visualize.\n",
    "plot_slice(study, params=['max_depth', 'subsample','learning_rate', 'n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bX5_TJENmXMh"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize parameter importances. See :func:`~optuna.visualization.plot_param_importances` for the details.\n",
    "#plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wqbcq1HvoaDp"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Learn which hyperparameters are affecting the trial duration with hyperparameter importance.\n",
    "# optuna.visualization.plot_param_importances( study, target=lambda t: t.duration.total_seconds(), target_name=\"duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23-nvgOFoaN8"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Visualize empirical distribution function. See :func:`~optuna.visualization.plot_edf` for the details.\n",
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nVNrHHSi347"
   },
   "source": [
    "### 1.2.3. Modelo Final\n",
    "Agora que temos os melhores parametros, vamos treinar uma modelo com esse parametros e fazer algumas análises, para o treinamento vamos utilizar o dataset de treino (train)  e validar a performance do modelo em dados que não foram utlizados no treinamento e  vamos fazer uma pequena análise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2898,
     "status": "ok",
     "timestamp": 1638140107898,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "xVXAMYYlvUZS"
   },
   "outputs": [],
   "source": [
    "name_model_clf = 'lgbm_'\n",
    "scaler_best = StandardScaler()\n",
    "SEED = 12359\n",
    "\n",
    "X_test_scaler = TunningModels.feature_scaler(df_          = X_test.copy(), \n",
    "                                                 scaler_      = StandardScaler(), \n",
    "                                                 feature_bin_ = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1638139982096,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Q2z5TRffX0dk"
   },
   "outputs": [],
   "source": [
    "params_best = param = {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'importance_type': 'gain', \n",
    "                       'class_weight': 'balanced', 'learning_rate': 0.1086844835393899, 'max_depth': 2, \n",
    "                       'n_estimators': 2260, 'min_child_samples': 222, 'extra_trees': 'True', 'extra_seed': 12359, 'max_delta_step': 0.8094967474479909, \n",
    "                       'reg_lambda': 1.0104114282718522, 'subsample': 0.6463258626367244, 'seed': 12359, 'verbosity': -1, 'n_jobs': -1, 'device': 'gpu'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "executionInfo": {
     "elapsed": 28949,
     "status": "error",
     "timestamp": 1638140357319,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "52gsbtwyi348",
    "outputId": "708f3822-a342-449f-ff55-2b18d96ac2c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_model = name_model_clf + '003_tun'\n",
    "\n",
    "model, score, _, _  = TunningModels.cross_valid(model_         = lgbm.LGBMClassifier(**params_best), \n",
    "                                                model_name_    = name_model, \n",
    "                                                X_train_       = X_train, \n",
    "                                                y_train_       = y_train, \n",
    "                                                X_test_        = X_test_scaler, \n",
    "                                                fold_          = 5, \n",
    "                                                target_        = 'target',\n",
    "                                                path_          = path,\n",
    "                                                level_         = '1',\n",
    "                                                save_predict_  = False, \n",
    "                                                print_result_  = True,\n",
    "                                                seed_          = SEED,\n",
    "                                                feature_       = feature_, \n",
    "                                                feature_bin_   = None, \n",
    "                                                scaler_        = scaler_best, \n",
    "                                                threshold      =.5                                                      \n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmA6tODli348"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "Observando os dados acima do treinamento, a AUC está na média em relação ao processo de tunning que foi realizado na etapa anterior, vamos fazer a predição em dados que o modelo não viu no treinamento e continuar com a análise, primeito vamos transformar os dados de validação.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIoXk1LxX0dl"
   },
   "outputs": [],
   "source": [
    "X_valid_scaler = TunningModels.feature_scaler(X_valid[feature_].copy(), scaler_best, None )\n",
    "X_valid_scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOMOyYkPX0dl"
   },
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba (X_valid_scaler)[:,1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2p1olpsi349"
   },
   "source": [
    "#### 1.2.3.1. Analise do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7HbJ8Tei349"
   },
   "source": [
    "#### 1.2.3.1.1. Curva Roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftidKrDUi34-"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, y_pred_proba)\n",
    "plot_roc_curve(fpr, tpr, label=\"LGBM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vm2gsRY3i34-"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "Observando o gráfico acima, podemos concluir que o melhor ponto de corte (threshold) fica em torno de .4 à .45, isto é, esse ponto de corte melhora o F1-score,  vamos fazer esse teste.  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7_XX5WHX0dn"
   },
   "source": [
    "- **SEM PONTO DE CORTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BcpHgTNi34-"
   },
   "outputs": [],
   "source": [
    "threshold = .5\n",
    "y_pred = (y_pred_proba >threshold)\n",
    "\n",
    "f1_002  = metrics.f1_score (y_valid, y_pred)\n",
    "auc_002 = metrics.roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "print('')\n",
    "print('F1-score: {:2.5f}'.format(f1_002))\n",
    "print('AUC     : {:2.5f}'.format(auc_002))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df6ogIVfX0dn"
   },
   "source": [
    "- **COM PONTO DE CORTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmyE4HnGX0do"
   },
   "outputs": [],
   "source": [
    "threshold = .49\n",
    "y_pred  = (y_pred_proba >threshold)\n",
    "f1_002  = metrics.f1_score (y_valid, y_pred)\n",
    "auc_002 = metrics.roc_auc_score(y_valid, y_pred)\n",
    "\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "print('')\n",
    "print('F1-score: {:2.5f}'.format(f1_002))\n",
    "print('AUC     : {:2.5f}'.format(auc_002))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vrn4XBWGX0do"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "Podemos observar acima, com um ponto de corte de .45 obtivemos um F1-score de 0.69162 em relação ao ponto de corte padrão de .5 que gerou um F1-score de 0.66127, uma observação importante que tenho que destacar é que o ponto de corte ideal depende muito do entendimento do negócio que estamos modelando.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1_DxLR-i34-"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "ax = plt.subplot(1,2,1)\n",
    "\n",
    "metrics.plot_confusion_matrix(model, \n",
    "                              X_valid_scaler, \n",
    "                              y_valid, \n",
    "                              cmap          = 'inferno', \n",
    "                              values_format = 'd', \n",
    "                              ax            = ax) #true’, ‘pred’, ‘all’\n",
    "\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "ax= plt.subplot(1,2,2)\n",
    "metrics.plot_confusion_matrix(model, X_valid_scaler, y_valid, cmap='inferno', normalize='all', ax=ax) \n",
    "plt.title('Confusion matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNQmQE4HX0do"
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "com as matrizes de confusão acima podemos ter uma melhor noção para dos número que o modelo consegue gerar na predição, podemos obeservar que o modelo de Random Forest para esse conjunto de dados tem uma taxa razoavel na predição, principalmente na predição de verdadeiro positivo com um percentual de erro de 23%, isto é, o modelo classifica erradamente falsos positivos com sendo verdadeiro posito e acerta 33%, em relação ao falso positivo tem um erro de 17% com certo de 28%.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SddO5fbXi34_"
   },
   "source": [
    "### 1.2.4. Divercidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFW2f9_hX0dp"
   },
   "source": [
    "#### 1.2.4.1. Feature Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGAddqK5i34_"
   },
   "source": [
    "#### 1.2.4.1. SEED\n",
    "Nesta etapa vamos utilizar os melhores parametros, que encontramos na tunagem acima, com `seed` diferentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aD5OMGA2gzKH",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "SEED_       = [42, 59, 100, 200, 1000, 1500, 2020, 2021, 5000, 10000, 7000]\n",
    "name_model  = name_model_clf + '005_div_seed' \n",
    "df_seed     = pd.DataFrame()\n",
    "params_seed = params_best.copy()\n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "\n",
    "for i, seed_ in  enumerate (SEED_):     \n",
    "    \n",
    "    params_seed.update({'random_state': seed_})\n",
    "    \n",
    "    _, score, y_hat, _ = TunningModels.cross_valid(model_         = lgbm.LGBMClassifier(**params_best), \n",
    "                                                   model_name_    = name_mdl,\n",
    "                                                   X_train_       = X,\n",
    "                                                   y_train_       = y, \n",
    "                                                   X_test_        = X_test_scaler, \n",
    "                                                   fold_          = 5, \n",
    "                                                   target_        = 'target',\n",
    "                                                   path_          = path,\n",
    "                                                   level_         = '1',\n",
    "                                                   save_predict_  = True, \n",
    "                                                   print_result_  = True,\n",
    "                                                   seed_          = seed_,\n",
    "                                                   feature_       = feature_, \n",
    "                                                   feature_bin_   = None, \n",
    "                                                   scaler_        = scaler_best, \n",
    "                                                   threshold      =.5                                                      \n",
    "                                                   )\n",
    "\n",
    "    if score > score_best: \n",
    "        seed_best  = seed_\n",
    "        score_best = score\n",
    "\n",
    "    df_seed['seed_' + str(seed_)] = y_hat \n",
    "   \n",
    "print('Seed best: {}'.format(seed_best))\n",
    "print('Score    : {:2.5f}'.format(score_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_Ul_1SEA1Wu"
   },
   "outputs": [],
   "source": [
    " df_seed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2DQqQ_HX0dq"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': df_submission.id, target: df_seed.mean(axis=1)})\n",
    "submission.to_csv(path + 'Data/submission/lgbm_005_div_seed.csv', index=False)\n",
    "# kaggle 0.74514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMJA2EZPi35A"
   },
   "source": [
    "### 1.2.5. Ensable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yo0Gg8ezi35A"
   },
   "source": [
    "#### 1.2.5.1. Recuparar dataset\n",
    "Vamos recuperar todas as previsões do LGBM para gerar um ensable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 357757,
     "status": "ok",
     "timestamp": 1635632249520,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "RW7YFOmpi35A",
    "outputId": "2d3582af-6067-42dc-d53f-f8b8ab0ed0e0"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "df_train, df_test = TunningModels.df_return_preds_tunning(train_shape_row = X.iloc[X_sample_idx].shape[0], \n",
    "                                                          test_shape_row  = X_test.shape[0])\n",
    "print(df_train.shape, df_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "error",
     "timestamp": 1635653302588,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "4MzP_wQssvmm",
    "outputId": "12838c8b-dd3c-457e-9ec6-d5b97493a682"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5YNY8dDi35B"
   },
   "outputs": [],
   "source": [
    "y_pred      = df_train_rf['target']\n",
    "df_train_rf = df_train_rf.filter(regex=r'_0.8' , axis=1)\n",
    "df_test_rf  = df_test_rf.filter(regex=r'_0.8', axis=1)\n",
    "\n",
    "df_train_rf['target'] = y_pred\n",
    "df_train_rf.shape, df_test_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2h7hCy3li35B"
   },
   "outputs": [],
   "source": [
    "df_train_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjE0558vi35B"
   },
   "source": [
    "#### 1.2.5.2. Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohQgKKpAi35B"
   },
   "outputs": [],
   "source": [
    "df_test_rf.mean(axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-wD5-jqi35B"
   },
   "source": [
    "#### 1.2.5.3. Gerar submission \n",
    "Vamos gerar uma submission com a media das previssões, para termos uma ideia de como estamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRnXoCBli35B"
   },
   "outputs": [],
   "source": [
    "y_hat_rf_mean = df_test_rf.mean(axis=1)\n",
    "submission = pd.DataFrame({'id': df_submission.id, 'claim': y_hat_rf_mean })\n",
    "submission.to_csv(path + 'Data/sumbmission/rf_003_feature_gr.csv', index=False) \n",
    "# score kaggle: 0.60423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilLCawrmi35B"
   },
   "outputs": [],
   "source": [
    "y_hat_rf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABSiqjJ6i35C"
   },
   "source": [
    "#### 1.2.5.4. Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1635556063137,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "cxfrr8nri35C",
    "outputId": "e3bd13e0-7cd5-4dfc-bbd3-2fe194e5e6f8"
   },
   "outputs": [],
   "source": [
    "graf_corr(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgPjew7ni35C"
   },
   "source": [
    "Temos muitas previsões autocorrelacionadas, vamos fazer a exclusão de algumas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1635556138271,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "8z8dijuki35C",
    "outputId": "5fe08ad4-759e-43d0-c217-68be0008da69"
   },
   "outputs": [],
   "source": [
    "corr_features = correlation(df_train, 0.75)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1635556144198,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "uh5ruyM9i35C",
    "outputId": "c1783637-54fb-43a3-c249-53e2c2b07ee0"
   },
   "outputs": [],
   "source": [
    "#df_train_lgbm.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "graf_corr(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQmZCcWOi35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Km30XSF1i35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JL9ovOji35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsCcwuYli35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZuPiQx0i35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8D2GU_zi35D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8inoxnHoi35E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQtf0EQCi35E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BKsnKtP-i35E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYYcJkpWi35F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HD8xVlwi35F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f13sutPOi35F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpD7byhji35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNAFtSx4i35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWldS0Vci35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOZqBQYli35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbnxpM3Ri35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhW5FN52i35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWVKD9FSi35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVYIn8LEi35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mthkDSY9i35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBk756-si35G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHjrjwxHi35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AETHT9Mni35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd-KsX3ti35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhJnL1UYi35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulbzMQ7Hi35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23YYz7yOi35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSUK4QWai35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql7QYTGKi35H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT14587Mi35H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "04 -  Tunning Linear LGBM .ipynb",
   "toc_visible": true,
   "version": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "552.8px",
    "left": "21px",
    "top": "111.6px",
    "width": "219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
