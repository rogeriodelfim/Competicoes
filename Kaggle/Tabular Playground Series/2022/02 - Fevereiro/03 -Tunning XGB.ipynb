{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFogj-Cdi34f",
    "papermill": {
     "duration": 0.062831,
     "end_time": "2022-02-18T03:57:59.782186",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.719355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 div class='alert alert-success'><center> Tunning Hyperparameters XGB\n",
    " </center></h1>\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKJFMrjqi34j",
    "papermill": {
     "duration": 0.060611,
     "end_time": "2022-02-18T03:57:59.904057",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.843446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div class=\"alert alert-success\">  0. IMPORTAÇÕES </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:36:57.637127Z",
     "start_time": "2022-02-13T14:36:49.058099Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:08:56.539803Z",
     "iopub.status.busy": "2022-02-24T03:08:56.539315Z",
     "iopub.status.idle": "2022-02-24T03:09:22.326881Z",
     "shell.execute_reply": "2022-02-24T03:09:22.326044Z",
     "shell.execute_reply.started": "2022-02-24T03:08:56.539773Z"
    },
    "executionInfo": {
     "elapsed": 12874,
     "status": "ok",
     "timestamp": 1645145676268,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "U2CKimxvi34k",
    "outputId": "5fa75f99-0fdc-48f2-ea90-839f9f6df8c3",
    "papermill": {
     "duration": 26.515095,
     "end_time": "2022-02-18T03:58:26.480329",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.965234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --q optuna\n",
    "!pip install --q GPUtil\n",
    "!pip install --q Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T20:41:09.622469Z",
     "start_time": "2022-02-15T20:41:09.240463Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:22.329148Z",
     "iopub.status.busy": "2022-02-24T03:09:22.328873Z",
     "iopub.status.idle": "2022-02-24T03:09:22.333817Z",
     "shell.execute_reply": "2022-02-24T03:09:22.3331Z",
     "shell.execute_reply.started": "2022-02-24T03:09:22.32911Z"
    },
    "executionInfo": {
     "elapsed": 2727,
     "status": "ok",
     "timestamp": 1645145678988,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Fk0qDNyXlyY4",
    "outputId": "b3bf4126-20cf-43ef-f1ba-1a175887adb6",
    "papermill": {
     "duration": 0.067995,
     "end_time": "2022-02-18T03:58:26.611947",
     "exception": false,
     "start_time": "2022-02-18T03:58:26.543952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckrEOEuUi34l",
    "papermill": {
     "duration": 0.060234,
     "end_time": "2022-02-18T03:58:26.732418",
     "exception": false,
     "start_time": "2022-02-18T03:58:26.672184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:54:50.031013Z",
     "start_time": "2022-02-25T17:54:40.340632Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:22.335337Z",
     "iopub.status.busy": "2022-02-24T03:09:22.335089Z",
     "iopub.status.idle": "2022-02-24T03:09:24.005609Z",
     "shell.execute_reply": "2022-02-24T03:09:24.004737Z",
     "shell.execute_reply.started": "2022-02-24T03:09:22.335302Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645145678988,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "icBhRH0Si34m",
    "papermill": {
     "duration": 1.643517,
     "end_time": "2022-02-18T03:58:28.436349",
     "exception": false,
     "start_time": "2022-02-18T03:58:26.792832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import glob\n",
    "import optuna\n",
    "import re\n",
    "import sklearn.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:54:50.984930Z",
     "start_time": "2022-02-25T17:54:50.914932Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:24.007774Z",
     "iopub.status.busy": "2022-02-24T03:09:24.007544Z",
     "iopub.status.idle": "2022-02-24T03:09:24.068519Z",
     "shell.execute_reply": "2022-02-24T03:09:24.067862Z",
     "shell.execute_reply.started": "2022-02-24T03:09:24.00774Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1645145678989,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OjwX36f3i34m",
    "papermill": {
     "duration": 0.128457,
     "end_time": "2022-02-18T03:58:28.627075",
     "exception": false,
     "start_time": "2022-02-18T03:58:28.498618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import matplotlib.pyplot    as plt \n",
    "import seaborn              as sns\n",
    "import joblib               as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:42.410892Z",
     "start_time": "2022-02-25T17:54:51.666582Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:24.070482Z",
     "iopub.status.busy": "2022-02-24T03:09:24.069598Z",
     "iopub.status.idle": "2022-02-24T03:09:25.26017Z",
     "shell.execute_reply": "2022-02-24T03:09:25.25943Z",
     "shell.execute_reply.started": "2022-02-24T03:09:24.070451Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645145678990,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "xyxT1_-ei34n",
    "papermill": {
     "duration": 1.31662,
     "end_time": "2022-02-18T03:58:30.004564",
     "exception": false,
     "start_time": "2022-02-18T03:58:28.687944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn             as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:44.058454Z",
     "start_time": "2022-02-25T17:55:42.412660Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.262198Z",
     "iopub.status.busy": "2022-02-24T03:09:25.261377Z",
     "iopub.status.idle": "2022-02-24T03:09:25.329966Z",
     "shell.execute_reply": "2022-02-24T03:09:25.329278Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.262158Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645145678990,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "me4iqeW8i34o",
    "papermill": {
     "duration": 0.14308,
     "end_time": "2022-02-18T03:58:30.209463",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.066383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost              as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:44.090454Z",
     "start_time": "2022-02-25T17:55:44.059436Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.331305Z",
     "iopub.status.busy": "2022-02-24T03:09:25.331053Z",
     "iopub.status.idle": "2022-02-24T03:09:25.345075Z",
     "shell.execute_reply": "2022-02-24T03:09:25.344422Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.33127Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645145678991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "RM2RI3_ti34p",
    "papermill": {
     "duration": 0.076855,
     "end_time": "2022-02-18T03:58:30.34785",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.270995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection       import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing         import QuantileTransformer, StandardScaler\n",
    "from sklearn.preprocessing         import RobustScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
    "from sklearn                       import metrics\n",
    "from sklearn.feature_selection     import SelectKBest, SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:44.106424Z",
     "start_time": "2022-02-25T17:55:44.092400Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.347785Z",
     "iopub.status.busy": "2022-02-24T03:09:25.347598Z",
     "iopub.status.idle": "2022-02-24T03:09:25.355304Z",
     "shell.execute_reply": "2022-02-24T03:09:25.354564Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.34776Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645145678991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "IMnB1bcOi34p",
    "papermill": {
     "duration": 0.069198,
     "end_time": "2022-02-18T03:58:30.478124",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.408926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optuna.samplers               import TPESampler\n",
    "from optuna.visualization          import plot_edf\n",
    "from optuna.visualization          import plot_optimization_history\n",
    "from optuna.visualization          import plot_parallel_coordinate\n",
    "from optuna.visualization          import plot_param_importances\n",
    "from optuna.visualization          import plot_slice\n",
    "from optuna.visualization          import plot_intermediate_values\n",
    "from optuna.visualization          import plot_contour\n",
    "from optuna.pruners                import MedianPruner\n",
    "from optuna.pruners                import BasePruner\n",
    "from optuna.trial._state           import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.560660Z",
     "start_time": "2022-02-25T17:55:44.108397Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.357294Z",
     "iopub.status.busy": "2022-02-24T03:09:25.35683Z",
     "iopub.status.idle": "2022-02-24T03:09:25.844887Z",
     "shell.execute_reply": "2022-02-24T03:09:25.844117Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.357255Z"
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1645145680299,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "rxIrWu38i34q",
    "outputId": "5c90197d-4977-4549-de18-8dac945cdd66",
    "papermill": {
     "duration": 0.587345,
     "end_time": "2022-02-18T03:58:31.126788",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.539443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from GPUtil                        import showUtilization as gpu_usage\n",
    "from numba                         import cuda\n",
    "from sklearn.ensemble              import IsolationForest\n",
    "from psutil                        import virtual_memory\n",
    "from datetime                      import datetime\n",
    "from psutil                        import virtual_memory\n",
    "from sklearn.utils.class_weight    import compute_sample_weight\n",
    "from boruta                        import BorutaPy\n",
    "from multiprocessing               import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwyizAfdi34r",
    "papermill": {
     "duration": 0.061772,
     "end_time": "2022-02-18T03:58:31.253664",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.191892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.2. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.607479Z",
     "start_time": "2022-02-25T17:55:47.566533Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.848283Z",
     "iopub.status.busy": "2022-02-24T03:09:25.847963Z",
     "iopub.status.idle": "2022-02-24T03:09:25.865066Z",
     "shell.execute_reply": "2022-02-24T03:09:25.864365Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.848244Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "hide_input": true,
    "id": "1vHZjDzgi34r",
    "papermill": {
     "duration": 0.079795,
     "end_time": "2022-02-18T03:58:31.395618",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.315823",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jupyter_setting():\n",
    "    \n",
    "    %matplotlib inline\n",
    "      \n",
    "    #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "    #plt.style.use('bmh') \n",
    "    #plt.rcParams['figure.figsize'] = [20,15]\n",
    "    #plt.rcParams['font.size']      = 13\n",
    "     \n",
    "    pd.options.display.max_columns = None\n",
    "    #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    warnings.simplefilter('ignore')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "    #sns.palplot(sns.color_palette(icecream))\n",
    "    \n",
    "    colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "    \n",
    "    # Colors\n",
    "    dark_red   = \"#b20710\"\n",
    "    black      = \"#221f1f\"\n",
    "    green      = \"#009473\"\n",
    "    myred      = '#CD5C5C'\n",
    "    myblue     = '#6495ED'\n",
    "    mygreen    = '#90EE90'    \n",
    "    color_cols = [myred, myblue,mygreen]\n",
    "    \n",
    "    return icecream, colors, color_cols\n",
    "\n",
    "icecream, colors, color_cols = jupyter_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.638468Z",
     "start_time": "2022-02-25T17:55:47.610473Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.86794Z",
     "iopub.status.busy": "2022-02-24T03:09:25.867275Z",
     "iopub.status.idle": "2022-02-24T03:09:25.882197Z",
     "shell.execute_reply": "2022-02-24T03:09:25.881525Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.867892Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "m-u-wKS5i34s",
    "papermill": {
     "duration": 0.075703,
     "end_time": "2022-02-18T03:58:31.532703",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.653469Z",
     "start_time": "2022-02-25T17:55:47.640472Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.884162Z",
     "iopub.status.busy": "2022-02-24T03:09:25.883577Z",
     "iopub.status.idle": "2022-02-24T03:09:25.894041Z",
     "shell.execute_reply": "2022-02-24T03:09:25.893252Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.884125Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "oT4xvNQxi34t",
    "papermill": {
     "duration": 0.073516,
     "end_time": "2022-02-18T03:58:31.66705",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.593534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision Recall vs threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.668469Z",
     "start_time": "2022-02-25T17:55:47.655469Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.895904Z",
     "iopub.status.busy": "2022-02-24T03:09:25.895686Z",
     "iopub.status.idle": "2022-02-24T03:09:25.905529Z",
     "shell.execute_reply": "2022-02-24T03:09:25.904708Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.895879Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OzJVgUuTi34u",
    "papermill": {
     "duration": 0.068545,
     "end_time": "2022-02-18T03:58:31.797089",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.728544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n",
    "    \n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision vs recall')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.683506Z",
     "start_time": "2022-02-25T17:55:47.671469Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.90806Z",
     "iopub.status.busy": "2022-02-24T03:09:25.907283Z",
     "iopub.status.idle": "2022-02-24T03:09:25.915693Z",
     "shell.execute_reply": "2022-02-24T03:09:25.915003Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.907981Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "51KsDDGLi34u",
    "papermill": {
     "duration": 0.06895,
     "end_time": "2022-02-18T03:58:31.926635",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.857685",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('XGBR ROC curve for TPS 09')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.699471Z",
     "start_time": "2022-02-25T17:55:47.685473Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.917475Z",
     "iopub.status.busy": "2022-02-24T03:09:25.917167Z",
     "iopub.status.idle": "2022-02-24T03:09:25.928613Z",
     "shell.execute_reply": "2022-02-24T03:09:25.927921Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.917429Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3gf0D8QLi34u",
    "papermill": {
     "duration": 0.070047,
     "end_time": "2022-02-18T03:58:32.056995",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.986948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_feature_corr(df, annot_=False, threshold=.8, print_var=False):\n",
    "    \n",
    "    df = df.corr(method ='pearson').round(5)\n",
    "\n",
    "    # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "    mask = np.zeros_like(df)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Making a plot\n",
    "    plt.figure(figsize=(20,12))\n",
    "    ax = sns.heatmap(df, annot=annot_, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n",
    "\n",
    "    ax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), \n",
    "             rotation      = 90, \n",
    "             ha            = \"right\",\n",
    "             rotation_mode = \"anchor\", \n",
    "             weight        = \"normal\")\n",
    "\n",
    "    plt.setp(ax.get_yticklabels(), \n",
    "             weight        = \"normal\",\n",
    "             rotation_mode = \"anchor\", \n",
    "             rotation      = 0, \n",
    "             ha            = \"right\");\n",
    "    \n",
    "    if print_var: \n",
    "        print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n",
    "        df_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\n",
    "        df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "        display(df_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.714470Z",
     "start_time": "2022-02-25T17:55:47.701473Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.930451Z",
     "iopub.status.busy": "2022-02-24T03:09:25.930231Z",
     "iopub.status.idle": "2022-02-24T03:09:25.939257Z",
     "shell.execute_reply": "2022-02-24T03:09:25.938407Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.930428Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "YYXsmuJwi34u",
    "papermill": {
     "duration": 0.07063,
     "end_time": "2022-02-18T03:58:32.191628",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.120998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "\n",
    "    col_corr    = set()  # Conjunto de todos os nomes de colunas correlacionadas\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold: # estamos interessados no valor coeficiente absoluto\n",
    "                colname = corr_matrix.columns[i]        # obtendo o nome da coluna\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.730507Z",
     "start_time": "2022-02-25T17:55:47.716468Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.940912Z",
     "iopub.status.busy": "2022-02-24T03:09:25.940629Z",
     "iopub.status.idle": "2022-02-24T03:09:25.947533Z",
     "shell.execute_reply": "2022-02-24T03:09:25.946745Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.940878Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "GuS0Lh52i34v",
    "papermill": {
     "duration": 0.066949,
     "end_time": "2022-02-18T03:58:32.318918",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.251969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    \n",
    "    # https://www.kaggle.com/getting-started/140636\n",
    "    #print(\"Initial GPU Usage\")\n",
    "    #gpu_usage()                             \n",
    "\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.746509Z",
     "start_time": "2022-02-25T17:55:47.732468Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.948666Z",
     "iopub.status.busy": "2022-02-24T03:09:25.948458Z",
     "iopub.status.idle": "2022-02-24T03:09:25.957094Z",
     "shell.execute_reply": "2022-02-24T03:09:25.956217Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.948642Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "25zqU_0-dvOi",
    "papermill": {
     "duration": 0.068318,
     "end_time": "2022-02-18T03:58:32.447875",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.379557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diff(t_a, t_b):\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.762509Z",
     "start_time": "2022-02-25T17:55:47.748466Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.959284Z",
     "iopub.status.busy": "2022-02-24T03:09:25.958611Z",
     "iopub.status.idle": "2022-02-24T03:09:25.970633Z",
     "shell.execute_reply": "2022-02-24T03:09:25.96977Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.959187Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "apj7RUQqdxBz",
    "papermill": {
     "duration": 0.080776,
     "end_time": "2022-02-18T03:58:32.589498",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.508722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe(df):\n",
    "    var = df.columns\n",
    "\n",
    "    # Medidas de tendência central, média e mediana \n",
    "    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "    # Dispensão - str, min , max range skew, kurtosis\n",
    "    d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "    d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "    d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "    # concatenete \n",
    "    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.778472Z",
     "start_time": "2022-02-25T17:55:47.764471Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.97304Z",
     "iopub.status.busy": "2022-02-24T03:09:25.972493Z",
     "iopub.status.idle": "2022-02-24T03:09:25.980551Z",
     "shell.execute_reply": "2022-02-24T03:09:25.979713Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.973005Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "itZLuff_d27q",
    "papermill": {
     "duration": 0.077438,
     "end_time": "2022-02-18T03:58:32.734219",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.656781",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for TPS 09')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.794470Z",
     "start_time": "2022-02-25T17:55:47.780489Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.982344Z",
     "iopub.status.busy": "2022-02-24T03:09:25.982023Z",
     "iopub.status.idle": "2022-02-24T03:09:25.991728Z",
     "shell.execute_reply": "2022-02-24T03:09:25.990882Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.98224Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "TRIUWUu0d68a",
    "papermill": {
     "duration": 0.081141,
     "end_time": "2022-02-18T03:58:32.879252",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.798111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_plot(matrix, labels = None, title = None):\n",
    "        \n",
    "    labels = labels if labels else ['Negative (0)', 'Positive (1)']    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    \n",
    "    sns.heatmap(data        = matrix, \n",
    "                cmap        = 'Blues', \n",
    "                annot       = True, \n",
    "                fmt         = 'd',\n",
    "                xticklabels = labels, \n",
    "                yticklabels = labels, \n",
    "                ax          = ax);\n",
    "    \n",
    "    ax.set_xlabel('\\n PREVISTO', fontsize=15)\n",
    "    ax.set_ylabel('REAL \\n', fontsize=15)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.close();\n",
    "    \n",
    "    return fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.809473Z",
     "start_time": "2022-02-25T17:55:47.795470Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.993173Z",
     "iopub.status.busy": "2022-02-24T03:09:25.992871Z",
     "iopub.status.idle": "2022-02-24T03:09:26.002489Z",
     "shell.execute_reply": "2022-02-24T03:09:26.00183Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.993138Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "q6u5INXLd_Vy",
    "papermill": {
     "duration": 0.073793,
     "end_time": "2022-02-18T03:58:33.023609",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.949816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_outlier(df, feature):\n",
    "    col = [(0,4), (5,9)]\n",
    "\n",
    "    df_plot = ((df[feature] - df[feature].min())/\n",
    "               (df[feature].max() - df[feature].min()))\n",
    "\n",
    "    fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "    for i, (x) in enumerate(col): \n",
    "        sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:47.825469Z",
     "start_time": "2022-02-25T17:55:47.811472Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:26.004377Z",
     "iopub.status.busy": "2022-02-24T03:09:26.003772Z",
     "iopub.status.idle": "2022-02-24T03:09:26.014485Z",
     "shell.execute_reply": "2022-02-24T03:09:26.013764Z",
     "shell.execute_reply.started": "2022-02-24T03:09:26.004276Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "lNMWoOTNeCni",
    "papermill": {
     "duration": 0.074269,
     "end_time": "2022-02-18T03:58:33.162804",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.088535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_eval():\n",
    "\n",
    "    results     = model.evals_result()\n",
    "    ntree_limit = model.best_ntree_limit\n",
    "\n",
    "    plt.figure(figsize=(20,7))\n",
    "\n",
    "    for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "        \n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "        plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "        plt.axvline(ntree_limit, \n",
    "                    color=\"gray\", \n",
    "                    label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "                    \n",
    "        \n",
    "        title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "        plt.title(title_name)\n",
    "        plt.xlabel(\"Número de árvores\")\n",
    "        plt.ylabel(error)\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puAI82JpDOJO",
    "papermill": {
     "duration": 0.059938,
     "end_time": "2022-02-18T03:58:33.28494",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.225002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.3. GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iISld6GaDyRM",
    "papermill": {
     "duration": 0.060529,
     "end_time": "2022-02-18T03:58:33.405688",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.345159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3.1. Informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:55:48.028469Z",
     "start_time": "2022-02-25T17:55:47.827486Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:20.308019Z",
     "iopub.status.busy": "2022-02-24T03:14:20.307662Z",
     "iopub.status.idle": "2022-02-24T03:14:20.374233Z",
     "shell.execute_reply": "2022-02-24T03:14:20.373401Z",
     "shell.execute_reply.started": "2022-02-24T03:14:20.307981Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Je1LG7eeDL1s",
    "outputId": "5f68635a-c0ed-4f19-979a-83456e39b44d",
    "papermill": {
     "duration": 0.12607,
     "end_time": "2022-02-18T03:58:33.592385",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.466315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 25 14:55:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.06       Driver Version: 510.06       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   54C    P8    N/A /  N/A |    847MiB /  4096MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1224    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A      3636    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A      4496    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      9984    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     12004    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14444    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     15164    C+G   ...afe Family\\SafeFamily.exe    N/A      |\n",
      "|    0   N/A  N/A     15696    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     17684    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19784    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     39224    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     73392    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     86416    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     94332    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     94588    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     95880    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWJ4r84ZEAIM",
    "papermill": {
     "duration": 0.06595,
     "end_time": "2022-02-18T03:58:33.720046",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.654096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3.2. Memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:56:31.474264Z",
     "start_time": "2022-02-25T17:56:31.459223Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:21.695627Z",
     "iopub.status.busy": "2022-02-24T03:14:21.694987Z",
     "iopub.status.idle": "2022-02-24T03:14:21.70313Z",
     "shell.execute_reply": "2022-02-24T03:14:21.702268Z",
     "shell.execute_reply.started": "2022-02-24T03:14:21.695585Z"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1645133006185,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OVohZ_xSD33t",
    "outputId": "040c8b16-54f0-41c5-bd8a-52cb5aea9e58",
    "papermill": {
     "duration": 0.071981,
     "end_time": "2022-02-18T03:58:33.865429",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.793448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 17.0 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "ram_gb = virtual_memory().total / 1e9\n",
    "\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_PfcxeGi34v",
    "papermill": {
     "duration": 0.061017,
     "end_time": "2022-02-18T03:58:33.98797",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.926953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.4. Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTgQwT5NeSu6",
    "papermill": {
     "duration": 0.060746,
     "end_time": "2022-02-18T03:58:34.110711",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.049965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.1. Estrutura de diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:56:35.585304Z",
     "start_time": "2022-02-25T17:56:35.571291Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:23.688213Z",
     "iopub.status.busy": "2022-02-24T03:14:23.687432Z",
     "iopub.status.idle": "2022-02-24T03:14:23.693944Z",
     "shell.execute_reply": "2022-02-24T03:14:23.693212Z",
     "shell.execute_reply.started": "2022-02-24T03:14:23.688161Z"
    },
    "id": "nvZIRsuIePhl",
    "papermill": {
     "duration": 0.07172,
     "end_time": "2022-02-18T03:58:34.245611",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.173891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'model', \n",
    "         'model/preds', 'model/optuna','model/preds/test', 'model/mdl/',\n",
    "         'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n",
    "         'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n",
    "         'model/preds/train/n3', 'model/preds/param',  \n",
    "         'Data/submission/tunning/']\n",
    "\n",
    "for path in paths:\n",
    "    try:\n",
    "        os.mkdir(path)       \n",
    "    except:\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:59:04.738277Z",
     "start_time": "2022-02-25T17:59:04.730282Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:25.407474Z",
     "iopub.status.busy": "2022-02-24T03:14:25.406929Z",
     "iopub.status.idle": "2022-02-24T03:14:25.41181Z",
     "shell.execute_reply": "2022-02-24T03:14:25.410763Z",
     "shell.execute_reply.started": "2022-02-24T03:14:25.40742Z"
    },
    "id": "UaT5Rgjli34v",
    "papermill": {
     "duration": 0.067957,
     "end_time": "2022-02-18T03:58:34.375506",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.307549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#path      = '/content/drive/MyDrive/kaggle/Tabular Playground Series/2022/02 - Fevereiro/'\n",
    "#path      = '../input/tabular-playground-series-feb-2022/'\n",
    "path      = 'Data/'\n",
    "path_data = ''  \n",
    "path_pkl  = 'pkl/' #'../input/tps-feb-01-22/'\n",
    "path_sub  = '' #'../input/tabular-playground-series-feb-2022/'\n",
    "target    = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:40:57.479332Z",
     "start_time": "2022-02-13T14:40:57.473293Z"
    },
    "id": "3lCczGg3cCgV",
    "papermill": {
     "duration": 0.061762,
     "end_time": "2022-02-18T03:58:34.501058",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.439296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2. Carregar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:59:06.706786Z",
     "start_time": "2022-02-25T17:59:05.682471Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:26.926877Z",
     "iopub.status.busy": "2022-02-24T03:14:26.926589Z",
     "iopub.status.idle": "2022-02-24T03:14:29.403323Z",
     "shell.execute_reply": "2022-02-24T03:14:29.40264Z",
     "shell.execute_reply.started": "2022-02-24T03:14:26.926842Z"
    },
    "executionInfo": {
     "elapsed": 5127,
     "status": "ok",
     "timestamp": 1645133017005,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Ar5Fty2Ei34v",
    "outputId": "b01a91f0-f9b6-4502-831b-6abe6c10335b",
    "papermill": {
     "duration": 3.456604,
     "end_time": "2022-02-18T03:58:38.018591",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.561987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123993, 318), (100000, 316))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train     = jb.load(path + path_data + path_pkl + 'df2_nb_02_train.pkl.z')\n",
    "df3_test      = jb.load(path + path_data + path_pkl + 'df2_nb_02_test.pkl.z')\n",
    "df_submission = pd.read_csv(path + path_sub + 'sample_submission.csv')\n",
    "\n",
    "df3_train.shape, df3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T17:59:59.201853Z",
     "start_time": "2022-02-25T17:59:58.697511Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:30.748321Z",
     "iopub.status.busy": "2022-02-24T03:14:30.74788Z",
     "iopub.status.idle": "2022-02-24T03:14:30.97518Z",
     "shell.execute_reply": "2022-02-24T03:14:30.974494Z",
     "shell.execute_reply.started": "2022-02-24T03:14:30.748283Z"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1645133017725,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "-qfjHtY0i34w",
    "outputId": "68c97d0c-e852-484b-e19d-47e003f2f3d4",
    "papermill": {
     "duration": 0.267393,
     "end_time": "2022-02-18T03:58:38.348227",
     "exception": false,
     "start_time": "2022-02-18T03:58:38.080834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A0T0G0C10</th>\n",
       "      <th>A0T0G1C9</th>\n",
       "      <th>A0T0G2C8</th>\n",
       "      <th>A0T0G3C7</th>\n",
       "      <th>A0T0G4C6</th>\n",
       "      <th>A0T0G5C5</th>\n",
       "      <th>A0T0G6C4</th>\n",
       "      <th>A0T0G7C3</th>\n",
       "      <th>A0T0G8C2</th>\n",
       "      <th>A0T0G9C1</th>\n",
       "      <th>A0T0G10C0</th>\n",
       "      <th>A0T1G0C9</th>\n",
       "      <th>A0T1G1C8</th>\n",
       "      <th>A0T1G2C7</th>\n",
       "      <th>A0T1G3C6</th>\n",
       "      <th>A0T1G4C5</th>\n",
       "      <th>A0T1G5C4</th>\n",
       "      <th>A0T1G6C3</th>\n",
       "      <th>A0T1G7C2</th>\n",
       "      <th>A0T1G8C1</th>\n",
       "      <th>A0T1G9C0</th>\n",
       "      <th>A0T2G0C8</th>\n",
       "      <th>A0T2G1C7</th>\n",
       "      <th>A0T2G2C6</th>\n",
       "      <th>A0T2G3C5</th>\n",
       "      <th>A0T2G4C4</th>\n",
       "      <th>A0T2G5C3</th>\n",
       "      <th>A0T2G6C2</th>\n",
       "      <th>A0T2G7C1</th>\n",
       "      <th>A0T2G8C0</th>\n",
       "      <th>A0T3G0C7</th>\n",
       "      <th>A0T3G1C6</th>\n",
       "      <th>A0T3G2C5</th>\n",
       "      <th>A0T3G3C4</th>\n",
       "      <th>A0T3G4C3</th>\n",
       "      <th>A0T3G5C2</th>\n",
       "      <th>A0T3G6C1</th>\n",
       "      <th>A0T3G7C0</th>\n",
       "      <th>A0T4G0C6</th>\n",
       "      <th>A0T4G1C5</th>\n",
       "      <th>A0T4G2C4</th>\n",
       "      <th>A0T4G3C3</th>\n",
       "      <th>A0T4G4C2</th>\n",
       "      <th>A0T4G5C1</th>\n",
       "      <th>A0T4G6C0</th>\n",
       "      <th>A0T5G0C5</th>\n",
       "      <th>A0T5G1C4</th>\n",
       "      <th>A0T5G2C3</th>\n",
       "      <th>A0T5G3C2</th>\n",
       "      <th>A0T5G4C1</th>\n",
       "      <th>A0T5G5C0</th>\n",
       "      <th>A0T6G0C4</th>\n",
       "      <th>A0T6G1C3</th>\n",
       "      <th>A0T6G2C2</th>\n",
       "      <th>A0T6G3C1</th>\n",
       "      <th>A0T6G4C0</th>\n",
       "      <th>A0T7G0C3</th>\n",
       "      <th>A0T7G1C2</th>\n",
       "      <th>A0T7G2C1</th>\n",
       "      <th>A0T7G3C0</th>\n",
       "      <th>A0T8G0C2</th>\n",
       "      <th>A0T8G1C1</th>\n",
       "      <th>A0T8G2C0</th>\n",
       "      <th>A0T9G0C1</th>\n",
       "      <th>A0T9G1C0</th>\n",
       "      <th>A0T10G0C0</th>\n",
       "      <th>A1T0G0C9</th>\n",
       "      <th>A1T0G1C8</th>\n",
       "      <th>A1T0G2C7</th>\n",
       "      <th>A1T0G3C6</th>\n",
       "      <th>A1T0G4C5</th>\n",
       "      <th>A1T0G5C4</th>\n",
       "      <th>A1T0G6C3</th>\n",
       "      <th>A1T0G7C2</th>\n",
       "      <th>A1T0G8C1</th>\n",
       "      <th>A1T0G9C0</th>\n",
       "      <th>A1T1G0C8</th>\n",
       "      <th>A1T1G1C7</th>\n",
       "      <th>A1T1G2C6</th>\n",
       "      <th>A1T1G3C5</th>\n",
       "      <th>A1T1G4C4</th>\n",
       "      <th>A1T1G5C3</th>\n",
       "      <th>A1T1G6C2</th>\n",
       "      <th>A1T1G7C1</th>\n",
       "      <th>A1T1G8C0</th>\n",
       "      <th>A1T2G0C7</th>\n",
       "      <th>A1T2G1C6</th>\n",
       "      <th>A1T2G2C5</th>\n",
       "      <th>A1T2G3C4</th>\n",
       "      <th>A1T2G4C3</th>\n",
       "      <th>A1T2G5C2</th>\n",
       "      <th>A1T2G6C1</th>\n",
       "      <th>A1T2G7C0</th>\n",
       "      <th>A1T3G0C6</th>\n",
       "      <th>A1T3G1C5</th>\n",
       "      <th>A1T3G2C4</th>\n",
       "      <th>A1T3G3C3</th>\n",
       "      <th>A1T3G4C2</th>\n",
       "      <th>A1T3G5C1</th>\n",
       "      <th>A1T3G6C0</th>\n",
       "      <th>A1T4G0C5</th>\n",
       "      <th>A1T4G1C4</th>\n",
       "      <th>A1T4G2C3</th>\n",
       "      <th>A1T4G3C2</th>\n",
       "      <th>A1T4G4C1</th>\n",
       "      <th>A1T4G5C0</th>\n",
       "      <th>A1T5G0C4</th>\n",
       "      <th>A1T5G1C3</th>\n",
       "      <th>A1T5G2C2</th>\n",
       "      <th>A1T5G3C1</th>\n",
       "      <th>A1T5G4C0</th>\n",
       "      <th>A1T6G0C3</th>\n",
       "      <th>A1T6G1C2</th>\n",
       "      <th>A1T6G2C1</th>\n",
       "      <th>A1T6G3C0</th>\n",
       "      <th>A1T7G0C2</th>\n",
       "      <th>A1T7G1C1</th>\n",
       "      <th>A1T7G2C0</th>\n",
       "      <th>A1T8G0C1</th>\n",
       "      <th>A1T8G1C0</th>\n",
       "      <th>A1T9G0C0</th>\n",
       "      <th>A2T0G0C8</th>\n",
       "      <th>A2T0G1C7</th>\n",
       "      <th>A2T0G2C6</th>\n",
       "      <th>A2T0G3C5</th>\n",
       "      <th>A2T0G4C4</th>\n",
       "      <th>A2T0G5C3</th>\n",
       "      <th>A2T0G6C2</th>\n",
       "      <th>A2T0G7C1</th>\n",
       "      <th>A2T0G8C0</th>\n",
       "      <th>A2T1G0C7</th>\n",
       "      <th>A2T1G1C6</th>\n",
       "      <th>A2T1G2C5</th>\n",
       "      <th>A2T1G3C4</th>\n",
       "      <th>A2T1G4C3</th>\n",
       "      <th>A2T1G5C2</th>\n",
       "      <th>A2T1G6C1</th>\n",
       "      <th>A2T1G7C0</th>\n",
       "      <th>A2T2G0C6</th>\n",
       "      <th>A2T2G1C5</th>\n",
       "      <th>A2T2G2C4</th>\n",
       "      <th>A2T2G3C3</th>\n",
       "      <th>A2T2G4C2</th>\n",
       "      <th>A2T2G5C1</th>\n",
       "      <th>A2T2G6C0</th>\n",
       "      <th>A2T3G0C5</th>\n",
       "      <th>A2T3G1C4</th>\n",
       "      <th>A2T3G2C3</th>\n",
       "      <th>A2T3G3C2</th>\n",
       "      <th>A2T3G4C1</th>\n",
       "      <th>A2T3G5C0</th>\n",
       "      <th>A2T4G0C4</th>\n",
       "      <th>A2T4G1C3</th>\n",
       "      <th>A2T4G2C2</th>\n",
       "      <th>A2T4G3C1</th>\n",
       "      <th>A2T4G4C0</th>\n",
       "      <th>A2T5G0C3</th>\n",
       "      <th>A2T5G1C2</th>\n",
       "      <th>A2T5G2C1</th>\n",
       "      <th>A2T5G3C0</th>\n",
       "      <th>A2T6G0C2</th>\n",
       "      <th>A2T6G1C1</th>\n",
       "      <th>A2T6G2C0</th>\n",
       "      <th>A2T7G0C1</th>\n",
       "      <th>A2T7G1C0</th>\n",
       "      <th>A2T8G0C0</th>\n",
       "      <th>A3T0G0C7</th>\n",
       "      <th>A3T0G1C6</th>\n",
       "      <th>A3T0G2C5</th>\n",
       "      <th>A3T0G3C4</th>\n",
       "      <th>A3T0G4C3</th>\n",
       "      <th>A3T0G5C2</th>\n",
       "      <th>A3T0G6C1</th>\n",
       "      <th>A3T0G7C0</th>\n",
       "      <th>A3T1G0C6</th>\n",
       "      <th>A3T1G1C5</th>\n",
       "      <th>A3T1G2C4</th>\n",
       "      <th>A3T1G3C3</th>\n",
       "      <th>A3T1G4C2</th>\n",
       "      <th>A3T1G5C1</th>\n",
       "      <th>A3T1G6C0</th>\n",
       "      <th>A3T2G0C5</th>\n",
       "      <th>A3T2G1C4</th>\n",
       "      <th>A3T2G2C3</th>\n",
       "      <th>A3T2G3C2</th>\n",
       "      <th>A3T2G4C1</th>\n",
       "      <th>A3T2G5C0</th>\n",
       "      <th>A3T3G0C4</th>\n",
       "      <th>A3T3G1C3</th>\n",
       "      <th>A3T3G2C2</th>\n",
       "      <th>A3T3G3C1</th>\n",
       "      <th>A3T3G4C0</th>\n",
       "      <th>A3T4G0C3</th>\n",
       "      <th>A3T4G1C2</th>\n",
       "      <th>A3T4G2C1</th>\n",
       "      <th>A3T4G3C0</th>\n",
       "      <th>A3T5G0C2</th>\n",
       "      <th>A3T5G1C1</th>\n",
       "      <th>A3T5G2C0</th>\n",
       "      <th>A3T6G0C1</th>\n",
       "      <th>A3T6G1C0</th>\n",
       "      <th>A3T7G0C0</th>\n",
       "      <th>A4T0G0C6</th>\n",
       "      <th>A4T0G1C5</th>\n",
       "      <th>A4T0G2C4</th>\n",
       "      <th>A4T0G3C3</th>\n",
       "      <th>A4T0G4C2</th>\n",
       "      <th>A4T0G5C1</th>\n",
       "      <th>A4T0G6C0</th>\n",
       "      <th>A4T1G0C5</th>\n",
       "      <th>A4T1G1C4</th>\n",
       "      <th>A4T1G2C3</th>\n",
       "      <th>A4T1G3C2</th>\n",
       "      <th>A4T1G4C1</th>\n",
       "      <th>A4T1G5C0</th>\n",
       "      <th>A4T2G0C4</th>\n",
       "      <th>A4T2G1C3</th>\n",
       "      <th>A4T2G2C2</th>\n",
       "      <th>A4T2G3C1</th>\n",
       "      <th>A4T2G4C0</th>\n",
       "      <th>A4T3G0C3</th>\n",
       "      <th>A4T3G1C2</th>\n",
       "      <th>A4T3G2C1</th>\n",
       "      <th>A4T3G3C0</th>\n",
       "      <th>A4T4G0C2</th>\n",
       "      <th>A4T4G1C1</th>\n",
       "      <th>A4T4G2C0</th>\n",
       "      <th>A4T5G0C1</th>\n",
       "      <th>A4T5G1C0</th>\n",
       "      <th>A4T6G0C0</th>\n",
       "      <th>A5T0G0C5</th>\n",
       "      <th>A5T0G1C4</th>\n",
       "      <th>A5T0G2C3</th>\n",
       "      <th>A5T0G3C2</th>\n",
       "      <th>A5T0G4C1</th>\n",
       "      <th>A5T0G5C0</th>\n",
       "      <th>A5T1G0C4</th>\n",
       "      <th>A5T1G1C3</th>\n",
       "      <th>A5T1G2C2</th>\n",
       "      <th>A5T1G3C1</th>\n",
       "      <th>A5T1G4C0</th>\n",
       "      <th>A5T2G0C3</th>\n",
       "      <th>A5T2G1C2</th>\n",
       "      <th>A5T2G2C1</th>\n",
       "      <th>A5T2G3C0</th>\n",
       "      <th>A5T3G0C2</th>\n",
       "      <th>A5T3G1C1</th>\n",
       "      <th>A5T3G2C0</th>\n",
       "      <th>A5T4G0C1</th>\n",
       "      <th>A5T4G1C0</th>\n",
       "      <th>A5T5G0C0</th>\n",
       "      <th>A6T0G0C4</th>\n",
       "      <th>A6T0G1C3</th>\n",
       "      <th>A6T0G2C2</th>\n",
       "      <th>A6T0G3C1</th>\n",
       "      <th>A6T0G4C0</th>\n",
       "      <th>A6T1G0C3</th>\n",
       "      <th>A6T1G1C2</th>\n",
       "      <th>A6T1G2C1</th>\n",
       "      <th>A6T1G3C0</th>\n",
       "      <th>A6T2G0C2</th>\n",
       "      <th>A6T2G1C1</th>\n",
       "      <th>A6T2G2C0</th>\n",
       "      <th>A6T3G0C1</th>\n",
       "      <th>A6T3G1C0</th>\n",
       "      <th>A6T4G0C0</th>\n",
       "      <th>A7T0G0C3</th>\n",
       "      <th>A7T0G1C2</th>\n",
       "      <th>A7T0G2C1</th>\n",
       "      <th>A7T0G3C0</th>\n",
       "      <th>A7T1G0C2</th>\n",
       "      <th>A7T1G1C1</th>\n",
       "      <th>A7T1G2C0</th>\n",
       "      <th>A7T2G0C1</th>\n",
       "      <th>A7T2G1C0</th>\n",
       "      <th>A7T3G0C0</th>\n",
       "      <th>A8T0G0C2</th>\n",
       "      <th>A8T0G1C1</th>\n",
       "      <th>A8T0G2C0</th>\n",
       "      <th>A8T1G0C1</th>\n",
       "      <th>A8T1G1C0</th>\n",
       "      <th>A8T2G0C0</th>\n",
       "      <th>A9T0G0C1</th>\n",
       "      <th>A9T0G1C0</th>\n",
       "      <th>A9T1G0C0</th>\n",
       "      <th>A10T0G0C0</th>\n",
       "      <th>target</th>\n",
       "      <th>sample_weight</th>\n",
       "      <th>fe_mean</th>\n",
       "      <th>fe_std</th>\n",
       "      <th>fe_median</th>\n",
       "      <th>fe_var</th>\n",
       "      <th>fe_min</th>\n",
       "      <th>fe_max</th>\n",
       "      <th>fe_skew</th>\n",
       "      <th>fe_kurt</th>\n",
       "      <th>fe_quantile_25</th>\n",
       "      <th>fe_quantile_50</th>\n",
       "      <th>fe_quantile_75</th>\n",
       "      <th>fe_range</th>\n",
       "      <th>fe_iqr</th>\n",
       "      <th>fe_tails</th>\n",
       "      <th>fe_dispersion_1</th>\n",
       "      <th>fe_A</th>\n",
       "      <th>fe_T</th>\n",
       "      <th>fe_G</th>\n",
       "      <th>fe_C</th>\n",
       "      <th>fe_gcd</th>\n",
       "      <th>fe_pca_0</th>\n",
       "      <th>fe_pca_1</th>\n",
       "      <th>fe_pca_2</th>\n",
       "      <th>fe_pca_3</th>\n",
       "      <th>fe_cluster_0</th>\n",
       "      <th>fe_cluster_1</th>\n",
       "      <th>fe_cluster_2</th>\n",
       "      <th>fe_cluster_3</th>\n",
       "      <th>fe_cluster_4</th>\n",
       "      <th>fe_cluster_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>-0.00721</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>0.00279</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.018021</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.016022</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>-0.014030</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.033997</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.00279</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.022797</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Escherichia_coli</td>\n",
       "      <td>18</td>\n",
       "      <td>0.062744</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>1.128906</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.9375</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>18.031250</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>7584.0</td>\n",
       "      <td>-0.144409</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.006012</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.015144</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>0.018860</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.00121</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.00021</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.002033</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.004021</td>\n",
       "      <td>-0.003033</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.004009</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Salmonella_enterica</td>\n",
       "      <td>17</td>\n",
       "      <td>0.059235</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.9375</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>10632.0</td>\n",
       "      <td>-0.053680</td>\n",
       "      <td>-0.010498</td>\n",
       "      <td>-0.015602</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.032410</td>\n",
       "      <td>-0.005146</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>-0.002708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.006210</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.011024</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>-0.007015</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.004211</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.00621</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.015022</td>\n",
       "      <td>-0.016037</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.00621</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.013031</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>-0.009026</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.015030</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>-0.004021</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.007015</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.012978</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Staphylococcus_aureus</td>\n",
       "      <td>17</td>\n",
       "      <td>0.059235</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>-0.016037</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.9375</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>17.015625</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>7412.0</td>\n",
       "      <td>-0.049835</td>\n",
       "      <td>0.085510</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>-0.080933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>-0.008186</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.016022</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.00721</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>-0.00721</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.00279</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Bacteroides_fragilis</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>0.944336</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.9375</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>16.031250</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>8124.0</td>\n",
       "      <td>-0.347900</td>\n",
       "      <td>0.024979</td>\n",
       "      <td>0.054993</td>\n",
       "      <td>-0.039001</td>\n",
       "      <td>-0.041016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>-0.006920</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.004009</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.005211</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.006210</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.015022</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.004009</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.008018</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.004597</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.003004</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>-0.00621</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.005211</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.00621</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.013031</td>\n",
       "      <td>-0.015030</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.012024</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>-0.013023</td>\n",
       "      <td>-0.011017</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.016037</td>\n",
       "      <td>-0.013031</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.007023</td>\n",
       "      <td>-0.010033</td>\n",
       "      <td>-0.006023</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.018188</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.007015</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.014984</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>0.009995</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.00001</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-9.536743e-07</td>\n",
       "      <td>Campylobacter_jejuni</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>0.944336</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.9375</td>\n",
       "      <td>999.0</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>16.015625</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>4444.0</td>\n",
       "      <td>-0.055542</td>\n",
       "      <td>0.090881</td>\n",
       "      <td>0.107361</td>\n",
       "      <td>-0.095825</td>\n",
       "      <td>-0.102478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059570</td>\n",
       "      <td>-0.012367</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  A0T0G6C4  \\\n",
       "0 -9.536743e-07  -0.00001 -0.000043 -0.000114   -0.0002  -0.00024   -0.0002   \n",
       "1 -9.536743e-07  -0.00001 -0.000043  0.000885   -0.0002   0.00076   -0.0002   \n",
       "2 -9.536743e-07  -0.00001 -0.000043 -0.000114   -0.0002  -0.00024   -0.0002   \n",
       "3 -9.536743e-07  -0.00001 -0.000043 -0.000114   -0.0002  -0.00024   -0.0002   \n",
       "4 -9.536743e-07  -0.00001 -0.000043 -0.000114   -0.0002  -0.00024   -0.0002   \n",
       "\n",
       "   A0T0G7C3  A0T0G8C2  A0T0G9C1     A0T0G10C0  A0T1G0C9  A0T1G1C8  A0T1G2C7  \\\n",
       "0 -0.000114 -0.000043  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343   \n",
       "1  0.000885 -0.000043  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343   \n",
       "2 -0.000114 -0.000043  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343   \n",
       "3 -0.000114 -0.000043  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343   \n",
       "4 -0.000114 -0.000043  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343   \n",
       "\n",
       "   A0T1G3C6  A0T1G4C5  A0T1G5C4  A0T1G6C3  A0T1G7C2  A0T1G8C1  A0T1G9C0  \\\n",
       "0 -0.000801 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001   \n",
       "1  0.001199 -0.001202  0.002798  0.000199 -0.000343 -0.000086  -0.00001   \n",
       "2 -0.000801 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001   \n",
       "3 -0.000801 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001   \n",
       "4 -0.000801 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001   \n",
       "\n",
       "   A0T2G0C8  A0T2G1C7  A0T2G2C6  A0T2G3C5  A0T2G4C4  A0T2G5C3  A0T2G6C2  \\\n",
       "0 -0.000043 -0.000343 -0.001202  0.007595 -0.003004 -0.002403  0.008797   \n",
       "1 -0.000043 -0.000343 -0.000202  0.002596  0.002996  0.002596  0.002798   \n",
       "2 -0.000043 -0.000343 -0.001202 -0.002403 -0.002005 -0.002403 -0.000202   \n",
       "3 -0.000043 -0.000343 -0.001202 -0.002403 -0.003004 -0.002403 -0.001202   \n",
       "4 -0.000043 -0.000343 -0.001202 -0.002403 -0.003004 -0.002403 -0.001202   \n",
       "\n",
       "   A0T2G7C1  A0T2G8C0  A0T3G0C7  A0T3G1C6  A0T3G2C5  A0T3G3C4  A0T3G4C3  \\\n",
       "0 -0.000343 -0.000043 -0.000114 -0.000801 -0.002403 -0.004005  0.005993   \n",
       "1 -0.000343 -0.000043 -0.000114 -0.000801  0.000597  0.000995  0.001995   \n",
       "2 -0.000343 -0.000043 -0.000114 -0.000801 -0.001403 -0.004005 -0.003006   \n",
       "3 -0.000343 -0.000043 -0.000114 -0.000801 -0.002403 -0.004005 -0.004005   \n",
       "4 -0.000343 -0.000043 -0.000114 -0.000801 -0.001403 -0.004005 -0.004005   \n",
       "\n",
       "   A0T3G5C2  A0T3G6C1  A0T3G7C0  A0T4G0C6  A0T4G1C5  A0T4G2C4  A0T4G3C3  \\\n",
       "0 -0.002403 -0.000801 -0.000114   -0.0002 -0.001202 -0.003004 -0.004005   \n",
       "1  0.004597 -0.000801 -0.000114   -0.0002  0.000798 -0.000004 -0.000005   \n",
       "2 -0.002403 -0.000801 -0.000114   -0.0002 -0.001202 -0.003004 -0.001005   \n",
       "3 -0.002403 -0.000801 -0.000114   -0.0002 -0.001202 -0.003004  0.005993   \n",
       "4 -0.002403 -0.000801 -0.000114   -0.0002 -0.000202 -0.002005 -0.003006   \n",
       "\n",
       "   A0T4G4C2  A0T4G5C1  A0T4G6C0  A0T5G0C5  A0T5G1C4  A0T5G2C3  A0T5G3C2  \\\n",
       "0 -0.003004 -0.001202   -0.0002  -0.00024 -0.001202 -0.002403 -0.002403   \n",
       "1 -0.000004  0.000798   -0.0002  -0.00024 -0.001202 -0.000403  0.004597   \n",
       "2 -0.002005 -0.000202   -0.0002  -0.00024 -0.001202 -0.001403 -0.000403   \n",
       "3 -0.003004 -0.001202   -0.0002  -0.00024 -0.001202  0.017593  0.007595   \n",
       "4 -0.003004 -0.001202   -0.0002  -0.00024  0.000798  0.000597 -0.001403   \n",
       "\n",
       "   A0T5G4C1  A0T5G5C0  A0T6G0C4  A0T6G1C3  A0T6G2C2  A0T6G3C1  A0T6G4C0  \\\n",
       "0  0.008797  -0.00024   -0.0002 -0.000801 -0.001202 -0.000801   -0.0002   \n",
       "1 -0.000202  -0.00024   -0.0002  0.002199 -0.001202  0.000199   -0.0002   \n",
       "2 -0.000202  -0.00024   -0.0002 -0.000801 -0.000202  0.004200   -0.0002   \n",
       "3 -0.001202  -0.00024   -0.0002 -0.000801 -0.001202 -0.000801   -0.0002   \n",
       "4  0.000798  -0.00024   -0.0002 -0.000801  0.001799  0.000199   -0.0002   \n",
       "\n",
       "   A0T7G0C3  A0T7G1C2  A0T7G2C1  A0T7G3C0  A0T8G0C2  A0T8G1C1  A0T8G2C0  \\\n",
       "0 -0.000114 -0.000343 -0.000343 -0.000114 -0.000043 -0.000086 -0.000043   \n",
       "1  0.000885  0.001657 -0.000343 -0.000114 -0.000043 -0.000086 -0.000043   \n",
       "2  0.000885  0.002657  0.000657 -0.000114 -0.000043 -0.000086  0.000957   \n",
       "3 -0.000114 -0.000343 -0.000343 -0.000114 -0.000043 -0.000086 -0.000043   \n",
       "4  0.000885  0.000657 -0.000343  0.001885 -0.000043  0.002914  0.000957   \n",
       "\n",
       "   A0T9G0C1  A0T9G1C0     A0T10G0C0  A1T0G0C9  A1T0G1C8  A1T0G2C7  A1T0G3C6  \\\n",
       "0 -0.000010  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343 -0.000801   \n",
       "1 -0.000010  -0.00001 -9.536743e-07  -0.00001 -0.000086  0.000657  0.001199   \n",
       "2 -0.000010  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343 -0.000801   \n",
       "3 -0.000010  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343 -0.000801   \n",
       "4  0.000991  -0.00001 -9.536743e-07  -0.00001 -0.000086 -0.000343 -0.000801   \n",
       "\n",
       "   A1T0G4C5  A1T0G5C4  A1T0G6C3  A1T0G7C2  A1T0G8C1  A1T0G9C0  A1T1G0C8  \\\n",
       "0  0.008797 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001 -0.000086   \n",
       "1 -0.000202  0.004799  0.002199 -0.000343 -0.000086  -0.00001 -0.000086   \n",
       "2 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001 -0.000086   \n",
       "3 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001 -0.000086   \n",
       "4 -0.001202 -0.001202 -0.000801 -0.000343 -0.000086  -0.00001 -0.000086   \n",
       "\n",
       "   A1T1G1C7  A1T1G2C6  A1T1G3C5  A1T1G4C4  A1T1G5C3  A1T1G6C2  A1T1G7C1  \\\n",
       "0 -0.000687 -0.002403  0.005192  0.013992  0.015190 -0.002403 -0.000687   \n",
       "1 -0.000687  0.001596  0.006195  0.003990  0.002193 -0.001403  0.000313   \n",
       "2 -0.000687 -0.002403 -0.004807 -0.006008 -0.004807 -0.002403 -0.000687   \n",
       "3 -0.000687 -0.002403 -0.004807  0.003990  0.005192 -0.002403 -0.000687   \n",
       "4 -0.000687 -0.002403 -0.004807 -0.004009 -0.003807 -0.002403 -0.000687   \n",
       "\n",
       "   A1T1G8C0  A1T2G0C7  A1T2G1C6  A1T2G2C5  A1T2G3C4  A1T2G4C3  A1T2G5C2  \\\n",
       "0 -0.000086 -0.000343 -0.002403  0.012787  0.007980  0.017990  0.002790   \n",
       "1  0.000914 -0.000343  0.002596 -0.003210  0.005985  0.006985  0.004791   \n",
       "2 -0.000086 -0.000343 -0.002403 -0.006210 -0.012016 -0.012016 -0.007210   \n",
       "3 -0.000086 -0.000343 -0.002403  0.002790  0.017990 -0.002016  0.002790   \n",
       "4 -0.000086 -0.000343 -0.002403 -0.005211 -0.010017 -0.012016 -0.006210   \n",
       "\n",
       "   A1T2G6C1  A1T2G7C0  A1T3G0C6  A1T3G1C5  A1T3G2C4  A1T3G3C3  A1T3G4C2  \\\n",
       "0 -0.002403 -0.000343 -0.000801 -0.004807 -0.002016 -0.006023 -0.002016   \n",
       "1 -0.001403 -0.000343  0.001199 -0.001806 -0.002016 -0.000022  0.004982   \n",
       "2 -0.001403 -0.000343  0.001199 -0.003807 -0.010017 -0.011024 -0.010017   \n",
       "3 -0.002403 -0.000343 -0.000801 -0.004807 -0.002016 -0.016022 -0.002016   \n",
       "4 -0.001403 -0.000343 -0.000801 -0.003807 -0.008018 -0.015022 -0.009018   \n",
       "\n",
       "   A1T3G5C1  A1T3G6C0  A1T4G0C5  A1T4G1C4  A1T4G2C3  A1T4G3C2  A1T4G4C1  \\\n",
       "0 -0.004807  0.009201 -0.001202  0.003990 -0.012016 -0.002016 -0.006008   \n",
       "1 -0.001806 -0.000801 -0.000202  0.001991 -0.000016 -0.000016 -0.002008   \n",
       "2 -0.004807  0.000199 -0.001202 -0.001008 -0.007015 -0.004017  0.000992   \n",
       "3 -0.004807 -0.000801 -0.001202 -0.006008 -0.002016 -0.002016  0.003990   \n",
       "4 -0.002806 -0.000801 -0.000202 -0.004009 -0.006016 -0.008018 -0.002008   \n",
       "\n",
       "   A1T4G5C0  A1T5G0C4  A1T5G1C3  A1T5G2C2  A1T5G3C1  A1T5G4C0  A1T6G0C3  \\\n",
       "0 -0.001202 -0.001202  0.015190  0.002790 -0.004807  0.008797 -0.000801   \n",
       "1 -0.001202 -0.000202 -0.000806 -0.003210 -0.000806 -0.001202  0.000199   \n",
       "2  0.001799  0.001799 -0.002806  0.004791  0.001193  0.000798 -0.000801   \n",
       "3 -0.001202 -0.001202  0.005192  0.002790  0.015190 -0.001202 -0.000801   \n",
       "4  0.001799  0.000798 -0.002806  0.000790 -0.001806 -0.000202  0.005199   \n",
       "\n",
       "   A1T6G1C2  A1T6G2C1  A1T6G3C0  A1T7G0C2  A1T7G1C1  A1T7G2C0  A1T8G0C1  \\\n",
       "0 -0.002403 -0.002403 -0.000801 -0.000343  0.009315 -0.000343 -0.000086   \n",
       "1  0.004597 -0.001403 -0.000801  0.000657  0.000313 -0.000343 -0.000086   \n",
       "2  0.006596  0.003597  0.001199  0.002657  0.002314  0.002657 -0.000086   \n",
       "3  0.017593 -0.002403 -0.000801 -0.000343  0.009315 -0.000343 -0.000086   \n",
       "4  0.004597  0.005596  0.003199  0.008659  0.011314  0.001657  0.002914   \n",
       "\n",
       "   A1T8G1C0  A1T9G0C0  A2T0G0C8  A2T0G1C7  A2T0G2C6  A2T0G3C5  A2T0G4C4  \\\n",
       "0 -0.000086 -0.000010 -0.000043 -0.000343 -0.001202 -0.002403 -0.003004   \n",
       "1 -0.000086 -0.000010 -0.000043  0.000657  0.000798  0.003597  0.003998   \n",
       "2 -0.000086 -0.000010 -0.000043 -0.000343 -0.001202 -0.002403 -0.003004   \n",
       "3 -0.000086 -0.000010 -0.000043 -0.000343 -0.001202 -0.002403 -0.003004   \n",
       "4  0.002914  0.000991 -0.000043 -0.000343 -0.001202 -0.001403 -0.003004   \n",
       "\n",
       "   A2T0G5C3  A2T0G6C2  A2T0G7C1  A2T0G8C0  A2T1G0C7  A2T1G1C6  A2T1G2C5  \\\n",
       "0 -0.002403 -0.001202 -0.000343 -0.000043 -0.000343 -0.002403  0.012787   \n",
       "1 -0.000403  0.000798 -0.000343 -0.000043 -0.000343 -0.001403 -0.001210   \n",
       "2 -0.002403 -0.001202 -0.000343 -0.000043 -0.000343 -0.001403 -0.004211   \n",
       "3 -0.002403 -0.001202 -0.000343 -0.000043 -0.000343 -0.002403 -0.007210   \n",
       "4 -0.002403 -0.001202 -0.000343 -0.000043 -0.000343 -0.002403 -0.007210   \n",
       "\n",
       "   A2T1G3C4  A2T1G4C3  A2T1G5C2  A2T1G6C1  A2T1G7C0  A2T2G0C6  A2T2G1C5  \\\n",
       "0 -0.012016  0.007980  -0.00721 -0.002403 -0.000343 -0.001202 -0.007210   \n",
       "1  0.005985 -0.001017  -0.00121 -0.001403 -0.000343  0.000798  0.002790   \n",
       "2 -0.012016 -0.012016  -0.00621 -0.001403 -0.000343 -0.001202 -0.007210   \n",
       "3 -0.012016 -0.012016  -0.00721 -0.002403 -0.000343 -0.001202 -0.007210   \n",
       "4 -0.012016 -0.012016  -0.00621 -0.002403 -0.000343 -0.001202 -0.005211   \n",
       "\n",
       "   A2T2G2C4  A2T2G3C3  A2T2G4C2  A2T2G5C1  A2T2G6C0  A2T3G0C5  A2T3G1C4  \\\n",
       "0  0.001976 -0.024033 -0.008026   0.00279 -0.001202  0.007595 -0.002016   \n",
       "1  0.002975  0.001966  0.001976  -0.00021 -0.001202  0.002596 -0.006016   \n",
       "2 -0.015022 -0.016037 -0.014023  -0.00621 -0.000202 -0.001403 -0.006016   \n",
       "3  0.001976 -0.024033 -0.008026  -0.00721 -0.001202 -0.002403 -0.002016   \n",
       "4 -0.014023 -0.022034 -0.014023  -0.00621 -0.001202  0.000597 -0.006016   \n",
       "\n",
       "   A2T3G2C3  A2T3G3C2  A2T3G4C1  A2T3G5C0  A2T4G0C4  A2T4G1C3  A2T4G2C2  \\\n",
       "0 -0.004032 -0.004032 -0.012016 -0.002403 -0.003004 -0.002016 -0.018021   \n",
       "1 -0.003033 -0.002033 -0.003016 -0.002403 -0.002005 -0.004017 -0.000024   \n",
       "2 -0.013031 -0.008034 -0.010017 -0.000403  0.001995  0.000983 -0.009026   \n",
       "3  0.015961 -0.024033 -0.002016 -0.002403  0.006996  0.007980  0.011978   \n",
       "4 -0.013031 -0.015030 -0.000016  0.001596 -0.001004 -0.000016 -0.012024   \n",
       "\n",
       "   A2T4G3C1  A2T4G4C0  A2T5G0C3  A2T5G1C2  A2T5G2C1  A2T5G3C0  A2T6G0C2  \\\n",
       "0  0.007980  0.016998 -0.002403  0.002790 -0.007210  0.007595  0.008797   \n",
       "1 -0.002016 -0.002005 -0.000403 -0.001210 -0.001210 -0.001403  0.000798   \n",
       "2 -0.000016 -0.000004 -0.000403  0.009789  0.008789  0.002596  0.004799   \n",
       "3  0.027985 -0.003004  0.007595  0.002790 -0.007210 -0.002403 -0.001202   \n",
       "4 -0.001017  0.003998  0.002596  0.006790  0.005791  0.002596  0.005798   \n",
       "\n",
       "   A2T6G1C1  A2T6G2C0  A2T7G0C1  A2T7G1C0  A2T8G0C0  A3T0G0C7  A3T0G1C6  \\\n",
       "0 -0.002403 -0.001202 -0.000343 -0.000343 -0.000043 -0.000114 -0.000801   \n",
       "1 -0.000403 -0.000202  0.000657  0.000657 -0.000043 -0.000114  0.001199   \n",
       "2  0.004597  0.003798  0.005657  0.001657  0.001957 -0.000114 -0.000801   \n",
       "3  0.017593  0.008797  0.009659 -0.000343 -0.000043 -0.000114 -0.000801   \n",
       "4  0.019592  0.003798  0.005657  0.008659  0.003956 -0.000114 -0.000801   \n",
       "\n",
       "   A3T0G2C5  A3T0G3C4  A3T0G4C3  A3T0G5C2  A3T0G6C1  A3T0G7C0  A3T1G0C6  \\\n",
       "0 -0.002403 -0.004005 -0.004005  0.007595 -0.000801 -0.000114 -0.000801   \n",
       "1  0.004597  0.004993  0.002995  0.001596  0.000199 -0.000114 -0.000801   \n",
       "2 -0.002403 -0.003006 -0.004005 -0.002403 -0.000801 -0.000114 -0.000801   \n",
       "3 -0.002403 -0.004005 -0.004005 -0.002403 -0.000801 -0.000114 -0.000801   \n",
       "4 -0.002403 -0.004005 -0.004005 -0.002403  0.000199 -0.000114  0.000199   \n",
       "\n",
       "   A3T1G1C5  A3T1G2C4  A3T1G3C3  A3T1G4C2  A3T1G5C1  A3T1G6C0  A3T2G0C5  \\\n",
       "0  0.005192 -0.002016 -0.016022 -0.002016  0.015190 -0.000801 -0.002403   \n",
       "1 -0.002806  0.001984 -0.005020  0.002983 -0.004807  0.000199 -0.001403   \n",
       "2  0.001193 -0.008018 -0.009018 -0.009018 -0.004807 -0.000801 -0.000403   \n",
       "3 -0.004807 -0.012016  0.003979 -0.002016 -0.004807 -0.000801  0.007595   \n",
       "4 -0.003807 -0.011017 -0.013023 -0.011017 -0.004807 -0.000801 -0.000403   \n",
       "\n",
       "   A3T2G1C4  A3T2G2C3  A3T2G3C2  A3T2G4C1  A3T2G5C0  A3T3G0C4  A3T3G1C3  \\\n",
       "0 -0.002016 -0.004032 -0.024033  0.007980 -0.002403 -0.004005 -0.006023   \n",
       "1 -0.005016 -0.004032 -0.002033 -0.002016 -0.000403 -0.001005 -0.004021   \n",
       "2 -0.001017 -0.015030 -0.008034 -0.005016 -0.001403  0.000995  0.005978   \n",
       "3 -0.002016  0.015961 -0.024033 -0.002016  0.007595 -0.004005 -0.006023   \n",
       "4 -0.001017 -0.016037 -0.013031 -0.009018 -0.001403 -0.003006 -0.007023   \n",
       "\n",
       "   A3T3G2C2  A3T3G3C1  A3T3G4C0  A3T4G0C3  A3T4G1C2  A3T4G2C1  A3T4G3C0  \\\n",
       "0 -0.014030  0.003979 -0.004005 -0.004005 -0.012016  0.007980  0.005993   \n",
       "1 -0.003033 -0.007023 -0.004005 -0.002005 -0.004017 -0.002016 -0.001005   \n",
       "2  0.001966 -0.004021  0.002995  0.006996  0.007980  0.000983  0.003994   \n",
       "3 -0.024033  0.003979  0.005993  0.005993 -0.002016 -0.012016 -0.004005   \n",
       "4 -0.010033 -0.006023  0.001995  0.004993  0.000983  0.012985  0.002995   \n",
       "\n",
       "   A3T5G0C2  A3T5G1C1  A3T5G2C0  A3T6G0C1  A3T6G1C0  A3T7G0C0  A4T0G0C6  \\\n",
       "0 -0.002403  0.015190  0.007595  0.009201 -0.000801 -0.000114   -0.0002   \n",
       "1 -0.001403 -0.002806 -0.001403  0.001199  0.000199 -0.000114   -0.0002   \n",
       "2  0.006596  0.018188  0.013596  0.004200  0.002199  0.000885   -0.0002   \n",
       "3 -0.002403 -0.004807  0.007595 -0.000801 -0.000801 -0.000114   -0.0002   \n",
       "4  0.013596  0.018188  0.013596  0.009201  0.004200  0.003885   -0.0002   \n",
       "\n",
       "   A4T0G1C5  A4T0G2C4  A4T0G3C3  A4T0G4C2  A4T0G5C1  A4T0G6C0  A4T1G0C5  \\\n",
       "0  0.018799  0.006996 -0.004005  0.006996 -0.001202   -0.0002 -0.001202   \n",
       "1 -0.000202 -0.001004 -0.000005  0.000996 -0.000202   -0.0002 -0.000202   \n",
       "2 -0.001202 -0.002005 -0.004005 -0.001004 -0.001202   -0.0002  0.000798   \n",
       "3 -0.001202 -0.003004 -0.004005 -0.003004  0.008797   -0.0002 -0.001202   \n",
       "4 -0.000202 -0.002005 -0.003006 -0.002005 -0.001202    0.0008 -0.001202   \n",
       "\n",
       "   A4T1G1C4  A4T1G2C3  A4T1G3C2  A4T1G4C1  A4T1G5C0  A4T2G0C4  A4T2G1C3  \\\n",
       "0  0.033997 -0.002016 -0.002016 -0.006008 -0.001202  0.006996  0.007980   \n",
       "1 -0.002008 -0.002016  0.000983 -0.003008 -0.001202 -0.001004 -0.000016   \n",
       "2 -0.000008 -0.007015 -0.001017  0.000992  0.000798  0.000996  0.003983   \n",
       "3 -0.006008 -0.002016 -0.002016  0.023987 -0.001202  0.006996 -0.012016   \n",
       "4 -0.002008 -0.006016 -0.007015 -0.002008  0.000798 -0.000004 -0.005016   \n",
       "\n",
       "   A4T2G2C2  A4T2G3C1  A4T2G4C0  A4T3G0C3  A4T3G1C2  A4T3G2C1  A4T3G3C0  \\\n",
       "0  0.001976 -0.012016 -0.003004 -0.004005 -0.012016 -0.012016 -0.004005   \n",
       "1 -0.004025 -0.000016  0.002996 -0.000005 -0.005016 -0.003016 -0.003006   \n",
       "2  0.012978  0.000983 -0.001004  0.003994  0.011986  0.008987  0.000995   \n",
       "3 -0.008026 -0.002016  0.006996  0.005993  0.027985 -0.002016  0.005993   \n",
       "4  0.000976 -0.005016 -0.001004  0.003994  0.003983  0.014984  0.005993   \n",
       "\n",
       "   A4T4G0C2  A4T4G1C1  A4T4G2C0  A4T5G0C1  A4T5G1C0  A4T6G0C0  A5T0G0C5  \\\n",
       "0  0.006996 -0.006008  0.006996 -0.001202 -0.001202 -0.000200  -0.00024   \n",
       "1 -0.003004 -0.004009  0.000996  0.000798  0.000798  0.000800  -0.00024   \n",
       "2  0.010994  0.021988  0.010994  0.005798  0.008797  0.002800  -0.00024   \n",
       "3  0.006996  0.023987 -0.003004 -0.001202 -0.001202 -0.000200  -0.00024   \n",
       "4  0.009995  0.010994  0.008995  0.009796  0.005798  0.008797  -0.00024   \n",
       "\n",
       "   A5T0G1C4  A5T0G2C3  A5T0G3C2  A5T0G4C1  A5T0G5C0  A5T1G0C4  A5T1G1C3  \\\n",
       "0 -0.001202 -0.002403 -0.002403 -0.001202  -0.00024 -0.001202 -0.004807   \n",
       "1  0.000798 -0.000403 -0.001403  0.001799  -0.00024 -0.001202  0.002193   \n",
       "2 -0.001202  0.000597 -0.002403 -0.000202  -0.00024  0.000798  0.003193   \n",
       "3 -0.001202 -0.002403 -0.002403 -0.001202  -0.00024 -0.001202  0.015190   \n",
       "4 -0.001202 -0.001403 -0.000403 -0.001202  -0.00024 -0.000202 -0.001806   \n",
       "\n",
       "   A5T1G2C2  A5T1G3C1  A5T1G4C0  A5T2G0C3  A5T2G1C2  A5T2G2C1  A5T2G3C0  \\\n",
       "0   0.00279  0.005192 -0.001202 -0.002403 -0.007210  0.022797 -0.002403   \n",
       "1   0.00179  0.002193 -0.000202 -0.002403 -0.001210  0.000790  0.000597   \n",
       "2   0.00079 -0.001806 -0.000202  0.007595  0.009789  0.007790  0.004597   \n",
       "3   0.00279 -0.004807 -0.001202 -0.002403  0.012787 -0.007210 -0.002403   \n",
       "4   0.00179 -0.000806  0.001799  0.006596  0.011787  0.003790  0.005596   \n",
       "\n",
       "   A5T3G0C2  A5T3G1C1  A5T3G2C0  A5T4G0C1  A5T4G1C0  A5T5G0C0  A6T0G0C4  \\\n",
       "0 -0.002403 -0.004807 -0.002403  0.008797 -0.001202 -0.000240   -0.0002   \n",
       "1 -0.000403  0.001193 -0.002403  0.003798 -0.000202 -0.000240   -0.0002   \n",
       "2  0.008598  0.018188  0.009598  0.010796  0.011795  0.005760   -0.0002   \n",
       "3 -0.002403  0.015190 -0.002403  0.008797 -0.001202 -0.000240   -0.0002   \n",
       "4  0.008598  0.027191  0.010597  0.011795  0.008797  0.004761   -0.0002   \n",
       "\n",
       "   A6T0G1C3  A6T0G2C2  A6T0G3C1  A6T0G4C0  A6T1G0C3  A6T1G1C2  A6T1G2C1  \\\n",
       "0 -0.000801 -0.001202 -0.000801   -0.0002 -0.000801  0.007595 -0.002403   \n",
       "1 -0.000801  0.000798 -0.000801   -0.0002  0.001199  0.000597 -0.000403   \n",
       "2  0.000199  0.000798  0.000199   -0.0002  0.000199  0.001596  0.002596   \n",
       "3 -0.000801 -0.001202 -0.000801   -0.0002 -0.000801  0.007595 -0.002403   \n",
       "4 -0.000801 -0.000202 -0.000801    0.0008  0.004200  0.003597  0.005596   \n",
       "\n",
       "   A6T1G3C0  A6T2G0C2  A6T2G1C1  A6T2G2C0  A6T3G0C1  A6T3G1C0  A6T4G0C0  \\\n",
       "0 -0.000801  0.008797 -0.002403 -0.001202 -0.000801 -0.000801 -0.000200   \n",
       "1  0.001199 -0.000202  0.002596  0.001799  0.000199  0.002199 -0.000200   \n",
       "2  0.000199  0.006798  0.002596  0.002798  0.006199  0.009201  0.001800   \n",
       "3 -0.000801 -0.001202 -0.002403 -0.001202 -0.000801  0.009201 -0.000200   \n",
       "4  0.004200  0.003798  0.007595  0.006798  0.005199  0.015198  0.005798   \n",
       "\n",
       "   A7T0G0C3  A7T0G1C2  A7T0G2C1  A7T0G3C0  A7T1G0C2  A7T1G1C1  A7T1G2C0  \\\n",
       "0 -0.000114 -0.000343 -0.000343 -0.000114  0.009659 -0.000687 -0.000343   \n",
       "1  0.000885 -0.000343 -0.000343 -0.000114 -0.000343  0.002314  0.001657   \n",
       "2 -0.000114 -0.000343  0.002657 -0.000114 -0.000343  0.002314  0.003656   \n",
       "3 -0.000114 -0.000343 -0.000343  0.009888 -0.000343 -0.000687 -0.000343   \n",
       "4 -0.000114  0.000657  0.002657 -0.000114  0.003656  0.006313  0.005657   \n",
       "\n",
       "   A7T2G0C1  A7T2G1C0  A7T3G0C0  A8T0G0C2  A8T0G1C1  A8T0G2C0  A8T1G0C1  \\\n",
       "0  0.009659 -0.000343 -0.000114 -0.000043 -0.000086 -0.000043 -0.000086   \n",
       "1 -0.000343 -0.000343 -0.000114 -0.000043  0.000914 -0.000043 -0.000086   \n",
       "2  0.000657  0.003656  0.003885 -0.000043 -0.000086 -0.000043 -0.000086   \n",
       "3 -0.000343 -0.000343 -0.000114 -0.000043 -0.000086 -0.000043 -0.000086   \n",
       "4  0.002657  0.004658  0.004887 -0.000043  0.000914  0.000957  0.001914   \n",
       "\n",
       "   A8T1G1C0  A8T2G0C0  A9T0G0C1  A9T0G1C0  A9T1G0C0     A10T0G0C0  \\\n",
       "0 -0.000086 -0.000043  -0.00001  -0.00001 -0.000010 -9.536743e-07   \n",
       "1 -0.000086 -0.000043  -0.00001  -0.00001  0.000991 -9.536743e-07   \n",
       "2  0.000914  0.002956  -0.00001  -0.00001 -0.000010 -9.536743e-07   \n",
       "3  0.009911 -0.000043  -0.00001  -0.00001 -0.000010 -9.536743e-07   \n",
       "4  0.000914 -0.000043  -0.00001  -0.00001 -0.000010 -9.536743e-07   \n",
       "\n",
       "                  target  sample_weight   fe_mean    fe_std  fe_median  \\\n",
       "0       Escherichia_coli             18  0.062744  1.062500  -0.000343   \n",
       "1    Salmonella_enterica             17  0.059235  1.002930  -0.000086   \n",
       "2  Staphylococcus_aureus             17  0.059235  1.002930  -0.000114   \n",
       "3   Bacteroides_fragilis             16  0.055756  0.944336  -0.000687   \n",
       "4   Campylobacter_jejuni             16  0.055756  0.944336  -0.000200   \n",
       "\n",
       "     fe_var    fe_min  fe_max  fe_skew  fe_kurt  fe_quantile_25  \\\n",
       "0  1.128906 -0.024033    18.0  16.9375    999.0       -0.002403   \n",
       "1  1.006836 -0.007023    17.0  16.9375    999.0       -0.000801   \n",
       "2  1.006836 -0.016037    17.0  16.9375    999.0       -0.001202   \n",
       "3  0.892090 -0.024033    16.0  16.9375    999.0       -0.002016   \n",
       "4  0.892090 -0.022034    16.0  16.9375    999.0       -0.001806   \n",
       "\n",
       "   fe_quantile_50  fe_quantile_75   fe_range    fe_iqr  fe_tails  \\\n",
       "0       -0.000343       -0.000026  18.031250  0.002377    7584.0   \n",
       "1       -0.000086        0.000798  17.000000  0.001599   10632.0   \n",
       "2       -0.000114        0.001095  17.015625  0.002296    7412.0   \n",
       "3       -0.000687       -0.000043  16.031250  0.001972    8124.0   \n",
       "4       -0.000200        0.001799  16.015625  0.003605    4444.0   \n",
       "\n",
       "   fe_dispersion_1      fe_A      fe_T      fe_G      fe_C  fe_gcd  fe_pca_0  \\\n",
       "0        -0.144409  0.008995 -0.002008 -0.006012 -0.001010       1 -0.015144   \n",
       "1        -0.053680 -0.010498 -0.015602  0.010605  0.015503       1 -0.032410   \n",
       "2        -0.049835  0.085510  0.080078 -0.084717 -0.080933       1  0.053589   \n",
       "3        -0.347900  0.024979  0.054993 -0.039001 -0.041016       1  0.011330   \n",
       "4        -0.055542  0.090881  0.107361 -0.095825 -0.102478       1  0.059570   \n",
       "\n",
       "   fe_pca_1  fe_pca_2  fe_pca_3  fe_cluster_0  fe_cluster_1  fe_cluster_2  \\\n",
       "0 -0.009125  0.018860 -0.009003             1             0             0   \n",
       "1 -0.005146  0.007671 -0.002708             0             0             0   \n",
       "2 -0.008186  0.005772 -0.000899             0             0             0   \n",
       "3  0.002100 -0.006920 -0.016907             0             0             0   \n",
       "4 -0.012367  0.019287 -0.017761             0             0             0   \n",
       "\n",
       "   fe_cluster_3  fe_cluster_4  fe_cluster_5  \n",
       "0             0             0             0  \n",
       "1             0             1             0  \n",
       "2             1             0             0  \n",
       "3             0             0             0  \n",
       "4             1             0             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:01.010702Z",
     "start_time": "2022-02-25T18:00:00.049367Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:31.614361Z",
     "iopub.status.busy": "2022-02-24T03:14:31.613943Z",
     "iopub.status.idle": "2022-02-24T03:14:34.239242Z",
     "shell.execute_reply": "2022-02-24T03:14:34.238497Z",
     "shell.execute_reply.started": "2022-02-24T03:14:31.614322Z"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1645133019645,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "_JUntp99QiWX",
    "outputId": "36f4d652-f431-43c4-eeef-bf1d3462823a",
    "papermill": {
     "duration": 2.275806,
     "end_time": "2022-02-18T03:58:40.689532",
     "exception": false,
     "start_time": "2022-02-18T03:58:38.413726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 74.97 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 59.60 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "df3_train = reduce_memory_usage(df3_train)\n",
    "df3_test  = reduce_memory_usage(df3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:42:43.769709Z",
     "start_time": "2022-02-13T14:42:43.75774Z"
    },
    "id": "lXM1616ZcCgX",
    "papermill": {
     "duration": 0.107583,
     "end_time": "2022-02-18T03:58:40.93197",
     "exception": false,
     "start_time": "2022-02-18T03:58:40.824387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div class=\"alert alert-success\"> 1.  Modelagem </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTfHy5aLcCgY",
    "papermill": {
     "duration": 0.1027,
     "end_time": "2022-02-18T03:58:41.138015",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.035315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:03.976422Z",
     "start_time": "2022-02-25T18:00:03.962424Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.241248Z",
     "iopub.status.busy": "2022-02-24T03:14:34.240923Z",
     "iopub.status.idle": "2022-02-24T03:14:34.248121Z",
     "shell.execute_reply": "2022-02-24T03:14:34.24717Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.24121Z"
    },
    "id": "YMyY91OecCgZ",
    "papermill": {
     "duration": 0.124943,
     "end_time": "2022-02-18T03:58:41.375728",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.250785",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_, y_pred_test_, score_, seed_, level_='1', target_='target'):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>.6:    \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_)  + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        \n",
    "        jb.dump(y_pred_train_prob_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        jb.dump(model_, path_name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:04.446076Z",
     "start_time": "2022-02-25T18:00:04.419039Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.25069Z",
     "iopub.status.busy": "2022-02-24T03:14:34.250432Z",
     "iopub.status.idle": "2022-02-24T03:14:34.283316Z",
     "shell.execute_reply": "2022-02-24T03:14:34.282642Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.250656Z"
    },
    "id": "W-AfEFTYcCga",
    "papermill": {
     "duration": 0.153287,
     "end_time": "2022-02-18T03:58:41.874592",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.721305",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_train_cv_fit(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), \n",
    "                       sc_second_=None, n_splits_=5, seed_=12359, save_sub_=True, \n",
    "                       path_='', save_predict_=False, level_='1'):\n",
    "    \n",
    "    taco              = 52 \n",
    "    y_preds_test      = []\n",
    "    y_preds_val_prob  = [] \n",
    "    y_preds_test_prob = []\n",
    "    score             = []\n",
    "    mdl               = []\n",
    "    lb                = LabelEncoder()\n",
    "    y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n",
    "    col_prob          = y_[target_].sort_values().unique()\n",
    "    df_preds_prob     = pd.DataFrame()\n",
    "    df_feature_imp    = pd.DataFrame()\n",
    "    time_start        = datetime.now()    \n",
    "    n_estimators      = model_.get_params()['n_estimators']\n",
    "    dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''\n",
    "    \n",
    "    print('='*taco)\n",
    "    print('Scaler: {} - n_estimators: {} {}'.format(sc, n_estimators, dub_scaler))\n",
    "    print('='*taco)\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_, groups=y)): \n",
    "        \n",
    "        time_fold_start = datetime.now()\n",
    "        \n",
    "        # ----------------------------------------------------\n",
    "        # Separar dados para treino \n",
    "        # ----------------------------------------------------\n",
    "        X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n",
    "        y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n",
    "                \n",
    "        # ----------------------------------------------------\n",
    "        # Processamento\n",
    "        # ----------------------------------------------------        \n",
    "        X_trn.drop('sample_weight', axis=1, inplace=True)\n",
    "        X_val.drop('sample_weight', axis=1, inplace=True)\n",
    "        \n",
    "        X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "        X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n",
    "        X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "        if sc_second_ is not None: \n",
    "            X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "            X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n",
    "            X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n",
    "                        \n",
    "        # ---------------------------------------------------- \n",
    "        # Treinar o modelo \n",
    "        # ----------------------------------------------------     \n",
    "        model_.fit(X_trn, \n",
    "                   y_trn,\n",
    "                   sample_weight_train,\n",
    "                   eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                   early_stopping_rounds = int(n_estimators*.1),\n",
    "                   verbose               = False)\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Predição \n",
    "        # ----------------------------------------------------     \n",
    "        #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n",
    "        y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n",
    "        y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n",
    "        \n",
    "        y_pred_val_prob += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])         \n",
    "        y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n",
    "        \n",
    "        y_preds_test.append(model_.predict(X_tst))\n",
    "        y_preds_test_prob.append(y_pred_test_prob)\n",
    "       \n",
    "        df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n",
    "        y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "        df_prob_temp['fold']    = fold+1\n",
    "        df_prob_temp['id']      = val_idx        \n",
    "        df_prob_temp['y_val']   = y_val.values        \n",
    "        df_prob_temp['y_pred']  = y_pred_val\n",
    "        df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n",
    "                \n",
    "        df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n",
    "        \n",
    "        # ---------------------------------------------------- \n",
    "        # Score \n",
    "        # ---------------------------------------------------- \n",
    "        acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n",
    "        score.append(acc)     \n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Print resultado  \n",
    "        # ---------------------------------------------------- \n",
    "        time_fold_end = diff(time_fold_start, datetime.now())        \n",
    "        msg = '[Fold {}] ACC: {:2.5f} -  {}'\n",
    "        print(msg.format(fold+1, acc, time_fold_end))\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Feature Importance\n",
    "        # ----------------------------------------------------             \n",
    "        feat_imp = pd.DataFrame(index   = X_trn.columns,\n",
    "                                data    = model_.feature_importances_,                            \n",
    "                                columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "        feat_imp['acc_'+str(fold+1)] = acc\n",
    "        df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Salvar o modelo \n",
    "        # ---------------------------------------------------- \n",
    "        dic_model = {'scaler': sc, 'scaler_second': sc_second_,'fold': fold+1,'model': model_}\n",
    "        mdl.append(dic_model)\n",
    "\n",
    "        time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "    acc_mean = np.mean(score) \n",
    "    acc_std  = np.std(score)\n",
    "\n",
    "    df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Pós-processamento\n",
    "    # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n",
    "    # -------------------------------        \n",
    "    y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n",
    "    y_proba += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])  \n",
    "    \n",
    "    y_pred_tuned      = lb.inverse_transform(np.argmax(y_proba, axis=1))\n",
    "    y_pred_tuned_prob = np.max(y_proba, axis=1)\n",
    "\n",
    "    if save_predict_:                 \n",
    "        save_data_model(model_             = mdl, \n",
    "                        model_name_        = model_name_ +'_'+str(sc_second_).lower()[:4], \n",
    "                        path_              = path_, \n",
    "                        y_pred_train_prob_ = df_preds_prob['y_proba'], \n",
    "                        y_pred_test_prob_  = y_pred_tuned_prob, \n",
    "                        y_pred_test_       = y_pred_tuned,\n",
    "                        score_             = acc_mean, \n",
    "                        seed_              = seed_, \n",
    "                        level_             = level_, \n",
    "                        target_            = target_\n",
    "                        ) \n",
    "\n",
    "    print('-'*taco)\n",
    "    print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n",
    "    print('='*taco)\n",
    "    print()\n",
    "\n",
    "    if save_sub_:         \n",
    "        df_submission[target_] = y_pred_tuned        \n",
    "        name_file_sub          = model_name_ +'_'+str(sc_second_).lower()[:4]+'.csv'\n",
    "        df_submission.to_csv(path_+'Data/submission/'+name_file_sub.format(acc_mean), index=False)\n",
    "        \n",
    "    del X_trn, X_val, y_trn, y_val, feat_imp\n",
    "\n",
    "    return mdl, df_feature_imp, df_feature_imp , df_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:04.966812Z",
     "start_time": "2022-02-25T18:00:04.946778Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.285293Z",
     "iopub.status.busy": "2022-02-24T03:14:34.285048Z",
     "iopub.status.idle": "2022-02-24T03:14:34.298854Z",
     "shell.execute_reply": "2022-02-24T03:14:34.298054Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.28526Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_graf(mdl_, df_fe_imp_, eval_metric_ ):\n",
    "\n",
    "    for erro in eval_metric_:\n",
    "        plt.figure(figsize=(20,15))\n",
    "        for m in range(len(mdl_)):\n",
    "            row = int(len(mdl_[m])/3 + 1)\n",
    "            for fold in range(len(mdl_[m])): \n",
    "                results     = mdl_[m][fold]['model'].evals_result() # merror\n",
    "                ntree_limit = mdl_[m][fold]['model'].best_ntree_limit\n",
    "                plt.subplot(row,3,fold+1)\n",
    "                plt.plot(results[\"validation_0\"][erro], label=\"Treinamento\")\n",
    "                plt.plot(results[\"validation_1\"][erro], label=\"Validação\")\n",
    "\n",
    "                plt.axvline(ntree_limit, \n",
    "                            color=\"gray\", \n",
    "                            label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "\n",
    "                plt.xlabel(\"Número de árvores\")\n",
    "                plt.ylabel(erro)\n",
    "                plt.legend();           \n",
    "\n",
    "            plt.suptitle('Performance XGB - {}'.format(erro), y=1.05, fontsize=24);\n",
    "            plt.tight_layout(h_pad=3.0); \n",
    "\n",
    "    for i in range(len(df_fe_imp_)):\n",
    "        plt.figure(figsize=(20,15))\n",
    "        row = int(np.round(df_fe_imp_[i].filter(regex=r'fold').shape[1] / 3 +1))\n",
    "        for fold, col in enumerate(df_fe_imp_[i].filter(regex=r'fold').columns):            \n",
    "            col_acc = 'acc_' + str(fold+1)\n",
    "            df_fi = df_fe_imp_[i].sort_values(by=col, ascending=False).reset_index().iloc[:25]\n",
    "            df_fi = df_fi[['index', col, col_acc]]\n",
    "            df_fi.columns = ['Feature', 'score', col_acc]\n",
    "            plt.subplot(row,3, fold+1)\n",
    "            sns.barplot(x='score', y='Feature', data=df_fi)    \n",
    "            plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n",
    "                      fontdict={'fontsize':18})    \n",
    "\n",
    "        plt.suptitle('Feature Importance XGB - {}'.format(scaler_list[i]), y=1.05, fontsize=24);\n",
    "        plt.tight_layout(h_pad=3.0); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CiKMmrgcCgc",
    "papermill": {
     "duration": 0.065734,
     "end_time": "2022-02-18T03:58:42.006011",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.940277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:07.305226Z",
     "start_time": "2022-02-25T18:00:07.187226Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:35.130655Z",
     "iopub.status.busy": "2022-02-24T03:14:35.130368Z",
     "iopub.status.idle": "2022-02-24T03:14:35.320002Z",
     "shell.execute_reply": "2022-02-24T03:14:35.319156Z",
     "shell.execute_reply.started": "2022-02-24T03:14:35.130619Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1645133019991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "GjKxi26LcCgc",
    "outputId": "e7d089e2-269d-41f0-c95d-66b740d7ba51",
    "papermill": {
     "duration": 0.301276,
     "end_time": "2022-02-18T03:58:42.372598",
     "exception": false,
     "start_time": "2022-02-18T03:58:42.071322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123993, 317), (123993,), (100000, 316))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X          = df3_train.drop([target], axis=1)\n",
    "y          = df3_train[target]\n",
    "X_test     = df3_test\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:00:56.758463Z",
     "start_time": "2022-02-25T18:00:56.699464Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:35.77837Z",
     "iopub.status.busy": "2022-02-24T03:14:35.778127Z",
     "iopub.status.idle": "2022-02-24T03:14:35.90489Z",
     "shell.execute_reply": "2022-02-24T03:14:35.904103Z",
     "shell.execute_reply.started": "2022-02-24T03:14:35.778342Z"
    },
    "papermill": {
     "duration": 0.073302,
     "end_time": "2022-02-18T03:58:42.514291",
     "exception": false,
     "start_time": "2022-02-18T03:58:42.440989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path             = ''\n",
    "cols_original_tr = X.filter(regex='A[0-9]').columns.to_list()\n",
    "cols_original_ts = cols_original_tr.copy()\n",
    "cols_original_tr.append('sample_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "Vamos fazer um modelo com as variáveis originais, para termos uma noção do efeito das novas variáveis, neste primeiro momento defini os parametros manualmente.\n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T23:07:47.534595Z",
     "start_time": "2022-02-20T23:03:16.2755Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:36.883713Z",
     "iopub.status.busy": "2022-02-24T03:14:36.883044Z",
     "iopub.status.idle": "2022-02-24T03:24:26.923497Z",
     "shell.execute_reply": "2022-02-24T03:24:26.922874Z",
     "shell.execute_reply.started": "2022-02-24T03:14:36.883672Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed_          = 12359\n",
    "mdl            = []\n",
    "df_trn_mdl     = []\n",
    "df_fe_imp      = []\n",
    "scaler_list    = [None]\n",
    "name_model_clf = 'xgb_'\n",
    "name_model     = name_model_clf + 'tunning_score_01_{:2.5f}'\n",
    "eval_metric    = ['merror', 'mlogloss']\n",
    "\n",
    "params = {\"objective\"          : 'multi:softprob', \n",
    "          'eval_metric'        : eval_metric,\n",
    "          'max_depth'          : 6, \n",
    "          'learning_rate'      : .1, \n",
    "          'subsample'          : 0.75, \n",
    "          'n_estimators'       : 1000,           \n",
    "          'reg_alpha'          : 1, \n",
    "          'reg_lambda'         : 75, \n",
    "          'min_child_weight'   : 7, \n",
    "          'colsample_bytree'   : 0.85,\n",
    "          'sampling_method'    : 'gradient_based',\n",
    "          'booster'            : 'gbtree',\n",
    "          'use_label_encoder'  : 'False', \n",
    "          'random_state'       : seed_}\n",
    "\n",
    "if torch.cuda.is_available():           \n",
    "    params.update({'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor'})\n",
    "    \n",
    "for sc in scaler_list:    \n",
    "    model, df_trn, df_feature_imp, df_preds_prob = \\\n",
    "    model_train_cv_fit(model_        = xgb.XGBClassifier(**params),\n",
    "                       model_name_   = name_model,\n",
    "                       X_            = X[cols_original_tr],\n",
    "                       y_            = y,\n",
    "                       X_test_       = X_test[cols_original_ts],                       \n",
    "                       target_       = target,\n",
    "                       sc_           = RobustScaler(), \n",
    "                       sc_second_    = sc,\n",
    "                       n_splits_     = 5,\n",
    "                       seed_         = seed_,\n",
    "                       save_sub_     = True,\n",
    "                       path_         = path, \n",
    "                       save_predict_ = True)\n",
    "\n",
    "    mdl.append(model)\n",
    "    df_trn_mdl.append(df_trn)\n",
    "    df_fe_imp.append(df_feature_imp)\n",
    "\n",
    "del model, df_trn, df_feature_imp\n",
    "\n",
    "print_graf(mdl, df_fe_imp, eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "Obtivemos na submissão o score de 0.93243, como podemos observar o nosso modelo tem uma performance boa, pois estamos apenas 1.83% abaixo, sendo assim, temos um baixo underfitting. \n",
    "    \n",
    "<br> \n",
    "    \n",
    "Agora vamos executar o mesmo modelo com todas as variáveis, isso é, com as novas variáveis criadas. \n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:09:50.093981Z",
     "start_time": "2022-02-21T00:03:15.223036Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:24:26.92991Z",
     "iopub.status.busy": "2022-02-24T03:24:26.927786Z",
     "iopub.status.idle": "2022-02-24T03:35:02.311666Z",
     "shell.execute_reply": "2022-02-24T03:35:02.310978Z",
     "shell.execute_reply.started": "2022-02-24T03:24:26.929869Z"
    },
    "executionInfo": {
     "elapsed": 39246,
     "status": "error",
     "timestamp": 1645133061299,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "ZR3VduvAcCgd",
    "outputId": "6e737ebf-155f-4e32-9254-f67c58d8f1b0",
    "papermill": {
     "duration": 619.258635,
     "end_time": "2022-02-18T04:09:01.839519",
     "exception": false,
     "start_time": "2022-02-18T03:58:42.580884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed_          = 12359\n",
    "mdl            = []\n",
    "df_trn_mdl     = []\n",
    "df_fe_imp      = []\n",
    "scaler_list    = [None]\n",
    "name_model_clf = 'xgb_'\n",
    "name_model     = name_model_clf + 'tunning_score_02_{:2.5f}'\n",
    "\n",
    "eval_metric = ['merror', 'mlogloss']\n",
    "\n",
    "params = {\"objective\"          : 'multi:softprob', \n",
    "          'eval_metric'        : eval_metric,\n",
    "          'max_depth'          : 6, \n",
    "          'learning_rate'      : .1, \n",
    "          'subsample'          : 0.75, \n",
    "          'n_estimators'       : 1000,           \n",
    "          'reg_alpha'          : 1, \n",
    "          'reg_lambda'         : 75, \n",
    "          'min_child_weight'   : 7, \n",
    "          'colsample_bytree'   : 0.85,\n",
    "          'sampling_method'    : 'gradient_based',\n",
    "          'booster'            : 'gbtree',  \n",
    "          'use_label_encoder'  : 'False',\n",
    "          'random_state'       : seed_}\n",
    "\n",
    "if torch.cuda.is_available():           \n",
    "    params.update({'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor'})\n",
    "    \n",
    "for sc in scaler_list:    \n",
    "    model, df_trn, df_feature_imp, df_preds_prob = \\\n",
    "    model_train_cv_fit(model_        = xgb.XGBClassifier(**params),\n",
    "                       model_name_   = name_model,\n",
    "                       X_            = X,\n",
    "                       y_            = y,\n",
    "                       X_test_       = X_test,                      \n",
    "                       target_       = target,\n",
    "                       sc_           = RobustScaler(), \n",
    "                       sc_second_    = sc,\n",
    "                       n_splits_     = 5,\n",
    "                       seed_         = seed_,\n",
    "                       save_sub_     = True,\n",
    "                       path_         = path, \n",
    "                       save_predict_ = True)\n",
    "\n",
    "    mdl.append(model)\n",
    "    df_trn_mdl.append(df_trn)\n",
    "    df_fe_imp.append(df_feature_imp)\n",
    "\n",
    "del model, df_trn, df_feature_imp\n",
    "   \n",
    "print_graf(mdl, df_fe_imp, eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "\n",
    "Na submissão obtivemos o score de 0.93032 que pior que o score anterior com apenas as variáveis originais, provavelmente isso acontece porque estamos adionando ruido com as novas variávies, o ponto importante é que podemos observar na importância das variáveis que temos variáveis que foram criadas entre as 25 mais importantes, sendo assim, precisamos fazer uma filtragem das melhores variáveis, mais à frente vamos utilizar o Boruta para fazer uma filtagem das melhores variáveis.\n",
    "\n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQ6DBwBLi34z",
    "papermill": {
     "duration": 0.139742,
     "end_time": "2022-02-18T04:09:03.133617",
     "exception": false,
     "start_time": "2022-02-18T04:09:02.993875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div class=\"alert alert-success\"> 2.  TUNNING </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cJfauA3i34z",
    "papermill": {
     "duration": 0.123981,
     "end_time": "2022-02-18T04:09:03.381493",
     "exception": false,
     "start_time": "2022-02-18T04:09:03.257512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1. Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:46:57.815594Z",
     "start_time": "2022-02-21T00:46:56.9916Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:02.313374Z",
     "iopub.status.busy": "2022-02-24T03:35:02.313114Z",
     "iopub.status.idle": "2022-02-24T03:35:03.653393Z",
     "shell.execute_reply": "2022-02-24T03:35:03.652687Z",
     "shell.execute_reply.started": "2022-02-24T03:35:02.313338Z"
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1645133076007,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "DvwbgoMAi340",
    "outputId": "a9f3eece-c8f7-4182-eae5-6b98e582100a",
    "papermill": {
     "duration": 1.034451,
     "end_time": "2022-02-18T04:09:04.539516",
     "exception": false,
     "start_time": "2022-02-18T04:09:03.505065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X      = df3_train.drop([target], axis=1)    \n",
    "y      = pd.DataFrame(df3_train[target], columns=[target]) \n",
    "X_test = df3_test\n",
    "idx_sample = X.sample(5000).index \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size    = 0.2,\n",
    "                                                      shuffle      = True, \n",
    "                                                      stratify     = y,\n",
    "                                                      random_state = 12359)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l1vmUmRi340",
    "papermill": {
     "duration": 0.075,
     "end_time": "2022-02-18T04:09:04.689659",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.614659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Classe Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:46:58.695731Z",
     "start_time": "2022-02-21T00:46:58.679702Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:03.655611Z",
     "iopub.status.busy": "2022-02-24T03:35:03.655249Z",
     "iopub.status.idle": "2022-02-24T03:35:03.663159Z",
     "shell.execute_reply": "2022-02-24T03:35:03.662486Z",
     "shell.execute_reply.started": "2022-02-24T03:35:03.655568Z"
    },
    "id": "Yhn5ylJScCgh",
    "papermill": {
     "duration": 0.084857,
     "end_time": "2022-02-18T04:09:04.849798",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.764941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LastPlacePruner(BasePruner):\n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/006_user_defined_pruner.html#sphx-glr-tutorial-20-recipes-006-user-defined-pruner-py    \n",
    "    def __init__(self, warmup_steps, warmup_trials):\n",
    "        self._warmup_steps = warmup_steps\n",
    "        self._warmup_trials = warmup_trials\n",
    "\n",
    "    def prune(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\") -> bool:\n",
    "        # Obtenha a pontuação mais recente relatada neste teste\n",
    "        step = trial.last_step\n",
    "\n",
    "        if step:  # trial.last_step == None when no scores have been reported yet\n",
    "            this_score = trial.intermediate_values[step]\n",
    "\n",
    "            # Get scores from other trials in the study reported at the same step\n",
    "            completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))\n",
    "            other_scores = [\n",
    "                t.intermediate_values[step]\n",
    "                for t in completed_trials\n",
    "                if step in t.intermediate_values\n",
    "            ]\n",
    "            other_scores = sorted(other_scores)\n",
    "\n",
    "            # Prune if this trial at this step has a lower value than all completed trials\n",
    "            # at the same step. Note that steps will begin numbering at 0 in the objective\n",
    "            # function definition below.\n",
    "            if step >= self._warmup_steps and len(other_scores) > self._warmup_trials:\n",
    "                if this_score < other_scores[0]:\n",
    "                    #print(f\"prune() True: Trial {trial.number}, Step {step}, Score {this_score}\")\n",
    "                    return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:52:46.324392Z",
     "start_time": "2022-02-21T02:52:46.223894Z"
    },
    "code_folding": [
     6,
     27,
     63,
     80,
     86,
     131,
     152,
     177,
     204,
     287,
     364,
     387,
     392,
     404,
     603,
     778
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:03.665535Z",
     "iopub.status.busy": "2022-02-24T03:35:03.665074Z",
     "iopub.status.idle": "2022-02-24T03:35:04.006017Z",
     "shell.execute_reply": "2022-02-24T03:35:04.005101Z",
     "shell.execute_reply.started": "2022-02-24T03:35:03.665497Z"
    },
    "id": "LpYUOrRpi340",
    "papermill": {
     "duration": 0.357889,
     "end_time": "2022-02-18T04:09:05.282578",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.924689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from operator import le\n",
    "class TunningModels(nn.Module):\n",
    "\n",
    "    from sklearn.preprocessing  import StandardScaler\n",
    "    from sklearn.linear_model   import RidgeClassifier\n",
    "    \n",
    "    def __init__(self, name_model_, X_trn_, y_trn_, X_ts_, feature_=None, \n",
    "                 seed_=12359, scaler_=StandardScaler(), feature_bin_=None, \n",
    "                 target_='target', path_='', level_='1', sc_second_= None, \n",
    "                 n_splits_=5):\n",
    "        \n",
    "        super(TunningModels,self).__init__() \n",
    "\n",
    "        self.name_clf    = name_model\n",
    "        self.X_trn       = X_trn_\n",
    "        self.y_trn       = y_trn_\n",
    "        self.X_ts        = X_ts_         \n",
    "        self.feature     = feature_\n",
    "        self.seed        = seed_\n",
    "        self.scaler      = scaler_\n",
    "        self.feature_bin = feature_bin_ \n",
    "        self.target      = target_\n",
    "        self.path        = path_\n",
    "        self.level       = level_\n",
    "        self.sc_second   = sc_second_\n",
    "        self.n_splits    = n_splits_\n",
    "\n",
    "    def recover_prediction_first_level():\n",
    "        \n",
    "        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n",
    "        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n",
    "        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n",
    "\n",
    "        df_train1     = []\n",
    "        scores_traint = dict()\n",
    "\n",
    "        for p_name in preds_train1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n",
    "            df_train1.append(p_df)    \n",
    "            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n",
    "\n",
    "        df_val1     = [] \n",
    "        scores_val1 = dict()\n",
    "        for p_name in preds_val1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n",
    "            df_val1.append(p_df)    \n",
    "            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n",
    "\n",
    "        df_test     = [] \n",
    "        scores_test = dict()\n",
    "        for p_name in preds_test:    \n",
    "            p         = jb.load(p_name)\n",
    "            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n",
    "            df_test.append(p_df_test)\n",
    "\n",
    "        df_train1 = pd.concat(df_train1, axis=1)\n",
    "        df_val1   = pd.concat(df_val1, axis=1)\n",
    "        df_test   = pd.concat(df_test, axis=1)\n",
    "\n",
    "        return df_train1, df_val1, df_test.shape\n",
    "        \n",
    "    def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))\n",
    " \n",
    "    def logging_callback(study, frozen_trail):\n",
    "        prev_best = study.user_attrs.get('prev_best', None)\n",
    "        if prev_best != study.best_value:\n",
    "            study.set_user_attr('prev_best', study.best_value)\n",
    "            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n",
    "\n",
    "    def df_return_preds_tunning(model_name=None, level=1, target_='target', train_shape_row=0, test_shape_row=0): \n",
    "\n",
    "        if level==1: \n",
    "            level_ = 'n1'\n",
    "        else: \n",
    "            if level==2:\n",
    "                level_ = 'n2'\n",
    "            else: \n",
    "                level_ = 'n3'\n",
    "\n",
    "        paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n",
    "\n",
    "        if model_name==None: \n",
    "            model_name=''\n",
    "\n",
    "        for i, path in enumerate(paths): \n",
    "\n",
    "            name_file_pkl     = glob.glob(path + '/'+ model_name + '*.pkl.z')\n",
    "            dic_preds_mdl_pkl = dict()\n",
    "\n",
    "            for p_name in name_file_pkl:    \n",
    "                y_model_pkl_name_col  = p_name.replace(path + '/', '').replace('.pkl.z','') \n",
    "                y_model_pkl           = jb.load(p_name)   \n",
    "\n",
    "                if i==0:\n",
    "                    if len(y_model_pkl)==test_shape_row:\n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                if i==1:\n",
    "                    if len(y_model_pkl)==train_shape_row:                        \n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            if i==0:         \n",
    "                X_test_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "            else:\n",
    "                X_train_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        X_train_pred_nivel_1[target_] = y\n",
    "\n",
    "        return X_train_pred_nivel_1, X_test_pred_nivel_1\n",
    "    \n",
    "    def feature_select(mdl, feature=[], best_score=0):\n",
    "    \n",
    "        best_feature = ''\n",
    "\n",
    "        for col in df_train1.columns:\n",
    "\n",
    "            if col not in feature:\n",
    "                Xtr  = df_train1[feature+[col]].copy()\n",
    "                Xval = df_val1[feature+[col]].copy()                \n",
    "\n",
    "                mdl.fit(Xtr, y_train1)\n",
    "\n",
    "                p = mdl.predict(Xval)\n",
    "                c = f1_score(y_val1, p)\n",
    "\n",
    "                if c > best_score:\n",
    "                    best_score = c\n",
    "                    best_feature = col \n",
    "\n",
    "        return best_score, best_feature\n",
    "\n",
    "    def permutation_test(mdl, feature_selected):\n",
    "\n",
    "        dist = []\n",
    "\n",
    "        for seed in range(100):\n",
    "\n",
    "            Xtr  = df_train1[feature_selected].copy()\n",
    "            Xval = df_val1[feature_selected].copy()\n",
    "\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            Xtr['random']  = np.random.permutation(Xtr.iloc[:, -1].values)\n",
    "            Xval['random'] = np.random.permutation(Xval.iloc[:, -1].values)\n",
    "\n",
    "            mdl.fit(Xtr, y_train1)\n",
    "\n",
    "            p = mdl.predict(Xval)\n",
    "            c = f1_score(y_val1, p)\n",
    "\n",
    "            dist.append(c)\n",
    "\n",
    "        dist = np.array(dist)\n",
    "\n",
    "        return dist.max()\n",
    "\n",
    "    def feature_selected_model(model = RidgeClassifier(alpha=1.) ):\n",
    "   \n",
    "        score_feature, best_feature =  TunningModels.feature_select(model)\n",
    "        print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        feature_selected = []\n",
    "        feature_selected.append(best_feature)\n",
    "\n",
    "        loop = True\n",
    "\n",
    "        while loop:\n",
    "\n",
    "            best_score = TunningModels.permutation_test(model, feature_selected) \n",
    "            best_score = best_score + 1e-4\n",
    "\n",
    "            score_feature, best_feature = TunningModels.feature_select(model, feature=feature_selected, best_score=best_score)\n",
    "            \n",
    "\n",
    "            if score_feature <= best_score:  \n",
    "                print('Fim')\n",
    "                loop= False\n",
    "            else: \n",
    "                feature_selected.append(best_feature)\n",
    "                print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        return feature_selected\n",
    "    \n",
    "    def model_of_diversity_feature_group(model_, name_model, X_, y_, X_ts_, sc_, target_, feature_imp_num=5, \n",
    "                                         seed_=12359, path_=''):\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        cols_tr = X_.columns.to_list() \n",
    "        cols_ts = cols_tr.copy()\n",
    "        cols_ts.remove('sample_weight')\n",
    "\n",
    "        model = model_\n",
    "        model = model.fit(X_[cols_ts], y_)\n",
    "\n",
    "        df               = pd.DataFrame()\n",
    "        df[\"feature\"]    = cols_ts\n",
    "        df[\"importance\"] = model.feature_importances_\n",
    "\n",
    "        df.sort_values(\"importance\", axis=0, ascending=False, inplace=True)\n",
    "\n",
    "        feature_import = df[:feature_imp_num]['feature'].to_list()\n",
    "\n",
    "        for feature_imp in  feature_import:\n",
    "\n",
    "            score_                =  0.09\n",
    "            feature_best          = []\n",
    "            feature               = X_ts_.columns            \n",
    "            feature               = [s for s in feature if s not in feature_import]\n",
    "            feature_number        = len(feature)\n",
    "            feature_select_number = np.round(np.sqrt(len(feature)))\n",
    "            feature_number_sample = int(np.round((feature_number/feature_select_number)))\n",
    "            feature_sample        = []\n",
    "\n",
    "            print('='*60)\n",
    "            print(' Divercidade de Grupos de Features => ({})'.format(feature_imp))\n",
    "            print('='*60)\n",
    "\n",
    "\n",
    "            for i in  range(0,5):\n",
    "\n",
    "                feature            = [s for s in feature if s not in feature_sample]\n",
    "                feature_sample     = pd.Series(feature).sample(feature_number_sample).to_list() \n",
    "                name_model_xgb_div = name_model + 'group_fe_' + str(i)   \n",
    "\n",
    "                feature_sample.append(feature_imp)\n",
    "                feature_sample_ts = feature_sample.copy()\n",
    "\n",
    "                feature_sample.append('sample_weight')\n",
    "\n",
    "                model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "                TunningModels.train_model_cv(model_         = model_, \n",
    "                                             X_             = X_[feature_sample], \n",
    "                                             y_             = y_, \n",
    "                                             X_test_        = X_ts_[feature_sample_ts], \n",
    "                                             target_        = target_, \n",
    "                                             model_name_    = name_model_xgb_div, \n",
    "                                             sc_            = sc_, \n",
    "                                             sc_second_     = None, \n",
    "                                             n_splits_      = 3, \n",
    "                                             seed_          = seed_,\n",
    "                                             path_          = path_, \n",
    "                                             save_predict_  = True, \n",
    "                                             level_         = '1', \n",
    "                                             print_result_  = False, \n",
    "                                             feature_       = None, \n",
    "                                             trial_         = None)\n",
    "\n",
    "                if score >.59:\n",
    "                    create = '*'\n",
    "                else: \n",
    "                    create = ' '\n",
    "\n",
    "                if score > score_:\n",
    "                    # score_ = np.abs(score)\n",
    "                    feature_best.append(feature)\n",
    "                    print('Score: {:2.5f} =>{} Gr.Feature: {} {}'.format(score, create, i,''))\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            print('')\n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "\n",
    "    def model_of_diversity_feature_one_(model, name_model, seed_=12359):\n",
    "\n",
    "        score_       =  0.09\n",
    "        feature_best = []\n",
    "\n",
    "        print('')\n",
    "        print('Feature apenas uma')\n",
    "        print('-'*20)\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        for feature in X_train.columns:\n",
    "\n",
    "            name_model_xgb_div = name_model + feature \n",
    "\n",
    "            score = TunningModels.cross_valid(model       = model, \n",
    "                                              model_name_ = name_model_xgb_div, \n",
    "                                              X_          = X, \n",
    "                                              y_          = y, \n",
    "                                              X_test_     = X_test_sc_qt, \n",
    "                                              type_model  = 2, \n",
    "                                              feature     = feature,\n",
    "                                              seed        = seed_, \n",
    "                                              tunning     = 1, \n",
    "                                              print_result= False, \n",
    "                                              n_splits    = 2\n",
    "                                              )\n",
    "            if score >.59:\n",
    "                create = '*'\n",
    "            else: \n",
    "                create = ' '\n",
    "\n",
    "            if score > score_:\n",
    "                score_ = np.abs(score)\n",
    "                feature_best.append(feature)\n",
    "                print('F1-score: {:2.5f} => {} feature: {}'.format(score, create, feature ))        \n",
    "\n",
    "        print('')\n",
    "        print('Feature dupla')\n",
    "        print('-'*20)\n",
    "\n",
    "        for feature in feature_best:\n",
    "\n",
    "            for feature_ in feature_best:\n",
    "                if feature != feature_:            \n",
    "                    name_model_xgb_div = name_model + feature + '_' + feature_     \n",
    "\n",
    "                    score = TunningModels.cross_valid(model       = model, \n",
    "                                                      model_name_ = name_model_xgb_div, \n",
    "                                                      X_          = X, \n",
    "                                                      y_          = y, \n",
    "                                                      X_test_     = X_test_sc_qt, \n",
    "                                                      type_model  = 2, \n",
    "                                                      feature     = [feature, feature_],\n",
    "                                                      seed        = seed_, \n",
    "                                                      tunning     = 1, \n",
    "                                                      print_result= False, \n",
    "                                                      n_splits    = 2\n",
    "                                                      )\n",
    "\n",
    "                    if score >.59:\n",
    "                        create = '*'\n",
    "                    else: \n",
    "                        create = ' '\n",
    "\n",
    "                    print('F1-score: {:.4f} => {} feature: {} | {}'.format(score*100, create,  feature, feature_ )) \n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "    \n",
    "\n",
    "\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_,\n",
    "                        y_pred_test_, score_, seed_, level_='1', target_='target'):\n",
    "        \n",
    "        level_ = 'n'+ level_ + '/'\n",
    "\n",
    "        if score_>.6:          \n",
    "\n",
    "            path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_)\n",
    "            path_name_train = path_ + 'model/preds/train/' + level_ + model_name_.format(score_, seed_)\n",
    "            path_name_test  = path_ + 'model/preds/test/'  + level_ + model_name_.format(score_, seed_)    \n",
    "            path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)    \n",
    "\n",
    "            jb.dump(y_pred_train_prob_, path_name_train)\n",
    "            jb.dump(y_pred_test_prob_, path_name_test)\n",
    "            jb.dump(model_, path_name_model)\n",
    "            #jb.dump(pd.DataFrame([model_[0][0]['model'].get_params()]), path_name_param)   \n",
    "\n",
    "            if score_>.7:                \n",
    "                # Gerar o arquivo de submissão \n",
    "                df_submission[target_] = y_pred_test_\n",
    "                name_file_sub =  path_ + 'Data/submission/tunning/' + model_name_.format(score_, seed_) + '.csv'\n",
    "                df_submission.to_csv(name_file_sub, index = False)\n",
    "                \n",
    "    def diff(t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def feature_scaler(df_, scaler_=None, feature_bin_=None):\n",
    "    \n",
    "        if scaler_!=None: \n",
    "            \n",
    "            #if feature_bin_!=None:\n",
    "            #    disc = KBinsDiscretizer(n_bins=50, encode='ordinal', strategy='uniform')\n",
    "            #    df_[feature_bin_] = disc.fit_transform(df_[feature_bin_])\n",
    "\n",
    "            df_ = pd.DataFrame(scaler_.fit_transform(df_), columns=df_.columns)\n",
    "    \n",
    "        return df_\n",
    "\n",
    "    def cross_valid(model_, model_name_, X_train_, y_train_, X_test_, fold_=5, target_='target', \n",
    "            path_='', level_='1', save_predict_=True, print_result_=True, seed_=12359, \n",
    "            feature_=None, feature_bin=None, scaler_=StandardScaler(), threshold=.5, print_report_=False \n",
    "            ):\n",
    "\n",
    "        if feature_!=None: \n",
    "            X_train_ = X_train_[feature_]\n",
    "            X_test_  = X_test_[feature_]\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Escorpo de variáveis\n",
    "        #--------------------------------------------------------\n",
    "\n",
    "        time_pred_start    = datetime.now()\n",
    "        preds_valid_f      = {}\n",
    "        preds_test         = []\n",
    "        total_auc          = []\n",
    "        f_scores           = []\n",
    "        auc_mean           = []\n",
    "        f1_mean            = []\n",
    "        lloss_mean         = []\n",
    "        preds_test         = 0  \n",
    "        pred_test_prob     = 0\n",
    "        df_score_history   = pd.DataFrame()\n",
    "        df_train_pred_fold = pd.DataFrame()\n",
    "        df_pred_fold       = pd.DataFrame()\n",
    "        random             = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_        = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'\n",
    "        clf_name           = model_.__class__.__name__\n",
    "        pri_result         = 92\n",
    "        learning_rate      = model_.learning_rate         \n",
    "        le                 = LabelEncoder()\n",
    "        y_train_           = pd.DataFrame(le.fit_transform(y_train_), columns=[target_])\n",
    "                                                   \n",
    "        #--------------------------------------------------------  \n",
    "        # Início do process de varilidação\n",
    "        #--------------------------------------------------------\n",
    "        have_observation=''\n",
    "\n",
    "        if print_result_:\n",
    "            num_parallel_tree = 1 #model_.get_params()['num_parallel_tree']\n",
    "            learning_rate     = model_.learning_rate\n",
    "            n_estimators      = model_.n_estimators * num_parallel_tree  \n",
    "            max_depth         = model_.max_depth \n",
    "            msg               = 'Training model: {} - seed {} - n_estimators: {} - learning_rate: {} {:2.5f}'\n",
    "\n",
    "            print('='*pri_result)            \n",
    "            print(msg.format(clf_name, seed_, n_estimators, max_depth, learning_rate))\n",
    "            print('='*pri_result)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=fold_, random_state=42, shuffle=True)\n",
    "\n",
    "        for fold,(idx_train, idx_val) in enumerate(kf.split(X_train_, y_train_, groups=y_train_)):\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Seleção dos dados\n",
    "            #--------------------------------------------------------\n",
    "            X_trn, X_val = X_train_.iloc[idx_train], X_train_.iloc[idx_val]\n",
    "            y_trn, y_val = y_train_.iloc[idx_train], y_train_.iloc[idx_val]\n",
    "            index_valid  = idx_train\n",
    "\n",
    "             \n",
    "        \n",
    "            #--------------------------------------------------------  \n",
    "            # Processamento\n",
    "            #--------------------------------------------------------        \n",
    "            X_trn = TunningModels.feature_scaler(X_trn, scaler_, feature_bin) \n",
    "            X_val = TunningModels.feature_scaler(X_val, scaler_, feature_bin) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Modelo\n",
    "            #--------------------------------------------------------\n",
    "            model = model_.fit(X_trn, y_trn,\n",
    "                               eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                               early_stopping_rounds = int(n_estimators*.1),\n",
    "                               verbose               = False)\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # oof\n",
    "            #--------------------------------------------------------\n",
    "            preds_valid_proba = model.predict_proba(X_val, ntree_limit=model_.best_ntree_limit)\n",
    "            y_pred_valid      = le.inverse_transform(np.argmax(preds_valid_proba, axis=1))\n",
    "            \n",
    "            #--------------------------------------------------------  \n",
    "            # Obtenha os valores médios de cada fold para a previsão\n",
    "            #--------------------------------------------------------  \n",
    "            y_pred_test_prob = model.predict_proba(X_test_, ntree_limit=model_.best_ntree_limit)\n",
    "            pred_test_prob  += np.max(y_pred_test_prob, axis=1) / fold_\n",
    "            preds_test      += le.inverse_transform(np.argmax(y_pred_test_prob, axis=1)) / fold_\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Métricas \n",
    "            #-------------------------------------------------------- \n",
    "            y_val = le.inverse_transform(y_val)\n",
    "            acc   = metrics.accuracy_score(y_val, y_pred_valid)\n",
    "            f1    = metrics.f1_score(y_val, y_pred_valid, average='weighted')\n",
    "            prec  = metrics.precision_score(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Concatenar validação e predição\n",
    "            #--------------------------------------------------------        \n",
    "            df_val_pred_fold = pd.DataFrame({'fold'     : fold+1,\n",
    "                                             'index'    : idx_val, \n",
    "                                             'acc'      : acc, \n",
    "                                             'f1'       : f1,\n",
    "                                             'prec'     : prec,                                              \n",
    "                                             'target'   : y_val, \n",
    "                                             'y_pred'   : y_pred_valid, \n",
    "                                             'pred_val' : np.max(preds_valid_proba, axis=1)\n",
    "                                             })\n",
    "\n",
    "            df_train_pred_fold = pd.concat([df_train_pred_fold, df_val_pred_fold], axis=0)\n",
    "\n",
    "            col_name        = le.inverse_transform(list(model.classes_))\n",
    "            df_prob_temp    = pd.DataFrame(preds_valid_proba, columns=col_name)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            \n",
    "            df_prob_temp['y_val']     = y_val\n",
    "            df_prob_temp['y_pred']    = y_pred_valid \n",
    "            df_prob_temp['y_proba']   = np.max(preds_valid_proba, axis=1)            \n",
    "            df_prob_temp['acc']       = acc   \n",
    "            df_prob_temp['f1']        = f1 \n",
    "            df_prob_temp['precision'] = prec              \n",
    "            df_prob_temp['fold']      = fold+1\n",
    "            df_prob_temp['index']     = idx_val   \n",
    "            \n",
    "            df_pred_fold = pd.concat([df_pred_fold, df_prob_temp], axis=0)\n",
    "            \n",
    "            del df_prob_temp\n",
    "            \n",
    "            #df_prob_temp['scaler']  = str(string_scaler)\n",
    "            \n",
    "            #preds_valid_proba = np.max(preds_valid_proba, axis=1)\n",
    "            \n",
    "            \n",
    "            auc_mean.append(acc)   \n",
    "            f1_mean.append(f1)    \n",
    "            lloss_mean.append(prec) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Print resultado Fold\n",
    "            #--------------------------------------------------------\n",
    "            if print_result_:\n",
    "                msg = 'Fold: {} - ACC: {:2.5f} - F1-score: {:2.5f} - Precision: {:2.5f} - {}'\n",
    "                time_fold_start_end = TunningModels.diff(time_fold_start, datetime.now())\n",
    "                print(msg.format(fold+1, acc, f1, prec, time_fold_start_end))\n",
    "\n",
    "            free_gpu_cache() \n",
    "        \n",
    "        \n",
    "\n",
    "        del X_trn, y_trn, X_val, y_val \n",
    "\n",
    "        df_train_pred_fold.sort_values(\"index\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Salvar predição em disco\n",
    "        #--------------------------------------------------------\n",
    "        X_train_prob      = df_train_pred_fold['pred_val'].to_list()\n",
    "        score             = np.mean(auc_mean)\n",
    "        y_pred_test       = np.int32(preds_test)\n",
    "\n",
    "        if save_predict_:\n",
    "            TunningModels.save_data_model(model_             = model_, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = X_train_prob, \n",
    "                                          y_pred_test_prob_  = pred_test_prob, \n",
    "                                          y_pred_test_       = y_pred_test,\n",
    "                                          score_             = score, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          )  \n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Print média dos Folds\n",
    "        #--------------------------------------------------------\n",
    "        time_pred_end = TunningModels.diff(time_pred_start, datetime.now())\n",
    "\n",
    "        if print_result_:\n",
    "            msg = '[Mean Fold]  ACC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - Precision: {:.5f}  {}'        \n",
    "            print('-'*pri_result)            \n",
    "            print(msg.format(np.mean(auc_mean),np.std(auc_mean) , np.mean(f1_mean), np.mean(lloss_mean), time_pred_end))\n",
    "            print('='*pri_result)\n",
    "            print()\n",
    "            \n",
    "            if print_report_: \n",
    "                y_pred = df_train_pred_fold['y_pred']\n",
    "                y_vl   = df_train_pred_fold['target']\n",
    "                print(metrics.classification_report(y_vl, y_pred))\n",
    "\n",
    "        free_gpu_cache() \n",
    "\n",
    "        return model, score, y_pred_test, df_pred_fold        \n",
    "    \n",
    "    def train_model_cv(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), sc_second_=None, \n",
    "                       n_splits_=5, seed_=12359, path_='', save_predict_=True, level_='1', \n",
    "                       print_result_=True, feature_=None, trial_=None):\n",
    "            \n",
    "        if feature_!=None: \n",
    "            X_      = X_[feature_]\n",
    "            X_test_ = X_test_[feature_]\n",
    "            \n",
    "        taco              = 52 \n",
    "        y_preds_test      = []\n",
    "        y_preds_val_prob  = [] \n",
    "        y_preds_test_prob = []\n",
    "        score             = []\n",
    "        mdl               = []\n",
    "        random            = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_       = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'    \n",
    "        clf_name          = model_.__class__.__name__        \n",
    "        df_preds_prob     = pd.DataFrame()\n",
    "        df_feature_imp    = pd.DataFrame()\n",
    "        time_start        = datetime.now()    \n",
    "        n_estimators      = model_.get_params()['n_estimators']\n",
    "        dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''        \n",
    "        lb                = LabelEncoder()\n",
    "        y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n",
    "        col_prob          = y_[target_].sort_values().unique()\n",
    "        vies              = np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0]) \n",
    "        \n",
    "        if print_result_:\n",
    "            print('='*taco)\n",
    "            print('{} - n_estimators: {} seed: {}  {}'.format(clf_name, n_estimators, seed_, dub_scaler))\n",
    "            print('='*taco)\n",
    "\n",
    "        folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_)): #, groups=y\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Separar dados para treino \n",
    "            # ----------------------------------------------------\n",
    "            X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n",
    "            y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Processamento\n",
    "            # ----------------------------------------------------        \n",
    "            X_trn.drop('sample_weight', axis=1, inplace=True)\n",
    "            X_val.drop('sample_weight', axis=1, inplace=True)\n",
    "\n",
    "            X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "            X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n",
    "            X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "            if sc_second_ is not None: \n",
    "                X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "                X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n",
    "                X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------     \n",
    "            model_.fit(X_trn, \n",
    "                       y_trn,\n",
    "                       sample_weight_train,\n",
    "                       eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                       early_stopping_rounds = int(n_estimators*.1),\n",
    "                       verbose               = False)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------     \n",
    "            #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n",
    "            y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n",
    "            y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n",
    "\n",
    "            y_pred_val_prob += vies         \n",
    "            y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n",
    "\n",
    "            y_preds_test.append(model_.predict(X_tst))\n",
    "            y_preds_test_prob.append(y_pred_test_prob)\n",
    "\n",
    "            df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            df_prob_temp['fold']    = fold+1\n",
    "            df_prob_temp['id']      = val_idx        \n",
    "            df_prob_temp['y_val']   = y_val.values        \n",
    "            df_prob_temp['y_pred']  = y_pred_val\n",
    "            df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n",
    "\n",
    "            df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ---------------------------------------------------- \n",
    "            acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n",
    "            score.append(acc)     \n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())        \n",
    "            msg = '[Fold {}] ACC: {:2.5f} -  {}'\n",
    "            \n",
    "            if print_result_:\n",
    "                print(msg.format(fold+1, acc, time_fold_end))\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_trn.columns,\n",
    "                                    data    = model_.feature_importances_,                            \n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['acc_'+str(fold+1)] = acc\n",
    "            df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Salva o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler': sc_, \n",
    "                         'scaler_second': sc_second_,\n",
    "                         'fold': fold+1,\n",
    "                         'model': model_,                         \n",
    "                         'vies': vies}\n",
    "\n",
    "            mdl.append(dic_model)\n",
    "            \n",
    "            if trial_ is not None:\n",
    "                trial_.report(acc, fold)\n",
    "                if trial_.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        acc_mean = np.mean(score) \n",
    "        acc_std  = np.std(score)\n",
    "        \n",
    "        df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Pós-processamento\n",
    "        # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n",
    "        # -------------------------------        \n",
    "        y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n",
    "        y_proba += vies          \n",
    "\n",
    "        y_pred_test       = np.argmax(y_proba, axis=1)\n",
    "        y_pred_tuned      = lb.inverse_transform(y_pred_test)\n",
    "        y_pred_tuned_prob = np.max(y_proba, axis=1)\n",
    "\n",
    "        if save_predict_:                 \n",
    "            TunningModels.save_data_model(model_             = mdl, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = df_preds_prob['y_proba'], \n",
    "                                          y_pred_test_prob_  = y_pred_tuned_prob, \n",
    "                                          y_pred_test_       = y_pred_tuned,\n",
    "                                          score_             = acc_mean, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          ) \n",
    "\n",
    "        if print_result_:\n",
    "            print('-'*taco)\n",
    "            print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n",
    "            print('='*taco)\n",
    "            print()\n",
    "\n",
    "        del X_trn, X_val, y_trn, y_val, feat_imp\n",
    "\n",
    "        return mdl, acc_mean , df_feature_imp , df_preds_prob, y_pred_test\n",
    "   \n",
    "    def xgb(self, trial):\n",
    "           \n",
    "        # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "        # https://amangupta16.medium.com/xgboost-hyperparameters-explained-bb6ce580501d     \n",
    "        \n",
    "        eval_metric = ['mlogloss']\n",
    "                \n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['multi:softprob']), \n",
    "                  'booster'           : trial.suggest_categorical('booster', ['gbtree']),                 \n",
    "                  'eval_metric'       : trial.suggest_categorical('eval_metric', ['mlogloss']), \n",
    "                  'use_label_encoder' : trial.suggest_categorical('use_label_encoder', ['False']),                   \n",
    "                  'n_estimators'      : trial.suggest_int('n_estimators', 550, 1500, 100),                  \n",
    "                  'max_depth'         : trial.suggest_int('max_depth', 5, 15),\n",
    "                  'subsample'         : trial.suggest_discrete_uniform('subsample', .7, 1.0, .05), \n",
    "                  'learning_rate'     : trial.suggest_discrete_uniform('learning_rate', .01, 0.19, 0.01),\n",
    "                  'reg_alpha'         : trial.suggest_int('reg_alpha', 1, 10), \n",
    "                  'reg_lambda'        : trial.suggest_int('reg_lambda', 5, 50),\n",
    "                  'min_child_weight'  : trial.suggest_int('min_child_weight', 5, 25),  \n",
    "                  'colsample_bytree'  : trial.suggest_float('colsample_bytree', 0.8, 1.0),   \n",
    "                  'sampling_method'   : trial.suggest_categorical('sampling_method', ['gradient_based']), \n",
    "                 }\n",
    "             \n",
    "        if torch.cuda.is_available():           \n",
    "            params.update({'predictor'  : trial.suggest_categorical('predictor', ['gpu_predictor']), \n",
    "                           'tree_method': trial.suggest_categorical('tree_method', ['gpu_hist']) , \n",
    "                           'gpu_id'     : trial.suggest_int('gpu_id', 0,0)})\n",
    "                \n",
    "        #pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
    "        \n",
    "        mdl = xgb.XGBClassifier(**params) #, callbacks=[pruning_callback])\n",
    "        \n",
    "        _, score, _, _, _  = TunningModels.train_model_cv(model_        = mdl, \n",
    "                                                          X_            = self.X_trn, \n",
    "                                                          y_            = self.y_trn, \n",
    "                                                          X_test_       = self.X_ts, \n",
    "                                                          target_       = self.target, \n",
    "                                                          model_name_   = self.name_clf, \n",
    "                                                          sc_           = self.scaler, \n",
    "                                                          sc_second_    = self.sc_second, \n",
    "                                                          feature_      = self.feature,\n",
    "                                                          n_splits_     = self.n_splits, \n",
    "                                                          seed_         = self.seed,\n",
    "                                                          path_         = self.path,\n",
    "                                                          level_        = self.level, \n",
    "                                                          trial_        = trial\n",
    "                                                      )\n",
    "            \n",
    "        print('param = {}'.format(params))\n",
    "        print()\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5fsZ-O5i345",
    "papermill": {
     "duration": 0.074708,
     "end_time": "2022-02-18T04:09:05.584391",
     "exception": false,
     "start_time": "2022-02-18T04:09:05.509683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3. Tunning \n",
    "Nesta etapa da modelagem, vamos criar 30 modelos e salvá-los para a nossa `Stacking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T00:53:14.884707Z",
     "start_time": "2022-02-21T00:47:05.328974Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:04.008072Z",
     "iopub.status.busy": "2022-02-24T03:35:04.007814Z",
     "iopub.status.idle": "2022-02-24T09:29:46.571698Z",
     "shell.execute_reply": "2022-02-24T09:29:46.571004Z",
     "shell.execute_reply.started": "2022-02-24T03:35:04.008039Z"
    },
    "executionInfo": {
     "elapsed": 12744938,
     "status": "ok",
     "timestamp": 1645060664988,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "-yNlljM6i345",
    "outputId": "f164f267-df11-4f7d-9b9d-0234eba6e7a2",
    "papermill": {
     "duration": 10401.646477,
     "end_time": "2022-02-18T07:02:27.30556",
     "exception": false,
     "start_time": "2022-02-18T04:09:05.659083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "SEED       = 12359\n",
    "n_trials_  = 25\n",
    "name_model = name_model_clf + '003_tunning' \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "    \n",
    "modelOpt = TunningModels(name_model_     = name_model, \n",
    "                         X_trn_          = X, \n",
    "                         y_trn_          = y, \n",
    "                         X_ts_           = X_test,                                     \n",
    "                         feature_        = None,  \n",
    "                         scaler_         = RobustScaler(), \n",
    "                         seed_           = SEED, \n",
    "                         feature_bin_    = None, \n",
    "                         target_         = target, \n",
    "                         path_           = path, \n",
    "                         level_          = '1')\n",
    "\n",
    "pruner = LastPlacePruner(warmup_steps  = 1, warmup_trials = 5)\n",
    "study  = optuna.create_study(direction  = 'maximize',\n",
    "                             sampler    = optuna.samplers.TPESampler(seed=SEED),\n",
    "                             #pruner     = optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "                             pruner     = pruner,\n",
    "                             study_name = 'xgb_tuning')\n",
    "\n",
    "study.optimize(modelOpt.xgb, n_trials=n_trials_)\n",
    "\n",
    "score_seed  = study.best_value \n",
    "params      = study.best_params \n",
    "path_name   = path + 'model/optuna/' + name_model + '_{:2.5f}.pkl.z'.format(score_seed)   \n",
    "scare_best  = score_seed \n",
    "params_best = params\n",
    "\n",
    "print()\n",
    "print('-'*110)\n",
    "print('Best score: {:2.5f}'.format(scare_best))\n",
    "print('Seed      : {}'.format(SEED))\n",
    "print('Parameters:\\n\\n{}'.format(params_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEQa44wEi346",
    "papermill": {
     "duration": 0.139401,
     "end_time": "2022-02-18T07:02:27.882297",
     "exception": false,
     "start_time": "2022-02-18T07:02:27.742896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4. Análise  de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T22:42:51.619976Z",
     "iopub.status.busy": "2022-02-21T22:42:51.619175Z",
     "iopub.status.idle": "2022-02-21T22:42:51.637128Z",
     "shell.execute_reply": "2022-02-21T22:42:51.63646Z",
     "shell.execute_reply.started": "2022-02-21T22:42:51.619925Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T22:28:16.06382Z",
     "iopub.status.busy": "2022-02-21T22:28:16.063568Z",
     "iopub.status.idle": "2022-02-21T22:28:16.113353Z",
     "shell.execute_reply": "2022-02-21T22:28:16.112548Z",
     "shell.execute_reply.started": "2022-02-21T22:28:16.063791Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T22:43:16.62917Z",
     "iopub.status.busy": "2022-02-21T22:43:16.628557Z",
     "iopub.status.idle": "2022-02-21T22:43:16.906506Z",
     "shell.execute_reply": "2022-02-21T22:43:16.905821Z",
     "shell.execute_reply.started": "2022-02-21T22:43:16.629128Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nVNrHHSi347",
    "papermill": {
     "duration": 0.343167,
     "end_time": "2022-02-18T07:02:29.625515",
     "exception": false,
     "start_time": "2022-02-18T07:02:29.282348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.5. Modelo\n",
    "\n",
    "Agora que temos os melhores parametros, vamos treinar um modelo com esse parametros e fazer algumas análises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:53:21.526543Z",
     "start_time": "2022-02-21T02:53:21.512503Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-22T14:48:12.007269Z",
     "iopub.status.busy": "2022-02-22T14:48:12.006733Z",
     "iopub.status.idle": "2022-02-22T14:48:12.013702Z",
     "shell.execute_reply": "2022-02-22T14:48:12.012888Z",
     "shell.execute_reply.started": "2022-02-22T14:48:12.00723Z"
    },
    "id": "GYk6QWP5lUM4",
    "papermill": {
     "duration": 0.257755,
     "end_time": "2022-02-18T07:02:30.113419",
     "exception": false,
     "start_time": "2022-02-18T07:02:29.855664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:56:31.277921Z",
     "start_time": "2022-02-21T02:53:22.163676Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-21T22:43:59.100093Z",
     "iopub.status.busy": "2022-02-21T22:43:59.099826Z",
     "iopub.status.idle": "2022-02-21T22:52:29.483491Z",
     "shell.execute_reply": "2022-02-21T22:52:29.482676Z",
     "shell.execute_reply.started": "2022-02-21T22:43:59.100062Z"
    },
    "executionInfo": {
     "elapsed": 1129658,
     "status": "ok",
     "timestamp": 1644988187609,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "52gsbtwyi348",
    "outputId": "5b06c926-ae7f-4ca8-d984-aff36e76f82e",
    "papermill": {
     "duration": 716.130964,
     "end_time": "2022-02-18T07:14:26.533079",
     "exception": false,
     "start_time": "2022-02-18T07:02:30.402115",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_model = name_model_clf + '004_tunning'\n",
    "\n",
    "model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n",
    "                                 X_             = X_train, \n",
    "                                 y_             = y_train, \n",
    "                                 X_test_        = X_test, \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = SEED,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = False, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FAnuS_dlUM5",
    "papermill": {
     "duration": 0.145538,
     "end_time": "2022-02-18T07:14:26.823756",
     "exception": false,
     "start_time": "2022-02-18T07:14:26.678218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2.5.1. Feature Importances  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:56:33.85895Z",
     "start_time": "2022-02-21T02:56:31.2799Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T22:52:36.037103Z",
     "iopub.status.busy": "2022-02-21T22:52:36.036803Z",
     "iopub.status.idle": "2022-02-21T22:52:38.682505Z",
     "shell.execute_reply": "2022-02-21T22:52:38.68184Z",
     "shell.execute_reply.started": "2022-02-21T22:52:36.037069Z"
    },
    "executionInfo": {
     "elapsed": 4557,
     "status": "ok",
     "timestamp": 1644988192152,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "RvmfIdSslUM6",
    "outputId": "4512a075-34f4-4e35-f886-ddf8d92c7dcb",
    "papermill": {
     "duration": 2.731522,
     "end_time": "2022-02-18T07:14:29.700645",
     "exception": false,
     "start_time": "2022-02-18T07:14:26.969123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "row = int(np.round(df_feature_imp.filter(regex=r'fold').shape[1] / 3 +1))\n",
    "for fold, col in enumerate(df_feature_imp.filter(regex=r'fold').columns):            \n",
    "    col_acc = 'acc_' + str(fold+1)\n",
    "    df_fi = df_feature_imp.sort_values(by=col, ascending=False).reset_index().iloc[:30]\n",
    "    df_fi = df_fi[['index', col, col_acc]]\n",
    "    df_fi.columns = ['Feature', 'score', col_acc]\n",
    "    plt.subplot(row,3, fold+1)\n",
    "    sns.barplot(x='score', y='Feature', data=df_fi)    \n",
    "    plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n",
    "              fontdict={'fontsize':18})    \n",
    "\n",
    "plt.suptitle('Feature Importance XGB ', y=1.05, fontsize=24);\n",
    "plt.tight_layout(h_pad=3.0); \n",
    "\n",
    "del df_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:20:02.217776Z",
     "start_time": "2022-02-21T03:20:02.197736Z"
    }
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:57:05.059405Z",
     "start_time": "2022-02-21T02:57:05.042368Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T01:33:51.579201Z",
     "iopub.status.busy": "2022-02-23T01:33:51.578943Z",
     "iopub.status.idle": "2022-02-23T01:33:51.582965Z",
     "shell.execute_reply": "2022-02-23T01:33:51.582304Z",
     "shell.execute_reply.started": "2022-02-23T01:33:51.579171Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = X_valid.columns.to_list()\n",
    "cols.remove('sample_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:11:41.591683Z",
     "start_time": "2022-02-21T03:11:40.842638Z"
    }
   },
   "outputs": [],
   "source": [
    "lb     = LabelEncoder()\n",
    "scaler = model[0]['scaler'] \n",
    "mdl    = model[0]['model']\n",
    "y_lb   = lb.fit_transform(y_valid)\n",
    "\n",
    "X_vld_scaler  = pd.DataFrame(scaler.transform(X_valid[cols]), columns=cols)\n",
    "y_pred_val    = mdl.predict(X_vld_scaler)\n",
    "acc           = metrics.accuracy_score(y_lb, y_pred_val)\n",
    "\n",
    "print('ACC: {:2.5f}'.format(acc))\n",
    "\n",
    "print(metrics.classification_report(y_lb, y_pred_val, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:14:35.72603Z",
     "start_time": "2022-02-21T03:14:35.710001Z"
    }
   },
   "source": [
    "### 2.5.3. Predição Teste e Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:14:47.954046Z",
     "start_time": "2022-02-21T03:14:46.125413Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T22:57:39.220342Z",
     "iopub.status.busy": "2022-02-21T22:57:39.220073Z",
     "iopub.status.idle": "2022-02-21T22:57:42.843767Z",
     "shell.execute_reply": "2022-02-21T22:57:42.843035Z",
     "shell.execute_reply.started": "2022-02-21T22:57:39.220312Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_scaler = pd.DataFrame(scaler.transform(X_test[cols]), columns=cols)\n",
    "y_pred_test   = mdl.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:18:39.574832Z",
     "start_time": "2022-02-21T03:18:39.400271Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T23:05:11.311911Z",
     "iopub.status.busy": "2022-02-21T23:05:11.311645Z",
     "iopub.status.idle": "2022-02-21T23:05:11.528872Z",
     "shell.execute_reply": "2022-02-21T23:05:11.52816Z",
     "shell.execute_reply.started": "2022-02-21T23:05:11.311881Z"
    }
   },
   "outputs": [],
   "source": [
    "name_model = name_model_clf + 'tunning_score_05_{:2.5f}_final.csv'.format(acc)\n",
    "\n",
    "df_submission[target] = lb.inverse_transform(y_pred_test)\n",
    "df_submission.to_csv(path +'Data/submission/' + name_model, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:00:37.806126Z",
     "start_time": "2022-02-21T03:00:37.799127Z"
    }
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-success\"> 3. FEATURE SELECTION </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14977,
     "end_time": "2022-02-18T07:14:29.999438",
     "exception": false,
     "start_time": "2022-02-18T07:14:29.849668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1. Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T14:48:46.608823Z",
     "iopub.status.busy": "2022-02-22T14:48:46.608145Z",
     "iopub.status.idle": "2022-02-22T14:48:49.837662Z",
     "shell.execute_reply": "2022-02-22T14:48:49.836977Z",
     "shell.execute_reply.started": "2022-02-22T14:48:46.60879Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = RobustScaler()\n",
    "lb = LabelEncoder()\n",
    "\n",
    "X_scaler = X.drop(['sample_weight'], axis=1)\n",
    "X_scaler = pd.DataFrame(sc.fit_transform(X_scaler), columns=X_scaler.columns)\n",
    "y_label  = pd.DataFrame(lb.fit_transform(y), columns=[target])\n",
    "\n",
    "X_scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:35:18.215356Z",
     "iopub.status.busy": "2022-02-23T01:35:18.215084Z",
     "iopub.status.idle": "2022-02-23T01:35:18.220828Z",
     "shell.execute_reply": "2022-02-23T01:35:18.219904Z",
     "shell.execute_reply.started": "2022-02-23T01:35:18.215325Z"
    }
   },
   "outputs": [],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T01:26:16.914255Z",
     "start_time": "2022-02-21T00:59:15.085066Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T23:07:33.226491Z",
     "iopub.status.busy": "2022-02-21T23:07:33.226238Z",
     "iopub.status.idle": "2022-02-21T23:20:01.056023Z",
     "shell.execute_reply": "2022-02-21T23:20:01.05525Z",
     "shell.execute_reply.started": "2022-02-21T23:07:33.226463Z"
    },
    "executionInfo": {
     "elapsed": 3610,
     "status": "ok",
     "timestamp": 1645133128911,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "SYbncKdAVzZI",
    "outputId": "95d3a417-7240-449a-9baa-1207bafa77a3",
    "papermill": {
     "duration": 8034.542892,
     "end_time": "2022-02-18T09:28:24.692174",
     "exception": false,
     "start_time": "2022-02-18T07:14:30.149282",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**params_best)\n",
    "\n",
    "feat_selector = BorutaPy(model, \n",
    "                         n_estimators = 'auto', \n",
    "                         two_step     = False,\n",
    "                         verbose      = 2, \n",
    "                         max_iter     = 100,\n",
    "                         random_state = 42)\n",
    "\n",
    "feat_selector.fit(X_scaler.values, y_label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:27:28.352272Z",
     "start_time": "2022-02-21T03:27:28.31029Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T23:20:45.828004Z",
     "iopub.status.busy": "2022-02-21T23:20:45.827702Z",
     "iopub.status.idle": "2022-02-21T23:20:45.857388Z",
     "shell.execute_reply": "2022-02-21T23:20:45.85674Z",
     "shell.execute_reply.started": "2022-02-21T23:20:45.827951Z"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1645112502849,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "mRf1BebkTqdW",
    "outputId": "8fdead1a-081f-4f0f-e1ae-7faaad8c85a2",
    "papermill": {
     "duration": 0.709069,
     "end_time": "2022-02-18T09:28:25.58063",
     "exception": false,
     "start_time": "2022-02-18T09:28:24.871561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_selected = X_scaler.iloc[:,feat_selector.support_]\n",
    "X_test_selected  = X_test.iloc[:,feat_selector.support_]\n",
    "\n",
    "X_train_selected['sample_weight'] = X['sample_weight']\n",
    "X_test_selected.shape , X_test_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:27:30.308524Z",
     "start_time": "2022-02-21T03:27:30.302527Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T02:11:22.768767Z",
     "iopub.status.busy": "2022-02-23T02:11:22.768111Z",
     "iopub.status.idle": "2022-02-23T02:11:22.773313Z",
     "shell.execute_reply": "2022-02-23T02:11:22.772102Z",
     "shell.execute_reply.started": "2022-02-23T02:11:22.768726Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645112536955,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "kzN_XEkFWLiG",
    "outputId": "98fbf679-e03f-41e7-8bcf-08c0f70f07ff",
    "papermill": {
     "duration": 0.318072,
     "end_time": "2022-02-18T09:28:26.255868",
     "exception": false,
     "start_time": "2022-02-18T09:28:25.937796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_feature_selected_boruta = X_train_selected.columns.to_list()\n",
    "print(cols_feature_selected_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:12:07.05492Z",
     "iopub.status.busy": "2022-02-23T02:12:07.054662Z",
     "iopub.status.idle": "2022-02-23T02:12:07.062991Z",
     "shell.execute_reply": "2022-02-23T02:12:07.062169Z",
     "shell.execute_reply.started": "2022-02-23T02:12:07.054892Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_rejected = [col for col in X.columns if col not in cols_feature_selected_boruta]\n",
    "print(feature_rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Feature autocorrelaciondas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:14:01.47786Z",
     "iopub.status.busy": "2022-02-23T02:14:01.4776Z",
     "iopub.status.idle": "2022-02-23T02:14:28.76368Z",
     "shell.execute_reply": "2022-02-23T02:14:28.763025Z",
     "shell.execute_reply.started": "2022-02-23T02:14:01.477832Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = .75\n",
    "\n",
    "print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n",
    "df = X[cols_feature_selected_boruta].corr(method ='pearson').round(5)\n",
    "df_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\n",
    "df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "df_corr.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T04:05:13.931104Z",
     "iopub.status.busy": "2022-02-25T04:05:13.930702Z",
     "iopub.status.idle": "2022-02-25T04:05:14.029091Z",
     "shell.execute_reply": "2022-02-25T04:05:14.027488Z",
     "shell.execute_reply.started": "2022-02-25T04:05:13.931021Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_aut_corr = list(df_corr['var_1'].unique())\n",
    "#feature_aut_corr.remove('sample_weight')\n",
    "print('Temos {} variáveis autocorrelaciodas.'.format(len(feature_aut_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos remover as variáveis autocorrelacionadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:16:48.109501Z",
     "iopub.status.busy": "2022-02-23T03:16:48.108944Z",
     "iopub.status.idle": "2022-02-23T03:16:48.115493Z",
     "shell.execute_reply": "2022-02-23T03:16:48.114747Z",
     "shell.execute_reply.started": "2022-02-23T03:16:48.10946Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_feature_selected = [col for col in cols_feature_selected_boruta if col not in feature_aut_corr]\n",
    "print('Temos agora {} variáveis.'.format(len(cols_feature_selected)), end='\\n\\n')\n",
    "print(cols_feature_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Modelagem\n",
    "Vamos fazer dois modelos, um com as variáveis selecionadas com o boruta e outro sem as variáveis autocorrelacionadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:16:56.397035Z",
     "iopub.status.busy": "2022-02-23T03:16:56.396762Z",
     "iopub.status.idle": "2022-02-23T03:16:56.403712Z",
     "shell.execute_reply": "2022-02-23T03:16:56.402951Z",
     "shell.execute_reply.started": "2022-02-23T03:16:56.396998Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_feature_selected_boruta_ts = cols_feature_selected_boruta.copy()\n",
    "cols_feature_selected_ts        = cols_feature_selected.copy() \n",
    "\n",
    "cols_feature_selected_boruta_ts.remove('sample_weight')\n",
    "cols_feature_selected_ts.remove('sample_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:47:20.625752Z",
     "iopub.status.busy": "2022-02-23T02:47:20.625153Z",
     "iopub.status.idle": "2022-02-23T03:12:49.139727Z",
     "shell.execute_reply": "2022-02-23T03:12:49.138931Z",
     "shell.execute_reply.started": "2022-02-23T02:47:20.625713Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "list_feature_imp = []\n",
    "feature          = [cols_feature_selected_boruta, cols_feature_selected]\n",
    "\n",
    "for i, cols in enumerate(feature): \n",
    "    cols_ts = cols.copy()\n",
    "    cols_ts.remove('sample_weight')\n",
    "    \n",
    "    name_model = name_model_clf + 'tunning_boruta_' + str(i+1) + '_score_06'\n",
    "        \n",
    "    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n",
    "                                 X_             = X[cols], \n",
    "                                 y_             = y, \n",
    "                                 X_test_        = X_test[cols_ts], \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = SEED,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = True, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)\n",
    "    \n",
    "    list_feature_imp.append(df_feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "**`NOTA:`** <br>\n",
    "Aqui temos um ponto interessante, o primeiro modelo tem melhor score, mas também com mais variáveis se tornando mais complexo e com mais ruidos, sendo assim, o segundo modelo me parece mais estável e a diferença é relativamente pequena, a partir desse ponto vamos utilizar apenas as variáveis do segundo modelo na geração dos próximos modelos.           \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:27:35.245099Z",
     "iopub.status.busy": "2022-02-23T03:27:35.244454Z",
     "iopub.status.idle": "2022-02-23T03:27:39.929297Z",
     "shell.execute_reply": "2022-02-23T03:27:39.928591Z",
     "shell.execute_reply.started": "2022-02-23T03:27:35.245059Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_feature_imp)):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    row = int(np.round(list_feature_imp[0].filter(regex=r'fold').shape[1] / 3 +1))\n",
    "    for fold, col in enumerate(list_feature_imp[0].filter(regex=r'fold').columns):            \n",
    "        col_acc = 'acc_' + str(fold+1)\n",
    "        df_fi = list_feature_imp[0].sort_values(by=col, ascending=False).reset_index().iloc[:25]\n",
    "        df_fi = df_fi[['index', col, col_acc]]\n",
    "        df_fi.columns = ['Feature', 'score', col_acc]\n",
    "        plt.subplot(row,3, fold+1)\n",
    "        sns.barplot(x='score', y='Feature', data=df_fi)    \n",
    "        plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n",
    "                  fontdict={'fontsize':18})    \n",
    "\n",
    "    plt.suptitle('Feature Importance XGB ', y=1.02, fontsize=24);\n",
    "    plt.tight_layout(h_pad=3.0); \n",
    "\n",
    "del df_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-success\"> 3. DIVERCIDADE </div>\n",
    "\n",
    "Nesta etapa vamos utilizar os melhores parametros, que encontramos na tunagem, para gerar diversos modelos com divercidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:28:34.531866Z",
     "iopub.status.busy": "2022-02-23T03:28:34.531157Z",
     "iopub.status.idle": "2022-02-23T03:34:57.277947Z",
     "shell.execute_reply": "2022-02-23T03:34:57.277113Z",
     "shell.execute_reply.started": "2022-02-23T03:28:34.531828Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "SEED_      = [42, 59, 1000, 1500, 2020, 2021]\n",
    "df_seed    = pd.DataFrame()\n",
    "score_best = 0 \n",
    "seed_best  = 0 \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "\n",
    "for i, seed_ in  enumerate (SEED_):     \n",
    "    name_model = name_model_clf + 'seed_'+ str(i+1) +'_score_07'\n",
    "        \n",
    "    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_best), \n",
    "                                 X_             = X[cols_feature_selected], \n",
    "                                 y_             = y,\n",
    "                                 X_test_        = X_test[cols_feature_selected_ts], \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = seed_,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = True, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)\n",
    "    \n",
    "    if score > score_best:\n",
    "        seed_best  = seed_  \n",
    "        score_best = score\n",
    "    \n",
    "    df_seed['seed_' + str(seed_)] = y_pred_test \n",
    "    \n",
    "print()\n",
    "print('Seed : {}'.format(seed_best))\n",
    "print('Score: {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:35:04.876731Z",
     "iopub.status.busy": "2022-02-23T03:35:04.876179Z",
     "iopub.status.idle": "2022-02-23T03:35:04.888718Z",
     "shell.execute_reply": "2022-02-23T03:35:04.887867Z",
     "shell.execute_reply.started": "2022-02-23T03:35:04.876695Z"
    }
   },
   "outputs": [],
   "source": [
    "df_seed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Gerar submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:36:39.577313Z",
     "iopub.status.busy": "2022-02-23T03:36:39.577029Z",
     "iopub.status.idle": "2022-02-23T03:37:15.130681Z",
     "shell.execute_reply": "2022-02-23T03:37:15.129976Z",
     "shell.execute_reply.started": "2022-02-23T03:36:39.577284Z"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit_transform(y)\n",
    "\n",
    "y_pred_test = df_seed.mode(axis=1)[0]\n",
    "y_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n",
    "\n",
    "name_model = name_model_clf + 'stacking_01_seed.csv'.format(score_best)\n",
    "\n",
    "df_submission[target] = y_pred_test\n",
    "df_submission.to_csv(path +'Data/submission/' + name_model, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T23:39:05.860706Z",
     "iopub.status.busy": "2022-02-21T23:39:05.860166Z",
     "iopub.status.idle": "2022-02-21T23:39:05.866755Z",
     "shell.execute_reply": "2022-02-21T23:39:05.865831Z",
     "shell.execute_reply.started": "2022-02-21T23:39:05.860656Z"
    }
   },
   "source": [
    "## 3.2. Leaning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:40:32.8112Z",
     "iopub.status.busy": "2022-02-23T03:40:32.81095Z",
     "iopub.status.idle": "2022-02-23T03:41:30.686643Z",
     "shell.execute_reply": "2022-02-23T03:41:30.685911Z",
     "shell.execute_reply.started": "2022-02-23T03:40:32.811172Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "learning_rate      = [0.1, 0.01, 0.005, 0.007]\n",
    "df_learning_rate   = pd.DataFrame()\n",
    "df_leaning_rate    = pd.DataFrame()\n",
    "params_l_rate      = params_best.copy()\n",
    "score_best         = 0 \n",
    "learning_rate_best = 0 \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "\n",
    "for i, learning_rate_ in  enumerate (learning_rate):   \n",
    "    name_model         = name_model_clf + 'leanig_rate_'+ str(i+1) +'_score_08'\n",
    "    params_l_rate['learning_rate'] = learning_rate_     \n",
    "    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_l_rate), \n",
    "                                 X_             = X[cols_feature_selected], \n",
    "                                 y_             = y, \n",
    "                                 X_test_        = X_test[cols_feature_selected_ts], \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = seed_best,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = True, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)\n",
    "    \n",
    "    if score > score_best:\n",
    "        learning_rate_best  = learning_rate_  \n",
    "        score_best          = score\n",
    "    \n",
    "    df_leaning_rate['leaning_rate_' + str(learning_rate_)] = y_pred_test \n",
    "\n",
    "print()\n",
    "print('Leaning Rate : {}'.format(learning_rate_best))\n",
    "print('Score        : {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:42:14.742823Z",
     "iopub.status.busy": "2022-02-23T03:42:14.742563Z",
     "iopub.status.idle": "2022-02-23T03:42:14.750295Z",
     "shell.execute_reply": "2022-02-23T03:42:14.749646Z",
     "shell.execute_reply.started": "2022-02-23T03:42:14.742795Z"
    }
   },
   "outputs": [],
   "source": [
    "df_leaning_rate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Gerar submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:42:20.35618Z",
     "iopub.status.busy": "2022-02-23T03:42:20.355906Z",
     "iopub.status.idle": "2022-02-23T03:42:40.972476Z",
     "shell.execute_reply": "2022-02-23T03:42:40.971597Z",
     "shell.execute_reply.started": "2022-02-23T03:42:20.356148Z"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit_transform(y)\n",
    "\n",
    "y_pred_test = df_leaning_rate.mode(axis=1)[0]\n",
    "y_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n",
    "\n",
    "name_model = name_model_clf + 'stacking_02_leaning_rate.csv'.format(score_best)\n",
    "\n",
    "df_submission[target] = y_pred_test\n",
    "df_submission.to_csv(path +'Data/submission/' + name_model, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:43:06.969873Z",
     "iopub.status.busy": "2022-02-23T03:43:06.969619Z",
     "iopub.status.idle": "2022-02-23T03:44:56.001822Z",
     "shell.execute_reply": "2022-02-23T03:44:56.000962Z",
     "shell.execute_reply.started": "2022-02-23T03:43:06.969845Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "max_dep        = [1, 3, 13, 15, 19]\n",
    "df_max_depth   = pd.DataFrame()\n",
    "params_max_dep = params_best.copy()\n",
    "score_best     = 0 \n",
    "max_dep_best   = 0 \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "\n",
    "for i, max_dep_ in  enumerate (max_dep):    \n",
    "    name_model = name_model_clf + 'max_dep_'+ str(i+1) + '_score_09'\n",
    "    params_max_dep['max_depth'] = max_dep_     \n",
    "    \n",
    "    model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = xgb.XGBClassifier(**params_max_dep), \n",
    "                                 X_             = X[cols_feature_selected], \n",
    "                                 y_             = y, \n",
    "                                 X_test_        = X_test[cols_feature_selected_ts], \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = seed_best,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = True, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)\n",
    "    \n",
    "    if score > score_best:\n",
    "        max_dep_best  = max_dep_  \n",
    "        score_best    = score\n",
    "    \n",
    "    df_max_depth['max_depth_' + str(max_dep_)] = y_pred_test \n",
    "\n",
    "print()\n",
    "print('Max Depth: {}'.format(max_dep_best))\n",
    "print('Score    : {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:44:56.003835Z",
     "iopub.status.busy": "2022-02-23T03:44:56.003505Z",
     "iopub.status.idle": "2022-02-23T03:44:56.013559Z",
     "shell.execute_reply": "2022-02-23T03:44:56.011709Z",
     "shell.execute_reply.started": "2022-02-23T03:44:56.003798Z"
    }
   },
   "outputs": [],
   "source": [
    "df_max_depth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Gerar submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:48:07.809294Z",
     "iopub.status.busy": "2022-02-23T03:48:07.80902Z",
     "iopub.status.idle": "2022-02-23T03:48:41.159154Z",
     "shell.execute_reply": "2022-02-23T03:48:41.158367Z",
     "shell.execute_reply.started": "2022-02-23T03:48:07.809263Z"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "lb.fit_transform(y)\n",
    "\n",
    "y_pred_test = df_max_depth.mode(axis=1)[0]\n",
    "y_pred_test = lb.inverse_transform(y_pred_test.astype(int))\n",
    "\n",
    "name_model = name_model_clf + 'stacking_03_max_depth.csv'.format(score_best)\n",
    "\n",
    "df_submission[target] = y_pred_test\n",
    "df_submission.to_csv(path +'Data/submission/' + name_model, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:49:05.436052Z",
     "iopub.status.busy": "2022-02-23T03:49:05.435804Z",
     "iopub.status.idle": "2022-02-23T03:54:06.645937Z",
     "shell.execute_reply": "2022-02-23T03:54:06.645253Z",
     "shell.execute_reply.started": "2022-02-23T03:49:05.436025Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_model = name_model_clf + '_div_feature_10_'\n",
    "\n",
    "TunningModels.model_of_diversity_feature_group(model_     = xgb.XGBClassifier(**params_best), \n",
    "                                               name_model = name_model, \n",
    "                                               X_         = X[cols_feature_selected], \n",
    "                                               y_         = y, \n",
    "                                               X_ts_      = X_test[cols_feature_selected_ts],\n",
    "                                               target_    = target,\n",
    "                                               sc_        = RobustScaler(),\n",
    "                                               seed_      = seed_best)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-success\"> 4. ENSEMBLE </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Recuparar dataset\n",
    "Vamos recuperar todas as previsões do XGBoost para gerar um ensable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T04:05:57.515004Z",
     "iopub.status.busy": "2022-02-23T04:05:57.514697Z",
     "iopub.status.idle": "2022-02-23T04:06:06.572161Z",
     "shell.execute_reply": "2022-02-23T04:06:06.570648Z",
     "shell.execute_reply.started": "2022-02-23T04:05:57.514971Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "df_train_xgb, df_test_xgb = TunningModels.df_return_preds_tunning('xgb', \n",
    "                                                                  train_shape_row = X.shape[0],\n",
    "                                                                  test_shape_row  = X_test.shape[0])\n",
    "print(df_train_xgb.shape, df_test_xgb.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T04:06:45.283898Z",
     "iopub.status.busy": "2022-02-23T04:06:45.283646Z",
     "iopub.status.idle": "2022-02-23T04:06:45.293949Z",
     "shell.execute_reply": "2022-02-23T04:06:45.293303Z",
     "shell.execute_reply.started": "2022-02-23T04:06:45.283869Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T04:07:05.649075Z",
     "iopub.status.busy": "2022-02-23T04:07:05.648355Z",
     "iopub.status.idle": "2022-02-23T04:07:06.055288Z",
     "shell.execute_reply": "2022-02-23T04:07:06.054623Z",
     "shell.execute_reply.started": "2022-02-23T04:07:05.64903Z"
    }
   },
   "outputs": [],
   "source": [
    "jb.dump(df_train_xgb, 'Data/pkl/df_nb_03_train_xgb.pkl.z')\n",
    "jb.dump(df_test_xgb,  'Data/pkl/df_nb_03_test_xgb.pkl.z')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "pt-br"
   ],
   "hotkey": "",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt-br",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.462px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
