{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFogj-Cdi34f",
    "papermill": {
     "duration": 0.062831,
     "end_time": "2022-02-18T03:57:59.782186",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.719355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#a7d5ed;font-size:170%;\n",
    "            font-family:Nexa;letter-spacing:4.5px;\">    \n",
    "    <h1 style=\"padding:15px;color:black;text-align: center\"> Tunning Hyperparameters LGBM</h1> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/kaggle-competitions/kaggle/26480/logos/header.png?t=2021-04-09-00-57-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKJFMrjqi34j",
    "papermill": {
     "duration": 0.060611,
     "end_time": "2022-02-18T03:57:59.904057",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.843446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 1. IMPORTAÇÕES </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:14.052531Z",
     "start_time": "2022-05-30T23:18:14.025552Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:08:56.539803Z",
     "iopub.status.busy": "2022-02-24T03:08:56.539315Z",
     "iopub.status.idle": "2022-02-24T03:09:22.326881Z",
     "shell.execute_reply": "2022-02-24T03:09:22.326044Z",
     "shell.execute_reply.started": "2022-02-24T03:08:56.539773Z"
    },
    "executionInfo": {
     "elapsed": 12874,
     "status": "ok",
     "timestamp": 1645145676268,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "U2CKimxvi34k",
    "outputId": "5fa75f99-0fdc-48f2-ea90-839f9f6df8c3",
    "papermill": {
     "duration": 26.515095,
     "end_time": "2022-02-18T03:58:26.480329",
     "exception": false,
     "start_time": "2022-02-18T03:57:59.965234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pub.towardsai.net/use-google-colab-like-a-pro-39a97184358d\n",
    "COLAB = 'google.colab' in str(get_ipython()) \n",
    "\n",
    "if COLAB:        \n",
    "    !pip install --q scikit-plot\n",
    "    !pip install --q category_encoders\n",
    "    !pip install --q shap\n",
    "    !pip install --q inflection  \n",
    "    !pip install --q optuna  \n",
    "    !pip install --q Boruta\n",
    "    !pip install --q GPUtil\n",
    "    #!pip install --q pycaret\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckrEOEuUi34l",
    "papermill": {
     "duration": 0.060234,
     "end_time": "2022-02-18T03:58:26.732418",
     "exception": false,
     "start_time": "2022-02-18T03:58:26.672184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.1. Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:54.113156Z",
     "start_time": "2022-05-30T23:18:15.327837Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:22.335337Z",
     "iopub.status.busy": "2022-02-24T03:09:22.335089Z",
     "iopub.status.idle": "2022-02-24T03:09:24.005609Z",
     "shell.execute_reply": "2022-02-24T03:09:24.004737Z",
     "shell.execute_reply.started": "2022-02-24T03:09:22.335302Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645145678988,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "icBhRH0Si34m",
    "papermill": {
     "duration": 1.643517,
     "end_time": "2022-02-18T03:58:28.436349",
     "exception": false,
     "start_time": "2022-02-18T03:58:26.792832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import math\n",
    "import sklearn.exceptions\n",
    "import datetime\n",
    "import shap\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.149701Z",
     "start_time": "2022-05-30T23:18:54.115974Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:24.007774Z",
     "iopub.status.busy": "2022-02-24T03:09:24.007544Z",
     "iopub.status.idle": "2022-02-24T03:09:24.068519Z",
     "shell.execute_reply": "2022-02-24T03:09:24.067862Z",
     "shell.execute_reply.started": "2022-02-24T03:09:24.00774Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1645145678989,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OjwX36f3i34m",
    "papermill": {
     "duration": 0.128457,
     "end_time": "2022-02-18T03:58:28.627075",
     "exception": false,
     "start_time": "2022-02-18T03:58:28.498618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn           as sns\n",
    "import joblib            as jb\n",
    "import xgboost           as xgb\n",
    "import lightgbm          as lgb\n",
    "import scikitplot        as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.165475Z",
     "start_time": "2022-05-30T23:18:57.151472Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:24.070482Z",
     "iopub.status.busy": "2022-02-24T03:09:24.069598Z",
     "iopub.status.idle": "2022-02-24T03:09:25.26017Z",
     "shell.execute_reply": "2022-02-24T03:09:25.25943Z",
     "shell.execute_reply.started": "2022-02-24T03:09:24.070451Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645145678990,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "xyxT1_-ei34n",
    "papermill": {
     "duration": 1.31662,
     "end_time": "2022-02-18T03:58:30.004564",
     "exception": false,
     "start_time": "2022-02-18T03:58:28.687944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn             as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.293298Z",
     "start_time": "2022-05-30T23:18:57.168467Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.331305Z",
     "iopub.status.busy": "2022-02-24T03:09:25.331053Z",
     "iopub.status.idle": "2022-02-24T03:09:25.345075Z",
     "shell.execute_reply": "2022-02-24T03:09:25.344422Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.33127Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1645145678991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "RM2RI3_ti34p",
    "papermill": {
     "duration": 0.076855,
     "end_time": "2022-02-18T03:58:30.34785",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.270995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn                     import metrics\n",
    "from sklearn.feature_selection   import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn.model_selection     import train_test_split,  KFold, StratifiedKFold\n",
    "from sklearn.preprocessing       import StandardScaler, MinMaxScaler, RobustScaler, Normalizer \n",
    "from sklearn.preprocessing       import MaxAbsScaler, QuantileTransformer, LabelEncoder\n",
    "from sklearn.impute              import SimpleImputer\n",
    "from sklearn                     import metrics\n",
    "from datetime                    import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.309260Z",
     "start_time": "2022-05-30T23:18:57.295262Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.347785Z",
     "iopub.status.busy": "2022-02-24T03:09:25.347598Z",
     "iopub.status.idle": "2022-02-24T03:09:25.355304Z",
     "shell.execute_reply": "2022-02-24T03:09:25.354564Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.34776Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645145678991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "IMnB1bcOi34p",
    "papermill": {
     "duration": 0.069198,
     "end_time": "2022-02-18T03:58:30.478124",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.408926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optuna.samplers               import TPESampler\n",
    "from optuna.visualization          import plot_edf\n",
    "from optuna.visualization          import plot_optimization_history\n",
    "from optuna.visualization          import plot_parallel_coordinate\n",
    "from optuna.visualization          import plot_param_importances\n",
    "from optuna.visualization          import plot_slice\n",
    "from optuna.visualization          import plot_intermediate_values\n",
    "from optuna.visualization          import plot_contour\n",
    "from optuna.pruners                import MedianPruner\n",
    "from optuna.pruners                import BasePruner\n",
    "from optuna.trial._state           import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.547848Z",
     "start_time": "2022-05-30T23:18:57.311269Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.357294Z",
     "iopub.status.busy": "2022-02-24T03:09:25.35683Z",
     "iopub.status.idle": "2022-02-24T03:09:25.844887Z",
     "shell.execute_reply": "2022-02-24T03:09:25.844117Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.357255Z"
    },
    "executionInfo": {
     "elapsed": 1318,
     "status": "ok",
     "timestamp": 1645145680299,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "rxIrWu38i34q",
    "outputId": "5c90197d-4977-4549-de18-8dac945cdd66",
    "papermill": {
     "duration": 0.587345,
     "end_time": "2022-02-18T03:58:31.126788",
     "exception": false,
     "start_time": "2022-02-18T03:58:30.539443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from GPUtil                        import showUtilization as gpu_usage\n",
    "from numba                         import cuda\n",
    "from sklearn.ensemble              import IsolationForest\n",
    "from psutil                        import virtual_memory\n",
    "from datetime                      import datetime\n",
    "from psutil                        import virtual_memory\n",
    "from sklearn.utils.class_weight    import compute_sample_weight\n",
    "from boruta                        import BorutaPy\n",
    "from multiprocessing               import cpu_count\n",
    "from sklearn.calibration           import CalibrationDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwyizAfdi34r",
    "papermill": {
     "duration": 0.061772,
     "end_time": "2022-02-18T03:58:31.253664",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.191892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.2. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.563043Z",
     "start_time": "2022-05-30T23:18:57.549818Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.848283Z",
     "iopub.status.busy": "2022-02-24T03:09:25.847963Z",
     "iopub.status.idle": "2022-02-24T03:09:25.865066Z",
     "shell.execute_reply": "2022-02-24T03:09:25.864365Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.848244Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "hide_input": true,
    "id": "1vHZjDzgi34r",
    "papermill": {
     "duration": 0.079795,
     "end_time": "2022-02-18T03:58:31.395618",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.315823",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jupyter_setting():\n",
    "    \n",
    "    %matplotlib inline\n",
    "      \n",
    "    #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "    #plt.style.use('bmh') \n",
    "    #plt.rcParams['figure.figsize'] = [20,15]\n",
    "    #plt.rcParams['font.size']      = 13\n",
    "     \n",
    "    pd.options.display.max_columns = None\n",
    "    #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    warnings.simplefilter('ignore')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "    #sns.palplot(sns.color_palette(icecream))\n",
    "    \n",
    "    colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "    \n",
    "    # Colors\n",
    "    dark_red   = \"#b20710\"\n",
    "    black      = \"#221f1f\"\n",
    "    green      = \"#009473\"\n",
    "    myred      = '#CD5C5C'\n",
    "    myblue     = '#6495ED'\n",
    "    mygreen    = '#90EE90'    \n",
    "    color_cols = [myred, myblue,mygreen]\n",
    "    \n",
    "    return icecream, colors, color_cols\n",
    "\n",
    "icecream, colors, color_cols = jupyter_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.578861Z",
     "start_time": "2022-05-30T23:18:57.565820Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def jupyter_setting():\n",
    "    \n",
    "    %matplotlib inline\n",
    "      \n",
    "    #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "    #plt.style.use('bmh') \n",
    "    #plt.rcParams['figure.figsize'] = [20,15]\n",
    "    #plt.rcParams['font.size']      = 13\n",
    "     \n",
    "    pd.options.display.max_columns = None\n",
    "    #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "    warnings.simplefilter('ignore')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "    pd.set_option('display.max_rows', 200)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "    icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "    #sns.palplot(sns.color_palette(icecream))\n",
    "    \n",
    "    colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "    \n",
    "    # Colors\n",
    "    dark_red   = \"#b20710\"\n",
    "    black      = \"#221f1f\"\n",
    "    green      = \"#009473\"\n",
    "    myred      = '#CD5C5C'\n",
    "    myblue     = '#6495ED'\n",
    "    mygreen    = '#90EE90'    \n",
    "    color_cols = [myred, myblue,mygreen]\n",
    "    \n",
    "    return icecream, colors, color_cols\n",
    "\n",
    "icecream, colors, color_cols = jupyter_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.594840Z",
     "start_time": "2022-05-30T23:18:57.580814Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.86794Z",
     "iopub.status.busy": "2022-02-24T03:09:25.867275Z",
     "iopub.status.idle": "2022-02-24T03:09:25.882197Z",
     "shell.execute_reply": "2022-02-24T03:09:25.881525Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.867892Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "m-u-wKS5i34s",
    "papermill": {
     "duration": 0.075703,
     "end_time": "2022-02-18T03:58:31.532703",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.610819Z",
     "start_time": "2022-05-30T23:18:57.598813Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def missing_zero_values_table(df):\n",
    "        mis_val         = df.isnull().sum()\n",
    "        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n",
    "        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n",
    "                                                     0 : 'Valores ausentes', \n",
    "                                                     1 : '% de valores totais'})\n",
    "        \n",
    "        mz_table['Tipo de dados'] = df.dtypes\n",
    "        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n",
    "                                     sort_values('% de valores totais', ascending=False)\n",
    "        \n",
    "        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n",
    "              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n",
    "            \n",
    "        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n",
    "        \n",
    "        return mz_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.626818Z",
     "start_time": "2022-05-30T23:18:57.612815Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.884162Z",
     "iopub.status.busy": "2022-02-24T03:09:25.883577Z",
     "iopub.status.idle": "2022-02-24T03:09:25.894041Z",
     "shell.execute_reply": "2022-02-24T03:09:25.893252Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.884125Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680300,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "oT4xvNQxi34t",
    "papermill": {
     "duration": 0.073516,
     "end_time": "2022-02-18T03:58:31.66705",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.593534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision Recall vs threshold')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.641812Z",
     "start_time": "2022-05-30T23:18:57.629830Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.895904Z",
     "iopub.status.busy": "2022-02-24T03:09:25.895686Z",
     "iopub.status.idle": "2022-02-24T03:09:25.905529Z",
     "shell.execute_reply": "2022-02-24T03:09:25.904708Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.895879Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OzJVgUuTi34u",
    "papermill": {
     "duration": 0.068545,
     "end_time": "2022-02-18T03:58:31.797089",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.728544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b-\", label=\"Precision\")\n",
    "    \n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('Precision vs recall')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.657849Z",
     "start_time": "2022-05-30T23:18:57.643814Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.90806Z",
     "iopub.status.busy": "2022-02-24T03:09:25.907283Z",
     "iopub.status.idle": "2022-02-24T03:09:25.915693Z",
     "shell.execute_reply": "2022-02-24T03:09:25.915003Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.907981Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "51KsDDGLi34u",
    "papermill": {
     "duration": 0.06895,
     "end_time": "2022-02-18T03:58:31.926635",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.857685",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('XGBR ROC curve for TPS 09')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.673818Z",
     "start_time": "2022-05-30T23:18:57.659815Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.917475Z",
     "iopub.status.busy": "2022-02-24T03:09:25.917167Z",
     "iopub.status.idle": "2022-02-24T03:09:25.928613Z",
     "shell.execute_reply": "2022-02-24T03:09:25.927921Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.917429Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3gf0D8QLi34u",
    "papermill": {
     "duration": 0.070047,
     "end_time": "2022-02-18T03:58:32.056995",
     "exception": false,
     "start_time": "2022-02-18T03:58:31.986948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_feature_corr(df, annot_=False, threshold=.8, print_var=False, print_graf=True):\n",
    "    \n",
    "    df = df.corr(method ='pearson').round(5)\n",
    "\n",
    "    if print_graf: \n",
    "        # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "        mask = np.zeros_like(df)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "        # Making a plot\n",
    "        ax = sns.heatmap(df, annot=annot_, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\n",
    "\n",
    "        ax.set_title(\"Mapa de calor de correlação das variável\", fontsize=17)\n",
    "\n",
    "        plt.setp(ax.get_xticklabels(), \n",
    "                 rotation      = 90, \n",
    "                 ha            = \"right\",\n",
    "                 rotation_mode = \"anchor\", \n",
    "                 weight        = \"normal\")\n",
    "\n",
    "        plt.setp(ax.get_yticklabels(), \n",
    "                 weight        = \"normal\",\n",
    "                 rotation_mode = \"anchor\", \n",
    "                 rotation      = 0, \n",
    "                 ha            = \"right\");\n",
    "\n",
    "    if print_var: \n",
    "        \n",
    "        df_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\n",
    "        if len(df_corr)>0:            \n",
    "            print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n",
    "            df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "            display(df_corr)\n",
    "        else: \n",
    "            print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.689850Z",
     "start_time": "2022-05-30T23:18:57.675826Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.930451Z",
     "iopub.status.busy": "2022-02-24T03:09:25.930231Z",
     "iopub.status.idle": "2022-02-24T03:09:25.939257Z",
     "shell.execute_reply": "2022-02-24T03:09:25.938407Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.930428Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680301,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "YYXsmuJwi34u",
    "papermill": {
     "duration": 0.07063,
     "end_time": "2022-02-18T03:58:32.191628",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.120998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "\n",
    "    col_corr    = set()  # Conjunto de todos os nomes de colunas correlacionadas\n",
    "    corr_matrix = dataset.corr()\n",
    "    \n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) >= threshold: # estamos interessados no valor coeficiente absoluto\n",
    "                colname = corr_matrix.columns[i]        # obtendo o nome da coluna\n",
    "                col_corr.add(colname)\n",
    "    \n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.705819Z",
     "start_time": "2022-05-30T23:18:57.691813Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.940912Z",
     "iopub.status.busy": "2022-02-24T03:09:25.940629Z",
     "iopub.status.idle": "2022-02-24T03:09:25.947533Z",
     "shell.execute_reply": "2022-02-24T03:09:25.946745Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.940878Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "GuS0Lh52i34v",
    "papermill": {
     "duration": 0.066949,
     "end_time": "2022-02-18T03:58:32.318918",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.251969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    \n",
    "    # https://www.kaggle.com/getting-started/140636\n",
    "    #print(\"Initial GPU Usage\")\n",
    "    #gpu_usage()                             \n",
    "\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)   \n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.721850Z",
     "start_time": "2022-05-30T23:18:57.708831Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.948666Z",
     "iopub.status.busy": "2022-02-24T03:09:25.948458Z",
     "iopub.status.idle": "2022-02-24T03:09:25.957094Z",
     "shell.execute_reply": "2022-02-24T03:09:25.956217Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.948642Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "25zqU_0-dvOi",
    "papermill": {
     "duration": 0.068318,
     "end_time": "2022-02-18T03:58:32.447875",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.379557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diff(t_a, t_b):\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "    return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.737818Z",
     "start_time": "2022-05-30T23:18:57.723819Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.959284Z",
     "iopub.status.busy": "2022-02-24T03:09:25.958611Z",
     "iopub.status.idle": "2022-02-24T03:09:25.970633Z",
     "shell.execute_reply": "2022-02-24T03:09:25.96977Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.959187Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "apj7RUQqdxBz",
    "papermill": {
     "duration": 0.080776,
     "end_time": "2022-02-18T03:58:32.589498",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.508722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe(df):\n",
    "    var = df.columns\n",
    "\n",
    "    # Medidas de tendência central, média e mediana \n",
    "    ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "    ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "    # Dispensão - str, min , max range skew, kurtosis\n",
    "    d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "    d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "    d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "    d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "    d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "    d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "    d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "    # concatenete \n",
    "    m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "    m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.753841Z",
     "start_time": "2022-05-30T23:18:57.740817Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.97304Z",
     "iopub.status.busy": "2022-02-24T03:09:25.972493Z",
     "iopub.status.idle": "2022-02-24T03:09:25.980551Z",
     "shell.execute_reply": "2022-02-24T03:09:25.979713Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.973005Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645145680302,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "itZLuff_d27q",
    "papermill": {
     "duration": 0.077438,
     "end_time": "2022-02-18T03:58:32.734219",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.656781",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "    ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.title('ROC curve for TPS 09')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.769850Z",
     "start_time": "2022-05-30T23:18:57.755821Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.982344Z",
     "iopub.status.busy": "2022-02-24T03:09:25.982023Z",
     "iopub.status.idle": "2022-02-24T03:09:25.991728Z",
     "shell.execute_reply": "2022-02-24T03:09:25.990882Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.98224Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "TRIUWUu0d68a",
    "papermill": {
     "duration": 0.081141,
     "end_time": "2022-02-18T03:58:32.879252",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.798111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_plot(matrix, labels = None, title = None):\n",
    "        \n",
    "    labels = labels if labels else ['Negative (0)', 'Positive (1)']    \n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    \n",
    "    sns.heatmap(data        = matrix, \n",
    "                cmap        = 'Blues', \n",
    "                annot       = True, \n",
    "                fmt         = 'd',\n",
    "                xticklabels = labels, \n",
    "                yticklabels = labels, \n",
    "                ax          = ax);\n",
    "    \n",
    "    ax.set_xlabel('\\n PREVISTO', fontsize=15)\n",
    "    ax.set_ylabel('REAL \\n', fontsize=15)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.close();\n",
    "    \n",
    "    return fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.785819Z",
     "start_time": "2022-05-30T23:18:57.771816Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:25.993173Z",
     "iopub.status.busy": "2022-02-24T03:09:25.992871Z",
     "iopub.status.idle": "2022-02-24T03:09:26.002489Z",
     "shell.execute_reply": "2022-02-24T03:09:26.00183Z",
     "shell.execute_reply.started": "2022-02-24T03:09:25.993138Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "q6u5INXLd_Vy",
    "papermill": {
     "duration": 0.073793,
     "end_time": "2022-02-18T03:58:33.023609",
     "exception": false,
     "start_time": "2022-02-18T03:58:32.949816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_outlier(df, feature):\n",
    "    col = [(0,4), (5,9)]\n",
    "\n",
    "    df_plot = ((df[feature] - df[feature].min())/\n",
    "               (df[feature].max() - df[feature].min()))\n",
    "\n",
    "    fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "    for i, (x) in enumerate(col): \n",
    "        sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:57.801818Z",
     "start_time": "2022-05-30T23:18:57.787814Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:09:26.004377Z",
     "iopub.status.busy": "2022-02-24T03:09:26.003772Z",
     "iopub.status.idle": "2022-02-24T03:09:26.014485Z",
     "shell.execute_reply": "2022-02-24T03:09:26.013764Z",
     "shell.execute_reply.started": "2022-02-24T03:09:26.004276Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "lNMWoOTNeCni",
    "papermill": {
     "duration": 0.074269,
     "end_time": "2022-02-18T03:58:33.162804",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.088535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graf_eval():\n",
    "\n",
    "    results     = model.evals_result()\n",
    "    ntree_limit = model.best_ntree_limit\n",
    "\n",
    "    plt.figure(figsize=(20,7))\n",
    "\n",
    "    for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "        \n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "        plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "        plt.axvline(ntree_limit, \n",
    "                    color=\"gray\", \n",
    "                    label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "                    \n",
    "        \n",
    "        title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "        plt.title(title_name)\n",
    "        plt.xlabel(\"Número de árvores\")\n",
    "        plt.ylabel(error)\n",
    "        plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puAI82JpDOJO",
    "papermill": {
     "duration": 0.059938,
     "end_time": "2022-02-18T03:58:33.28494",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.225002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.3. GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iISld6GaDyRM",
    "papermill": {
     "duration": 0.060529,
     "end_time": "2022-02-18T03:58:33.405688",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.345159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3.1. Informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:58.035853Z",
     "start_time": "2022-05-30T23:18:57.804813Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:20.308019Z",
     "iopub.status.busy": "2022-02-24T03:14:20.307662Z",
     "iopub.status.idle": "2022-02-24T03:14:20.374233Z",
     "shell.execute_reply": "2022-02-24T03:14:20.373401Z",
     "shell.execute_reply.started": "2022-02-24T03:14:20.307981Z"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1645145680303,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Je1LG7eeDL1s",
    "outputId": "5f68635a-c0ed-4f19-979a-83456e39b44d",
    "papermill": {
     "duration": 0.12607,
     "end_time": "2022-02-18T03:58:33.592385",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.466315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 30 20:18:57 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.69       Driver Version: 511.69       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   55C    P8    N/A /  N/A |   1160MiB /  4096MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1280    C+G   C:\\Windows\\System32\\dwm.exe     N/A      |\n",
      "|    0   N/A  N/A      1972    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      4276    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8272    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9220    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10200    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     10328    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     14044    C+G   ...afe Family\\SafeFamily.exe    N/A      |\n",
      "|    0   N/A  N/A     29952    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     30880    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     32688    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     63996    C+G   ...indows\\System32\\mstsc.exe    N/A      |\n",
      "|    0   N/A  N/A     97980    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A    104260    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A    104852    C+G   ...Office\\Office16\\EXCEL.EXE    N/A      |\n",
      "|    0   N/A  N/A    106660    C+G   ...ava-runtime\\bin\\javaw.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWJ4r84ZEAIM",
    "papermill": {
     "duration": 0.06595,
     "end_time": "2022-02-18T03:58:33.720046",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.654096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3.2. Memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:58.051852Z",
     "start_time": "2022-05-30T23:18:58.037816Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:21.695627Z",
     "iopub.status.busy": "2022-02-24T03:14:21.694987Z",
     "iopub.status.idle": "2022-02-24T03:14:21.70313Z",
     "shell.execute_reply": "2022-02-24T03:14:21.702268Z",
     "shell.execute_reply.started": "2022-02-24T03:14:21.695585Z"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1645133006185,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "OVohZ_xSD33t",
    "outputId": "040c8b16-54f0-41c5-bd8a-52cb5aea9e58",
    "papermill": {
     "duration": 0.071981,
     "end_time": "2022-02-18T03:58:33.865429",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.793448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 17.0 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "source": [
    "ram_gb = virtual_memory().total / 1e9\n",
    "\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_PfcxeGi34v",
    "papermill": {
     "duration": 0.061017,
     "end_time": "2022-02-18T03:58:33.98797",
     "exception": false,
     "start_time": "2022-02-18T03:58:33.926953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0.4. Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTgQwT5NeSu6",
    "papermill": {
     "duration": 0.060746,
     "end_time": "2022-02-18T03:58:34.110711",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.049965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.1. Estrutura de diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:58.067813Z",
     "start_time": "2022-05-30T23:18:58.053815Z"
    }
   },
   "outputs": [],
   "source": [
    "path        = '/content/drive/MyDrive/kaggle/Tabular Playground Series/2022/05 - Maio/' if COLAB else ''    \n",
    "path_data   = 'Data/'  \n",
    "target      = 'target'\n",
    "path_automl = 'automl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:58.083817Z",
     "start_time": "2022-05-30T23:18:58.069815Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:23.688213Z",
     "iopub.status.busy": "2022-02-24T03:14:23.687432Z",
     "iopub.status.idle": "2022-02-24T03:14:23.693944Z",
     "shell.execute_reply": "2022-02-24T03:14:23.693212Z",
     "shell.execute_reply.started": "2022-02-24T03:14:23.688161Z"
    },
    "id": "nvZIRsuIePhl",
    "papermill": {
     "duration": 0.07172,
     "end_time": "2022-02-18T03:58:34.245611",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.173891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'Data/tunning', \n",
    "         'model', 'model/preds', 'model/optuna','model/preds/test', 'Data/shap',\n",
    "         'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n",
    "         'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n",
    "         'model/preds/train/n3', 'model/preds/param', 'model/mdl', 'model/preds/folds' ]\n",
    "\n",
    "for p in paths:\n",
    "    try:\n",
    "        os.mkdir(path + p)       \n",
    "    except:\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:40:57.479332Z",
     "start_time": "2022-02-13T14:40:57.473293Z"
    },
    "id": "3lCczGg3cCgV",
    "papermill": {
     "duration": 0.061762,
     "end_time": "2022-02-18T03:58:34.501058",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.439296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2. Carregar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:59.622289Z",
     "start_time": "2022-05-30T23:18:58.085820Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:26.926877Z",
     "iopub.status.busy": "2022-02-24T03:14:26.926589Z",
     "iopub.status.idle": "2022-02-24T03:14:29.403323Z",
     "shell.execute_reply": "2022-02-24T03:14:29.40264Z",
     "shell.execute_reply.started": "2022-02-24T03:14:26.926842Z"
    },
    "executionInfo": {
     "elapsed": 5127,
     "status": "ok",
     "timestamp": 1645133017005,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "Ar5Fty2Ei34v",
    "outputId": "b01a91f0-f9b6-4502-831b-6abe6c10335b",
    "papermill": {
     "duration": 3.456604,
     "end_time": "2022-02-18T03:58:38.018591",
     "exception": false,
     "start_time": "2022-02-18T03:58:34.561987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 62), (700000, 61), (700000, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train     = jb.load(path + path_data + 'pkl/df3_train_fe_4.pkl.z')\n",
    "df3_test      = jb.load(path + path_data + 'pkl/df3_test_fe_4.pkl.z')\n",
    "df_submission = pd.read_csv(path + path_data + 'sample_submission.csv')\n",
    "\n",
    "df3_train.shape, df3_test.shape, df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:18:59.732630Z",
     "start_time": "2022-05-30T23:18:59.627280Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:30.748321Z",
     "iopub.status.busy": "2022-02-24T03:14:30.74788Z",
     "iopub.status.idle": "2022-02-24T03:14:30.97518Z",
     "shell.execute_reply": "2022-02-24T03:14:30.974494Z",
     "shell.execute_reply.started": "2022-02-24T03:14:30.748283Z"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1645133017725,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "-qfjHtY0i34w",
    "outputId": "68c97d0c-e852-484b-e19d-47e003f2f3d4",
    "papermill": {
     "duration": 0.267393,
     "end_time": "2022-02-18T03:58:38.348227",
     "exception": false,
     "start_time": "2022-02-18T03:58:38.080834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>target</th>\n",
       "      <th>fe_02_21</th>\n",
       "      <th>fe_05_22</th>\n",
       "      <th>fe_i_00_01_26</th>\n",
       "      <th>fe_27_a</th>\n",
       "      <th>fe_27_b</th>\n",
       "      <th>fe_27_c</th>\n",
       "      <th>fe_27_d</th>\n",
       "      <th>fe_27_e</th>\n",
       "      <th>fe_27_f</th>\n",
       "      <th>fe_27_g</th>\n",
       "      <th>fe_27_h</th>\n",
       "      <th>fe_27_i</th>\n",
       "      <th>fe_27_j</th>\n",
       "      <th>fe_27_k</th>\n",
       "      <th>fe_27_l</th>\n",
       "      <th>fe_27_m</th>\n",
       "      <th>fe_27_n</th>\n",
       "      <th>fe_27_o</th>\n",
       "      <th>fe_27_p</th>\n",
       "      <th>fe_27_q</th>\n",
       "      <th>fe_27_r</th>\n",
       "      <th>fe_27_s</th>\n",
       "      <th>fe_27_t</th>\n",
       "      <th>fe_27_count_unique</th>\n",
       "      <th>fe_27_count_zero</th>\n",
       "      <th>fe_27_mean</th>\n",
       "      <th>fe_27_sum</th>\n",
       "      <th>fe_27_std</th>\n",
       "      <th>fe_outlier</th>\n",
       "      <th>fe_pca_0</th>\n",
       "      <th>fe_pca_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.373047</td>\n",
       "      <td>0.238892</td>\n",
       "      <td>-0.243408</td>\n",
       "      <td>0.567383</td>\n",
       "      <td>-0.647949</td>\n",
       "      <td>0.839355</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.298340</td>\n",
       "      <td>-0.919922</td>\n",
       "      <td>3.058594</td>\n",
       "      <td>-2.541016</td>\n",
       "      <td>0.767090</td>\n",
       "      <td>-2.730469</td>\n",
       "      <td>-0.208130</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>67.625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3.333984</td>\n",
       "      <td>10</td>\n",
       "      <td>0.942871</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.637714</td>\n",
       "      <td>-5.339258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.697266</td>\n",
       "      <td>-1.709961</td>\n",
       "      <td>-2.230469</td>\n",
       "      <td>-0.545898</td>\n",
       "      <td>1.113281</td>\n",
       "      <td>-1.551758</td>\n",
       "      <td>0.447754</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.148438</td>\n",
       "      <td>-1.075195</td>\n",
       "      <td>2.179688</td>\n",
       "      <td>2.277344</td>\n",
       "      <td>-0.633789</td>\n",
       "      <td>-1.216797</td>\n",
       "      <td>-3.781250</td>\n",
       "      <td>-0.058319</td>\n",
       "      <td>377.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.264648</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.160857</td>\n",
       "      <td>-5.274908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.681641</td>\n",
       "      <td>0.616699</td>\n",
       "      <td>-1.027344</td>\n",
       "      <td>0.810547</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>0.113953</td>\n",
       "      <td>-0.708496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.820312</td>\n",
       "      <td>-3.484375</td>\n",
       "      <td>-0.784180</td>\n",
       "      <td>-1.385742</td>\n",
       "      <td>-0.520508</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>2.789062</td>\n",
       "      <td>-3.703125</td>\n",
       "      <td>-195.625</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1.666992</td>\n",
       "      <td>10</td>\n",
       "      <td>1.490234</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.205235</td>\n",
       "      <td>5.057066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118164</td>\n",
       "      <td>-0.587891</td>\n",
       "      <td>-0.804688</td>\n",
       "      <td>2.085938</td>\n",
       "      <td>0.371094</td>\n",
       "      <td>-0.128784</td>\n",
       "      <td>-0.282471</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.081055</td>\n",
       "      <td>-2.099609</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>0.572754</td>\n",
       "      <td>-1.653320</td>\n",
       "      <td>1.685547</td>\n",
       "      <td>-2.533203</td>\n",
       "      <td>-0.608398</td>\n",
       "      <td>210.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.635226</td>\n",
       "      <td>-5.175442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.148438</td>\n",
       "      <td>-0.176514</td>\n",
       "      <td>-0.665039</td>\n",
       "      <td>-1.101562</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.407471</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.126221</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>-3.912109</td>\n",
       "      <td>-1.430664</td>\n",
       "      <td>2.126953</td>\n",
       "      <td>-3.306641</td>\n",
       "      <td>4.371094</td>\n",
       "      <td>-217.250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1.666992</td>\n",
       "      <td>10</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.891048</td>\n",
       "      <td>-0.461735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_00      f_01      f_02      f_03      f_04      f_05      f_06  f_07  \\\n",
       "0 -1.373047  0.238892 -0.243408  0.567383 -0.647949  0.839355  0.113159     1   \n",
       "1  1.697266 -1.709961 -2.230469 -0.545898  1.113281 -1.551758  0.447754     1   \n",
       "2  1.681641  0.616699 -1.027344  0.810547 -0.608887  0.113953 -0.708496     1   \n",
       "3 -0.118164 -0.587891 -0.804688  2.085938  0.371094 -0.128784 -0.282471     3   \n",
       "4  1.148438 -0.176514 -0.665039 -1.101562  0.467773  0.500000  0.407471     3   \n",
       "\n",
       "   f_08  f_09  f_10  f_11  f_12  f_13  f_14  f_15  f_16  f_17  f_18      f_19  \\\n",
       "0     5     1     3     3     3     1     6     1     0     7     4  0.298340   \n",
       "1     3     4     0     2     3     0     1     0     4     6     0 -3.148438   \n",
       "2     0     2     6     6     4     3     1     2     2     1     4  2.820312   \n",
       "3     2     1     0     1     6     4     2     3     3     0     3  1.081055   \n",
       "4     3     0     4     3     0     6     0     3     3     1     0 -0.126221   \n",
       "\n",
       "       f_20      f_21      f_22      f_23      f_24      f_25      f_26  \\\n",
       "0 -0.919922  3.058594 -2.541016  0.767090 -2.730469 -0.208130  1.363281   \n",
       "1 -1.075195  2.179688  2.277344 -0.633789 -1.216797 -3.781250 -0.058319   \n",
       "2 -3.484375 -0.784180 -1.385742 -0.520508 -0.009125  2.789062 -3.703125   \n",
       "3 -2.099609 -2.343750  0.572754 -1.653320  1.685547 -2.533203 -0.608398   \n",
       "4  0.604980  1.133789 -3.912109 -1.430664  2.126953 -3.306641  4.371094   \n",
       "\n",
       "      f_28  f_29  f_30  target  fe_02_21  fe_05_22  fe_i_00_01_26  fe_27_a  \\\n",
       "0   67.625     0     0       0         0         0              0        4   \n",
       "1  377.000     0     0       1         0         0              0        3   \n",
       "2 -195.625     0     2       1         0         0              0        5   \n",
       "3  210.875     0     0       1         0         0              0        2   \n",
       "4 -217.250     0     1       1         0         0              1        0   \n",
       "\n",
       "   fe_27_b  fe_27_c  fe_27_d  fe_27_e  fe_27_f  fe_27_g  fe_27_h  fe_27_i  \\\n",
       "0        4        0        2        0        0        0        0        0   \n",
       "1        1        4        1        1        0        0        0        0   \n",
       "2        1        1        1        1        0        0        0        0   \n",
       "3        5        2        1        0        0        0        0        0   \n",
       "4        4        2        1        1        1        0        1        0   \n",
       "\n",
       "   fe_27_j  fe_27_k  fe_27_l  fe_27_m  fe_27_n  fe_27_o  fe_27_p  fe_27_q  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        1        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   fe_27_r  fe_27_s  fe_27_t  fe_27_count_unique  fe_27_count_zero  \\\n",
       "0        0        0        0                   3                17   \n",
       "1        0        0        0                   5                15   \n",
       "2        0        0        0                   6                14   \n",
       "3        0        0        0                   4                16   \n",
       "4        0        0        0                   6                14   \n",
       "\n",
       "   fe_27_mean  fe_27_sum  fe_27_std  fe_outlier  fe_pca_0  fe_pca_1  \n",
       "0    3.333984         10   0.942871           0 -3.637714 -5.339258  \n",
       "1    2.000000         10   1.264648           0 -4.160857 -5.274908  \n",
       "2    1.666992         10   1.490234           0 -3.205235  5.057066  \n",
       "3    2.500000         10   1.500000           0 -3.635226 -5.175442  \n",
       "4    1.666992         10   1.105469           0 -2.891048 -0.461735  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:19:00.485630Z",
     "start_time": "2022-05-30T23:18:59.735628Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:31.614361Z",
     "iopub.status.busy": "2022-02-24T03:14:31.613943Z",
     "iopub.status.idle": "2022-02-24T03:14:34.239242Z",
     "shell.execute_reply": "2022-02-24T03:14:34.238497Z",
     "shell.execute_reply.started": "2022-02-24T03:14:31.614322Z"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1645133019645,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "_JUntp99QiWX",
    "outputId": "36f4d652-f431-43c4-eeef-bf1d3462823a",
    "papermill": {
     "duration": 2.275806,
     "end_time": "2022-02-18T03:58:40.689532",
     "exception": false,
     "start_time": "2022-02-18T03:58:38.413726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 70.38 Mb (25.5% reduction)\n",
      "Mem. usage decreased to 54.07 Mb (25.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "df3_train = reduce_memory_usage(df3_train)\n",
    "df3_test  = reduce_memory_usage(df3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-13T14:42:43.769709Z",
     "start_time": "2022-02-13T14:42:43.75774Z"
    },
    "id": "lXM1616ZcCgX",
    "papermill": {
     "duration": 0.107583,
     "end_time": "2022-02-18T03:58:40.93197",
     "exception": false,
     "start_time": "2022-02-18T03:58:40.824387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 1.  Modelagem </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTfHy5aLcCgY",
    "papermill": {
     "duration": 0.1027,
     "end_time": "2022-02-18T03:58:41.138015",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.035315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:19:00.500630Z",
     "start_time": "2022-05-30T23:19:00.487630Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def delete_files(namefile):\n",
    "                \n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:19:00.516632Z",
     "start_time": "2022-05-30T23:19:00.502631Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.241248Z",
     "iopub.status.busy": "2022-02-24T03:14:34.240923Z",
     "iopub.status.idle": "2022-02-24T03:14:34.248121Z",
     "shell.execute_reply": "2022-02-24T03:14:34.24717Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.24121Z"
    },
    "id": "YMyY91OecCgZ",
    "papermill": {
     "duration": 0.124943,
     "end_time": "2022-02-18T03:58:41.375728",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.250785",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, df_, y_pred_test_prob_, y_pred_test_subm_, score_, \n",
    "                    seed_, level_='1', target_='target', cutoff_value_=.6, save_submission_=True, \n",
    "                    save_predictions_=True):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_) + '.pkl.z'   \n",
    "        \n",
    "        if save_predictions_:\n",
    "            delete_files(model_name_)\n",
    "\n",
    "            jb.dump(df_, path_name_train)\n",
    "            jb.dump(y_pred_test_prob_, path_name_test)\n",
    "            jb.dump(model_, path_name_model)\n",
    "\n",
    "        if save_submission_:\n",
    "            model_name_ = model_name_.format(score_, seed_)\n",
    "            df_submission[target] = y_pred_test_subm_\n",
    "            df_submission.to_csv(path_ + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:19:00.531632Z",
     "start_time": "2022-05-30T23:19:00.518626Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def df_return_preds_stacking(shape_, model_name_=None, path_='', target_='target', level=1): \n",
    "\n",
    "    if level==1: \n",
    "        level_ = 'n1'\n",
    "    else: \n",
    "        if level==2:\n",
    "            level_ = 'n2'\n",
    "        else: \n",
    "            level_ = 'n3'\n",
    "\n",
    "    paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n",
    "\n",
    "    if model_name_==None: \n",
    "        model_name_=''\n",
    "\n",
    "    for i, p in enumerate(paths): \n",
    "\n",
    "        p = path_ + p \n",
    "\n",
    "        name_file_pkl     = glob.glob(p + '/'+ model_name_ + '*.pkl.z')\n",
    "        dic_preds_mdl_pkl = dict()    \n",
    "\n",
    "        for p_name in name_file_pkl:    \n",
    "            y_model_pkl_name_col  = p_name.replace(p + '\\\\', '').replace('.pkl.z','') \n",
    "            #y_model_pkl           = jb.load(p_name)\n",
    "            df_pkl =jb.load(p_name)\n",
    "\n",
    "            \n",
    "            if i==0: \n",
    "                x_proba = df_pkl\n",
    "                dic_preds_mdl_pkl[y_model_pkl_name_col] = x_proba\n",
    "            else: \n",
    "                if shape_==len(df_pkl): \n",
    "                    x_proba = df_pkl['y_proba']        \n",
    "                    dic_preds_mdl_pkl[y_model_pkl_name_col] = x_proba\n",
    "\n",
    "        if i==0:\n",
    "            df_ts = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "        else: \n",
    "            df_tr = pd.DataFrame(dic_preds_mdl_pkl) \n",
    "            df_tr[target_] = df_pkl['y_proba']\n",
    "         \n",
    "    cols_stanking = df_tr.columns.to_list()\n",
    "    cols_stanking.remove(target_)\n",
    "    df_ts = df_ts[cols_stanking]\n",
    "\n",
    "    return df_tr, df_ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T00:37:33.472640Z",
     "start_time": "2022-05-31T00:37:33.423639Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_model(model_, model_name_, X_, y_, X_test_, target_, scalers_, lb_, fold_=5, path_='',  \n",
    "                    seed_=12359, feature_scaler_=None, print_report_=False, save_submission_=False, \n",
    "                    save_predict_=False, level_='1', cutoff_value_save_=.6, print_result_best_=True,\n",
    "                    train_with_created_folds_=False, is_tunning_=False, save_predictions_=False, \n",
    "                    model_type_=1):\n",
    "    \n",
    "    n_estimators = model_.get_params()['n_estimators']\n",
    "             \n",
    "    valid_preds     = {}\n",
    "    taco            = 76 \n",
    "    acc_best        = 0  \n",
    "    df_proba        = pd.DataFrame()\n",
    "    feature_imp     = pd.DataFrame()\n",
    "    test_preds      = []\n",
    "    preds           = []\n",
    "    model           = []\n",
    "    folds           = []\n",
    "    cols_sencond_level = ['fold', 'idx_fold', 'y', 'y_pred', 'y_proba']\n",
    "    \n",
    "    # Recuperar os indices do kf \n",
    "    if train_with_created_folds_:\n",
    "        for i in range(fold_):         \n",
    "            folds.append(jb.load(path + 'model/preds/folds/kf_folds_{}_{}.pkl.z'.format(fold_, i+1)))\n",
    "    else:        \n",
    "        folds = StratifiedKFold(n_splits=fold_, shuffle=True, random_state=seed_)\n",
    "        folds = folds.split(X_, y_, groups=y_)\n",
    "        \n",
    "\n",
    "    for i, scaler_ in enumerate(scalers_): \n",
    "\n",
    "        time_start  = datetime.now()\n",
    "        score       = [] \n",
    "        score_lloss = []\n",
    "                \n",
    "        if scaler_!=None:            \n",
    "            string_scaler = str(scaler_)        \n",
    "            string_scaler = string_scaler[:string_scaler.index('(')]\n",
    "        else:\n",
    "            string_scaler = None \n",
    "            \n",
    "        y_pred_test = np.zeros(len(X_test_))        \n",
    "        \n",
    "        print('='*taco)\n",
    "        print('Scaler: {} - n_estimators: {}'.format(string_scaler, n_estimators))\n",
    "        print('='*taco)\n",
    "        \n",
    "        y_pred_test_prob_oof = 0      \n",
    "        second_level         = np.zeros((X_.shape[0], 5))        \n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds): \n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "            \n",
    "            if train_with_created_folds_:\n",
    "                trn_idx = folds[fold][trn_idx]\n",
    "                val_idx = folds[fold][val_idx]\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Separar dados para treino \n",
    "            # ----------------------------------------------------     \n",
    "            X_trn, X_val = X_.iloc[trn_idx], X_.iloc[val_idx]\n",
    "            y_trn, y_val = y_.iloc[trn_idx], y_.iloc[val_idx] \n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Processamento \n",
    "            # ----------------------------------------------------     \n",
    "            if scaler_!=None: \n",
    "                X_tst = X_test_.copy()\n",
    "                if feature_scaler_!=None:                     \n",
    "                    X_trn[feature_scaler_] = scaler_.fit_transform(X_trn[feature_scaler_])\n",
    "                    X_val[feature_scaler_] = scaler_.transform(X_val[feature_scaler_])                      \n",
    "                    X_tst[feature_scaler_] = scaler_.transform(X_tst[feature_scaler_])\n",
    "                else:            \n",
    "                    X_trn = scaler_.fit_transform(X_trn)\n",
    "                    X_val = scaler_.transform(X_val)\n",
    "                    X_tst = scaler_.transform(X_test_.copy())\n",
    "                \n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------   \n",
    "            #if model_type_==1:\n",
    "            #    model_.fit(X_trn, y_trn,\n",
    "            #               eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "            #               early_stopping_rounds = int(n_estimators*.1),\n",
    "            #               verbose               = False)\n",
    "            #    \n",
    "            #if model_type_==2:                               \n",
    "            model_.fit(X_trn, y_trn,\n",
    "                       eval_set              = [(X_trn, y_trn), (X_val, y_val)], \n",
    "                       eval_names            = ['valid', 'train'],\n",
    "                       early_stopping_rounds = int(n_estimators*.1),\n",
    "                       #callbacks = [early_stopping(30), log_evaluation(period=50)]\n",
    "                       verbose               = False)\n",
    "                \n",
    "                \n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------     \n",
    "            \n",
    "            if model_type_==1:\n",
    "                y_pred_val_prob = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit)[:,1]   \n",
    "                \n",
    "            if model_type_==2: \n",
    "                y_pred_val_prob = model_.predict_proba(X_val)[:,1]\n",
    "                \n",
    "            \n",
    "            y_pred_val      = (y_pred_val_prob>.5).astype(int)\n",
    "\n",
    "            y_pred_test_prob_oof += model_.predict_proba(X_tst)[:, 1] / fold_\n",
    "                        \n",
    "            second_level[val_idx, 0] = fold+1 \n",
    "            second_level[val_idx, 1] = val_idx \n",
    "            second_level[val_idx, 2] = y_val[target_].values\n",
    "            second_level[val_idx, 3] = y_pred_val \n",
    "            second_level[val_idx, 4] = y_pred_val_prob\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ---------------------------------------------------- \n",
    "            acc   = metrics.accuracy_score(y_val, y_pred_val)\n",
    "            auc   = metrics.roc_auc_score(y_val, y_pred_val_prob)\n",
    "            f1    = metrics.f1_score(y_val, y_pred_val) \n",
    "            prec  = metrics.log_loss (y_val, y_pred_val)\n",
    "            \n",
    "            score.append(auc)     \n",
    "            score_lloss.append(prec)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_.columns,\n",
    "                                    data    = model_.feature_importances_,\n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['auc_'+str(fold+1)] = auc\n",
    "            feature_imp = pd.concat([feature_imp, feat_imp], axis=1)\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())\n",
    "            msg = '[Fold {}] AUC: {:2.5f} - F1-score: {:2.5f} - L. Loss: {:2.5f}  - {}'\n",
    "            print(msg.format(fold+1, auc, f1, prec, time_fold_end))\n",
    "            \n",
    "            # ---------------------------------------------------- \n",
    "            # Salvar o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler' : scaler_, \n",
    "                         'fold'   : fold+1, \n",
    "                         'model'  : model_ }\n",
    "            \n",
    "            model.append(dic_model)\n",
    "        \n",
    "        df_proba           = pd.DataFrame(second_level, columns=cols_sencond_level)\n",
    "        df_proba['scaler'] = string_scaler\n",
    "        \n",
    "        for col in ['fold', 'idx_fold', 'y', 'y_pred']:\n",
    "            df_proba[col] = df_proba[col].astype(np.int)\n",
    "        \n",
    "        score_mean     = np.mean(score) \n",
    "        score_std      = np.std(score)\n",
    "        score_llg_mean = np.mean(score_lloss)\n",
    "        \n",
    "        if score_mean > acc_best:     \n",
    "            acc_best    = score_mean           \n",
    "            model_best  = model_    \n",
    "            scaler_best = scaler_\n",
    "\n",
    "        time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        msg ='[Mean Fold] AUC: {:2.5f} std: {:2.5f} - L.Loss {:2.5f} - {}'\n",
    "        \n",
    "        print('-'*taco)        \n",
    "        print(msg.format(score_mean,score_std, score_llg_mean, time_end))\n",
    "        print('='*taco)\n",
    "        print()\n",
    "        \n",
    "        if print_report_:\n",
    "            y_pred = df_proba[df_proba['scaler']==str(string_scaler)]['y_pred']\n",
    "            y_vl   = df_proba[df_proba['scaler']==str(string_scaler)]['y']\n",
    "            print(metrics.classification_report(y_vl, y_pred))\n",
    "                                 \n",
    "        # Salvar as predições           \n",
    "        save_data_model(model_             = model_, \n",
    "                        model_name_        = model_name_+'_score_{:2.5f}_seed_{}_'+str(scaler_).lower()[:4], \n",
    "                        path_              = path_,                             \n",
    "                        df_                = df_proba,       # stacking\n",
    "                        y_pred_test_prob_  = y_pred_test_prob_oof,   # stacking \n",
    "                        y_pred_test_subm_  = y_pred_test_prob_oof,   # sumission \n",
    "                        score_             = score_mean, \n",
    "                        seed_              = seed_, \n",
    "                        level_             = level_, \n",
    "                        target_            = target_, \n",
    "                        cutoff_value_      = cutoff_value_save_, \n",
    "                        save_predictions_  = save_predictions_, \n",
    "                        save_submission_   = save_submission_) \n",
    "     \n",
    "    if print_result_best_:\n",
    "        print('-'*taco)\n",
    "        print('Scaler Best: {}'.format(scaler_best))\n",
    "        print('Score      : {:2.5f}'.format(acc_best))\n",
    "        print('-'*taco)\n",
    "        print()\n",
    "\n",
    "    free_gpu_cache()\n",
    "        \n",
    "    return model, df_proba , feature_imp, score_mean, y_pred_test_prob_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:37:33.816845Z",
     "start_time": "2022-05-30T23:37:33.791880Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.25069Z",
     "iopub.status.busy": "2022-02-24T03:14:34.250432Z",
     "iopub.status.idle": "2022-02-24T03:14:34.283316Z",
     "shell.execute_reply": "2022-02-24T03:14:34.282642Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.250656Z"
    },
    "id": "W-AfEFTYcCga",
    "papermill": {
     "duration": 0.153287,
     "end_time": "2022-02-18T03:58:41.874592",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.721305",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_train_cv_fit(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), \n",
    "                       sc_second_=None, n_splits_=5, seed_=12359, save_sub_=True, \n",
    "                       path_='', save_predict_=False, level_='1'):\n",
    "    \n",
    "    taco              = 52 \n",
    "    y_preds_test      = []\n",
    "    y_preds_val_prob  = [] \n",
    "    y_preds_test_prob = []\n",
    "    score             = []\n",
    "    mdl               = []\n",
    "    lb                = LabelEncoder()\n",
    "    y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n",
    "    col_prob          = y_[target_].sort_values().unique()\n",
    "    df_preds_prob     = pd.DataFrame()\n",
    "    df_feature_imp    = pd.DataFrame()\n",
    "    time_start        = datetime.now()    \n",
    "    n_estimators      = model_.get_params()['n_estimators']\n",
    "    dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''\n",
    "    \n",
    "    print('='*taco)\n",
    "    print('Scaler: {} - n_estimators: {} {}'.format(sc, n_estimators, dub_scaler))\n",
    "    print('='*taco)\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_, groups=y)): \n",
    "        \n",
    "        time_fold_start = datetime.now()\n",
    "        \n",
    "        # ----------------------------------------------------\n",
    "        # Separar dados para treino \n",
    "        # ----------------------------------------------------\n",
    "        X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n",
    "        y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n",
    "                \n",
    "        # ----------------------------------------------------\n",
    "        # Processamento\n",
    "        # ----------------------------------------------------        \n",
    "        X_trn.drop('sample_weight', axis=1, inplace=True)\n",
    "        X_val.drop('sample_weight', axis=1, inplace=True)\n",
    "        \n",
    "        X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "        X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n",
    "        X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "        if sc_second_ is not None: \n",
    "            X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "            X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n",
    "            X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n",
    "                        \n",
    "        # ---------------------------------------------------- \n",
    "        # Treinar o modelo \n",
    "        # ----------------------------------------------------     \n",
    "        model_.fit(X_trn, \n",
    "                   y_trn,\n",
    "                   sample_weight_train,\n",
    "                   eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                   early_stopping_rounds = int(n_estimators*.1),\n",
    "                   verbose               = False)\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Predição \n",
    "        # ----------------------------------------------------     \n",
    "        #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n",
    "        y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n",
    "        y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n",
    "        \n",
    "        y_pred_val_prob += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])         \n",
    "        y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n",
    "        \n",
    "        y_preds_test.append(model_.predict(X_tst))\n",
    "        y_preds_test_prob.append(y_pred_test_prob)\n",
    "       \n",
    "        df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n",
    "        y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "        df_prob_temp['fold']    = fold+1\n",
    "        df_prob_temp['id']      = val_idx        \n",
    "        df_prob_temp['y_val']   = y_val.values        \n",
    "        df_prob_temp['y_pred']  = y_pred_val\n",
    "        df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n",
    "                \n",
    "        df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n",
    "        \n",
    "        # ---------------------------------------------------- \n",
    "        # Score \n",
    "        # ---------------------------------------------------- \n",
    "        acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n",
    "        score.append(acc)     \n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Print resultado  \n",
    "        # ---------------------------------------------------- \n",
    "        time_fold_end = diff(time_fold_start, datetime.now())        \n",
    "        msg = '[Fold {}] ACC: {:2.5f} -  {}'\n",
    "        print(msg.format(fold+1, acc, time_fold_end))\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Feature Importance\n",
    "        # ----------------------------------------------------             \n",
    "        feat_imp = pd.DataFrame(index   = X_trn.columns,\n",
    "                                data    = model_.feature_importances_,                            \n",
    "                                columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "        feat_imp['acc_'+str(fold+1)] = acc\n",
    "        df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n",
    "\n",
    "        # ---------------------------------------------------- \n",
    "        # Salvar o modelo \n",
    "        # ---------------------------------------------------- \n",
    "        dic_model = {'scaler': sc, 'scaler_second': sc_second_,'fold': fold+1,'model': model_}\n",
    "        mdl.append(dic_model)\n",
    "\n",
    "        time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "    acc_mean = np.mean(score) \n",
    "    acc_std  = np.std(score)\n",
    "\n",
    "    df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Pós-processamento\n",
    "    # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n",
    "    # -------------------------------        \n",
    "    y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n",
    "    y_proba += np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0])  \n",
    "    \n",
    "    y_pred_tuned      = lb.inverse_transform(np.argmax(y_proba, axis=1))\n",
    "    y_pred_tuned_prob = np.max(y_proba, axis=1)\n",
    "\n",
    "    if save_predict_:                 \n",
    "        save_data_model(model_             = mdl, \n",
    "                        model_name_        = model_name_ +'_'+str(sc_second_).lower()[:4], \n",
    "                        path_              = path_, \n",
    "                        y_pred_train_prob_ = df_preds_prob['y_proba'], \n",
    "                        y_pred_test_prob_  = y_pred_tuned_prob, \n",
    "                        y_pred_test_       = y_pred_tuned,\n",
    "                        score_             = acc_mean, \n",
    "                        seed_              = seed_, \n",
    "                        level_             = level_, \n",
    "                        target_            = target_\n",
    "                        ) \n",
    "\n",
    "    print('-'*taco)\n",
    "    print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n",
    "    print('='*taco)\n",
    "    print()\n",
    "\n",
    "    if save_sub_:         \n",
    "        df_submission[target_] = y_pred_tuned        \n",
    "        name_file_sub          = model_name_ +'_'+str(sc_second_).lower()[:4]+'.csv'\n",
    "        df_submission.to_csv(path_+'Data/submission/'+name_file_sub.format(acc_mean), index=False)\n",
    "        \n",
    "    del X_trn, X_val, y_trn, y_val, feat_imp\n",
    "\n",
    "    return mdl, df_feature_imp, df_feature_imp , df_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:37:34.269107Z",
     "start_time": "2022-05-30T23:37:34.245940Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:34.285293Z",
     "iopub.status.busy": "2022-02-24T03:14:34.285048Z",
     "iopub.status.idle": "2022-02-24T03:14:34.298854Z",
     "shell.execute_reply": "2022-02-24T03:14:34.298054Z",
     "shell.execute_reply.started": "2022-02-24T03:14:34.28526Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_graf(mdl_, df_fe_imp_, eval_metric_ ):\n",
    "\n",
    "    for erro in eval_metric_:\n",
    "        plt.figure(figsize=(20,15))\n",
    "        for m in range(len(mdl_)):\n",
    "            row = int(len(mdl_[m])/3 + 1)\n",
    "            for fold in range(len(mdl_[m])): \n",
    "                results     = mdl_[m][fold]['model'].evals_result() # merror\n",
    "                ntree_limit = mdl_[m][fold]['model'].best_ntree_limit\n",
    "                plt.subplot(row,3,fold+1)\n",
    "                plt.plot(results[\"validation_0\"][erro], label=\"Treinamento\")\n",
    "                plt.plot(results[\"validation_1\"][erro], label=\"Validação\")\n",
    "\n",
    "                plt.axvline(ntree_limit, \n",
    "                            color=\"gray\", \n",
    "                            label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "\n",
    "                plt.xlabel(\"Número de árvores\")\n",
    "                plt.ylabel(erro)\n",
    "                plt.legend();           \n",
    "\n",
    "            plt.suptitle('Performance XGB - {}'.format(erro), y=1.05, fontsize=24);\n",
    "            plt.tight_layout(h_pad=3.0); \n",
    "\n",
    "    for i in range(len(df_fe_imp_)):\n",
    "        plt.figure(figsize=(20,15))\n",
    "        row = int(np.round(df_fe_imp_[i].filter(regex=r'fold').shape[1] / 3 +1))\n",
    "        for fold, col in enumerate(df_fe_imp_[i].filter(regex=r'fold').columns):            \n",
    "            col_acc = 'acc_' + str(fold+1)\n",
    "            df_fi = df_fe_imp_[i].sort_values(by=col, ascending=False).reset_index().iloc[:25]\n",
    "            df_fi = df_fi[['index', col, col_acc]]\n",
    "            df_fi.columns = ['Feature', 'score', col_acc]\n",
    "            plt.subplot(row,3, fold+1)\n",
    "            sns.barplot(x='score', y='Feature', data=df_fi)    \n",
    "            plt.title('Fold {} - score: {:2.5f}'.format(fold+1, df_fi[col_acc].mean()), \n",
    "                      fontdict={'fontsize':18})    \n",
    "\n",
    "        plt.suptitle('Feature Importance XGB - {}'.format(scaler_list[i]), y=1.05, fontsize=24);\n",
    "        plt.tight_layout(h_pad=3.0); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CiKMmrgcCgc",
    "papermill": {
     "duration": 0.065734,
     "end_time": "2022-02-18T03:58:42.006011",
     "exception": false,
     "start_time": "2022-02-18T03:58:41.940277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2. Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T23:53:46.044099Z",
     "start_time": "2022-05-30T23:53:45.879498Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:35.130655Z",
     "iopub.status.busy": "2022-02-24T03:14:35.130368Z",
     "iopub.status.idle": "2022-02-24T03:14:35.320002Z",
     "shell.execute_reply": "2022-02-24T03:14:35.319156Z",
     "shell.execute_reply.started": "2022-02-24T03:14:35.130619Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1645133019991,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "GjKxi26LcCgc",
    "outputId": "e7d089e2-269d-41f0-c95d-66b740d7ba51",
    "papermill": {
     "duration": 0.301276,
     "end_time": "2022-02-18T03:58:42.372598",
     "exception": false,
     "start_time": "2022-02-18T03:58:42.071322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_drop_cor = ['fe_27_sum', 'fe_27_count_zero', 'fe_27_count_unique']\n",
    "\n",
    "df3_train = df3_train.drop(feature_drop_cor, axis=1).copy()\n",
    "df3_test  = df3_test.drop(feature_drop_cor, axis=1).copy()\n",
    "\n",
    "X      = df3_train.drop(target, axis=1).copy()\n",
    "y      = pd.DataFrame(df3_train[target], columns=[target])\n",
    "X_test = df3_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> \n",
    "    \n",
    "Vamos fazer um modelo com as variáveis originais, para termos uma noção do efeito das novas variáveis, neste primeiro momento defini os parametros manualmente.\n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.216620Z",
     "start_time": "2022-05-31T01:20:25.069484Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:14:36.883713Z",
     "iopub.status.busy": "2022-02-24T03:14:36.883044Z",
     "iopub.status.idle": "2022-02-24T03:24:26.923497Z",
     "shell.execute_reply": "2022-02-24T03:24:26.922874Z",
     "shell.execute_reply.started": "2022-02-24T03:14:36.883672Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Scaler: QuantileTransformer - n_estimators: 5000\n",
      "============================================================================\n",
      "[Fold 1] AUC: 0.99056 - F1-score: 0.94781 - L. Loss: 1.74787  - 0h 22m 43s\n",
      "[Fold 2] AUC: 0.99015 - F1-score: 0.94741 - L. Loss: 1.76111  - 0h 21m 32s\n",
      "[Fold 3] AUC: 0.99021 - F1-score: 0.94751 - L. Loss: 1.75843  - 0h 21m 32s\n",
      "[Fold 4] AUC: 0.99039 - F1-score: 0.94775 - L. Loss: 1.74883  - 0h 20m 13s\n",
      "[Fold 5] AUC: 0.99060 - F1-score: 0.94873 - L. Loss: 1.71967  - 0h 17m 50s\n",
      "----------------------------------------------------------------------------\n",
      "[Mean Fold] AUC: 0.99038 std: 0.00018 - L.Loss 1.74718 - 1h 43m 52s\n",
      "============================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95    462161\n",
      "           1       0.95      0.94      0.95    437839\n",
      "\n",
      "    accuracy                           0.95    900000\n",
      "   macro avg       0.95      0.95      0.95    900000\n",
      "weighted avg       0.95      0.95      0.95    900000\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Scaler Best: QuantileTransformer(output_distribution='normal', random_state=0)\n",
      "Score      : 0.99038\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "CPU times: total: 11h 11min 48s\n",
      "Wall time: 1h 43min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "seed        = 12359\n",
    "eval_metric = ['auc', 'error'] # 'mlogloss'\n",
    "scalers     = [QuantileTransformer(output_distribution='normal', random_state=0)]\n",
    "\n",
    "params = {'objective'     : 'binary', \n",
    "          'metric'        : eval_metric,\n",
    "          'n_estimators'  : 5000,\n",
    "          'num_leaves'    : 150,\n",
    "          #'max_bins'      : 254,         \n",
    "          'boosting_type' : 'gbdt',          \n",
    "          'random_state'  : seed,\n",
    "          'n_jobs'        : -1}\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():           \n",
    "    params.update({'device' : 'gpu'})\n",
    "\n",
    "model_name = 'lgbm_tuni_01_cv_kfold_5'\n",
    "\n",
    "delete_files(model_name)\n",
    "\n",
    "model, df_proba, feature_imp, score, y_pred_test_prob_oof = \\\n",
    "    cross_val_model(model_                    = lgb.LGBMClassifier(**params),\n",
    "                    model_name_               = model_name,\n",
    "                    X_                        = X,\n",
    "                    y_                        = y,\n",
    "                    X_test_                   = X_test,\n",
    "                    target_                   = target,\n",
    "                    scalers_                  = scalers,\n",
    "                    fold_                     = 5,  \n",
    "                    lb_                       = None,\n",
    "                    path_                     = path,\n",
    "                    seed_                     = seed, \n",
    "                    feature_scaler_           = None, \n",
    "                    print_report_             = True, \n",
    "                    save_submission_          = True,#  \n",
    "                    cutoff_value_save_        = .6, \n",
    "                    train_with_created_folds_ = True, \n",
    "                    model_type_               = 2)\n",
    "\n",
    "print()\n",
    "\n",
    "# AUC: 0.98914 std: 0.00010 - L.Loss 1.87521 - 0h 11m 51s  => 0.99075\n",
    "# AUC: 0.98955 std: 0.00014 - L.Loss 1.82800 - 0h 11m 53s\n",
    "# AUC: 0.98970 std: 0.00021 - L.Loss 1.81826 - 0h 20m 13s\n",
    "# AUC: 0.99001 std: 0.00017 - L.Loss 1.78529 - 0h 35m 54s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p><br>\n",
    "\n",
    "Obtivemos na submissão o score de 0.99092, como podemos observar o nosso modelo tem uma performance boa. \n",
    "   \n",
    "\n",
    "       \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQ6DBwBLi34z",
    "papermill": {
     "duration": 0.139742,
     "end_time": "2022-02-18T04:09:03.133617",
     "exception": false,
     "start_time": "2022-02-18T04:09:02.993875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 2.  TUNNING </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cJfauA3i34z",
    "papermill": {
     "duration": 0.123981,
     "end_time": "2022-02-18T04:09:03.381493",
     "exception": false,
     "start_time": "2022-02-18T04:09:03.257512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.1. Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.390637Z",
     "start_time": "2022-05-31T03:04:21.219591Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:02.313374Z",
     "iopub.status.busy": "2022-02-24T03:35:02.313114Z",
     "iopub.status.idle": "2022-02-24T03:35:03.653393Z",
     "shell.execute_reply": "2022-02-24T03:35:03.652687Z",
     "shell.execute_reply.started": "2022-02-24T03:35:02.313338Z"
    },
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1645133076007,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "DvwbgoMAi340",
    "outputId": "a9f3eece-c8f7-4182-eae5-6b98e582100a",
    "papermill": {
     "duration": 1.034451,
     "end_time": "2022-02-18T04:09:04.539516",
     "exception": false,
     "start_time": "2022-02-18T04:09:03.505065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X      = df3_train.drop(target, axis=1).copy()\n",
    "y      = pd.DataFrame(df3_train[target], columns=[target])\n",
    "X_test = df3_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l1vmUmRi340",
    "papermill": {
     "duration": 0.075,
     "end_time": "2022-02-18T04:09:04.689659",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.614659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2. Classe Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.406581Z",
     "start_time": "2022-05-31T03:04:21.392582Z"
    },
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:03.655611Z",
     "iopub.status.busy": "2022-02-24T03:35:03.655249Z",
     "iopub.status.idle": "2022-02-24T03:35:03.663159Z",
     "shell.execute_reply": "2022-02-24T03:35:03.662486Z",
     "shell.execute_reply.started": "2022-02-24T03:35:03.655568Z"
    },
    "id": "Yhn5ylJScCgh",
    "papermill": {
     "duration": 0.084857,
     "end_time": "2022-02-18T04:09:04.849798",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.764941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LastPlacePruner(BasePruner):\n",
    "    # https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/006_user_defined_pruner.html#sphx-glr-tutorial-20-recipes-006-user-defined-pruner-py    \n",
    "    def __init__(self, warmup_steps, warmup_trials):\n",
    "        self._warmup_steps = warmup_steps\n",
    "        self._warmup_trials = warmup_trials\n",
    "\n",
    "    def prune(self, study: \"optuna.study.Study\", trial: \"optuna.trial.FrozenTrial\") -> bool:\n",
    "        # Obtenha a pontuação mais recente relatada neste teste\n",
    "        step = trial.last_step\n",
    "\n",
    "        if step:  # trial.last_step == None when no scores have been reported yet\n",
    "            this_score = trial.intermediate_values[step]\n",
    "\n",
    "            # Get scores from other trials in the study reported at the same step\n",
    "            completed_trials = study.get_trials(deepcopy=False, states=(TrialState.COMPLETE,))\n",
    "            other_scores = [\n",
    "                t.intermediate_values[step]\n",
    "                for t in completed_trials\n",
    "                if step in t.intermediate_values\n",
    "            ]\n",
    "            other_scores = sorted(other_scores)\n",
    "\n",
    "            # Prune if this trial at this step has a lower value than all completed trials\n",
    "            # at the same step. Note that steps will begin numbering at 0 in the objective\n",
    "            # function definition below.\n",
    "            if step >= self._warmup_steps and len(other_scores) > self._warmup_trials:\n",
    "                if this_score < other_scores[0]:\n",
    "                    #print(f\"prune() True: Trial {trial.number}, Step {step}, Score {this_score}\")\n",
    "                    return True\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T11:20:26.711749Z",
     "start_time": "2022-05-31T11:20:26.589973Z"
    },
    "code_folding": [
     31,
     67,
     84,
     90,
     135,
     156,
     181,
     208,
     291,
     368,
     391,
     396,
     408,
     607,
     782
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T03:35:03.665535Z",
     "iopub.status.busy": "2022-02-24T03:35:03.665074Z",
     "iopub.status.idle": "2022-02-24T03:35:04.006017Z",
     "shell.execute_reply": "2022-02-24T03:35:04.005101Z",
     "shell.execute_reply.started": "2022-02-24T03:35:03.665497Z"
    },
    "id": "LpYUOrRpi340",
    "papermill": {
     "duration": 0.357889,
     "end_time": "2022-02-18T04:09:05.282578",
     "exception": false,
     "start_time": "2022-02-18T04:09:04.924689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TunningModels(nn.Module):\n",
    "\n",
    "    from sklearn.preprocessing  import StandardScaler\n",
    "    from sklearn.linear_model   import RidgeClassifier\n",
    "    \n",
    "    def __init__(self, name_model_, X_trn_, y_trn_, X_ts_, feature_=None, \n",
    "                 seed_=12359, scaler_=StandardScaler(), feature_bin_=None, \n",
    "                 target_='target', path_='', level_='1', sc_second_= None, \n",
    "                 n_splits_=5, created_folds_=True, save_submission_=True, \n",
    "                 model_type_=1, save_predictions_=True):\n",
    "        \n",
    "        super(TunningModels,self).__init__() \n",
    "\n",
    "        self.name_clf        = name_model + '_' + str(np.random.rand(1)[0]).replace('.','')\n",
    "        self.X_trn           = X_trn_\n",
    "        self.y_trn           = y_trn_\n",
    "        self.X_ts            = X_ts_         \n",
    "        self.feature         = feature_\n",
    "        self.seed            = seed_\n",
    "        self.scaler          = scaler_\n",
    "        self.feature_bin     = feature_bin_ \n",
    "        self.target          = target_\n",
    "        self.path            = path_\n",
    "        self.level           = level_\n",
    "        self.sc_second       = sc_second_\n",
    "        self.n_splits        = n_splits_\n",
    "        self.created_folds   = created_folds_ \n",
    "        self.save_submission = save_submission_\n",
    "        self.save_predictions= save_predictions_\n",
    "        self.model_type      = model_type_\n",
    "\n",
    "    def recover_prediction_first_level():\n",
    "        \n",
    "        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n",
    "        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n",
    "        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n",
    "\n",
    "        df_train1     = []\n",
    "        scores_traint = dict()\n",
    "\n",
    "        for p_name in preds_train1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n",
    "            df_train1.append(p_df)    \n",
    "            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n",
    "\n",
    "        df_val1     = [] \n",
    "        scores_val1 = dict()\n",
    "        for p_name in preds_val1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n",
    "            df_val1.append(p_df)    \n",
    "            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n",
    "\n",
    "        df_test     = [] \n",
    "        scores_test = dict()\n",
    "        for p_name in preds_test:    \n",
    "            p         = jb.load(p_name)\n",
    "            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n",
    "            df_test.append(p_df_test)\n",
    "\n",
    "        df_train1 = pd.concat(df_train1, axis=1)\n",
    "        df_val1   = pd.concat(df_val1, axis=1)\n",
    "        df_test   = pd.concat(df_test, axis=1)\n",
    "\n",
    "        return df_train1, df_val1, df_test.shape\n",
    "        \n",
    "    def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))\n",
    " \n",
    "    def logging_callback(study, frozen_trail):\n",
    "        prev_best = study.user_attrs.get('prev_best', None)\n",
    "        if prev_best != study.best_value:\n",
    "            study.set_user_attr('prev_best', study.best_value)\n",
    "            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n",
    "\n",
    "    def df_return_preds_tunning(model_name=None, level=1, target_='target', train_shape_row=0, test_shape_row=0): \n",
    "\n",
    "        if level==1: \n",
    "            level_ = 'n1'\n",
    "        else: \n",
    "            if level==2:\n",
    "                level_ = 'n2'\n",
    "            else: \n",
    "                level_ = 'n3'\n",
    "\n",
    "        paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n",
    "\n",
    "        if model_name==None: \n",
    "            model_name=''\n",
    "\n",
    "        for i, path in enumerate(paths): \n",
    "\n",
    "            name_file_pkl     = glob.glob(path + '/'+ model_name + '*.pkl.z')\n",
    "            dic_preds_mdl_pkl = dict()\n",
    "\n",
    "            for p_name in name_file_pkl:    \n",
    "                y_model_pkl_name_col  = p_name.replace(path + '/', '').replace('.pkl.z','') \n",
    "                y_model_pkl           = jb.load(p_name)   \n",
    "\n",
    "                if i==0:\n",
    "                    if len(y_model_pkl)==test_shape_row:\n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                if i==1:\n",
    "                    if len(y_model_pkl)==train_shape_row:                        \n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            if i==0:         \n",
    "                X_test_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "            else:\n",
    "                X_train_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        X_train_pred_nivel_1[target_] = y\n",
    "\n",
    "        return X_train_pred_nivel_1, X_test_pred_nivel_1\n",
    "\n",
    "    def feature_select(mdl, feature=[], best_score=0):\n",
    "    \n",
    "        best_feature = ''\n",
    "\n",
    "        for col in df_train1.columns:\n",
    "\n",
    "            if col not in feature:\n",
    "                Xtr  = df_train1[feature+[col]].copy()\n",
    "                Xval = df_val1[feature+[col]].copy()                \n",
    "\n",
    "                mdl.fit(Xtr, y_train1)\n",
    "\n",
    "                p = mdl.predict(Xval)\n",
    "                c = f1_score(y_val1, p)\n",
    "\n",
    "                if c > best_score:\n",
    "                    best_score = c\n",
    "                    best_feature = col \n",
    "\n",
    "        return best_score, best_feature\n",
    "\n",
    "    def permutation_test(mdl, feature_selected):\n",
    "\n",
    "        dist = []\n",
    "\n",
    "        for seed in range(100):\n",
    "\n",
    "            Xtr  = df_train1[feature_selected].copy()\n",
    "            Xval = df_val1[feature_selected].copy()\n",
    "\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            Xtr['random']  = np.random.permutation(Xtr.iloc[:, -1].values)\n",
    "            Xval['random'] = np.random.permutation(Xval.iloc[:, -1].values)\n",
    "\n",
    "            mdl.fit(Xtr, y_train1)\n",
    "\n",
    "            p = mdl.predict(Xval)\n",
    "            c = f1_score(y_val1, p)\n",
    "\n",
    "            dist.append(c)\n",
    "\n",
    "        dist = np.array(dist)\n",
    "\n",
    "        return dist.max()\n",
    "\n",
    "    def feature_selected_model(model = RidgeClassifier(alpha=1.) ):\n",
    "   \n",
    "        score_feature, best_feature =  TunningModels.feature_select(model)\n",
    "        print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        feature_selected = []\n",
    "        feature_selected.append(best_feature)\n",
    "\n",
    "        loop = True\n",
    "\n",
    "        while loop:\n",
    "\n",
    "            best_score = TunningModels.permutation_test(model, feature_selected) \n",
    "            best_score = best_score + 1e-4\n",
    "\n",
    "            score_feature, best_feature = TunningModels.feature_select(model, feature=feature_selected, best_score=best_score)\n",
    "            \n",
    "\n",
    "            if score_feature <= best_score:  \n",
    "                print('Fim')\n",
    "                loop= False\n",
    "            else: \n",
    "                feature_selected.append(best_feature)\n",
    "                print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        return feature_selected\n",
    "    \n",
    "    def model_of_diversity_feature_group(model_, name_model, X_, y_, X_ts_, sc_, target_, feature_imp_num=5, \n",
    "                                         seed_=12359, path_=''):\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        cols_tr = X_.columns.to_list() \n",
    "        cols_ts = cols_tr.copy()\n",
    "        cols_ts.remove('sample_weight')\n",
    "\n",
    "        model = model_\n",
    "        model = model.fit(X_[cols_ts], y_)\n",
    "\n",
    "        df               = pd.DataFrame()\n",
    "        df[\"feature\"]    = cols_ts\n",
    "        df[\"importance\"] = model.feature_importances_\n",
    "\n",
    "        df.sort_values(\"importance\", axis=0, ascending=False, inplace=True)\n",
    "\n",
    "        feature_import = df[:feature_imp_num]['feature'].to_list()\n",
    "\n",
    "        for feature_imp in  feature_import:\n",
    "\n",
    "            score_                =  0.09\n",
    "            feature_best          = []\n",
    "            feature               = X_ts_.columns            \n",
    "            feature               = [s for s in feature if s not in feature_import]\n",
    "            feature_number        = len(feature)\n",
    "            feature_select_number = np.round(np.sqrt(len(feature)))\n",
    "            feature_number_sample = int(np.round((feature_number/feature_select_number)))\n",
    "            feature_sample        = []\n",
    "\n",
    "            print('='*60)\n",
    "            print(' Divercidade de Grupos de Features => ({})'.format(feature_imp))\n",
    "            print('='*60)\n",
    "\n",
    "\n",
    "            for i in  range(0,5):\n",
    "\n",
    "                feature            = [s for s in feature if s not in feature_sample]\n",
    "                feature_sample     = pd.Series(feature).sample(feature_number_sample).to_list() \n",
    "                name_model_xgb_div = name_model + 'group_fe_' + str(i)   \n",
    "\n",
    "                feature_sample.append(feature_imp)\n",
    "                feature_sample_ts = feature_sample.copy()\n",
    "\n",
    "                feature_sample.append('sample_weight')\n",
    "\n",
    "                model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "                TunningModels.train_model_cv(model_         = model_, \n",
    "                                             X_             = X_[feature_sample], \n",
    "                                             y_             = y_, \n",
    "                                             X_test_        = X_ts_[feature_sample_ts], \n",
    "                                             target_        = target_, \n",
    "                                             model_name_    = name_model_xgb_div, \n",
    "                                             sc_            = sc_, \n",
    "                                             sc_second_     = None, \n",
    "                                             n_splits_      = 3, \n",
    "                                             seed_          = seed_,\n",
    "                                             path_          = path_, \n",
    "                                             save_predict_  = True, \n",
    "                                             level_         = '1', \n",
    "                                             print_result_  = False, \n",
    "                                             feature_       = None, \n",
    "                                             trial_         = None)\n",
    "\n",
    "                if score >.59:\n",
    "                    create = '*'\n",
    "                else: \n",
    "                    create = ' '\n",
    "\n",
    "                if score > score_:\n",
    "                    # score_ = np.abs(score)\n",
    "                    feature_best.append(feature)\n",
    "                    print('Score: {:2.5f} =>{} Gr.Feature: {} {}'.format(score, create, i,''))\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            print('')\n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "\n",
    "    def model_of_diversity_feature_one_(model, name_model, seed_=12359):\n",
    "\n",
    "        score_       =  0.09\n",
    "        feature_best = []\n",
    "\n",
    "        print('')\n",
    "        print('Feature apenas uma')\n",
    "        print('-'*20)\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        for feature in X_train.columns:\n",
    "\n",
    "            name_model_xgb_div = name_model + feature \n",
    "\n",
    "            score = TunningModels.cross_valid(model       = model, \n",
    "                                              model_name_ = name_model_xgb_div, \n",
    "                                              X_          = X, \n",
    "                                              y_          = y, \n",
    "                                              X_test_     = X_test_sc_qt, \n",
    "                                              type_model  = 2, \n",
    "                                              feature     = feature,\n",
    "                                              seed        = seed_, \n",
    "                                              tunning     = 1, \n",
    "                                              print_result= False, \n",
    "                                              n_splits    = 2\n",
    "                                              )\n",
    "            if score >.59:\n",
    "                create = '*'\n",
    "            else: \n",
    "                create = ' '\n",
    "\n",
    "            if score > score_:\n",
    "                score_ = np.abs(score)\n",
    "                feature_best.append(feature)\n",
    "                print('F1-score: {:2.5f} => {} feature: {}'.format(score, create, feature ))        \n",
    "\n",
    "        print('')\n",
    "        print('Feature dupla')\n",
    "        print('-'*20)\n",
    "\n",
    "        for feature in feature_best:\n",
    "\n",
    "            for feature_ in feature_best:\n",
    "                if feature != feature_:            \n",
    "                    name_model_xgb_div = name_model + feature + '_' + feature_     \n",
    "\n",
    "                    score = TunningModels.cross_valid(model       = model, \n",
    "                                                      model_name_ = name_model_xgb_div, \n",
    "                                                      X_          = X, \n",
    "                                                      y_          = y, \n",
    "                                                      X_test_     = X_test_sc_qt, \n",
    "                                                      type_model  = 2, \n",
    "                                                      feature     = [feature, feature_],\n",
    "                                                      seed        = seed_, \n",
    "                                                      tunning     = 1, \n",
    "                                                      print_result= False, \n",
    "                                                      n_splits    = 2\n",
    "                                                      )\n",
    "\n",
    "                    if score >.59:\n",
    "                        create = '*'\n",
    "                    else: \n",
    "                        create = ' '\n",
    "\n",
    "                    print('F1-score: {:.4f} => {} feature: {} | {}'.format(score*100, create,  feature, feature_ )) \n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "    \n",
    "\n",
    "\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_,\n",
    "                        y_pred_test_, score_, seed_, level_='1', target_='target'):\n",
    "        \n",
    "        level_ = 'n'+ level_ + '/'\n",
    "\n",
    "        if score_>.6:          \n",
    "\n",
    "            path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_)\n",
    "            path_name_train = path_ + 'model/preds/train/' + level_ + model_name_.format(score_, seed_)\n",
    "            path_name_test  = path_ + 'model/preds/test/'  + level_ + model_name_.format(score_, seed_)    \n",
    "            path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)    \n",
    "\n",
    "            jb.dump(y_pred_train_prob_, path_name_train)\n",
    "            jb.dump(y_pred_test_prob_, path_name_test)\n",
    "            jb.dump(model_, path_name_model)\n",
    "            #jb.dump(pd.DataFrame([model_[0][0]['model'].get_params()]), path_name_param)   \n",
    "\n",
    "            if score_>.7:                \n",
    "                # Gerar o arquivo de submissão \n",
    "                df_submission[target_] = y_pred_test_\n",
    "                name_file_sub =  path_ + 'Data/submission/tunning/' + model_name_.format(score_, seed_) + '.csv'\n",
    "                df_submission.to_csv(name_file_sub, index = False)\n",
    "                \n",
    "    def diff(t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def feature_scaler(df_, scaler_=None, feature_bin_=None):\n",
    "    \n",
    "        if scaler_!=None: \n",
    "            \n",
    "            #if feature_bin_!=None:\n",
    "            #    disc = KBinsDiscretizer(n_bins=50, encode='ordinal', strategy='uniform')\n",
    "            #    df_[feature_bin_] = disc.fit_transform(df_[feature_bin_])\n",
    "\n",
    "            df_ = pd.DataFrame(scaler_.fit_transform(df_), columns=df_.columns)\n",
    "    \n",
    "        return df_\n",
    "\n",
    "    def cross_valid(model_, model_name_, X_train_, y_train_, X_test_, fold_=5, target_='target', \n",
    "            path_='', level_='1', save_predict_=True, print_result_=True, seed_=12359, \n",
    "            feature_=None, feature_bin=None, scaler_=StandardScaler(), threshold=.5, print_report_=False \n",
    "            ):\n",
    "\n",
    "        if feature_!=None: \n",
    "            X_train_ = X_train_[feature_]\n",
    "            X_test_  = X_test_[feature_]\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Escorpo de variáveis\n",
    "        #--------------------------------------------------------\n",
    "\n",
    "        time_pred_start    = datetime.now()\n",
    "        preds_valid_f      = {}\n",
    "        preds_test         = []\n",
    "        total_auc          = []\n",
    "        f_scores           = []\n",
    "        auc_mean           = []\n",
    "        f1_mean            = []\n",
    "        lloss_mean         = []\n",
    "        preds_test         = 0  \n",
    "        pred_test_prob     = 0\n",
    "        df_score_history   = pd.DataFrame()\n",
    "        df_train_pred_fold = pd.DataFrame()\n",
    "        df_pred_fold       = pd.DataFrame()\n",
    "        random             = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_        = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'\n",
    "        clf_name           = model_.__class__.__name__\n",
    "        pri_result         = 92\n",
    "        learning_rate      = model_.learning_rate         \n",
    "        le                 = LabelEncoder()\n",
    "        y_train_           = pd.DataFrame(le.fit_transform(y_train_), columns=[target_])\n",
    "                                                   \n",
    "        #--------------------------------------------------------  \n",
    "        # Início do process de varilidação\n",
    "        #--------------------------------------------------------\n",
    "        have_observation=''\n",
    "\n",
    "        if print_result_:\n",
    "            num_parallel_tree = 1 #model_.get_params()['num_parallel_tree']\n",
    "            learning_rate     = model_.learning_rate\n",
    "            n_estimators      = model_.n_estimators * num_parallel_tree  \n",
    "            max_depth         = model_.max_depth \n",
    "            msg               = 'Training model: {} - seed {} - n_estimators: {} - learning_rate: {} {:2.5f}'\n",
    "\n",
    "            print('='*pri_result)            \n",
    "            print(msg.format(clf_name, seed_, n_estimators, max_depth, learning_rate))\n",
    "            print('='*pri_result)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=fold_, random_state=42, shuffle=True)\n",
    "\n",
    "        for fold,(idx_train, idx_val) in enumerate(kf.split(X_train_, y_train_, groups=y_train_)):\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Seleção dos dados\n",
    "            #--------------------------------------------------------\n",
    "            X_trn, X_val = X_train_.iloc[idx_train], X_train_.iloc[idx_val]\n",
    "            y_trn, y_val = y_train_.iloc[idx_train], y_train_.iloc[idx_val]\n",
    "            index_valid  = idx_train\n",
    "\n",
    "             \n",
    "        \n",
    "            #--------------------------------------------------------  \n",
    "            # Processamento\n",
    "            #--------------------------------------------------------        \n",
    "            X_trn = TunningModels.feature_scaler(X_trn, scaler_, feature_bin) \n",
    "            X_val = TunningModels.feature_scaler(X_val, scaler_, feature_bin) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Modelo\n",
    "            #--------------------------------------------------------\n",
    "            model = model_.fit(X_trn, y_trn,\n",
    "                               eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                               early_stopping_rounds = int(n_estimators*.1),\n",
    "                               verbose               = False)\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # oof\n",
    "            #--------------------------------------------------------\n",
    "            preds_valid_proba = model.predict_proba(X_val, ntree_limit=model_.best_ntree_limit)\n",
    "            y_pred_valid      = le.inverse_transform(np.argmax(preds_valid_proba, axis=1))\n",
    "            \n",
    "            #--------------------------------------------------------  \n",
    "            # Obtenha os valores médios de cada fold para a previsão\n",
    "            #--------------------------------------------------------  \n",
    "            y_pred_test_prob = model.predict_proba(X_test_, ntree_limit=model_.best_ntree_limit)\n",
    "            pred_test_prob  += np.max(y_pred_test_prob, axis=1) / fold_\n",
    "            preds_test      += le.inverse_transform(np.argmax(y_pred_test_prob, axis=1)) / fold_\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Métricas \n",
    "            #-------------------------------------------------------- \n",
    "            y_val = le.inverse_transform(y_val)\n",
    "            acc   = metrics.accuracy_score(y_val, y_pred_valid)\n",
    "            f1    = metrics.f1_score(y_val, y_pred_valid, average='weighted')\n",
    "            prec  = metrics.precision_score(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Concatenar validação e predição\n",
    "            #--------------------------------------------------------        \n",
    "            df_val_pred_fold = pd.DataFrame({'fold'     : fold+1,\n",
    "                                             'index'    : idx_val, \n",
    "                                             'acc'      : acc, \n",
    "                                             'f1'       : f1,\n",
    "                                             'prec'     : prec,                                              \n",
    "                                             'target'   : y_val, \n",
    "                                             'y_pred'   : y_pred_valid, \n",
    "                                             'pred_val' : np.max(preds_valid_proba, axis=1)\n",
    "                                             })\n",
    "\n",
    "            df_train_pred_fold = pd.concat([df_train_pred_fold, df_val_pred_fold], axis=0)\n",
    "\n",
    "            col_name        = le.inverse_transform(list(model.classes_))\n",
    "            df_prob_temp    = pd.DataFrame(preds_valid_proba, columns=col_name)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            \n",
    "            df_prob_temp['y_val']     = y_val\n",
    "            df_prob_temp['y_pred']    = y_pred_valid \n",
    "            df_prob_temp['y_proba']   = np.max(preds_valid_proba, axis=1)            \n",
    "            df_prob_temp['acc']       = acc   \n",
    "            df_prob_temp['f1']        = f1 \n",
    "            df_prob_temp['precision'] = prec              \n",
    "            df_prob_temp['fold']      = fold+1\n",
    "            df_prob_temp['index']     = idx_val   \n",
    "            \n",
    "            df_pred_fold = pd.concat([df_pred_fold, df_prob_temp], axis=0)\n",
    "            \n",
    "            del df_prob_temp\n",
    "            \n",
    "            #df_prob_temp['scaler']  = str(string_scaler)\n",
    "            \n",
    "            #preds_valid_proba = np.max(preds_valid_proba, axis=1)\n",
    "            \n",
    "            \n",
    "            auc_mean.append(acc)   \n",
    "            f1_mean.append(f1)    \n",
    "            lloss_mean.append(prec) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Print resultado Fold\n",
    "            #--------------------------------------------------------\n",
    "            if print_result_:\n",
    "                msg = 'Fold: {} - ACC: {:2.5f} - F1-score: {:2.5f} - Precision: {:2.5f} - {}'\n",
    "                time_fold_start_end = TunningModels.diff(time_fold_start, datetime.now())\n",
    "                print(msg.format(fold+1, acc, f1, prec, time_fold_start_end))\n",
    "\n",
    "            free_gpu_cache() \n",
    "        \n",
    "        \n",
    "\n",
    "        del X_trn, y_trn, X_val, y_val \n",
    "\n",
    "        df_train_pred_fold.sort_values(\"index\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Salvar predição em disco\n",
    "        #--------------------------------------------------------\n",
    "        X_train_prob      = df_train_pred_fold['pred_val'].to_list()\n",
    "        score             = np.mean(auc_mean)\n",
    "        y_pred_test       = np.int32(preds_test)\n",
    "\n",
    "        if save_predict_:\n",
    "            TunningModels.save_data_model(model_             = model_, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = X_train_prob, \n",
    "                                          y_pred_test_prob_  = pred_test_prob, \n",
    "                                          y_pred_test_       = y_pred_test,\n",
    "                                          score_             = score, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          )  \n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Print média dos Folds\n",
    "        #--------------------------------------------------------\n",
    "        time_pred_end = TunningModels.diff(time_pred_start, datetime.now())\n",
    "\n",
    "        if print_result_:\n",
    "            msg = '[Mean Fold]  ACC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - Precision: {:.5f}  {}'        \n",
    "            print('-'*pri_result)            \n",
    "            print(msg.format(np.mean(auc_mean),np.std(auc_mean) , np.mean(f1_mean), np.mean(lloss_mean), time_pred_end))\n",
    "            print('='*pri_result)\n",
    "            print()\n",
    "            \n",
    "            if print_report_: \n",
    "                y_pred = df_train_pred_fold['y_pred']\n",
    "                y_vl   = df_train_pred_fold['target']\n",
    "                print(metrics.classification_report(y_vl, y_pred))\n",
    "\n",
    "        free_gpu_cache() \n",
    "\n",
    "        return model, score, y_pred_test, df_pred_fold        \n",
    "    \n",
    "    def train_model_cv(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), sc_second_=None, \n",
    "                       n_splits_=5, seed_=12359, path_='', save_predict_=True, level_='1', \n",
    "                       print_result_=True, feature_=None, trial_=None):\n",
    "            \n",
    "        if feature_!=None: \n",
    "            X_      = X_[feature_]\n",
    "            X_test_ = X_test_[feature_]\n",
    "            \n",
    "        taco              = 52 \n",
    "        y_preds_test      = []\n",
    "        y_preds_val_prob  = [] \n",
    "        y_preds_test_prob = []\n",
    "        score             = []\n",
    "        mdl               = []\n",
    "        random            = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_       = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'    \n",
    "        clf_name          = model_.__class__.__name__        \n",
    "        df_preds_prob     = pd.DataFrame()\n",
    "        df_feature_imp    = pd.DataFrame()\n",
    "        time_start        = datetime.now()    \n",
    "        n_estimators      = model_.get_params()['n_estimators']\n",
    "        dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''        \n",
    "        lb                = LabelEncoder()\n",
    "        y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n",
    "        col_prob          = y_[target_].sort_values().unique()\n",
    "        vies              = np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0]) \n",
    "        \n",
    "        if print_result_:\n",
    "            print('='*taco)\n",
    "            print('{} - n_estimators: {} seed: {}  {}'.format(clf_name, n_estimators, seed_, dub_scaler))\n",
    "            print('='*taco)\n",
    "\n",
    "        folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_)): #, groups=y\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Separar dados para treino \n",
    "            # ----------------------------------------------------\n",
    "            X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n",
    "            y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Processamento\n",
    "            # ----------------------------------------------------        \n",
    "            X_trn.drop('sample_weight', axis=1, inplace=True)\n",
    "            X_val.drop('sample_weight', axis=1, inplace=True)\n",
    "\n",
    "            X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "            X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n",
    "            X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "            if sc_second_ is not None: \n",
    "                X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "                X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n",
    "                X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------     \n",
    "            model_.fit(X_trn, \n",
    "                       y_trn,\n",
    "                       sample_weight_train,\n",
    "                       eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                       early_stopping_rounds = int(n_estimators*.1),\n",
    "                       verbose               = False)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------     \n",
    "            #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n",
    "            y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n",
    "            y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n",
    "\n",
    "            y_pred_val_prob += vies         \n",
    "            y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n",
    "\n",
    "            y_preds_test.append(model_.predict(X_tst))\n",
    "            y_preds_test_prob.append(y_pred_test_prob)\n",
    "\n",
    "            df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            df_prob_temp['fold']    = fold+1\n",
    "            df_prob_temp['id']      = val_idx        \n",
    "            df_prob_temp['y_val']   = y_val.values        \n",
    "            df_prob_temp['y_pred']  = y_pred_val\n",
    "            df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n",
    "\n",
    "            df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ---------------------------------------------------- \n",
    "            acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n",
    "            score.append(acc)     \n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())        \n",
    "            msg = '[Fold {}] ACC: {:2.5f} -  {}'\n",
    "            \n",
    "            if print_result_:\n",
    "                print(msg.format(fold+1, acc, time_fold_end))\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_trn.columns,\n",
    "                                    data    = model_.feature_importances_,                            \n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['acc_'+str(fold+1)] = acc\n",
    "            df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Salva o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler': sc_, \n",
    "                         'scaler_second': sc_second_,\n",
    "                         'fold': fold+1,\n",
    "                         'model': model_,                         \n",
    "                         'vies': vies}\n",
    "\n",
    "            mdl.append(dic_model)\n",
    "            \n",
    "            if trial_ is not None:\n",
    "                trial_.report(acc, fold)\n",
    "                if trial_.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        acc_mean = np.mean(score) \n",
    "        acc_std  = np.std(score)\n",
    "        \n",
    "        df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Pós-processamento\n",
    "        # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n",
    "        # -------------------------------        \n",
    "        y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n",
    "        y_proba += vies          \n",
    "\n",
    "        y_pred_test       = np.argmax(y_proba, axis=1)\n",
    "        y_pred_tuned      = lb.inverse_transform(y_pred_test)\n",
    "        y_pred_tuned_prob = np.max(y_proba, axis=1)\n",
    "\n",
    "        if save_predict_:                 \n",
    "            TunningModels.save_data_model(model_             = mdl, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = df_preds_prob['y_proba'], \n",
    "                                          y_pred_test_prob_  = y_pred_tuned_prob, \n",
    "                                          y_pred_test_       = y_pred_tuned,\n",
    "                                          score_             = acc_mean, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          ) \n",
    "\n",
    "        if print_result_:\n",
    "            print('-'*taco)\n",
    "            print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n",
    "            print('='*taco)\n",
    "            print()\n",
    "\n",
    "        del X_trn, X_val, y_trn, y_val, feat_imp\n",
    "\n",
    "        return mdl, acc_mean , df_feature_imp , df_preds_prob, y_pred_test\n",
    "    \n",
    "    def xgb(self, trial):\n",
    "           \n",
    "        # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "        # https://amangupta16.medium.com/xgboost-hyperparameters-explained-bb6ce580501d     \n",
    "        \n",
    "        eval_metric = ['mlogloss']\n",
    "                \n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['binary:logistic']), \n",
    "                  'eval_metric'       : trial.suggest_categorical('eval_metric', ['auc']), \n",
    "                  'max_depth'         : trial.suggest_int('max_depth', 4, 10),\n",
    "                  'learning_rate'     : trial.suggest_discrete_uniform('learning_rate', 0.2, 0.35, 0.01),\n",
    "                  'n_estimators'      : trial.suggest_int('n_estimators', 900, 3000, 100),\n",
    "                  'sampling_method'   : trial.suggest_categorical('sampling_method', ['gradient_based'])                                                                  \n",
    "                 }                    \n",
    "        \n",
    "        if torch.cuda.is_available():           \n",
    "            params.update({'predictor'  : trial.suggest_categorical('predictor', ['gpu_predictor']), \n",
    "                           'tree_method': trial.suggest_categorical('tree_method', ['gpu_hist']) , \n",
    "                           'gpu_id'     : trial.suggest_int('gpu_id', 0,0)})\n",
    "                \n",
    "        #pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
    "        \n",
    "        mdl = xgb.XGBClassifier(**params) #, callbacks=[pruning_callback])\n",
    "        \n",
    "        #_, score, _, _, _  = TunningModels.train_model_cv(model_        = mdl, \n",
    "        #                                                  X_            = self.X_trn, \n",
    "        #                                                  y_            = self.y_trn, \n",
    "        #                                                  X_test_       = self.X_ts, \n",
    "        #                                                  target_       = self.target, \n",
    "        #                                                  model_name_   = self.name_clf, \n",
    "        #                                                  sc_           = self.scaler, \n",
    "        #                                                  sc_second_    = self.sc_second, \n",
    "        #                                                  feature_      = self.feature,\n",
    "        #                                                  n_splits_     = self.n_splits, \n",
    "        #                                                  seed_         = self.seed,\n",
    "        #                                                  path_         = self.path,\n",
    "        #                                                  level_        = self.level, \n",
    "        #                                                  trial_        = trial\n",
    "        #                                              )\n",
    "        #    \n",
    "        \n",
    "        _, _, _, score, _ = \\\n",
    "            cross_val_model(model_                    = mdl,\n",
    "                            model_name_               = self.name_clf,\n",
    "                            X_                        = self.X_trn,\n",
    "                            y_                        = self.y_trn,\n",
    "                            X_test_                   = self.X_ts,\n",
    "                            target_                   = self.target,\n",
    "                            scalers_                  = self.scaler,\n",
    "                            fold_                     = self.n_splits,  \n",
    "                            lb_                       = None,\n",
    "                            path_                     = self.path,\n",
    "                            seed_                     = self.seed, \n",
    "                            feature_scaler_           = None, \n",
    "                            print_report_             = False, \n",
    "                            save_submission_          = self.save_submission,  \n",
    "                            cutoff_value_save_        = .6, \n",
    "                            train_with_created_folds_ = self.created_folds \n",
    "                           )\n",
    "        \n",
    "        print('param = {}'.format(params))\n",
    "        print()\n",
    "\n",
    "        return score\n",
    "                \n",
    "    def lgbm(self, trial):\n",
    "        # https://neptune.ai/blog/lightgbm-parameters-guide\n",
    "        \n",
    "        # https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n",
    "        # https://buildmedia.readthedocs.org/media/pdf/optuna/stable/optuna.pdf\n",
    "        # https://medium.com/@am.sharma/lgbm-on-colab-with-gpu-c1c09e83f2af\n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['binary']),     \n",
    "                  'metric'            : trial.suggest_categorical('metric', ['auc']),                   \n",
    "                  'boosting_type'     : trial.suggest_categorical('boosting_type', ['gbdt']),  \n",
    "                  'importance_type'   : trial.suggest_categorical('importance_type', ['gain']),  \n",
    "                  'class_weight'      : trial.suggest_categorical('class_weight', ['balanced']),                   \n",
    "                  'learning_rate'     : trial.suggest_float('learning_rate', 0.0095, 0.11),               \n",
    "                  'max_depth'         : trial.suggest_int('max_depth', 2, 8),\n",
    "                  'n_estimators'      : trial.suggest_int('n_estimators', 100, 4000),\n",
    "                  'min_child_samples' : trial.suggest_int('min_child_samples', 180, 250),\n",
    "                  'extra_trees'       : trial.suggest_categorical('extra_trees', ['True']),  \n",
    "                  'extra_seed'        : trial.suggest_int('extra_seed', self.seed, self.seed),\n",
    "                  'max_delta_step'    : trial.suggest_float('max_delta_step', .75, .89), \n",
    "                  'reg_lambda'        : trial.suggest_float('reg_lambda', .95, 1.05), \n",
    "                  'subsample'         : trial.suggest_float('subsample', .59, .95),\n",
    "                  'seed'              : trial.suggest_int('random_state', self.seed, self.seed),                  \n",
    "                  'verbosity'         : trial.suggest_int('verbosity', -1, -1),\n",
    "                  'n_jobs'            : trial.suggest_int('n_jobs', -1, -1),\n",
    "                }\n",
    "        \n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['binary']),     \n",
    "                   'metric'            : trial.suggest_categorical('metric', ['auc']),                   \n",
    "                   'n_estimators'      : trial.suggest_int('n_estimators', 500, 3000),\n",
    "                   'max_depth'         : trial.suggest_int('max_depth', 2, 15),\n",
    "                   'num_leaves'        : trial.suggest_int('num_leaves', 90, 200),\n",
    "                   'boosting_type'     : trial.suggest_categorical('boosting_type', ['gbdt']),  \n",
    "                   'seed'              : trial.suggest_int('random_state', self.seed, self.seed),                    \n",
    "                   'n_jobs'            : trial.suggest_int('n_jobs', -1, -1)}\n",
    "        \n",
    "        if torch.cuda.is_available():                  \n",
    "            params.update({'device': trial.suggest_categorical('device', ['gpu'])})\n",
    "                      \n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc', valid_name='valid_1')\n",
    "       \n",
    "        mdl = lgb.LGBMClassifier(**params) #, callbacks=[pruning_callback])\n",
    "        \n",
    "        _, _, _, score, _ = \\\n",
    "            cross_val_model(model_                    = mdl,\n",
    "                            model_name_               = self.name_clf,\n",
    "                            X_                        = self.X_trn,\n",
    "                            y_                        = self.y_trn,\n",
    "                            X_test_                   = self.X_ts,\n",
    "                            target_                   = self.target,\n",
    "                            scalers_                  = self.scaler,\n",
    "                            fold_                     = self.n_splits,  \n",
    "                            lb_                       = None,\n",
    "                            path_                     = self.path,\n",
    "                            seed_                     = self.seed, \n",
    "                            feature_scaler_           = None, \n",
    "                            print_report_             = False, \n",
    "                            save_submission_          = self.save_submission,  \n",
    "                            save_predictions_         = self.save_predictions,\n",
    "                            cutoff_value_save_        = .6, \n",
    "                            train_with_created_folds_ = self.created_folds,\n",
    "                            model_type_               = self.model_type\n",
    "                           )\n",
    "        \n",
    "        print('param = {}'.format(params))\n",
    "        print()\n",
    "\n",
    "        return score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5fsZ-O5i345",
    "papermill": {
     "duration": 0.074708,
     "end_time": "2022-02-18T04:09:05.584391",
     "exception": false,
     "start_time": "2022-02-18T04:09:05.509683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3. Tunning \n",
    "Nesta etapa da modelagem, vamos criar 30 modelos e salvá-los para a nossa `Stacking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T11:25:24.595828Z",
     "start_time": "2022-05-31T11:22:56.755457Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-31 08:22:56,771]\u001b[0m A new study created in memory with name: lgbm_tuning\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Scaler: QuantileTransformer - n_estimators: 1525\n",
      "============================================================================\n",
      "[Fold 1] AUC: 0.73930 - F1-score: 0.62745 - L. Loss: 13.12489  - 0h 0m 18s\n",
      "[Fold 2] AUC: 0.76190 - F1-score: 0.68269 - L. Loss: 11.39794  - 0h 0m 11s\n",
      "[Fold 3] AUC: 0.79740 - F1-score: 0.69744 - L. Loss: 10.18905  - 0h 0m 13s\n",
      "[Fold 4] AUC: 0.76005 - F1-score: 0.71287 - L. Loss: 10.01637  - 0h 0m 12s\n",
      "[Fold 5] AUC: 0.80478 - F1-score: 0.75622 - L. Loss: 8.46210  - 0h 0m 11s\n",
      "----------------------------------------------------------------------------\n",
      "[Mean Fold] AUC: 0.77269 std: 0.02462 - L.Loss 10.63807 - 0h 1m 7s\n",
      "============================================================================\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Scaler Best: QuantileTransformer(output_distribution='normal', random_state=0)\n",
      "Score      : 0.77269\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-31 08:24:06,336]\u001b[0m Trial 0 finished with value: 0.772686095609561 and parameters: {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'importance_type': 'gain', 'class_weight': 'balanced', 'learning_rate': 0.03981794327284047, 'max_depth': 3, 'n_estimators': 1525, 'min_child_samples': 241, 'extra_trees': 'True', 'extra_seed': 12359, 'max_delta_step': 0.80849797131504, 'reg_lambda': 1.0261351664138112, 'subsample': 0.8382891972492301, 'random_state': 12359, 'verbosity': -1, 'n_jobs': -1, 'num_leaves': 130, 'device': 'gpu'}. Best is trial 0 with value: 0.772686095609561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = {'objective': 'binary', 'metric': 'auc', 'n_estimators': 1525, 'num_leaves': 130, 'boosting_type': 'gbdt', 'seed': 12359, 'n_jobs': -1, 'device': 'gpu'}\n",
      "\n",
      "============================================================================\n",
      "Scaler: QuantileTransformer - n_estimators: 3505\n",
      "============================================================================\n",
      "[Fold 1] AUC: 0.73950 - F1-score: 0.63415 - L. Loss: 12.95220  - 0h 0m 20s\n",
      "[Fold 2] AUC: 0.76250 - F1-score: 0.68269 - L. Loss: 11.39794  - 0h 0m 13s\n",
      "[Fold 3] AUC: 0.79870 - F1-score: 0.70769 - L. Loss: 9.84366  - 0h 0m 15s\n",
      "[Fold 4] AUC: 0.76005 - F1-score: 0.71287 - L. Loss: 10.01637  - 0h 0m 13s\n",
      "[Fold 5] AUC: 0.80428 - F1-score: 0.75622 - L. Loss: 8.46210  - 0h 0m 13s\n",
      "----------------------------------------------------------------------------\n",
      "[Mean Fold] AUC: 0.77301 std: 0.02465 - L.Loss 10.53445 - 0h 1m 15s\n",
      "============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-31 08:25:24,576]\u001b[0m Trial 1 finished with value: 0.7730060856085609 and parameters: {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'importance_type': 'gain', 'class_weight': 'balanced', 'learning_rate': 0.08534554105266592, 'max_depth': 4, 'n_estimators': 3505, 'min_child_samples': 214, 'extra_trees': 'True', 'extra_seed': 12359, 'max_delta_step': 0.7744026404755341, 'reg_lambda': 0.9690541069961618, 'subsample': 0.8975067497422087, 'random_state': 12359, 'verbosity': -1, 'n_jobs': -1, 'num_leaves': 152, 'device': 'gpu'}. Best is trial 1 with value: 0.7730060856085609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Scaler Best: QuantileTransformer(output_distribution='normal', random_state=0)\n",
      "Score      : 0.77301\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "param = {'objective': 'binary', 'metric': 'auc', 'n_estimators': 3505, 'num_leaves': 152, 'boosting_type': 'gbdt', 'seed': 12359, 'n_jobs': -1, 'device': 'gpu'}\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Best score: 0.77301\n",
      "Seed      : 12359\n",
      "Parameters:\n",
      "\n",
      "{'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'importance_type': 'gain', 'class_weight': 'balanced', 'learning_rate': 0.08534554105266592, 'max_depth': 4, 'n_estimators': 3505, 'min_child_samples': 214, 'extra_trees': 'True', 'extra_seed': 12359, 'max_delta_step': 0.7744026404755341, 'reg_lambda': 0.9690541069961618, 'subsample': 0.8975067497422087, 'random_state': 12359, 'verbosity': -1, 'n_jobs': -1, 'num_leaves': 152, 'device': 'gpu'}\n",
      "\n",
      "CPU times: total: 5min 46s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "SEED       = 12359\n",
    "n_trials_  = 5\n",
    "name_model = 'lgbm_tuni_02_cv_kfold_5' \n",
    "\n",
    "TunningModels.delete_files(name_model)\n",
    "    \n",
    "scaler = [QuantileTransformer(output_distribution='normal', random_state=0)]\n",
    "\n",
    "modelOpt = TunningModels(name_model_      = name_model, \n",
    "                         X_trn_           = X, \n",
    "                         y_trn_           = y, \n",
    "                         X_ts_            = X_test,                                     \n",
    "                         feature_         = None,  \n",
    "                         scaler_          = scaler, \n",
    "                         seed_            = SEED, \n",
    "                         feature_bin_     = None, \n",
    "                         target_          = target, \n",
    "                         path_            = path, \n",
    "                         level_           = '1',  \n",
    "                         save_submission_ = True, \n",
    "                         save_predictions_= True,\n",
    "                         created_folds_   = False, \n",
    "                         model_type_      = 2\n",
    "                        )\n",
    "\n",
    "pruner = LastPlacePruner(warmup_steps  = 1, warmup_trials = 5)\n",
    "study  = optuna.create_study(direction  = 'maximize',\n",
    "                             sampler    = optuna.samplers.TPESampler(seed=SEED),\n",
    "                             #pruner     = optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "                             pruner     = pruner,\n",
    "                             study_name = 'lgbm_tuning')\n",
    "\n",
    "study.optimize(modelOpt.lgbm, n_trials=n_trials_)\n",
    "\n",
    "score_seed  = study.best_value \n",
    "params      = study.best_params \n",
    "path_name   = path + 'model/optuna/' + name_model + '_{:2.5f}.pkl.z'.format(score_seed)   \n",
    "scare_best  = score_seed \n",
    "params_best = params\n",
    "\n",
    "print()\n",
    "print('-'*110)\n",
    "print('Best score: {:2.5f}'.format(scare_best))\n",
    "print('Seed      : {}'.format(SEED))\n",
    "print('Parameters:\\n\\n{}'.format(params_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p><br>\n",
    "Melhoramos o score da submissão, de 0.99045 para 0.99095, uma observação importante é que o modelo tem uma boa performance nas submissões, com o score sempre superior das previsões realizadas, um cuidado que temos ter é que estamos sendo avaliado em 30% dos dados de treino, vamos fazer uma pequena analise desses parametros ajustados.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEQa44wEi346",
    "papermill": {
     "duration": 0.139401,
     "end_time": "2022-02-18T07:02:27.882297",
     "exception": false,
     "start_time": "2022-02-18T07:02:27.742896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4. Análise  de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.538587Z",
     "start_time": "2022-05-31T03:04:21.538587Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T22:42:51.619976Z",
     "iopub.status.busy": "2022-02-21T22:42:51.619175Z",
     "iopub.status.idle": "2022-02-21T22:42:51.637128Z",
     "shell.execute_reply": "2022-02-21T22:42:51.63646Z",
     "shell.execute_reply.started": "2022-02-21T22:42:51.619925Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.539580Z",
     "start_time": "2022-05-31T03:04:21.539580Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T22:28:16.06382Z",
     "iopub.status.busy": "2022-02-21T22:28:16.063568Z",
     "iopub.status.idle": "2022-02-21T22:28:16.113353Z",
     "shell.execute_reply": "2022-02-21T22:28:16.112548Z",
     "shell.execute_reply.started": "2022-02-21T22:28:16.063791Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.541580Z",
     "start_time": "2022-05-31T03:04:21.541580Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T22:43:16.62917Z",
     "iopub.status.busy": "2022-02-21T22:43:16.628557Z",
     "iopub.status.idle": "2022-02-21T22:43:16.906506Z",
     "shell.execute_reply": "2022-02-21T22:43:16.905821Z",
     "shell.execute_reply.started": "2022-02-21T22:43:16.629128Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nVNrHHSi347",
    "papermill": {
     "duration": 0.343167,
     "end_time": "2022-02-18T07:02:29.625515",
     "exception": false,
     "start_time": "2022-02-18T07:02:29.282348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.5. Modelo\n",
    "\n",
    "Agora que temos os melhores parametros ajustados, vamos treinar um modelo com 50% dos dados e fazer algumas análises. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.544579Z",
     "start_time": "2022-05-31T03:04:21.544579Z"
    }
   },
   "outputs": [],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 3. FEATURE SELECTION </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14977,
     "end_time": "2022-02-18T07:14:29.999438",
     "exception": false,
     "start_time": "2022-02-18T07:14:29.849668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1. Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T02:56:31.277921Z",
     "start_time": "2022-02-21T02:53:22.163676Z"
    },
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-21T22:43:59.100093Z",
     "iopub.status.busy": "2022-02-21T22:43:59.099826Z",
     "iopub.status.idle": "2022-02-21T22:52:29.483491Z",
     "shell.execute_reply": "2022-02-21T22:52:29.482676Z",
     "shell.execute_reply.started": "2022-02-21T22:43:59.100062Z"
    },
    "executionInfo": {
     "elapsed": 1129658,
     "status": "ok",
     "timestamp": 1644988187609,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "52gsbtwyi348",
    "outputId": "5b06c926-ae7f-4ca8-d984-aff36e76f82e",
    "papermill": {
     "duration": 716.130964,
     "end_time": "2022-02-18T07:14:26.533079",
     "exception": false,
     "start_time": "2022-02-18T07:02:30.402115",
     "status": "completed"
    },
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_model = name_model_clf + \n",
    "\n",
    "model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "    TunningModels.train_model_cv(model_         = lgb.LGBMClassifier(**params_best), \n",
    "                                 X_             = X_train, \n",
    "                                 y_             = y_train, \n",
    "                                 X_test_        = X_test, \n",
    "                                 target_        = target, \n",
    "                                 model_name_    = name_model, \n",
    "                                 sc_            = RobustScaler(), \n",
    "                                 sc_second_     = None, \n",
    "                                 n_splits_      = 5, \n",
    "                                 seed_          = SEED,\n",
    "                                 path_          = path, \n",
    "                                 save_predict_  = False, \n",
    "                                 level_         = '1', \n",
    "                                 print_result_  = True, \n",
    "                                 feature_       = None, \n",
    "                                 trial_         = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T14:48:46.608823Z",
     "iopub.status.busy": "2022-02-22T14:48:46.608145Z",
     "iopub.status.idle": "2022-02-22T14:48:49.837662Z",
     "shell.execute_reply": "2022-02-22T14:48:49.836977Z",
     "shell.execute_reply.started": "2022-02-22T14:48:46.60879Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = RobustScaler()\n",
    "lb = LabelEncoder()\n",
    "\n",
    "X_scaler = X.drop(['sample_weight'], axis=1)\n",
    "X_scaler = pd.DataFrame(sc.fit_transform(X_scaler), columns=X_scaler.columns)\n",
    "y_label  = pd.DataFrame(lb.fit_transform(y), columns=[target])\n",
    "\n",
    "X_scaler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:35:18.215356Z",
     "iopub.status.busy": "2022-02-23T01:35:18.215084Z",
     "iopub.status.idle": "2022-02-23T01:35:18.220828Z",
     "shell.execute_reply": "2022-02-23T01:35:18.219904Z",
     "shell.execute_reply.started": "2022-02-23T01:35:18.215325Z"
    }
   },
   "outputs": [],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T16:49:43.967552Z",
     "start_time": "2022-05-30T16:49:43.756996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra para treinamento: 450000\n"
     ]
    }
   ],
   "source": [
    "sample     = int(X.shape[0]/2)\n",
    "idx_sample = X.sample(sample).index.to_list()\n",
    "\n",
    "X_sample = X.iloc[idx_sample] \n",
    "y_sample = y.iloc[idx_sample]\n",
    "\n",
    "print('Amostra para treinamento: {}'.format(len(idx_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T17:25:42.728869Z",
     "start_time": "2022-05-30T17:25:42.717888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12359"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T01:26:16.914255Z",
     "start_time": "2022-02-21T00:59:15.085066Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T23:07:33.226491Z",
     "iopub.status.busy": "2022-02-21T23:07:33.226238Z",
     "iopub.status.idle": "2022-02-21T23:20:01.056023Z",
     "shell.execute_reply": "2022-02-21T23:20:01.05525Z",
     "shell.execute_reply.started": "2022-02-21T23:07:33.226463Z"
    },
    "executionInfo": {
     "elapsed": 3610,
     "status": "ok",
     "timestamp": 1645133128911,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "SYbncKdAVzZI",
    "outputId": "95d3a417-7240-449a-9baa-1207bafa77a3",
    "papermill": {
     "duration": 8034.542892,
     "end_time": "2022-02-18T09:28:24.692174",
     "exception": false,
     "start_time": "2022-02-18T07:14:30.149282",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**params_best)\n",
    "\n",
    "feat_selector = BorutaPy(model, \n",
    "                         n_estimators = 'auto', \n",
    "                         two_step     = False,\n",
    "                         verbose      = 2, \n",
    "                         max_iter     = 100,\n",
    "                         random_state = 42)\n",
    "\n",
    "feat_selector.fit(X_scaler.values, y_label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T19:21:59.143432Z",
     "start_time": "2022-05-30T19:21:59.080470Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:27:28.352272Z",
     "start_time": "2022-02-21T03:27:28.31029Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-21T23:20:45.828004Z",
     "iopub.status.busy": "2022-02-21T23:20:45.827702Z",
     "iopub.status.idle": "2022-02-21T23:20:45.857388Z",
     "shell.execute_reply": "2022-02-21T23:20:45.85674Z",
     "shell.execute_reply.started": "2022-02-21T23:20:45.827951Z"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1645112502849,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "mRf1BebkTqdW",
    "outputId": "8fdead1a-081f-4f0f-e1ae-7faaad8c85a2",
    "papermill": {
     "duration": 0.709069,
     "end_time": "2022-02-18T09:28:25.58063",
     "exception": false,
     "start_time": "2022-02-18T09:28:24.871561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_selected = X_scaler.iloc[:,feat_selector.support_]\n",
    "X_test_selected  = X_test.iloc[:,feat_selector.support_]\n",
    "\n",
    "X_train_selected['sample_weight'] = X['sample_weight']\n",
    "X_test_selected.shape , X_test_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T03:27:30.308524Z",
     "start_time": "2022-02-21T03:27:30.302527Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T02:11:22.768767Z",
     "iopub.status.busy": "2022-02-23T02:11:22.768111Z",
     "iopub.status.idle": "2022-02-23T02:11:22.773313Z",
     "shell.execute_reply": "2022-02-23T02:11:22.772102Z",
     "shell.execute_reply.started": "2022-02-23T02:11:22.768726Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1645112536955,
     "user": {
      "displayName": "Rogério Delfim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8lDYWTfZHU0U0sMojRPio71Ec7YDcSEpCaOEE=s64",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "kzN_XEkFWLiG",
    "outputId": "98fbf679-e03f-41e7-8bcf-08c0f70f07ff",
    "papermill": {
     "duration": 0.318072,
     "end_time": "2022-02-18T09:28:26.255868",
     "exception": false,
     "start_time": "2022-02-18T09:28:25.937796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_feature_selected_boruta = X_train_selected.columns.to_list()\n",
    "print(cols_feature_selected_boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:12:07.05492Z",
     "iopub.status.busy": "2022-02-23T02:12:07.054662Z",
     "iopub.status.idle": "2022-02-23T02:12:07.062991Z",
     "shell.execute_reply": "2022-02-23T02:12:07.062169Z",
     "shell.execute_reply.started": "2022-02-23T02:12:07.054892Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_rejected = [col for col in X.columns if col not in cols_feature_selected_boruta]\n",
    "print(feature_rejected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Feature autocorrelaciondas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T02:14:01.47786Z",
     "iopub.status.busy": "2022-02-23T02:14:01.4776Z",
     "iopub.status.idle": "2022-02-23T02:14:28.76368Z",
     "shell.execute_reply": "2022-02-23T02:14:28.763025Z",
     "shell.execute_reply.started": "2022-02-23T02:14:01.477832Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = .75\n",
    "\n",
    "print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold))\n",
    "df = X[cols_feature_selected_boruta].corr(method ='pearson').round(5)\n",
    "df_corr = df[abs(df)>threshold][df!=1.0].unstack().dropna().reset_index()\n",
    "df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "df_corr.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T18:11:55.043927Z",
     "start_time": "2022-05-30T18:11:55.032907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T18:13:22.137586Z",
     "start_time": "2022-05-30T18:13:21.322828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.51725 - F1-score: 0.17152 - L. loss: 16.28437\n",
      "\n",
      "Probabilidade do modelo\n",
      "Prever negativo: 0.91671\n",
      "Prever positivo: 0.08329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_pred_proba_ts  = model.predict_proba(X_test_sc)[:,1]\n",
    "#y_pred_ts        = (y_pred_proba_ts>.5).astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-25T04:05:13.931104Z",
     "iopub.status.busy": "2022-02-25T04:05:13.930702Z",
     "iopub.status.idle": "2022-02-25T04:05:14.029091Z",
     "shell.execute_reply": "2022-02-25T04:05:14.027488Z",
     "shell.execute_reply.started": "2022-02-25T04:05:13.931021Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_aut_corr = list(df_corr['var_1'].unique())\n",
    "#feature_aut_corr.remove('sample_weight')\n",
    "print('Temos {} variáveis autocorrelaciodas.'.format(len(feature_aut_corr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos remover as variáveis autocorrelacionadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T18:36:48.958182Z",
     "start_time": "2022-05-30T18:36:48.946164Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba_pos = df_proba['y_proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:16:48.109501Z",
     "iopub.status.busy": "2022-02-23T03:16:48.108944Z",
     "iopub.status.idle": "2022-02-23T03:16:48.115493Z",
     "shell.execute_reply": "2022-02-23T03:16:48.114747Z",
     "shell.execute_reply.started": "2022-02-23T03:16:48.10946Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_feature_selected = [col for col in cols_feature_selected_boruta if col not in feature_aut_corr]\n",
    "print('Temos agora {} variáveis.'.format(len(cols_feature_selected)), end='\\n\\n')\n",
    "print(cols_feature_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 3. DIVERCIDADE </h1>    \n",
    "</div>\n",
    "\n",
    "Nesta etapa vamos utilizar os melhores parametros ajustados com o tunning, para gerar diversos modelos com divercidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.546580Z",
     "start_time": "2022-05-31T03:04:21.546580Z"
    }
   },
   "outputs": [],
   "source": [
    "params_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.548580Z",
     "start_time": "2022-05-31T03:04:21.548580Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed        = seed_best\n",
    "eval_metric = ['auc', 'error'] \n",
    "scalers     = [QuantileTransformer(output_distribution='normal', random_state=0)]\n",
    "\n",
    "parmas_values    = [1500, 2020, 2021]\n",
    "param_name       = 'random_state'\n",
    "params_div       = params_best.copy()\n",
    "\n",
    "y_pred_test_seed = np.zeros((X_test.shape[0], len(parmas_values))) \n",
    "cols_feature     = []\n",
    "score_best       = 0 \n",
    "seed_best        = 0 \n",
    "name_model       = 'lgbm_div_01_' + param_name\n",
    "\n",
    "\n",
    "delete_files(name_model)\n",
    "\n",
    "for i, value in  enumerate (parmas_values):    \n",
    "    \n",
    "    name_mdl               = name_model + '_' + str(i+1) + '_cv_kfold_5'\n",
    "    params_div[param_name] = value \n",
    "    \n",
    "    model, df_proba, feature_imp, score, y_pred_test_prob_oof = \\\n",
    "        cross_val_model(model_                    = lgb.LGBMClassifier(**params_div),\n",
    "                        model_name_               = name_mdl,\n",
    "                        X_                        = X,\n",
    "                        y_                        = y,\n",
    "                        X_test_                   = X_test,\n",
    "                        target_                   = target,\n",
    "                        scalers_                  = scalers,\n",
    "                        fold_                     = 5,  \n",
    "                        lb_                       = None,\n",
    "                        path_                     = path,\n",
    "                        seed_                     = seed, \n",
    "                        feature_scaler_           = None, \n",
    "                        print_report_             = False, \n",
    "                        save_submission_          = False,#  \n",
    "                        save_predictions_         = True,\n",
    "                        train_with_created_folds_ = False,\n",
    "                        print_result_best_        = False, \n",
    "                        cutoff_value_save_        = .6)\n",
    "    \n",
    "    if score > score_best:\n",
    "        seed_best  = seed  \n",
    "        score_best = score\n",
    "    \n",
    "    cols_feature.append(param_name +'_' + str(seed_))\n",
    "    y_pred_test_seed[:,i] = y_pred_test_prob_oof\n",
    "    \n",
    "df_div = pd.DataFrame(y_pred_test, columns=cols_feature) \n",
    " \n",
    "# Gera submission \n",
    "name_mdl = name_model + '_stacking_score_{:2.5f}.csv'.format(score_best)\n",
    "df_submission[target] = df_seed.mean(axis=1)\n",
    "df_submission.to_csv(path +'Data/submission/' + name_mdl, index=False)\n",
    "\n",
    "print()\n",
    "print('Seed : {}'.format(seed_best))\n",
    "print('Score: {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.550588Z",
     "start_time": "2022-05-31T03:04:21.550588Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T23:39:05.860706Z",
     "iopub.status.busy": "2022-02-21T23:39:05.860166Z",
     "iopub.status.idle": "2022-02-21T23:39:05.866755Z",
     "shell.execute_reply": "2022-02-21T23:39:05.865831Z",
     "shell.execute_reply.started": "2022-02-21T23:39:05.860656Z"
    }
   },
   "source": [
    "## 3.2. Leaning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.552594Z",
     "start_time": "2022-05-31T03:04:21.552594Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed        = seed_best\n",
    "eval_metric = ['auc', 'error'] \n",
    "scalers     = [QuantileTransformer(output_distribution='normal', random_state=0)]\n",
    "\n",
    "parmas_values    = [0.15, 0.25, .35]\n",
    "param_name       = 'learning_rate'\n",
    "params_div       = params_best.copy()\n",
    "\n",
    "y_pred_test_seed = np.zeros((X_test.shape[0], len(parmas_values))) \n",
    "cols_feature     = []\n",
    "score_best       = 0 \n",
    "seed_best        = 0 \n",
    "name_model       = 'lgbm_div_02_' + param_name\n",
    "\n",
    "\n",
    "delete_files(name_model)\n",
    "\n",
    "for i, value in  enumerate (parmas_values):    \n",
    "    \n",
    "    name_mdl               = name_model + '_' + str(i+1) + '_cv_kfold_5'\n",
    "    params_div[param_name] = value \n",
    "    \n",
    "    model, df_proba, feature_imp, score, y_pred_test_prob_oof = \\\n",
    "        cross_val_model(model_                    = lgb.LGBMClassifier(**params_div),\n",
    "                        model_name_               = name_mdl,\n",
    "                        X_                        = X,\n",
    "                        y_                        = y,\n",
    "                        X_test_                   = X_test,\n",
    "                        target_                   = target,\n",
    "                        scalers_                  = scalers,\n",
    "                        fold_                     = 5,  \n",
    "                        lb_                       = None,\n",
    "                        path_                     = path,\n",
    "                        seed_                     = seed, \n",
    "                        feature_scaler_           = None, \n",
    "                        print_report_             = False, \n",
    "                        save_submission_          = False,#  \n",
    "                        save_predictions_         = True,\n",
    "                        save_predictions_         = True,\n",
    "                        train_with_created_folds_ = False,\n",
    "                        print_result_best_        = False, \n",
    "                        cutoff_value_save_        = .6)\n",
    "    \n",
    "    if score > score_best:\n",
    "        seed_best  = seed  \n",
    "        score_best = score\n",
    "    \n",
    "    cols_feature.append(param_name +'_' + str(seed_))\n",
    "    y_pred_test_seed[:,i] = y_pred_test_prob_oof\n",
    "    \n",
    "df_div = pd.DataFrame(y_pred_test, columns=cols_feature) \n",
    "    \n",
    "# Gera submission \n",
    "name_mdl = name_model + '_stacking_score_{:2.5f}.csv'.format(score_best)\n",
    "df_submission[target] = df_seed.mean(axis=1)\n",
    "df_submission.to_csv(path +'Data/submission/' + name_mdl, index=False)\n",
    "\n",
    "print()\n",
    "print('Seed : {}'.format(seed_best))\n",
    "print('Score: {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.554580Z",
     "start_time": "2022-05-31T03:04:21.554580Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "seed        = seed_best\n",
    "eval_metric = ['auc', 'error'] \n",
    "scalers     = [QuantileTransformer(output_distribution='normal', random_state=0)]\n",
    "\n",
    "parmas_values    = [2, 7, 15]\n",
    "param_name       = 'max_depth'\n",
    "params_div       = params_best.copy()\n",
    "\n",
    "y_pred_test_seed = np.zeros((X_test.shape[0], len(parmas_values))) \n",
    "cols_feature     = []\n",
    "score_best       = 0 \n",
    "seed_best        = 0 \n",
    "name_model       = 'lgbm_div_03_' + param_name\n",
    "\n",
    "delete_files(name_model)\n",
    "\n",
    "for i, value in  enumerate (parmas_values):    \n",
    "    \n",
    "    name_mdl               = name_model + '_' + str(i+1) + '_cv_kfold_5'\n",
    "    params_div[param_name] = value \n",
    "    \n",
    "    model, df_proba, feature_imp, score, y_pred_test_prob_oof = \\\n",
    "        cross_val_model(model_                    = lgb.LGBMClassifier(**params_div),\n",
    "                        model_name_               = name_mdl,\n",
    "                        X_                        = X,\n",
    "                        y_                        = y,\n",
    "                        X_test_                   = X_test,\n",
    "                        target_                   = target,\n",
    "                        scalers_                  = scalers,\n",
    "                        fold_                     = 5,  \n",
    "                        lb_                       = None,\n",
    "                        path_                     = path,\n",
    "                        seed_                     = seed, \n",
    "                        feature_scaler_           = None, \n",
    "                        print_report_             = False, \n",
    "                        save_submission_          = False,#  \n",
    "                        save_predictions_         = True,\n",
    "                        train_with_created_folds_ = False,\n",
    "                        print_result_best_        = False, \n",
    "                        cutoff_value_save_        = .6)\n",
    "    \n",
    "    if score > score_best:\n",
    "        seed_best  = seed  \n",
    "        score_best = score\n",
    "    \n",
    "    cols_feature.append(param_name +'_' + str(seed_))\n",
    "    y_pred_test_seed[:,i] = y_pred_test_prob_oof\n",
    "    \n",
    "df_div = pd.DataFrame(y_pred_test, columns=cols_feature) \n",
    "\n",
    "# Gera submission \n",
    "name_mdl = name_model + '_stacking_score_{:2.5f}.csv'.format(score_best)\n",
    "df_submission[target] = df_div.mean(axis=1)\n",
    "df_submission.to_csv(path +'Data/submission/' + name_mdl, index=False)\n",
    "\n",
    "print()\n",
    "print('Seed : {}'.format(seed_best))\n",
    "print('Score: {}'.format(score_best))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:04:21.555580Z",
     "start_time": "2022-05-31T03:04:21.555580Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T03:44:56.003835Z",
     "iopub.status.busy": "2022-02-23T03:44:56.003505Z",
     "iopub.status.idle": "2022-02-23T03:44:56.013559Z",
     "shell.execute_reply": "2022-02-23T03:44:56.011709Z",
     "shell.execute_reply.started": "2022-02-23T03:44:56.003798Z"
    }
   },
   "outputs": [],
   "source": [
    "df_div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T03:49:05.436052Z",
     "iopub.status.busy": "2022-02-23T03:49:05.435804Z",
     "iopub.status.idle": "2022-02-23T03:54:06.645937Z",
     "shell.execute_reply": "2022-02-23T03:54:06.645253Z",
     "shell.execute_reply.started": "2022-02-23T03:49:05.436025Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "name_model = name_model_clf + '_div_feature_10_'\n",
    "\n",
    "TunningModels.model_of_diversity_feature_group(model_     = lgb.LGBMClassifier(**params_best), \n",
    "                                               name_model = name_model, \n",
    "                                               X_         = X[cols_feature_selected], \n",
    "                                               y_         = y, \n",
    "                                               X_ts_      = X_test[cols_feature_selected_ts],\n",
    "                                               target_    = target,\n",
    "                                               sc_        = RobustScaler(),\n",
    "                                               seed_      = seed_best)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 5. ENSEMBLE </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Recuparar dataset\n",
    "Vamos recuperar todas as previsões do XGBoost para gerar um ensable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T22:48:52.385162Z",
     "start_time": "2022-05-30T22:48:50.034276Z"
    },
    "execution": {
     "iopub.execute_input": "2022-02-23T04:05:57.515004Z",
     "iopub.status.busy": "2022-02-23T04:05:57.514697Z",
     "iopub.status.idle": "2022-02-23T04:06:06.572161Z",
     "shell.execute_reply": "2022-02-23T04:06:06.570648Z",
     "shell.execute_reply.started": "2022-02-23T04:05:57.514971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 13), (700000, 12))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_stacking, df_ts_stacking = \\\n",
    "    df_return_preds_stacking(model_name_=None, shape_=X.shape[0], path_=path, target_=target, level=1)\n",
    "\n",
    "df_tr_stacking.shape, df_ts_stacking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T22:51:03.391139Z",
     "start_time": "2022-05-30T22:51:03.383140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['xgb_fe_01_score_0.98787_seed_12359',\n",
       "       'xgb_fe_02_outlier_score_0.98801_seed_12359',\n",
       "       'xgb_fe_03_pca_score_0.98824_seed_12359',\n",
       "       'xgb_fe_04_cv_kfold_5_score_0.98914_seed_12359_quan',\n",
       "       'xgb_fe_05_cv_kfold_10_score_0.98884_seed_12359_quan',\n",
       "       'xgb_tuni_01_cv_kfold_5_score_0.99001_seed_12359_quan',\n",
       "       'xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.98844_seed_12359_quan',\n",
       "       'xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.98857_seed_12359_quan',\n",
       "       'xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.98898_seed_12359_quan',\n",
       "       'xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.98983_seed_12359_quan',\n",
       "       'xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.99006_seed_12359_quan',\n",
       "       'xgb_tuni_05_cv_kfold_5_score_0.98881_seed_12359_quan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_stacking.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T22:51:50.314302Z",
     "start_time": "2022-05-30T22:51:49.018306Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission[target] = df_ts_stacking.mean(axis=1)\n",
    "df_submission.to_csv(path + 'Data/submission/xgb_tun_1_stacking_mean.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T22:57:56.688924Z",
     "start_time": "2022-05-30T22:57:55.401746Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_1 = df_ts_stacking['xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.99006_seed_12359_quan'].values *.8\n",
    "auc_2 = df_ts_stacking['xgb_tuni_02_cv_kfold_5_02620534577784065_score_0.98898_seed_12359_quan'].values *.1\n",
    "auc_3 = df_ts_stacking['xgb_tuni_01_cv_kfold_5_score_0.99001_seed_12359_quan'].values *.1\n",
    "\n",
    "df_submission[target] = auc_1 + auc_2 + auc_3\n",
    "df_submission.to_csv(path + 'Data/submission/xgb_tun_2_stacking_mean.csv', index=False) "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T04:07:05.649075Z",
     "iopub.status.busy": "2022-02-23T04:07:05.648355Z",
     "iopub.status.idle": "2022-02-23T04:07:06.055288Z",
     "shell.execute_reply": "2022-02-23T04:07:06.054623Z",
     "shell.execute_reply.started": "2022-02-23T04:07:05.64903Z"
    }
   },
   "outputs": [],
   "source": [
    "#jb.dump(df_train_xgb, 'Data/pkl/df_nb_03_train_xgb.pkl.z')\n",
    "#jb.dump(df_test_xgb,  'Data/pkl/df_nb_03_test_xgb.pkl.z')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "pt-br"
   ],
   "hotkey": "",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "pt-br",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
