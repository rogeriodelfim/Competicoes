{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb90dde2",
   "metadata": {
    "id": "eb90dde2"
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#a7d5ed;font-size:170%;\n",
    "            font-family:Nexa;letter-spacing:4.5px;\">    \n",
    "    <h1 style=\"padding:15px;color:black;text-align: center\"> Rede Neural com Keras </h1> \n",
    "</div>\n",
    "\n",
    "![](img/header.png?t=2021-04-09-00-57-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b64cce",
   "metadata": {
    "id": "97b64cce"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> OBJETIVO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1a1da",
   "metadata": {
    "id": "74a1a1da"
   },
   "source": [
    "O objetivo neste notebook é criação novas variáveis (feature) que possam ajudar na identificação de novos padrões, com a finalidade de bater a baseline estabelecida no [notebook](https://www.kaggle.com/code/rogeriodelfim/tps-nov-2022-01-eda-baseline), para isso vamos os seguintes passos: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50853d",
   "metadata": {
    "id": "3e50853d"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0572e",
   "metadata": {
    "id": "09d0572e"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 1. IMPORTAÇÕES </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26201eb",
   "metadata": {
    "id": "b26201eb"
   },
   "source": [
    "## 1.1. Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e8ead3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:16.021531Z",
     "start_time": "2022-11-25T01:26:15.994491Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66652,
     "status": "ok",
     "timestamp": 1669317942050,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "51e8ead3",
    "outputId": "67599e0e-e61c-4f22-ee8e-f4627d14bd43"
   },
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython()) \n",
    "\n",
    "if COLAB:        \n",
    "    !pip install --q scikit-plot\n",
    "    !pip install --q category_encoders\n",
    "    !pip install --q shap\n",
    "    !pip install --q inflection    \n",
    "    !pip install --q catboost\n",
    "    !pip install --q colorama\n",
    "    !pip install --q tensorflow\n",
    "    !pip install --q wandb \n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ba737",
   "metadata": {
    "id": "e30ba737"
   },
   "source": [
    "## 1.2. Bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042dfe80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:38.130326Z",
     "start_time": "2022-11-25T01:26:17.270235Z"
    },
    "executionInfo": {
     "elapsed": 2541,
     "status": "ok",
     "timestamp": 1669317944586,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "042dfe80"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import sklearn.exceptions\n",
    "import multiprocessing\n",
    "import glob\n",
    "import glob\n",
    "import pickle\n",
    "import scipy.optimize \n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7603208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:45.104096Z",
     "start_time": "2022-11-25T01:26:38.196980Z"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1669317950953,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "c7603208"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas                    as pd\n",
    "import numpy                     as np\n",
    "import matplotlib.pyplot         as plt \n",
    "import seaborn                   as sns\n",
    "import joblib                    as jb\n",
    "#import scipy.stats               as stats\n",
    "#import plotly.express            as px\n",
    "#import xgboost                   as xgb\n",
    "import lightgbm                  as lgb\n",
    "#import scikitplot                as skplt\n",
    "import sklearn.feature_selection as fs\n",
    "#import category_encoders         as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8fad3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:45.182042Z",
     "start_time": "2022-11-25T01:26:45.169868Z"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1669317952009,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "0c8fad3d"
   },
   "outputs": [],
   "source": [
    "from matplotlib.axes._axes     import _log as matplotlib_axes_logger\n",
    "from sklearn.model_selection   import train_test_split, StratifiedKFold #, KFold, , cross_val_score\n",
    "from sklearn.preprocessing     import StandardScaler #,  OneHotEncoder, KBinsDiscretizer, MaxAbsScaler\n",
    "from sklearn.metrics           import roc_auc_score, f1_score, log_loss, roc_curve, auc\n",
    "from sklearn.metrics           import classification_report, confusion_matrix\n",
    "# from scipy.stats               import spearmanr\n",
    "# from sklearn.impute            import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d42809f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:48.832986Z",
     "start_time": "2022-11-25T01:26:45.248359Z"
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1669317953232,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "8d42809f"
   },
   "outputs": [],
   "source": [
    "from sklearn                    import set_config \n",
    "from sklearn.utils              import estimator_html_repr \n",
    "from IPython.core.display       import HTML , display_html \n",
    "from imblearn.pipeline          import Pipeline\n",
    "from sklearn.compose            import ColumnTransformer, make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dddb84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:26:48.909654Z",
     "start_time": "2022-11-25T01:26:48.895618Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1669317953460,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "f5dddb84"
   },
   "outputs": [],
   "source": [
    "#from tqdm.notebook             import tqdm, trange\n",
    "from datetime                  import datetime\n",
    "from colorama                  import Fore, Back, Style\n",
    "#from sklearn.calibration       import CalibrationDisplay\n",
    "from sklearn.feature_selection import SelectPercentile, VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.pipeline          import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.decomposition     import PCA\n",
    "#from sklearn.mixture           import GaussianMixture, BayesianGaussianMixture\n",
    "#from yellowbrick.cluster       import KElbowVisualizer, SilhouetteVisualizer, InterclusterDistance\n",
    "#from sklearn.cluster           import KMeans, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3c7aebb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T21:45:55.647101Z",
     "start_time": "2022-11-27T21:45:55.633104Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1669317954332,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "3c7aebb7"
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model      import LogisticRegression\n",
    "#from sklearn.neighbors         import KNeighborsClassifier\n",
    "#from sklearn.ensemble          import ExtraTreesClassifier   \n",
    "#from sklearn.neighbors         import KNeighborsClassifier\n",
    "#from sklearn.neural_network    import MLPClassifier\n",
    "from sklearn.ensemble          import RandomForestClassifier\n",
    "#from sklearn.ensemble          import AdaBoostClassifier\n",
    "#from sklearn.ensemble          import HistGradientBoostingClassifier\n",
    "#from sklearn.ensemble          import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "15H8NWg0zUlo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T03:45:11.287440Z",
     "start_time": "2022-11-26T03:45:11.124011Z"
    },
    "executionInfo": {
     "elapsed": 3418,
     "status": "ok",
     "timestamp": 1669317958354,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "15H8NWg0zUlo"
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import wandb\n",
    "import graphviz \n",
    "# import math\n",
    "\n",
    "import tensorflow as tf\n",
    "  \n",
    "from sklearn.tree           import export_graphviz\n",
    "from tensorflow             import keras\n",
    "from keras                  import backend as K\n",
    "from tensorflow.keras       import layers, callbacks, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from wandb.keras            import WandbCallback\n",
    "from sklearn.metrics        import log_loss, accuracy_score\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau#, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, BatchNormalization, Embedding, Conv1D, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "#from sklearn.utils import class_weight as cw \n",
    "\n",
    "#from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "#user_secrets = UserSecretsClient()\n",
    "#wandb_auth = user_secrets.get_secret(\"wandb_tps_nov22\")\n",
    "#!wandb login $wandb_auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "172457ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T02:57:26.478529Z",
     "start_time": "2022-11-27T02:57:13.613043Z"
    }
   },
   "outputs": [],
   "source": [
    "from optuna.samplers               import TPESampler\n",
    "from optuna.visualization          import plot_edf\n",
    "from optuna.visualization          import plot_optimization_history\n",
    "from optuna.visualization          import plot_parallel_coordinate\n",
    "from optuna.visualization          import plot_param_importances\n",
    "from optuna.visualization          import plot_slice\n",
    "from optuna.visualization          import plot_intermediate_values\n",
    "from optuna.visualization          import plot_contour\n",
    "from optuna.pruners                import MedianPruner\n",
    "from optuna.pruners                import BasePruner\n",
    "from optuna.trial._state           import TrialState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7cdab",
   "metadata": {
    "id": "d1f7cdab"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f0147",
   "metadata": {
    "id": "110f0147"
   },
   "source": [
    "## 1.3. Funções\n",
    "Aqui centralizamos todas as funções desenvolvidas durante o projeto para melhor organização do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "10d2530b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:39:17.793433Z",
     "start_time": "2022-11-26T17:39:17.741447Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669317958354,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "10d2530b"
   },
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    history_df = pd.DataFrame(hist.history)\n",
    "    \n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history_df['loss'],label='Train')\n",
    "    plt.plot(history_df['val_loss'],label='Valid')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history_df['auc'],label='Train')\n",
    "    plt.plot(history_df['val_auc'],label='Valid')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "48cb40d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:39:23.231670Z",
     "start_time": "2022-11-26T17:39:23.142160Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669317958354,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "48cb40d1"
   },
   "outputs": [],
   "source": [
    "def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):                    \n",
    "                        os.remove(os.path.join(raiz, arquivo))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7cd9f619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T18:20:46.862094Z",
     "start_time": "2022-11-26T18:20:46.839102Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1669317958634,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "7cd9f619"
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_, y_pred_test_submission_, \n",
    "                    score_, seed_, level_='1', target_='target', cutoff_value_=.6, gera_submission_=True, \n",
    "                    type_model_=1):    \n",
    "    \n",
    "    level       = 'n' + level_ + '/'\n",
    "    model_name_ = model_name_.replace('.csv', '')\n",
    "    \n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_)  + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        \n",
    "        delete_files(model_name_)\n",
    "        \n",
    "        jb.dump(y_pred_train_prob_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        \n",
    "        if type_model_!=3:\n",
    "            jb.dump(model_, path_name_model)\n",
    "        #else: \n",
    "         #   model_.save(path_name_model)\n",
    "                \n",
    "        if gera_submission_:\n",
    "            df_submission[target_] = y_pred_test_submission_\n",
    "            df_submission.to_csv(path_ + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "36458054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:39:33.788548Z",
     "start_time": "2022-11-26T17:39:33.617415Z"
    },
    "code_folding": [
     0,
     41
    ],
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1669317973752,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "36458054"
   },
   "outputs": [],
   "source": [
    "def model_cv_fit_(models_, X_, y_, X_test_, path_, target_='pred', seed_=12359, print_report_=False, \n",
    "                 print_score_mdl_=True, n_splits_=5, create_sub_=False, var_th_=1.0e-03, level_='1',\n",
    "                 save_ensamble_=True, clip_=1e-6, batch_size_=2048):\n",
    "    \n",
    "    cols        = []\n",
    "    cols_score  = []\n",
    "    df_history  = pd.DataFrame()\n",
    "    num_model   = len(models_)+1\n",
    "    oof_train   = np.zeros((len(X_), num_model))\n",
    "    oof_test    = np.zeros((len(X_test_), num_model-1))\n",
    "    score_mdl   = np.zeros(len(models_),)    \n",
    "    kf          = StratifiedKFold(shuffle=True, n_splits=n_splits_, random_state=seed_)        \n",
    "    X_ts        = scipy.special.logit(X_test_.clip(clip_, 1-clip_))\n",
    "    \n",
    "    for i, m in enumerate(models_):\n",
    "        \n",
    "        time_start  = datetime.now()        \n",
    "        model       = m[1]\n",
    "        type_model  = m[2]\n",
    "        name_sub    = m[3]\n",
    "        score_list  = []\n",
    "        y_ts_pred   = 0 \n",
    "        \n",
    "        delete_files(name_sub)\n",
    "        \n",
    "        print()\n",
    "        print('=> {} - {}'.format(m[0], seed_))\n",
    "        print('='*73)\n",
    "\n",
    "        for fold, (idx_tr, idx_va) in enumerate(kf.split(X_, y_)):\n",
    "            \n",
    "            time_fold_start = datetime.now()\n",
    "            \n",
    "            X_tr = scipy.special.logit(X_.iloc[idx_tr].clip(clip_, 1-clip_))\n",
    "            X_va = scipy.special.logit(X_.iloc[idx_va].clip(clip_, 1-clip_))\n",
    "            y_tr = y_.iloc[idx_tr]\n",
    "            y_va = y_.iloc[idx_va]\n",
    "            \n",
    "            if type_model==1:\n",
    "                model.fit(X_tr, y_tr)\n",
    "\n",
    "            if type_model==2:\n",
    "                model.fit(X_tr, y_tr, \n",
    "                          model__eval_set=[(X_va, y_va)], \n",
    "                          model__eval_metric ='binary_logloss', \n",
    "                          model__callbacks=[early_stopping(100)])\n",
    "            \n",
    "            if type_model==3:   \n",
    "\n",
    "                X_ts_ = X_ts.copy()\n",
    "               \n",
    "                if m[6] is not None:\n",
    "                    process = m[6].fit(X_tr, y_tr)                                    \n",
    "                    X_tr    = process.transform(X_tr) \n",
    "                    X_va    = process.transform(X_va)  \n",
    "                    X_ts_   = process.transform(X_ts_)\n",
    "                    \n",
    "                history = model.fit(X_tr, y_tr,\n",
    "                                    epochs          = 1000, \n",
    "                                    batch_size      = batch_size_,\n",
    "                                    callbacks       = [m[4], m[5]], # [early_stopping, plateau],\n",
    "                                    validation_data = (X_va, y_va), \n",
    "                                    shuffle         = True, \n",
    "                                    verbose         = False)  \n",
    "                \n",
    "                y_va_pred  = model.predict(X_va, verbose=False)\n",
    "                y_ts_pred += model.predict(X_ts_, verbose=False)/kf.n_splits         \n",
    "                \n",
    "                val_loss  = log_loss(y_va, y_va_pred)  \n",
    "                val_f1    = f1_score(y_va,(y_va_pred>.5).astype(int))  \n",
    "\n",
    "                _df          = pd.DataFrame(history.history)\n",
    "                _df['fold']  = fold +1 \n",
    "                _df['score'] = val_loss \n",
    "                df_history   = pd.concat([df_history, _df], axis=0)\n",
    "                \n",
    "                # Log metrics\n",
    "                #run.log({'val_loss': val_loss, 'val_f1': val_f1})\n",
    "\n",
    "            if type_model!=3:\n",
    "                y_va_pred  = model.predict_proba(X_va)[:,1]\n",
    "                y_ts_pred += model.predict_proba(X_ts)[:,1]/kf.n_splits                      \n",
    "            \n",
    "            logloss    = log_loss(y_va, y_va_pred) \n",
    "            f1         = f1_score(y_va, (y_va_pred>.5).astype(int))\n",
    "            roc_auc    = roc_auc_score(y_va, (y_va_pred>.5).astype(int))            \n",
    "            \n",
    "            oof_train[idx_va, i]           = np.ravel(y_va_pred)\n",
    "            oof_train[idx_va, num_model-1] = fold + 1\n",
    "            \n",
    "            time_fold_end = utility.diff(time_fold_start, datetime.now())\n",
    "            \n",
    "            msg = \"Fold {} => L.Loss: {:2.5f} - F1-score: {:2.5f} - AUC:{:2.5f} - {}\"            \n",
    "            print(msg.format(fold+1,logloss,f1,roc_auc, time_fold_end))\n",
    "            \n",
    "            score_list.append(logloss)\n",
    "\n",
    "        #tf.keras.backend.clear_session()\n",
    "        \n",
    "        oof_test[:,i] = np.ravel(y_ts_pred)\n",
    "        score_mean    = np.mean(score_list).round(5)\n",
    "        \n",
    "        cols.append(m[0])\n",
    "        cols_score.append(str.lower(m[0])+'_'+str(score_mean)+'_seed_{}'.format(seed_))\n",
    "                \n",
    "        if create_sub_:\n",
    "            if target_ is None: target_=target\n",
    "            name_sub = name_sub+'_{:2.5f}_folds_{}_seed_{}.csv'.format(score_mean, n_splits_, seed_)\n",
    "\n",
    "            save_data_model(model_                  = model, \n",
    "                            model_name_             = name_sub, \n",
    "                            path_                   = path_, \n",
    "                            y_pred_train_prob_      = oof_train[:, i], \n",
    "                            y_pred_test_prob_       = oof_test[:,i], \n",
    "                            y_pred_test_submission_ = oof_test[:,i], \n",
    "                            score_                  = score_mean, \n",
    "                            seed_                   = seed_, \n",
    "                            level_                  = level_, \n",
    "                            target_                 = target_, \n",
    "                            cutoff_value_           = .1, \n",
    "                            gera_submission_        = True, \n",
    "                            type_model_             = type_model)  \n",
    "        \n",
    "        score_mdl[i] = score_mean\n",
    "        \n",
    "        time_end = utility.diff(time_start, datetime.now()) \n",
    "        \n",
    "        print('-'*73)\n",
    "        print(f'{Fore.GREEN}{Style.BRIGHT}[Fold Mean] L.Loss: {score_mean:.5f}{Style.RESET_ALL} - {time_end}') \n",
    "        print('='*73)\n",
    "        \n",
    "        if print_report_: \n",
    "            y_pred = (oof_train[:, i]>.5).astype(int)\n",
    "            print()\n",
    "            print(classification_report(y_, y_pred))\n",
    "            print(confusion_matrix(y_, y_pred))    \n",
    "\n",
    "        utility.free_gpu_cache()\n",
    "           \n",
    "    df_oof_tr         = pd.DataFrame(oof_train, columns=cols_score+['fold']) \n",
    "    df_oof_tr['fold'] = df_oof_tr['fold'].astype(int)\n",
    "    df_oof_ts         = pd.DataFrame(oof_test, columns=cols_score) \n",
    "    df_score_mdl      = pd.DataFrame(score_mdl, columns= ['score'])\n",
    "    \n",
    "    df_score_mdl.index = cols    \n",
    "    df_score_mdl       = df_score_mdl.sort_values(by='score',ascending=True)  \n",
    "    \n",
    "    if save_ensamble_:\n",
    "        jb.dump(df_oof_tr, path_ + 'Data/pkl/df_pred_tr_n{}.pkl.z'.format(level_))\n",
    "        jb.dump(df_oof_ts, path_ + 'Data/pkl/df_pred_ts_n{}.pkl.z'.format(level_));\n",
    "\n",
    "    if print_score_mdl_: display(df_score_mdl)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    return df_oof_tr, df_oof_ts, df_score_mdl, df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f8d426ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T02:35:02.815269Z",
     "start_time": "2022-11-27T02:35:02.660268Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_cv_fit(models_, X_, y_, X_test_, path_, target_='pred', seed_=12359, print_report_=False, \n",
    "                 print_score_mdl_=True, n_splits_=5, create_sub_=False, var_th_=1.0e-03, level_='1',\n",
    "                 save_ensamble_=True, cli_=1e-6, batch_size_=2048, kf_=None):\n",
    "    \n",
    "    cols        = []\n",
    "    cols_score  = []\n",
    "    num_model   = len(models_)+1\n",
    "    oof_train   = np.zeros((len(X_), num_model))\n",
    "    score_mdl   = np.zeros(len(models_),)\n",
    "    oof_test    = np.zeros((len(X_test_), num_model-1))\n",
    "    kf          = StratifiedKFold(shuffle=True, n_splits=n_splits_, random_state=seed_)        \n",
    "    X_ts        = scipy.special.logit(X_test_.clip(cli_, 1-cli_))\n",
    "    df_history  = pd.DataFrame()\n",
    "    \n",
    "    if kf_ is not None:\n",
    "        kf = kf_\n",
    "    else:  \n",
    "        jb.dump(kf, path_ + 'Data/pkl/StratifiedKFold_{}.pkl.z'.format(level_))\n",
    "\n",
    "    for i, m in enumerate(models_):\n",
    "        \n",
    "        time_start  = datetime.now()        \n",
    "        model       = m[1]\n",
    "        type_model  = m[2]\n",
    "        name_sub    = m[3]\n",
    "        score_list  = []\n",
    "        y_ts_pred   = 0 \n",
    "        \n",
    "        delete_files(name_sub)\n",
    "        \n",
    "        print()\n",
    "        print('=> {} - {}'.format(m[0], seed_))\n",
    "        print('='*73)\n",
    "\n",
    "        for fold, (idx_tr, idx_va) in enumerate(kf.split(X_, y_)):\n",
    "            \n",
    "            time_fold_start = datetime.now()\n",
    "            \n",
    "            X_tr = scipy.special.logit(X_.iloc[idx_tr].clip(cli_, 1-cli_))\n",
    "            X_va = scipy.special.logit(X_.iloc[idx_va].clip(cli_, 1-cli_))\n",
    "            y_tr = y_.iloc[idx_tr]\n",
    "            y_va = y_.iloc[idx_va]            \n",
    "            \n",
    "            if type_model==1:\n",
    "                model.fit(X_tr, y_tr)\n",
    "\n",
    "            if type_model==2:\n",
    "                model.fit(X_tr, y_tr, \n",
    "                          model__eval_set=[(X_va, y_va)], \n",
    "                          model__eval_metric ='binary_logloss', \n",
    "                          model__callbacks=[early_stopping(100)])\n",
    "            \n",
    "            if type_model==3:   \n",
    "                X_ts_ = X_ts.copy()    \n",
    "                if m[6] is not None:\n",
    "                    process = m[6].fit(X_tr, y_tr)                                    \n",
    "                    X_tr    = process.transform(X_tr) \n",
    "                    X_va    = process.transform(X_va)  \n",
    "                    X_ts_   = process.transform(X_ts_)\n",
    "                    \n",
    "                model, early_stopping, plateau=create_model(input_shape_=len(X_tr[0]), type_model_=m[7],seed_=fold+seed_)\n",
    "\n",
    "                history = model.fit(X_tr, y_tr,\n",
    "                                    epochs          = 1000, \n",
    "                                    batch_size      = batch_size_,\n",
    "                                    callbacks       = [m[4], m[5]], # [early_stopping, plateau],\n",
    "                                    validation_data = (X_va, y_va), \n",
    "                                    shuffle         = True, \n",
    "                                    verbose         = False)  \n",
    "                \n",
    "                y_va_pred  = model.predict(X_va, verbose=False)\n",
    "                y_ts_pred += model.predict(X_ts_, verbose=False)/kf.n_splits         \n",
    "                \n",
    "                val_loss  = log_loss(y_va, y_va_pred)  \n",
    "                val_f1    = f1_score(y_va,(y_va_pred>.5).astype(int))  \n",
    "\n",
    "                _df          = pd.DataFrame(history.history)\n",
    "                _df['model'] = m[3]\n",
    "                _df['fold']  = fold+1 \n",
    "                _df['score'] = val_loss \n",
    "                df_history   = pd.concat([df_history, _df], axis=0)\n",
    "            \n",
    "            if type_model!=3:\n",
    "                y_va_pred  = model.predict_proba(X_va)[:,1]\n",
    "                y_ts_pred += model.predict_proba(X_ts)[:,1]/kf.n_splits                      \n",
    "                \n",
    "            #y_va_pred  = model.predict_proba(X_va)[:,1]\n",
    "            #y_ts_pred += model.predict_proba(X_ts)[:,1]/kf.n_splits                      \n",
    "            logloss    = log_loss(y_va, y_va_pred) \n",
    "            f1         = f1_score(y_va, (y_va_pred>.5).astype(int))\n",
    "            roc_auc    = roc_auc_score(y_va, (y_va_pred>.5).astype(int))            \n",
    "            \n",
    "            oof_train[idx_va, i]           = y_va_pred if type_model!=3 else np.ravel(y_va_pred)\n",
    "            oof_train[idx_va, num_model-1] = fold + 1\n",
    "\n",
    "            time_fold_end = utility.diff(time_fold_start, datetime.now())\n",
    "            \n",
    "            msg = \"Fold {} => L.Loss: {:2.5f} - F1-score: {:2.5f} - AUC:{:2.5f} - {}\"            \n",
    "            print(msg.format(fold+1,logloss,f1,roc_auc, time_fold_end))\n",
    "            \n",
    "            score_list.append(logloss)\n",
    "\n",
    "        oof_test[:,i] = y_ts_pred if type_model!=3  else np.ravel(y_ts_pred)\n",
    "        score_mean    = np.mean(score_list).round(5)\n",
    "        score_std     = np.std(score_list).round(5)\n",
    "        \n",
    "        cols.append(m[0])\n",
    "        cols_score.append(str.lower(m[0])+'_'+str(score_mean)+'_seed_{}'.format(seed_))\n",
    "                \n",
    "        if create_sub_:\n",
    "            if target_ is None: target_=target\n",
    "            name_sub = name_sub+'_{:2.5f}_folds_{}_seed_{}.csv'.format(score_mean, n_splits_, seed_)\n",
    "\n",
    "            save_data_model(model_                  = model, \n",
    "                            model_name_             = name_sub, \n",
    "                            path_                   = path_, \n",
    "                            y_pred_train_prob_      = oof_train[:, i], \n",
    "                            y_pred_test_prob_       = oof_test[:,i], \n",
    "                            y_pred_test_submission_ = oof_test[:,i], \n",
    "                            score_                  = score_mean, \n",
    "                            seed_                   = seed_, \n",
    "                            level_                  = level_, \n",
    "                            target_                 = target_, \n",
    "                            cutoff_value_           = .1, \n",
    "                            gera_submission_        = True, \n",
    "                            type_model_             = type_model)  \n",
    "        \n",
    "        score_mdl[i] = score_mean\n",
    "        \n",
    "        time_end = utility.diff(time_start, datetime.now()) \n",
    "        \n",
    "        msg=f'{Fore.GREEN}{Style.BRIGHT}[Fold Mean] L.Loss: {score_mean:.5f} - \\\n",
    "             {score_std:.5f}+- {Style.RESET_ALL}-{time_end}'\n",
    "        \n",
    "        msg = '{}{}[Fold Mean] L.Loss: {:.5f} - {:.5f} +- {} - {}'.format(Fore.GREEN,\n",
    "                                                                          Style.BRIGHT, \n",
    "                                                                          score_mean, score_std, \n",
    "                                                                          Style.RESET_ALL, \n",
    "                                                                          time_end)\n",
    "        print('-'*73)\n",
    "        print(msg) \n",
    "        print('='*73)\n",
    "        \n",
    "        if print_report_: \n",
    "            y_pred = (oof_train[:, i]>.5).astype(int)\n",
    "            print()\n",
    "            print(classification_report(y_, y_pred))\n",
    "            print(confusion_matrix(y_, y_pred))    \n",
    "\n",
    "        utility.free_gpu_cache()\n",
    "    \n",
    "    df_oof_tr         = pd.DataFrame(oof_train, columns=cols_score+['fold']) \n",
    "    df_oof_tr['fold'] = df_oof_tr['fold'].astype(int)\n",
    "    df_oof_ts         = pd.DataFrame(oof_test, columns=cols_score) \n",
    "    df_score_mdl      = pd.DataFrame(score_mdl, columns= ['score'])\n",
    "    \n",
    "    df_score_mdl.index = cols    \n",
    "    df_score_mdl       = df_score_mdl.sort_values(by='score',ascending=True)  \n",
    "    \n",
    "    df_score_mdl.index = cols    \n",
    "    df_score_mdl       = df_score_mdl.sort_values(by='score',ascending=True)  \n",
    "    \n",
    "    if save_ensamble_:\n",
    "        jb.dump(df_oof_tr, path_ + 'Data/pkl/df_pred_tr_tensor_f_n{}.pkl.z'.format(level_))\n",
    "        jb.dump(df_oof_ts, path_ + 'Data/pkl/df_pred_ts_tensor_f_n{}.pkl.z'.format(level_));\n",
    "\n",
    "    if print_score_mdl_: display(df_score_mdl)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    return df_oof_tr, df_oof_ts, df_score_mdl, df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f537851d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T02:59:52.821342Z",
     "start_time": "2022-11-27T02:59:51.981678Z"
    },
    "code_folding": [
     2,
     7,
     28,
     64,
     81,
     87,
     132,
     153,
     205,
     288,
     365,
     388,
     393,
     405,
     604,
     779
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [257], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#from operator import le\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTunningModels\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m   \u001b[38;5;28;01mimport\u001b[39;00m RidgeClassifier\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#from operator import le\n",
    "\n",
    "class TunningModels(nn.Module):\n",
    "\n",
    "    from sklearn.preprocessing  import StandardScaler\n",
    "    from sklearn.linear_model   import RidgeClassifier\n",
    "    \n",
    "    def __init__(self, name_model_, X_trn_, y_trn_, X_ts_, feature_=None, \n",
    "                 seed_=12359, scaler_=StandardScaler(), feature_bin_=None, \n",
    "                 target_='target', path_='', level_='1', sc_second_= None, \n",
    "                 n_splits_=5):\n",
    "        \n",
    "        super(TunningModels,self).__init__() \n",
    "\n",
    "        self.name_clf    = name_model\n",
    "        self.X_trn       = X_trn_\n",
    "        self.y_trn       = y_trn_\n",
    "        self.X_ts        = X_ts_         \n",
    "        self.feature     = feature_\n",
    "        self.seed        = seed_\n",
    "        self.scaler      = scaler_\n",
    "        self.feature_bin = feature_bin_ \n",
    "        self.target      = target_\n",
    "        self.path        = path_\n",
    "        self.level       = level_\n",
    "        self.sc_second   = sc_second_\n",
    "        self.n_splits    = n_splits_\n",
    "\n",
    "    def recover_prediction_first_level():\n",
    "        \n",
    "        preds_train1 = glob.glob(\"model/train/*.pkl.z\")\n",
    "        preds_test   = glob.glob(\"model/test/*.pkl.z\")\n",
    "        preds_val1   = glob.glob(\"model/valid/*.pkl.z\")\n",
    "\n",
    "        df_train1     = []\n",
    "        scores_traint = dict()\n",
    "\n",
    "        for p_name in preds_train1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/train\\\\', '')])    \n",
    "            df_train1.append(p_df)    \n",
    "            scores_traint[p_name] = f1_score(y_train1, (p_df>.5))\n",
    "\n",
    "        df_val1     = [] \n",
    "        scores_val1 = dict()\n",
    "        for p_name in preds_val1:    \n",
    "            p    = jb.load(p_name)\n",
    "            p_df = pd.DataFrame(p, columns=[p_name.replace('model/valid\\\\', '')])    \n",
    "            df_val1.append(p_df)    \n",
    "            scores_val1[p_name] = f1_score(y_val1, (p_df>.5))\n",
    "\n",
    "        df_test     = [] \n",
    "        scores_test = dict()\n",
    "        for p_name in preds_test:    \n",
    "            p         = jb.load(p_name)\n",
    "            p_df_test = pd.DataFrame(p, columns=[p_name.replace('model/test\\\\', '')])    \n",
    "            df_test.append(p_df_test)\n",
    "\n",
    "        df_train1 = pd.concat(df_train1, axis=1)\n",
    "        df_val1   = pd.concat(df_val1, axis=1)\n",
    "        df_test   = pd.concat(df_test, axis=1)\n",
    "\n",
    "        return df_train1, df_val1, df_test.shape\n",
    "        \n",
    "    def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):\n",
    "                        os.remove(os.path.join(raiz, arquivo))\n",
    " \n",
    "    def logging_callback(study, frozen_trail):\n",
    "        prev_best = study.user_attrs.get('prev_best', None)\n",
    "        if prev_best != study.best_value:\n",
    "            study.set_user_attr('prev_best', study.best_value)\n",
    "            print(f\"Trail {frozen_trail.number} finished with best value {frozen_trail.value}\")\n",
    "\n",
    "    def df_return_preds_tunning(model_name=None, level=1, target_='target', train_shape_row=0, test_shape_row=0): \n",
    "\n",
    "        if level==1: \n",
    "            level_ = 'n1'\n",
    "        else: \n",
    "            if level==2:\n",
    "                level_ = 'n2'\n",
    "            else: \n",
    "                level_ = 'n3'\n",
    "\n",
    "        paths = ['model/preds/test/'+ level_, 'model/preds/train/' + level_ ]    \n",
    "\n",
    "        if model_name==None: \n",
    "            model_name=''\n",
    "\n",
    "        for i, path in enumerate(paths): \n",
    "\n",
    "            name_file_pkl     = glob.glob(path + '/'+ model_name + '*.pkl.z')\n",
    "            dic_preds_mdl_pkl = dict()\n",
    "\n",
    "            for p_name in name_file_pkl:    \n",
    "                y_model_pkl_name_col  = p_name.replace(path + '/', '').replace('.pkl.z','') \n",
    "                y_model_pkl           = jb.load(p_name)   \n",
    "\n",
    "                if i==0:\n",
    "                    if len(y_model_pkl)==test_shape_row:\n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                if i==1:\n",
    "                    if len(y_model_pkl)==train_shape_row:                        \n",
    "                        dic_preds_mdl_pkl[y_model_pkl_name_col] = y_model_pkl\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            if i==0:         \n",
    "                X_test_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "            else:\n",
    "                X_train_pred_nivel_1 = pd.DataFrame(dic_preds_mdl_pkl)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "        X_train_pred_nivel_1[target_] = y\n",
    "\n",
    "        return X_train_pred_nivel_1, X_test_pred_nivel_1\n",
    "    \n",
    "    def feature_select(mdl, feature=[], best_score=0):\n",
    "    \n",
    "        best_feature = ''\n",
    "\n",
    "        for col in df_train1.columns:\n",
    "\n",
    "            if col not in feature:\n",
    "                Xtr  = df_train1[feature+[col]].copy()\n",
    "                Xval = df_val1[feature+[col]].copy()                \n",
    "\n",
    "                mdl.fit(Xtr, y_train1)\n",
    "\n",
    "                p = mdl.predict(Xval)\n",
    "                c = f1_score(y_val1, p)\n",
    "\n",
    "                if c > best_score:\n",
    "                    best_score = c\n",
    "                    best_feature = col \n",
    "\n",
    "        return best_score, best_feature\n",
    "\n",
    "    def permutation_test(mdl, feature_selected):\n",
    "\n",
    "        dist = []\n",
    "\n",
    "        for seed in range(100):\n",
    "\n",
    "            Xtr  = df_train1[feature_selected].copy()\n",
    "            Xval = df_val1[feature_selected].copy()\n",
    "\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            Xtr['random']  = np.random.permutation(Xtr.iloc[:, -1].values)\n",
    "            Xval['random'] = np.random.permutation(Xval.iloc[:, -1].values)\n",
    "\n",
    "            mdl.fit(Xtr, y_train1)\n",
    "\n",
    "            p = mdl.predict(Xval)\n",
    "            c = f1_score(y_val1, p)\n",
    "\n",
    "            dist.append(c)\n",
    "\n",
    "        dist = np.array(dist)\n",
    "\n",
    "        return dist.max()\n",
    "\n",
    "    def feature_selected_model(model = RidgeClassifier(alpha=1.) ):\n",
    "   \n",
    "        score_feature, best_feature =  TunningModels.feature_select(model)\n",
    "        print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        feature_selected = []\n",
    "        feature_selected.append(best_feature)\n",
    "\n",
    "        loop = True\n",
    "\n",
    "        while loop:\n",
    "\n",
    "            best_score = TunningModels.permutation_test(model, feature_selected) \n",
    "            best_score = best_score + 1e-4\n",
    "\n",
    "            score_feature, best_feature = TunningModels.feature_select(model, feature=feature_selected, best_score=best_score)\n",
    "            \n",
    "\n",
    "            if score_feature <= best_score:  \n",
    "                print('Fim')\n",
    "                loop= False\n",
    "            else: \n",
    "                feature_selected.append(best_feature)\n",
    "                print('Score: {:2.4f} => Feature: {}'. format(score_feature*100 , best_feature))\n",
    "\n",
    "        return feature_selected\n",
    "    \n",
    "    def model_of_diversity_feature_group(model_, name_model, X_, y_, X_ts_, sc_, target_, feature_imp_num=5, \n",
    "                                         seed_=12359, path_=''):\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        cols_tr = X_.columns.to_list() \n",
    "        cols_ts = cols_tr.copy()\n",
    "        cols_ts.remove('sample_weight')\n",
    "\n",
    "        model = model_\n",
    "        model = model.fit(X_[cols_ts], y_)\n",
    "\n",
    "        df               = pd.DataFrame()\n",
    "        df[\"feature\"]    = cols_ts\n",
    "        df[\"importance\"] = model.feature_importances_\n",
    "\n",
    "        df.sort_values(\"importance\", axis=0, ascending=False, inplace=True)\n",
    "\n",
    "        feature_import = df[:feature_imp_num]['feature'].to_list()\n",
    "\n",
    "        for feature_imp in  feature_import:\n",
    "\n",
    "            score_                =  0.09\n",
    "            feature_best          = []\n",
    "            feature               = X_ts_.columns            \n",
    "            feature               = [s for s in feature if s not in feature_import]\n",
    "            feature_number        = len(feature)\n",
    "            feature_select_number = np.round(np.sqrt(len(feature)))\n",
    "            feature_number_sample = int(np.round((feature_number/feature_select_number)))\n",
    "            feature_sample        = []\n",
    "\n",
    "            print('='*60)\n",
    "            print(' Divercidade de Grupos de Features => ({})'.format(feature_imp))\n",
    "            print('='*60)\n",
    "\n",
    "\n",
    "            for i in  range(0,5):\n",
    "\n",
    "                feature            = [s for s in feature if s not in feature_sample]\n",
    "                feature_sample     = pd.Series(feature).sample(feature_number_sample).to_list() \n",
    "                name_model_xgb_div = name_model + 'group_fe_' + str(i)   \n",
    "\n",
    "                feature_sample.append(feature_imp)\n",
    "                feature_sample_ts = feature_sample.copy()\n",
    "\n",
    "                feature_sample.append('sample_weight')\n",
    "\n",
    "                model, score, df_feature_imp , df_preds_prob, y_pred_test = \\\n",
    "                TunningModels.train_model_cv(model_         = model_, \n",
    "                                             X_             = X_[feature_sample], \n",
    "                                             y_             = y_, \n",
    "                                             X_test_        = X_ts_[feature_sample_ts], \n",
    "                                             target_        = target_, \n",
    "                                             model_name_    = name_model_xgb_div, \n",
    "                                             sc_            = sc_, \n",
    "                                             sc_second_     = None, \n",
    "                                             n_splits_      = 3, \n",
    "                                             seed_          = seed_,\n",
    "                                             path_          = path_, \n",
    "                                             save_predict_  = True, \n",
    "                                             level_         = '1', \n",
    "                                             print_result_  = False, \n",
    "                                             feature_       = None, \n",
    "                                             trial_         = None)\n",
    "\n",
    "                if score >.59:\n",
    "                    create = '*'\n",
    "                else: \n",
    "                    create = ' '\n",
    "\n",
    "                if score > score_:\n",
    "                    # score_ = np.abs(score)\n",
    "                    feature_best.append(feature)\n",
    "                    print('Score: {:2.5f} =>{} Gr.Feature: {} {}'.format(score, create, i,''))\n",
    "\n",
    "                gc.collect()\n",
    "\n",
    "            print('')\n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "\n",
    "    def model_of_diversity_feature_one_(model, name_model, seed_=12359):\n",
    "\n",
    "        score_       =  0.09\n",
    "        feature_best = []\n",
    "\n",
    "        print('')\n",
    "        print('Feature apenas uma')\n",
    "        print('-'*20)\n",
    "\n",
    "        TunningModels.delete_files(name_model)\n",
    "\n",
    "        for feature in X_train.columns:\n",
    "\n",
    "            name_model_xgb_div = name_model + feature \n",
    "\n",
    "            score = TunningModels.cross_valid(model       = model, \n",
    "                                              model_name_ = name_model_xgb_div, \n",
    "                                              X_          = X, \n",
    "                                              y_          = y, \n",
    "                                              X_test_     = X_test_sc_qt, \n",
    "                                              type_model  = 2, \n",
    "                                              feature     = feature,\n",
    "                                              seed        = seed_, \n",
    "                                              tunning     = 1, \n",
    "                                              print_result= False, \n",
    "                                              n_splits    = 2\n",
    "                                              )\n",
    "            if score >.59:\n",
    "                create = '*'\n",
    "            else: \n",
    "                create = ' '\n",
    "\n",
    "            if score > score_:\n",
    "                score_ = np.abs(score)\n",
    "                feature_best.append(feature)\n",
    "                print('F1-score: {:2.5f} => {} feature: {}'.format(score, create, feature ))        \n",
    "\n",
    "        print('')\n",
    "        print('Feature dupla')\n",
    "        print('-'*20)\n",
    "\n",
    "        for feature in feature_best:\n",
    "\n",
    "            for feature_ in feature_best:\n",
    "                if feature != feature_:            \n",
    "                    name_model_xgb_div = name_model + feature + '_' + feature_     \n",
    "\n",
    "                    score = TunningModels.cross_valid(model       = model, \n",
    "                                                      model_name_ = name_model_xgb_div, \n",
    "                                                      X_          = X, \n",
    "                                                      y_          = y, \n",
    "                                                      X_test_     = X_test_sc_qt, \n",
    "                                                      type_model  = 2, \n",
    "                                                      feature     = [feature, feature_],\n",
    "                                                      seed        = seed_, \n",
    "                                                      tunning     = 1, \n",
    "                                                      print_result= False, \n",
    "                                                      n_splits    = 2\n",
    "                                                      )\n",
    "\n",
    "                    if score >.59:\n",
    "                        create = '*'\n",
    "                    else: \n",
    "                        create = ' '\n",
    "\n",
    "                    print('F1-score: {:.4f} => {} feature: {} | {}'.format(score*100, create,  feature, feature_ )) \n",
    "\n",
    "        print('')\n",
    "        print('FIM')\n",
    "        print('')\n",
    "    \n",
    "\n",
    "\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_,\n",
    "                        y_pred_test_, score_, seed_, level_='1', target_='target'):\n",
    "        \n",
    "        level_ = 'n'+ level_ + '/'\n",
    "\n",
    "        if score_>.6:          \n",
    "\n",
    "            path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_)\n",
    "            path_name_train = path_ + 'model/preds/train/' + level_ + model_name_.format(score_, seed_)\n",
    "            path_name_test  = path_ + 'model/preds/test/'  + level_ + model_name_.format(score_, seed_)    \n",
    "            path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)    \n",
    "\n",
    "            jb.dump(y_pred_train_prob_, path_name_train)\n",
    "            jb.dump(y_pred_test_prob_, path_name_test)\n",
    "            jb.dump(model_, path_name_model)\n",
    "            #jb.dump(pd.DataFrame([model_[0][0]['model'].get_params()]), path_name_param)   \n",
    "\n",
    "            if score_>.7:                \n",
    "                # Gerar o arquivo de submissão \n",
    "                df_submission[target_] = y_pred_test_\n",
    "                name_file_sub =  path_ + 'Data/submission/tunning/' + model_name_.format(score_, seed_) + '.csv'\n",
    "                df_submission.to_csv(name_file_sub, index = False)\n",
    "                \n",
    "    def diff(t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "        \n",
    "    def feature_scaler(df_, scaler_=None, feature_bin_=None):\n",
    "    \n",
    "        if scaler_!=None: \n",
    "            \n",
    "            #if feature_bin_!=None:\n",
    "            #    disc = KBinsDiscretizer(n_bins=50, encode='ordinal', strategy='uniform')\n",
    "            #    df_[feature_bin_] = disc.fit_transform(df_[feature_bin_])\n",
    "\n",
    "            df_ = pd.DataFrame(scaler_.fit_transform(df_), columns=df_.columns)\n",
    "    \n",
    "        return df_\n",
    "\n",
    "    def cross_valid(model_, model_name_, X_train_, y_train_, X_test_, fold_=5, target_='target', \n",
    "            path_='', level_='1', save_predict_=True, print_result_=True, seed_=12359, \n",
    "            feature_=None, feature_bin=None, scaler_=StandardScaler(), threshold=.5, print_report_=False \n",
    "            ):\n",
    "\n",
    "        if feature_!=None: \n",
    "            X_train_ = X_train_[feature_]\n",
    "            X_test_  = X_test_[feature_]\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Escorpo de variáveis\n",
    "        #--------------------------------------------------------\n",
    "\n",
    "        time_pred_start    = datetime.now()\n",
    "        preds_valid_f      = {}\n",
    "        preds_test         = []\n",
    "        total_auc          = []\n",
    "        f_scores           = []\n",
    "        auc_mean           = []\n",
    "        f1_mean            = []\n",
    "        lloss_mean         = []\n",
    "        preds_test         = 0  \n",
    "        pred_test_prob     = 0\n",
    "        df_score_history   = pd.DataFrame()\n",
    "        df_train_pred_fold = pd.DataFrame()\n",
    "        df_pred_fold       = pd.DataFrame()\n",
    "        random             = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_        = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'\n",
    "        clf_name           = model_.__class__.__name__\n",
    "        pri_result         = 92\n",
    "        learning_rate      = model_.learning_rate         \n",
    "        le                 = LabelEncoder()\n",
    "        y_train_           = pd.DataFrame(le.fit_transform(y_train_), columns=[target_])\n",
    "                                                   \n",
    "        #--------------------------------------------------------  \n",
    "        # Início do process de varilidação\n",
    "        #--------------------------------------------------------\n",
    "        have_observation=''\n",
    "\n",
    "        if print_result_:\n",
    "            num_parallel_tree = 1 #model_.get_params()['num_parallel_tree']\n",
    "            learning_rate     = model_.learning_rate\n",
    "            n_estimators      = model_.n_estimators * num_parallel_tree  \n",
    "            max_depth         = model_.max_depth \n",
    "            msg               = 'Training model: {} - seed {} - n_estimators: {} - learning_rate: {} {:2.5f}'\n",
    "\n",
    "            print('='*pri_result)            \n",
    "            print(msg.format(clf_name, seed_, n_estimators, max_depth, learning_rate))\n",
    "            print('='*pri_result)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=fold_, random_state=42, shuffle=True)\n",
    "\n",
    "        for fold,(idx_train, idx_val) in enumerate(kf.split(X_train_, y_train_, groups=y_train_)):\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Seleção dos dados\n",
    "            #--------------------------------------------------------\n",
    "            X_trn, X_val = X_train_.iloc[idx_train], X_train_.iloc[idx_val]\n",
    "            y_trn, y_val = y_train_.iloc[idx_train], y_train_.iloc[idx_val]\n",
    "            index_valid  = idx_train\n",
    "\n",
    "             \n",
    "        \n",
    "            #--------------------------------------------------------  \n",
    "            # Processamento\n",
    "            #--------------------------------------------------------        \n",
    "            X_trn = TunningModels.feature_scaler(X_trn, scaler_, feature_bin) \n",
    "            X_val = TunningModels.feature_scaler(X_val, scaler_, feature_bin) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Modelo\n",
    "            #--------------------------------------------------------\n",
    "            model = model_.fit(X_trn, y_trn,\n",
    "                               eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                               early_stopping_rounds = int(n_estimators*.1),\n",
    "                               verbose               = False)\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # oof\n",
    "            #--------------------------------------------------------\n",
    "            preds_valid_proba = model.predict_proba(X_val, ntree_limit=model_.best_ntree_limit)\n",
    "            y_pred_valid      = le.inverse_transform(np.argmax(preds_valid_proba, axis=1))\n",
    "            \n",
    "            #--------------------------------------------------------  \n",
    "            # Obtenha os valores médios de cada fold para a previsão\n",
    "            #--------------------------------------------------------  \n",
    "            y_pred_test_prob = model.predict_proba(X_test_, ntree_limit=model_.best_ntree_limit)\n",
    "            pred_test_prob  += np.max(y_pred_test_prob, axis=1) / fold_\n",
    "            preds_test      += le.inverse_transform(np.argmax(y_pred_test_prob, axis=1)) / fold_\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Métricas \n",
    "            #-------------------------------------------------------- \n",
    "            y_val = le.inverse_transform(y_val)\n",
    "            acc   = metrics.accuracy_score(y_val, y_pred_valid)\n",
    "            f1    = metrics.f1_score(y_val, y_pred_valid, average='weighted')\n",
    "            prec  = metrics.precision_score(y_val, y_pred_valid, average='macro')\n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Concatenar validação e predição\n",
    "            #--------------------------------------------------------        \n",
    "            df_val_pred_fold = pd.DataFrame({'fold'     : fold+1,\n",
    "                                             'index'    : idx_val, \n",
    "                                             'acc'      : acc, \n",
    "                                             'f1'       : f1,\n",
    "                                             'prec'     : prec,                                              \n",
    "                                             'target'   : y_val, \n",
    "                                             'y_pred'   : y_pred_valid, \n",
    "                                             'pred_val' : np.max(preds_valid_proba, axis=1)\n",
    "                                             })\n",
    "\n",
    "            df_train_pred_fold = pd.concat([df_train_pred_fold, df_val_pred_fold], axis=0)\n",
    "\n",
    "            col_name        = le.inverse_transform(list(model.classes_))\n",
    "            df_prob_temp    = pd.DataFrame(preds_valid_proba, columns=col_name)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            \n",
    "            df_prob_temp['y_val']     = y_val\n",
    "            df_prob_temp['y_pred']    = y_pred_valid \n",
    "            df_prob_temp['y_proba']   = np.max(preds_valid_proba, axis=1)            \n",
    "            df_prob_temp['acc']       = acc   \n",
    "            df_prob_temp['f1']        = f1 \n",
    "            df_prob_temp['precision'] = prec              \n",
    "            df_prob_temp['fold']      = fold+1\n",
    "            df_prob_temp['index']     = idx_val   \n",
    "            \n",
    "            df_pred_fold = pd.concat([df_pred_fold, df_prob_temp], axis=0)\n",
    "            \n",
    "            del df_prob_temp\n",
    "            \n",
    "            #df_prob_temp['scaler']  = str(string_scaler)\n",
    "            \n",
    "            #preds_valid_proba = np.max(preds_valid_proba, axis=1)\n",
    "            \n",
    "            \n",
    "            auc_mean.append(acc)   \n",
    "            f1_mean.append(f1)    \n",
    "            lloss_mean.append(prec) \n",
    "\n",
    "            #--------------------------------------------------------  \n",
    "            # Print resultado Fold\n",
    "            #--------------------------------------------------------\n",
    "            if print_result_:\n",
    "                msg = 'Fold: {} - ACC: {:2.5f} - F1-score: {:2.5f} - Precision: {:2.5f} - {}'\n",
    "                time_fold_start_end = TunningModels.diff(time_fold_start, datetime.now())\n",
    "                print(msg.format(fold+1, acc, f1, prec, time_fold_start_end))\n",
    "\n",
    "            free_gpu_cache() \n",
    "        \n",
    "        \n",
    "\n",
    "        del X_trn, y_trn, X_val, y_val \n",
    "\n",
    "        df_train_pred_fold.sort_values(\"index\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Salvar predição em disco\n",
    "        #--------------------------------------------------------\n",
    "        X_train_prob      = df_train_pred_fold['pred_val'].to_list()\n",
    "        score             = np.mean(auc_mean)\n",
    "        y_pred_test       = np.int32(preds_test)\n",
    "\n",
    "        if save_predict_:\n",
    "            TunningModels.save_data_model(model_             = model_, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = X_train_prob, \n",
    "                                          y_pred_test_prob_  = pred_test_prob, \n",
    "                                          y_pred_test_       = y_pred_test,\n",
    "                                          score_             = score, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          )  \n",
    "\n",
    "        #--------------------------------------------------------  \n",
    "        # Print média dos Folds\n",
    "        #--------------------------------------------------------\n",
    "        time_pred_end = TunningModels.diff(time_pred_start, datetime.now())\n",
    "\n",
    "        if print_result_:\n",
    "            msg = '[Mean Fold]  ACC: {:.5f}(Std:{:.5f}) - F1: {:.5f} - Precision: {:.5f}  {}'        \n",
    "            print('-'*pri_result)            \n",
    "            print(msg.format(np.mean(auc_mean),np.std(auc_mean) , np.mean(f1_mean), np.mean(lloss_mean), time_pred_end))\n",
    "            print('='*pri_result)\n",
    "            print()\n",
    "            \n",
    "            if print_report_: \n",
    "                y_pred = df_train_pred_fold['y_pred']\n",
    "                y_vl   = df_train_pred_fold['target']\n",
    "                print(metrics.classification_report(y_vl, y_pred))\n",
    "\n",
    "        free_gpu_cache() \n",
    "\n",
    "        return model, score, y_pred_test, df_pred_fold        \n",
    "    \n",
    "    def train_model_cv(model_, X_, y_, X_test_, target_, model_name_, sc_=MinMaxScaler(), sc_second_=None, \n",
    "                       n_splits_=5, seed_=12359, path_='', save_predict_=True, level_='1', \n",
    "                       print_result_=True, feature_=None, trial_=None):\n",
    "            \n",
    "        if feature_!=None: \n",
    "            X_      = X_[feature_]\n",
    "            X_test_ = X_test_[feature_]\n",
    "            \n",
    "        taco              = 52 \n",
    "        y_preds_test      = []\n",
    "        y_preds_val_prob  = [] \n",
    "        y_preds_test_prob = []\n",
    "        score             = []\n",
    "        mdl               = []\n",
    "        random            = str(np.random.rand(1)[0]).replace('.','')\n",
    "        model_name_       = model_name_ + '_score_{:2.5f}_{}_' + random + '.pkl.z'    \n",
    "        clf_name          = model_.__class__.__name__        \n",
    "        df_preds_prob     = pd.DataFrame()\n",
    "        df_feature_imp    = pd.DataFrame()\n",
    "        time_start        = datetime.now()    \n",
    "        n_estimators      = model_.get_params()['n_estimators']\n",
    "        dub_scaler        = '=> Double Scaler' if sc_second_!=None else ''        \n",
    "        lb                = LabelEncoder()\n",
    "        y_                = pd.DataFrame(lb.fit_transform(y_), columns=[target_])\n",
    "        col_prob          = y_[target_].sort_values().unique()\n",
    "        vies              = np.array([0, 0, 0.03, 0.036, 0, 0, 0, 0, 0, 0]) \n",
    "        \n",
    "        if print_result_:\n",
    "            print('='*taco)\n",
    "            print('{} - n_estimators: {} seed: {}  {}'.format(clf_name, n_estimators, seed_, dub_scaler))\n",
    "            print('='*taco)\n",
    "\n",
    "        folds = StratifiedKFold(n_splits=n_splits_, shuffle=True, random_state=seed_)\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds.split(X_, y_)): #, groups=y\n",
    "\n",
    "            time_fold_start = datetime.now()\n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Separar dados para treino \n",
    "            # ----------------------------------------------------\n",
    "            X_trn, X_val, sample_weight_train = X_.iloc[trn_idx], X_.iloc[val_idx], X_.iloc[trn_idx]['sample_weight']\n",
    "            y_trn, y_val, sample_weight_valid = y_.iloc[trn_idx], y_.iloc[val_idx], X_.iloc[val_idx]['sample_weight'] \n",
    "\n",
    "            # ----------------------------------------------------\n",
    "            # Processamento\n",
    "            # ----------------------------------------------------        \n",
    "            X_trn.drop('sample_weight', axis=1, inplace=True)\n",
    "            X_val.drop('sample_weight', axis=1, inplace=True)\n",
    "\n",
    "            X_trn = pd.DataFrame(sc_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "            X_val = pd.DataFrame(sc_.transform(X_val), columns=X_val.columns)\n",
    "            X_tst = pd.DataFrame(sc_.transform(X_test_), columns=X_test_.columns)\n",
    "\n",
    "            if sc_second_ is not None: \n",
    "                X_trn = pd.DataFrame(sc_second_.fit_transform(X_trn), columns=X_trn.columns)\n",
    "                X_val = pd.DataFrame(sc_second_.transform(X_val), columns=X_val.columns)\n",
    "                X_tst = pd.DataFrame(sc_second_.transform(X_tst), columns=X_tst.columns)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Treinar o modelo \n",
    "            # ----------------------------------------------------     \n",
    "            model_.fit(X_trn, \n",
    "                       y_trn,\n",
    "                       sample_weight_train,\n",
    "                       eval_set              = [(X_trn, y_trn), (X_val, y_val)],          \n",
    "                       early_stopping_rounds = int(n_estimators*.1),\n",
    "                       verbose               = False)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Predição \n",
    "            # ----------------------------------------------------     \n",
    "            #y_pred_val       = model_.predict(X_val, ntree_limit=model_.best_ntree_limit)    \n",
    "            y_pred_val_prob  = model_.predict_proba(X_val, ntree_limit=model_.best_ntree_limit) \n",
    "            y_pred_test_prob = model_.predict_proba(X_tst, ntree_limit=model_.best_ntree_limit)\n",
    "\n",
    "            y_pred_val_prob += vies         \n",
    "            y_pred_val       = np.argmax(y_pred_val_prob, axis=1)\n",
    "\n",
    "            y_preds_test.append(model_.predict(X_tst))\n",
    "            y_preds_test_prob.append(y_pred_test_prob)\n",
    "\n",
    "            df_prob_temp    = pd.DataFrame(y_pred_val_prob, columns=col_prob)\n",
    "            y_pred_pbro_max = df_prob_temp.max(axis=1)\n",
    "\n",
    "            df_prob_temp['fold']    = fold+1\n",
    "            df_prob_temp['id']      = val_idx        \n",
    "            df_prob_temp['y_val']   = y_val.values        \n",
    "            df_prob_temp['y_pred']  = y_pred_val\n",
    "            df_prob_temp['y_proba'] = np.max(y_pred_val_prob, axis=1)\n",
    "\n",
    "            df_preds_prob = pd.concat([df_preds_prob, df_prob_temp], axis=0)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Score \n",
    "            # ---------------------------------------------------- \n",
    "            acc = metrics.accuracy_score(y_val, y_pred_val, sample_weight=sample_weight_valid)\n",
    "            score.append(acc)     \n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Print resultado  \n",
    "            # ---------------------------------------------------- \n",
    "            time_fold_end = diff(time_fold_start, datetime.now())        \n",
    "            msg = '[Fold {}] ACC: {:2.5f} -  {}'\n",
    "            \n",
    "            if print_result_:\n",
    "                print(msg.format(fold+1, acc, time_fold_end))\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Feature Importance\n",
    "            # ----------------------------------------------------             \n",
    "            feat_imp = pd.DataFrame(index   = X_trn.columns,\n",
    "                                    data    = model_.feature_importances_,                            \n",
    "                                    columns = ['fold_{}'.format(fold+1)])\n",
    "\n",
    "            feat_imp['acc_'+str(fold+1)] = acc\n",
    "            df_feature_imp = pd.concat([df_feature_imp, feat_imp], axis=1)\n",
    "\n",
    "            # ---------------------------------------------------- \n",
    "            # Salva o modelo \n",
    "            # ---------------------------------------------------- \n",
    "            dic_model = {'scaler': sc_, \n",
    "                         'scaler_second': sc_second_,\n",
    "                         'fold': fold+1,\n",
    "                         'model': model_,                         \n",
    "                         'vies': vies}\n",
    "\n",
    "            mdl.append(dic_model)\n",
    "            \n",
    "            if trial_ is not None:\n",
    "                trial_.report(acc, fold)\n",
    "                if trial_.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            time_end = diff(time_start, datetime.now())   \n",
    "\n",
    "        acc_mean = np.mean(score) \n",
    "        acc_std  = np.std(score)\n",
    "        \n",
    "        df_preds_prob.sort_values(\"id\", axis=0, ascending=True, inplace=True)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Pós-processamento\n",
    "        # referencia: https://www.kaggle.com/ambrosm/tpsfeb22-02-postprocessing-against-the-mutants\n",
    "        # -------------------------------        \n",
    "        y_proba  = sum(y_preds_test_prob) / len(y_preds_test_prob)\n",
    "        y_proba += vies          \n",
    "\n",
    "        y_pred_test       = np.argmax(y_proba, axis=1)\n",
    "        y_pred_tuned      = lb.inverse_transform(y_pred_test)\n",
    "        y_pred_tuned_prob = np.max(y_proba, axis=1)\n",
    "\n",
    "        if save_predict_:                 \n",
    "            TunningModels.save_data_model(model_             = mdl, \n",
    "                                          model_name_        = model_name_, \n",
    "                                          path_              = path_, \n",
    "                                          y_pred_train_prob_ = df_preds_prob['y_proba'], \n",
    "                                          y_pred_test_prob_  = y_pred_tuned_prob, \n",
    "                                          y_pred_test_       = y_pred_tuned,\n",
    "                                          score_             = acc_mean, \n",
    "                                          seed_              = seed_, \n",
    "                                          level_             = level_, \n",
    "                                          target_            = target_\n",
    "                                          ) \n",
    "\n",
    "        if print_result_:\n",
    "            print('-'*taco)\n",
    "            print('[Mean Fold] ACC: {:2.5f} std: {:2.5f} - {}'.format(acc_mean, acc_std, time_end))    \n",
    "            print('='*taco)\n",
    "            print()\n",
    "\n",
    "        del X_trn, X_val, y_trn, y_val, feat_imp\n",
    "\n",
    "        return mdl, acc_mean , df_feature_imp , df_preds_prob, y_pred_test\n",
    "   \n",
    "    def xgb(self, trial):\n",
    "           \n",
    "        # https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "        # https://amangupta16.medium.com/xgboost-hyperparameters-explained-bb6ce580501d     \n",
    "        \n",
    "        eval_metric = ['mlogloss']\n",
    "                \n",
    "        params = {'objective'         : trial.suggest_categorical('objective', ['multi:softprob']), \n",
    "                  'booster'           : trial.suggest_categorical('booster', ['gbtree']),                 \n",
    "                  'eval_metric'       : trial.suggest_categorical('eval_metric', ['mlogloss']), \n",
    "                  'use_label_encoder' : trial.suggest_categorical('use_label_encoder', ['False']),                   \n",
    "                  'n_estimators'      : trial.suggest_int('n_estimators', 550, 1500, 100),                  \n",
    "                  'max_depth'         : trial.suggest_int('max_depth', 5, 15),\n",
    "                  'subsample'         : trial.suggest_discrete_uniform('subsample', .7, 1.0, .05), \n",
    "                  'learning_rate'     : trial.suggest_discrete_uniform('learning_rate', .01, 0.19, 0.01),\n",
    "                  'reg_alpha'         : trial.suggest_int('reg_alpha', 1, 10), \n",
    "                  'reg_lambda'        : trial.suggest_int('reg_lambda', 5, 50),\n",
    "                  'min_child_weight'  : trial.suggest_int('min_child_weight', 5, 25),  \n",
    "                  'colsample_bytree'  : trial.suggest_float('colsample_bytree', 0.8, 1.0),   \n",
    "                  'sampling_method'   : trial.suggest_categorical('sampling_method', ['gradient_based']), \n",
    "                 }\n",
    "             \n",
    "        if torch.cuda.is_available():           \n",
    "            params.update({'predictor'  : trial.suggest_categorical('predictor', ['gpu_predictor']), \n",
    "                           'tree_method': trial.suggest_categorical('tree_method', ['gpu_hist']) , \n",
    "                           'gpu_id'     : trial.suggest_int('gpu_id', 0,0)})\n",
    "                \n",
    "        #pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
    "        \n",
    "        mdl = xgb.XGBClassifier(**params) #, callbacks=[pruning_callback])\n",
    "        \n",
    "        _, score, _, _, _  = TunningModels.train_model_cv(model_        = mdl, \n",
    "                                                          X_            = self.X_trn, \n",
    "                                                          y_            = self.y_trn, \n",
    "                                                          X_test_       = self.X_ts, \n",
    "                                                          target_       = self.target, \n",
    "                                                          model_name_   = self.name_clf, \n",
    "                                                          sc_           = self.scaler, \n",
    "                                                          sc_second_    = self.sc_second, \n",
    "                                                          feature_      = self.feature,\n",
    "                                                          n_splits_     = self.n_splits, \n",
    "                                                          seed_         = self.seed,\n",
    "                                                          path_         = self.path,\n",
    "                                                          level_        = self.level, \n",
    "                                                          trial_        = trial\n",
    "                                                      )\n",
    "            \n",
    "        print('param = {}'.format(params))\n",
    "        print()\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "35ca29b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T17:39:44.990769Z",
     "start_time": "2022-11-26T17:39:44.635526Z"
    },
    "code_folding": [
     0,
     5,
     54,
     74,
     119,
     142,
     178,
     190,
     241,
     263,
     274,
     279,
     292,
     316,
     324,
     332,
     343,
     358,
     407,
     420,
     436,
     455,
     465,
     482,
     495,
     522,
     537,
     576,
     634,
     656,
     659,
     665,
     669,
     688,
     699,
     723,
     731,
     739
    ],
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1669317974362,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "35ca29b2"
   },
   "outputs": [],
   "source": [
    "class Utility():\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.name_ =''\n",
    "       \n",
    "    def jupyter_setting():\n",
    "    \n",
    "        %matplotlib inline\n",
    "\n",
    "        #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "        #plt.style.use('bmh') \n",
    "        #plt.rcParams['figure.figsize'] = [20,15]\n",
    "        #plt.rcParams['font.size']      = 13\n",
    "\n",
    "        matplotlib_axes_logger.setLevel('ERROR')\n",
    "\n",
    "        pd.options.display.max_columns = None\n",
    "        #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        warnings.simplefilter('ignore')\n",
    "        warnings.filterwarnings('ignore')\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "        warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "        pd.options.mode.chained_assignment = None \n",
    "        pd.set_option('display.max_rows', 200)\n",
    "        pd.set_option('display.max_columns', 500)\n",
    "        pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "        icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "        #sns.palplot(sns.color_palette(icecream))\n",
    "\n",
    "        colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "              \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "              \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "              \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "\n",
    "        # Colors\n",
    "        dark_red   = \"#b20710\"\n",
    "        black      = \"#221f1f\"\n",
    "        green      = \"#009473\"\n",
    "        myred      = '#CD5C5C'\n",
    "        myblue     = '#6495ED'\n",
    "        mygreen    = '#90EE90'    \n",
    "        color_cols = [myred, myblue,mygreen]\n",
    "\n",
    "        return icecream, colors, color_cols\n",
    "\n",
    "    def missing_zero_values_table(self, df):\n",
    "        \n",
    "        mis_val         = df.isnull().sum()\n",
    "        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n",
    "        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n",
    "                                                     0 : 'Valores ausentes', \n",
    "                                                     1 : '% de valores totais'})\n",
    "        \n",
    "        mz_table['Tipo de dados'] = df.dtypes\n",
    "        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n",
    "                                     sort_values('% de valores totais', ascending=False)\n",
    "        \n",
    "        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n",
    "              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n",
    "            \n",
    "        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n",
    "        \n",
    "        return mz_table.reset_index()\n",
    "    \n",
    "    def reduce_memory_usage(self, df, verbose=True):\n",
    "    \n",
    "        numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "        start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            col_type = df[col].dtypes\n",
    "\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "        end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                    end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def graf_label(self, ax, total):\n",
    "\n",
    "         for i in ax.patches:\n",
    "            # get_width pulls left or right; get_y pushes up or down\n",
    "            width, height = i.get_width() -.2 , i.get_height()\n",
    "\n",
    "            x, y  = i.get_xy()  \n",
    "            color = 'white'\n",
    "            alt   = .5\n",
    "            soma  = 0 \n",
    "\n",
    "            if height < 70:\n",
    "                color = 'black'\n",
    "                alt   = 1\n",
    "                soma  = 10\n",
    "\n",
    "            ax.annotate(str(round((i.get_height() * 100.0 / total), 1) )+'%', \n",
    "                        (i.get_x()+.55*width, \n",
    "                         i.get_y()+soma + alt*height),\n",
    "                         color   = color,\n",
    "                         weight = 'bold',\n",
    "                         size   = 14)\n",
    "            \n",
    "    def graf_bar(self, df, col, title, xlabel, ylabel, tol = 0):\n",
    "    \n",
    "        #ax    = df.groupby(['churn_cat'])['churn_cat'].count()\n",
    "        ax     = df    \n",
    "        colors = col\n",
    "\n",
    "        if tol == 0: \n",
    "            total  = sum(ax)\n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           color   = colors, \n",
    "                           grid    = False)\n",
    "        else:\n",
    "            total  = tol     \n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           figsize = (10,6),\n",
    "                           color   = colors,\n",
    "                           grid    = False)\n",
    "\n",
    "        title   = title #+ ' \\n'\n",
    "        xlabel  = '\\n ' + xlabel \n",
    "        ylabel  = ylabel + ' \\n'\n",
    "\n",
    "        ax.set_title(title  , fontsize=22)\n",
    "        ax.set_xlabel(xlabel, fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)    \n",
    "\n",
    "        min = [0,23000000]\n",
    "        #ax.set_ylim(min)\n",
    "        self.graf_label(ax, total)\n",
    "\n",
    "    def correlation(self, df_, threshold_):\n",
    "        col_corr    = set()  \n",
    "        corr_matrix = df_.corr()\n",
    "        \n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > threshold_: \n",
    "                    colname = corr_matrix.columns[i]  \n",
    "                    col_corr.add(colname)\n",
    "                    \n",
    "        return col_corr\n",
    "\n",
    "    def __graf_fature_corr(df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                         print_graf_=True, mask_=True, title_='', method_='pearson'):\n",
    "        \n",
    "        msg_title = '\\n Correlação das variável {} -{} \\n'.format(title_, 'method_')\n",
    "        \n",
    "        df = df_.copy().corr(method =method_).round(5)\n",
    "        \n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "            \n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot=annot_, \n",
    "                             mask=mask, \n",
    "                             cmap=\"RdBu\", \n",
    "                             annot_kws={\"weight\": \"bold\", \"fontsize\":13}                              \n",
    "                            )\n",
    "\n",
    "            ax.set_title(msg_title, fontsize=17)\n",
    "            \n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\", style = 'whitegrid', palette= 'pastel')\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\", style = 'whitegrid', palette= 'pastel')\n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.show();\n",
    "            \n",
    "            \n",
    "            \n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "        \n",
    "        #sns.set(style=\"darkgrid\")\n",
    "        plt.show();\n",
    "                        \n",
    "    def describe(self, df):\n",
    "        var = df.columns\n",
    "\n",
    "        # Medidas de tendência central, média e mediana \n",
    "        ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "        ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "        # Dispensão - str, min , max range skew, kurtosis\n",
    "        d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "        d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "        d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "        d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "        d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "        d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "        d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "        # concatenete \n",
    "        m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "        m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "\n",
    "        return m\n",
    "\n",
    "    def graf_outlier(self, df, feature):\n",
    "        col = [(0,4), (5,9)]\n",
    "\n",
    "        df_plot = ((df[feature] - df[feature].min())/\n",
    "                   (df[feature].max() - df[feature].min()))\n",
    "\n",
    "        fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "        for i, (x) in enumerate(col): \n",
    "            sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); \n",
    "\n",
    "    def diff(self, t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "    \n",
    "    def free_gpu_cache(self):\n",
    "\n",
    "        # https://www.kaggle.com/getting-started/140636\n",
    "        #print(\"Initial GPU Usage\")\n",
    "        #gpu_usage()                             \n",
    "\n",
    "        #cuda.select_device(0)\n",
    "        #cuda.close()\n",
    "        #cuda.select_device(0)   \n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def graf_eval(self):\n",
    "\n",
    "        results     = model.evals_result()\n",
    "        ntree_limit = model.best_ntree_limit\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "\n",
    "        for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "\n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "            plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "            plt.axvline(ntree_limit, \n",
    "                        color=\"gray\", \n",
    "                        label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "\n",
    "\n",
    "            title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "            plt.title(title_name)\n",
    "            plt.xlabel(\"Número de árvores\")\n",
    "            plt.ylabel(error)\n",
    "            plt.legend();\n",
    "\n",
    "    def linear_fit_slope(self, y):\n",
    "        \"\"\"Return the slope of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return slope\n",
    "\n",
    "    def linear_fit_intercept(self, y):\n",
    "        \"\"\"Return the intercept of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return intercept\n",
    "\n",
    "    def cromer_v(self, x, y):\n",
    "        cm       = pd.crosstab(x, y).to_numpy()        \n",
    "        n        = cm.sum()\n",
    "        r, k     = cm.shape\n",
    "        chi2     = stats.chi2_contingency(cm)[0]\n",
    "        chi2corr = max(0, chi2 - (k-1) * (r-1) /(n-1))\n",
    "        kcorr    = k - (k-1) **2/(n-1)\n",
    "        rcorr    = r - (r-1) **2/(n-1)    \n",
    "        v        = np.sqrt((chi2corr/n) / (min(kcorr-1, rcorr-1)))        \n",
    "        return v  \n",
    "\n",
    "    def generate_category_table(self, data):\n",
    "\n",
    "        cols    = data.select_dtypes(include='object').columns\n",
    "        dataset = pd.DataFrame()\n",
    "\n",
    "        for i in cols:\n",
    "            corr = []\n",
    "            for x in cols: \n",
    "                corr.append(self.cromer_v(data[i],data[x]))\n",
    "\n",
    "            aux     = pd.DataFrame({i:corr})\n",
    "            dataset = pd.concat([dataset, aux], axis=1) \n",
    "\n",
    "        return dataset.set_index(dataset.columns)\n",
    "            \n",
    "    def graf_feature_corr(self, df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                          print_graf_=True, mask_=True, title_='', method_='pearson'):\n",
    "\n",
    "        df = df_.corr(method=method_).round(5)\n",
    "\n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "\n",
    "            sns.set(style=\"whitegrid\", palette=\"pastel\") \n",
    "            \n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot = annot_, \n",
    "                             mask      = mask, \n",
    "                             cmap      = \"RdBu\", \n",
    "                             fmt       = \".2f\",\n",
    "                             annot_kws = {\"weight\": \"bold\", \"fontsize\":10}\n",
    "                            )\n",
    "            \n",
    "            ax.set_title(\"\\n Correlação das variável {} - {} \\n\".format(title_, method_.upper()), fontsize=17)\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\")\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\")\n",
    "            \n",
    "            sns.set(style=\"darkgrid\")\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                \n",
    "        return self.correlation(df_, threshold_)\n",
    "\n",
    "    def plot_roc_curve(self, fpr, tpr, label=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "        ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for FLAI 08')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "\n",
    "    def feature_engineering(self, df_):\n",
    "\n",
    "        var_f27 = ''\n",
    "        for col in df_['f_27']: \n",
    "            var_f27 +=col\n",
    "\n",
    "        var_f27 = list(set(var_f27))\n",
    "        var_f27.sort()\n",
    "\n",
    "        df_[\"fe_f_27_unique\"] = df_[\"f_27\"].apply(lambda x: len(set(x)))\n",
    "\n",
    "        for letra in var_f27:             \n",
    "            df_['fe_' + letra.lower() + '_count'] = df2_train[\"f_27\"].str.count(letra)\n",
    "\n",
    "        return df_ \n",
    "\n",
    "    def identifies_outliers(self, df):\n",
    "\n",
    "        cols_num = df.select_dtypes(np.number).columns\n",
    "\n",
    "        for col in cols_num: \n",
    "            if col != 'unnamed':            \n",
    "                Q1  = df[col].quantile(0.25)\n",
    "                Q3  = df[col].quantile(0.75)\n",
    "                IQR = Q3-Q1\n",
    "                lowqe_bound=Q1 - 1.5 * IQR\n",
    "                upper_bound=Q3 + 1.5 * IQR\n",
    "\n",
    "                df['outliers_'+ col] = 0\n",
    "                df['outliers_'+ col][(df[col]<=lowqe_bound)|(df[col]>=upper_bound)] = 1    \n",
    "\n",
    "                df[col] = np.where(df[col] > df[col].quantile(0.95),\n",
    "                                                df[col].median(),\n",
    "                                                df[col])\n",
    "\n",
    "    def evaluation(self, y_, predictions_, smape_base_=100):\n",
    "        from sklearn import metrics\n",
    "        mae   = metrics.mean_absolute_error(y_, predictions_)\n",
    "        mse   = metrics.mean_squared_error(y_, predictions_)\n",
    "        rmse  = metrics.mean_squared_error(y_, predictions_, squared=False) \n",
    "        mape  = metrics.mean_absolute_percentage_error(y_, predictions_)\n",
    "        smape = self.smape(y_, predictions_)\n",
    "        r2    = metrics.r2_score(y_, predictions_)    \n",
    "        return rmse, mae, mse, mape, r2, smape\n",
    "    \n",
    "    def feature_statistic(self, df, feature_float, feature_cat=None):\n",
    "        df['fe_mean']        = df[feature_float].mean(axis=1)   \n",
    "        df['fe_std']         = df[feature_float].std(axis=1)   \n",
    "        df['fe_median']      = df[feature_float].median(axis=1)   \n",
    "        df['fe_var']         = df[feature_float].var(axis=1) \n",
    "        df['fe_min']         = df[feature_float].min(axis=1)   \n",
    "        df['fe_max']         = df[feature_float].max(axis=1)   \n",
    "        df['fe_skew']        = df[feature_float].skew(axis=1)   \n",
    "        df['fe_quantile_25'] = df[feature_float].quantile(q=.25, axis=1)\n",
    "        df['fe_quantile_50'] = df[feature_float].quantile(q=.5, axis=1)\n",
    "        df['fe_quantile_75'] = df[feature_float].quantile(q=.75, axis=1)\n",
    "        \n",
    "        if feature_cat is not None:\n",
    "            df['fe_dammy_count'] = df[feature_cat].sum(axis=1)   \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def gridSearchCV(self, model_, params_, X_train_, y_train_):\n",
    "        \"\"\"\n",
    "        @param    model: sklearn estimator\n",
    "        @param    params (dict): Dictionary of possible parameters\n",
    "\n",
    "        @return   cv_results (DataFrame)\n",
    "        \"\"\"\n",
    "        model_cv = GridSearchCV(model_, param_grid=params_, scoring='roc_auc', cv=5)\n",
    "        model_cv.fit(X_train_, y_train_)\n",
    "        cv_results = pd.DataFrame(model_cv.cv_results_)[['params', 'mean_test_score']]\n",
    "\n",
    "        return cv_results\n",
    "    \n",
    "    def evaluate(self, model,X_train_, y_train_, X_test_, plotROC=False):\n",
    "\n",
    "        model.fit(X_train_, y_train_)\n",
    "        probs = model.predict_proba(X_train_)\n",
    "        preds = probs[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(y_train_, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f'AUC: {roc_auc:.4f}')\n",
    "\n",
    "        rocDf = pd.DataFrame({'fpr': fpr, 'tpr':tpr, 'threshold':threshold})\n",
    "        rocDf['tpr - fpr'] = rocDf.tpr - rocDf.fpr\n",
    "        optimalThreshold = rocDf.threshold[rocDf['tpr - fpr'].idxmax()]\n",
    "\n",
    "        y_pred = np.where(preds >= optimalThreshold, 1, 0)\n",
    "\n",
    "        # Plot ROC AUC\n",
    "        if plotROC:\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.plot([0, 1], [0, 1],'r--')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.show()    \n",
    "\n",
    "    def iqr_outliers(self, df,ft):\n",
    "\n",
    "        q1  = df[ft].quantile(0.25)\n",
    "        q3  = df[ft].quantile(0.75)\n",
    "        iqr = q3-q1\n",
    "        c   = 0 \n",
    "\n",
    "        Lower_tail = q1 - 1.5 * iqr\n",
    "        Upper_tail = q3 + 1.5 * iqr\n",
    "\n",
    "        for i in range(len(df[ft])):\n",
    "            if df[ft][i] > Upper_tail or df[ft][i] < Lower_tail:\n",
    "                c+=1\n",
    "        return c\n",
    "    \n",
    "    def outlier_create_feature_check(self, df_tr_, df_ts_, cols_=[], qt_inferior_=.25, qt_superior_=.75, \n",
    "                                     flg_ts_=True, input_limete_=False, verbose_=True):\n",
    "    \n",
    "        col_oltlier         = 'fe_outlier'\n",
    "        df_tr_[col_oltlier] = 0 \n",
    "        df_ts_[col_oltlier] = 0 \n",
    "\n",
    "        for c in cols_:\n",
    "\n",
    "            percentil25 = df_tr_[c].quantile(qt_inferior_)\n",
    "            percentil75 = df_tr_[c].quantile(qt_superior_)\n",
    "\n",
    "            iqr= percentil75 - percentil25 \n",
    "\n",
    "            limite_inferior = percentil25 - 1.5 * iqr\n",
    "            limite_superior = percentil75 + 1.5 * iqr\n",
    "\n",
    "            df_tr_[col_oltlier][df_tr_[c]>limite_superior] = -1\n",
    "            df_tr_[col_oltlier][df_tr_[c]<limite_inferior] = -1\n",
    "\n",
    "            if input_limete_:\n",
    "                df_tr_[c][df_tr_[c]>limite_superior] = limite_superior\n",
    "                df_tr_[c][df_tr_[c]<limite_inferior] = limite_inferior\n",
    "\n",
    "            if flg_ts_:\n",
    "                df_ts_[col_oltlier][df_ts_[c]>limite_superior] = -1\n",
    "                df_ts_[col_oltlier][df_ts_[c]<limite_inferior] = -1\n",
    "                \n",
    "                if input_limete_:\n",
    "                    df_ts_[c][df_ts_[c]>limite_superior] = limite_superior\n",
    "                    df_ts_[c][df_ts_[c]<limite_inferior] = limite_inferior\n",
    "\n",
    "            if verbose_:\n",
    "                print('Com a variável {}'.format(c))\n",
    "                print(df_tr_[col_oltlier].value_counts())\n",
    "                print()\n",
    "\n",
    "        return df_tr_, df_ts_\n",
    "        \n",
    "    def calibrated_classifier_graf_model(self, mdl_list_, X_, y_, seed_=12359, figsize_=(10, 10), verbose_=False): \n",
    "\n",
    "        fig = plt.figure(1, figsize=figsize_)\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "        \n",
    "        if verbose_: ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfeitamente calibrado\")\n",
    "\n",
    "        for name, mdl1 in mdl_list_:  \n",
    "            model_pipeline  = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor_1),\n",
    "                #('sampler_over', over), \n",
    "                #('sampler_under', under),    \n",
    "                ('variancethreshold', VarianceThreshold(threshold=0.1)),    \n",
    "                ('selectpercentile', SelectPercentile(f_classif, percentile=90)), \n",
    "                ('model', mdl1)\n",
    "                ])\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.5, random_state=seed_)\n",
    "\n",
    "            model_calibrated = CalibratedClassifierCV(model_pipeline, method='isotonic', cv=2) \n",
    "            # method='isotonic' sigmoid\n",
    "\n",
    "            model_calibrated.fit(X_train, y_train)\n",
    "\n",
    "            if hasattr(model_calibrated, \"predict_proba\"):\n",
    "                prob_pos = model_calibrated.predict_proba(X_val)[:, 1]\n",
    "            else:  \n",
    "                prob_pos = model_calibrated.decision_function(X_val)\n",
    "                prob_pos = (prob_pos-prob_pos.min()) / (prob_pos.max()-prob_pos.min())\n",
    "\n",
    "            score = brier_score_loss(y_val, prob_pos, pos_label=y_val.max())\n",
    "\n",
    "            frac_of_pos, mean_pred_value = calibration_curve(y_val, prob_pos, n_bins=15, normalize=True)      \n",
    "\n",
    "            ax1.plot(mean_pred_value, frac_of_pos, \"s-\", label=\"%s (%1.3f)\" % (name, score))\n",
    "\n",
    "            ax1.set_ylabel('Fração de positivos')\n",
    "            ax1.set_ylim([-0.05, 1.05])\n",
    "            ax1.legend(loc='upper left' )\n",
    "            ax1.set_title('\\nGráficos de calibração (curva de confiabilidade)\\n', fontsize=18)\n",
    "\n",
    "            if verbose_: \n",
    "                ax2.hist(prob_pos, range=(0, 1), bins=100, label=name, histtype=\"step\", lw=2)    \n",
    "                ax2.set_xlabel('Valor médio previsto')\n",
    "                ax2.set_ylabel('Quantidade')\n",
    "                ax2.legend(loc=\"upper left\", ncol=1)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                msg = 'AUC: {:2.5f} - F1: {:2.5f} - Perda: {:2.3f} -> {}'\n",
    "                auc = roc_auc_score(y_val, prob_pos)\n",
    "                f1  = f1_score(y_val, (prob_pos>.5).astype(int))\n",
    "                print(msg.format(auc,f1, score, name))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def describe(df):\n",
    "        var = df.columns\n",
    "\n",
    "        # Medidas de tendência central, média e mediana \n",
    "        ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "        ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "        # Dispensão - str, min , max range skew, kurtosis\n",
    "        d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "        d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "        d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "        d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "        d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "        d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "        d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "        # concatenete \n",
    "        m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "        m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "        \n",
    "        return m\n",
    "        \n",
    "    def smape(self, a, f):\n",
    "        return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)\n",
    "\n",
    "    def smape_(self, y_true, y_pred, base_=100.):\n",
    "        denominator          = (np.abs(y_true)+np.abs(y_pred))/base_\n",
    "        diff                 = np.abs(y_true-y_pred)/denominator\n",
    "        diff[denominator==0] = 0.0\n",
    "        return np.nanmean(diff)\n",
    "    \n",
    "    def smape_loss(y_true, y_pred):\n",
    "        \"\"\"SMAPE Loss\"\"\"\n",
    "        return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200\n",
    "    \n",
    "    def calc_erro(y, y_pred, outros=True, ruturn_score=False):\n",
    "        erro   = smape(y, y_pred)    \n",
    "        \n",
    "        \n",
    "        if outros:        \n",
    "            rmse = metrics.mean_squared_error(y, y_pred, squared=False)\n",
    "            mape = metrics.mean_absolute_percentage_error(y, y_pred)\n",
    "            mae  = metrics.mean_absolute_error(y, y_pred)\n",
    "            \n",
    "            print('RMSE : {:2.5f}'.format(rmse))\n",
    "            print('MAE  : {:2.5f}'.format(mae))\n",
    "            print('MAPE : {:2.5f}'.format(mape))\n",
    "            \n",
    "            \n",
    "        if ruturn_score: \n",
    "            return erro\n",
    "        else: \n",
    "            print('SMAPE: {:2.5f}'.format(erro))\n",
    "            \n",
    "    def graf_outlier(df, feature):\n",
    "        col = [(0,4), (5,9)]\n",
    "\n",
    "        df_plot = ((df[feature] - df[feature].min())/\n",
    "                (df[feature].max() - df[feature].min()))\n",
    "\n",
    "        fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "        for i, (x) in enumerate(col): \n",
    "            sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); \n",
    "                    \n",
    "    def graf_eval():\n",
    "\n",
    "        results     = model.evals_result()\n",
    "        ntree_limit = model.best_ntree_limit\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "\n",
    "        for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "            \n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "            plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "            plt.axvline(ntree_limit, \n",
    "                        color=\"gray\", \n",
    "                        label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "                        \n",
    "            \n",
    "            title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "            plt.title(title_name)\n",
    "            plt.xlabel(\"Número de árvores\")\n",
    "            plt.ylabel(error)\n",
    "            plt.legend();\n",
    "        \n",
    "    def linear_fit_slope(y):\n",
    "        \"\"\"Return the slope of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return slope\n",
    "        \n",
    "    def linear_fit_intercept(y):\n",
    "        \"\"\"Return the intercept of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return intercept\n",
    "    \n",
    "    def create_fold(self, path_): \n",
    "\n",
    "        paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'Data/tunning', \n",
    "                 'model', 'model/preds', 'model/optuna','model/preds/test', 'Data/shap',\n",
    "                 'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n",
    "                 'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n",
    "                 'model/preds/train/n3', 'model/preds/param', 'model/mdl', 'model/preds/folds' ]\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                os.mkdir(path_+p)       \n",
    "            except:\n",
    "                #print('Erro ao criar pasta: {} '.format(path+p))\n",
    "                pass \n",
    "        \n",
    "utility = Utility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f9070a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:27:38.097633Z",
     "start_time": "2022-11-25T01:27:37.693409Z"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1669317977075,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "f8f9070a"
   },
   "outputs": [],
   "source": [
    "icecream, colors, color_cols = Utility.jupyter_setting()\n",
    "n_threads = multiprocessing.cpu_count()\n",
    "\n",
    "# http://www.lps.usp.br/hae/apostila/densakeras-ead.pdf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']      = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']      = '1' \n",
    "os.environ['WANDB_SILENT']              = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']      = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99f1cb",
   "metadata": {
    "id": "eb99f1cb"
   },
   "source": [
    "## 1.4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df774779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T12:09:08.996933Z",
     "start_time": "2022-11-25T12:09:08.983927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 11 \n",
    "x = i if i==1 else 2 \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5a5c573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:27:38.174963Z",
     "start_time": "2022-11-25T01:27:38.162952Z"
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1669317981243,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "d5a5c573"
   },
   "outputs": [],
   "source": [
    "path        =  '/content/drive/MyDrive/kaggle/Tabular Playground Series/2022/10 - Novembro/' if COLAB else ''      \n",
    "path_data   = 'Data/'  \n",
    "path_automl = 'automl/'\n",
    "target      = 'label'\n",
    "clip        = 1e-6\n",
    "\n",
    "utility.create_fold(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4941bfce",
   "metadata": {
    "id": "4941bfce"
   },
   "source": [
    "### 1.4.4. Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29b36719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:27:38.691161Z",
     "start_time": "2022-11-25T01:27:38.247926Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1669317983017,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "29b36719",
    "outputId": "5ce6992c-3ca1-4c10-e4cd-8aca2824c948"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      1\n",
       "2   2      1\n",
       "3   3      1\n",
       "4   4      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data: Rows=20000, Columns=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.640707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>0.636904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>0.392496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>0.588658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>0.783603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      pred\n",
       "0  20000  0.640707\n",
       "1  20001  0.636904\n",
       "2  20002  0.392496\n",
       "3  20003  0.588658\n",
       "4  20004  0.783603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_train     = pd.read_csv(path + path_data + \"train_labels.csv\")\n",
    "df_submission = pd.read_csv(path + path_data + \"sample_submission.csv\")\n",
    "\n",
    "display(df1_train.head())\n",
    "print(f\" train data: Rows={df1_train.shape[0]}, Columns={df1_train.shape[1]}\")\n",
    "display(df_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee17f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:27:38.816187Z",
     "start_time": "2022-11-25T01:27:38.772149Z"
    },
    "executionInfo": {
     "elapsed": 25611,
     "status": "ok",
     "timestamp": 1669318008872,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "fee17f3c"
   },
   "outputs": [],
   "source": [
    "df_pred       = pd.DataFrame(np.zeros(40000), columns=['id'])\n",
    "df_pred['id'] = df_pred.index\n",
    "\n",
    "file_list = sorted(glob.glob(os.path.join(path + path_data, \"submission_files/*.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62212319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:28:03.586957Z",
     "start_time": "2022-11-25T01:27:38.945150Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 17571,
     "status": "ok",
     "timestamp": 1669318026431,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "62212319",
    "outputId": "85978089-e1eb-4da7-a0d5-5270b628fcf5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.8 s\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "      <th>pred_13</th>\n",
       "      <th>pred_14</th>\n",
       "      <th>pred_15</th>\n",
       "      <th>pred_16</th>\n",
       "      <th>pred_17</th>\n",
       "      <th>pred_18</th>\n",
       "      <th>pred_19</th>\n",
       "      <th>pred_20</th>\n",
       "      <th>pred_21</th>\n",
       "      <th>pred_22</th>\n",
       "      <th>pred_23</th>\n",
       "      <th>pred_24</th>\n",
       "      <th>pred_25</th>\n",
       "      <th>pred_26</th>\n",
       "      <th>pred_27</th>\n",
       "      <th>pred_28</th>\n",
       "      <th>pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>pred_32</th>\n",
       "      <th>pred_33</th>\n",
       "      <th>pred_34</th>\n",
       "      <th>pred_35</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>pred_38</th>\n",
       "      <th>pred_39</th>\n",
       "      <th>pred_40</th>\n",
       "      <th>pred_41</th>\n",
       "      <th>pred_42</th>\n",
       "      <th>pred_43</th>\n",
       "      <th>pred_44</th>\n",
       "      <th>pred_45</th>\n",
       "      <th>pred_46</th>\n",
       "      <th>pred_47</th>\n",
       "      <th>pred_48</th>\n",
       "      <th>pred_49</th>\n",
       "      <th>pred_50</th>\n",
       "      <th>pred_51</th>\n",
       "      <th>pred_52</th>\n",
       "      <th>pred_53</th>\n",
       "      <th>pred_54</th>\n",
       "      <th>pred_55</th>\n",
       "      <th>pred_56</th>\n",
       "      <th>pred_57</th>\n",
       "      <th>pred_58</th>\n",
       "      <th>pred_59</th>\n",
       "      <th>pred_60</th>\n",
       "      <th>pred_61</th>\n",
       "      <th>pred_62</th>\n",
       "      <th>pred_63</th>\n",
       "      <th>pred_64</th>\n",
       "      <th>pred_65</th>\n",
       "      <th>pred_66</th>\n",
       "      <th>pred_67</th>\n",
       "      <th>pred_68</th>\n",
       "      <th>pred_69</th>\n",
       "      <th>pred_70</th>\n",
       "      <th>pred_71</th>\n",
       "      <th>pred_72</th>\n",
       "      <th>pred_73</th>\n",
       "      <th>pred_74</th>\n",
       "      <th>pred_75</th>\n",
       "      <th>pred_76</th>\n",
       "      <th>pred_77</th>\n",
       "      <th>pred_78</th>\n",
       "      <th>pred_79</th>\n",
       "      <th>pred_80</th>\n",
       "      <th>pred_81</th>\n",
       "      <th>pred_82</th>\n",
       "      <th>pred_83</th>\n",
       "      <th>pred_84</th>\n",
       "      <th>pred_85</th>\n",
       "      <th>pred_86</th>\n",
       "      <th>pred_87</th>\n",
       "      <th>pred_88</th>\n",
       "      <th>pred_89</th>\n",
       "      <th>pred_90</th>\n",
       "      <th>pred_91</th>\n",
       "      <th>pred_92</th>\n",
       "      <th>pred_93</th>\n",
       "      <th>pred_94</th>\n",
       "      <th>pred_95</th>\n",
       "      <th>pred_96</th>\n",
       "      <th>pred_97</th>\n",
       "      <th>pred_98</th>\n",
       "      <th>pred_99</th>\n",
       "      <th>pred_100</th>\n",
       "      <th>pred_101</th>\n",
       "      <th>pred_102</th>\n",
       "      <th>pred_103</th>\n",
       "      <th>pred_104</th>\n",
       "      <th>pred_105</th>\n",
       "      <th>pred_106</th>\n",
       "      <th>pred_107</th>\n",
       "      <th>pred_108</th>\n",
       "      <th>pred_109</th>\n",
       "      <th>pred_110</th>\n",
       "      <th>pred_111</th>\n",
       "      <th>pred_112</th>\n",
       "      <th>pred_113</th>\n",
       "      <th>pred_114</th>\n",
       "      <th>pred_115</th>\n",
       "      <th>pred_116</th>\n",
       "      <th>pred_117</th>\n",
       "      <th>pred_118</th>\n",
       "      <th>pred_119</th>\n",
       "      <th>pred_120</th>\n",
       "      <th>pred_121</th>\n",
       "      <th>pred_122</th>\n",
       "      <th>pred_123</th>\n",
       "      <th>pred_124</th>\n",
       "      <th>pred_125</th>\n",
       "      <th>pred_126</th>\n",
       "      <th>pred_127</th>\n",
       "      <th>pred_128</th>\n",
       "      <th>pred_129</th>\n",
       "      <th>pred_130</th>\n",
       "      <th>pred_131</th>\n",
       "      <th>pred_132</th>\n",
       "      <th>pred_133</th>\n",
       "      <th>pred_134</th>\n",
       "      <th>pred_135</th>\n",
       "      <th>pred_136</th>\n",
       "      <th>pred_137</th>\n",
       "      <th>pred_138</th>\n",
       "      <th>pred_139</th>\n",
       "      <th>pred_140</th>\n",
       "      <th>pred_141</th>\n",
       "      <th>pred_142</th>\n",
       "      <th>pred_143</th>\n",
       "      <th>pred_144</th>\n",
       "      <th>pred_145</th>\n",
       "      <th>pred_146</th>\n",
       "      <th>pred_147</th>\n",
       "      <th>pred_148</th>\n",
       "      <th>pred_149</th>\n",
       "      <th>pred_150</th>\n",
       "      <th>pred_151</th>\n",
       "      <th>pred_152</th>\n",
       "      <th>pred_153</th>\n",
       "      <th>pred_154</th>\n",
       "      <th>pred_155</th>\n",
       "      <th>pred_156</th>\n",
       "      <th>pred_157</th>\n",
       "      <th>pred_158</th>\n",
       "      <th>pred_159</th>\n",
       "      <th>pred_160</th>\n",
       "      <th>pred_161</th>\n",
       "      <th>pred_162</th>\n",
       "      <th>pred_163</th>\n",
       "      <th>pred_164</th>\n",
       "      <th>pred_165</th>\n",
       "      <th>pred_166</th>\n",
       "      <th>pred_167</th>\n",
       "      <th>pred_168</th>\n",
       "      <th>pred_169</th>\n",
       "      <th>pred_170</th>\n",
       "      <th>pred_171</th>\n",
       "      <th>pred_172</th>\n",
       "      <th>pred_173</th>\n",
       "      <th>pred_174</th>\n",
       "      <th>pred_175</th>\n",
       "      <th>pred_176</th>\n",
       "      <th>pred_177</th>\n",
       "      <th>pred_178</th>\n",
       "      <th>pred_179</th>\n",
       "      <th>pred_180</th>\n",
       "      <th>pred_181</th>\n",
       "      <th>pred_182</th>\n",
       "      <th>pred_183</th>\n",
       "      <th>pred_184</th>\n",
       "      <th>pred_185</th>\n",
       "      <th>pred_186</th>\n",
       "      <th>pred_187</th>\n",
       "      <th>pred_188</th>\n",
       "      <th>pred_189</th>\n",
       "      <th>pred_190</th>\n",
       "      <th>pred_191</th>\n",
       "      <th>pred_192</th>\n",
       "      <th>pred_193</th>\n",
       "      <th>pred_194</th>\n",
       "      <th>pred_195</th>\n",
       "      <th>pred_196</th>\n",
       "      <th>pred_197</th>\n",
       "      <th>pred_198</th>\n",
       "      <th>pred_199</th>\n",
       "      <th>pred_200</th>\n",
       "      <th>pred_201</th>\n",
       "      <th>pred_202</th>\n",
       "      <th>pred_203</th>\n",
       "      <th>pred_204</th>\n",
       "      <th>pred_205</th>\n",
       "      <th>pred_206</th>\n",
       "      <th>pred_207</th>\n",
       "      <th>pred_208</th>\n",
       "      <th>pred_209</th>\n",
       "      <th>pred_210</th>\n",
       "      <th>pred_211</th>\n",
       "      <th>pred_212</th>\n",
       "      <th>pred_213</th>\n",
       "      <th>pred_214</th>\n",
       "      <th>pred_215</th>\n",
       "      <th>pred_216</th>\n",
       "      <th>pred_217</th>\n",
       "      <th>pred_218</th>\n",
       "      <th>pred_219</th>\n",
       "      <th>pred_220</th>\n",
       "      <th>pred_221</th>\n",
       "      <th>pred_222</th>\n",
       "      <th>pred_223</th>\n",
       "      <th>pred_224</th>\n",
       "      <th>pred_225</th>\n",
       "      <th>pred_226</th>\n",
       "      <th>pred_227</th>\n",
       "      <th>pred_228</th>\n",
       "      <th>pred_229</th>\n",
       "      <th>pred_230</th>\n",
       "      <th>pred_231</th>\n",
       "      <th>pred_232</th>\n",
       "      <th>pred_233</th>\n",
       "      <th>pred_234</th>\n",
       "      <th>pred_235</th>\n",
       "      <th>pred_236</th>\n",
       "      <th>pred_237</th>\n",
       "      <th>pred_238</th>\n",
       "      <th>pred_239</th>\n",
       "      <th>pred_240</th>\n",
       "      <th>pred_241</th>\n",
       "      <th>pred_242</th>\n",
       "      <th>pred_243</th>\n",
       "      <th>pred_244</th>\n",
       "      <th>pred_245</th>\n",
       "      <th>pred_246</th>\n",
       "      <th>pred_247</th>\n",
       "      <th>pred_248</th>\n",
       "      <th>pred_249</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_4750</th>\n",
       "      <th>pred_4751</th>\n",
       "      <th>pred_4752</th>\n",
       "      <th>pred_4753</th>\n",
       "      <th>pred_4754</th>\n",
       "      <th>pred_4755</th>\n",
       "      <th>pred_4756</th>\n",
       "      <th>pred_4757</th>\n",
       "      <th>pred_4758</th>\n",
       "      <th>pred_4759</th>\n",
       "      <th>pred_4760</th>\n",
       "      <th>pred_4761</th>\n",
       "      <th>pred_4762</th>\n",
       "      <th>pred_4763</th>\n",
       "      <th>pred_4764</th>\n",
       "      <th>pred_4765</th>\n",
       "      <th>pred_4766</th>\n",
       "      <th>pred_4767</th>\n",
       "      <th>pred_4768</th>\n",
       "      <th>pred_4769</th>\n",
       "      <th>pred_4770</th>\n",
       "      <th>pred_4771</th>\n",
       "      <th>pred_4772</th>\n",
       "      <th>pred_4773</th>\n",
       "      <th>pred_4774</th>\n",
       "      <th>pred_4775</th>\n",
       "      <th>pred_4776</th>\n",
       "      <th>pred_4777</th>\n",
       "      <th>pred_4778</th>\n",
       "      <th>pred_4779</th>\n",
       "      <th>pred_4780</th>\n",
       "      <th>pred_4781</th>\n",
       "      <th>pred_4782</th>\n",
       "      <th>pred_4783</th>\n",
       "      <th>pred_4784</th>\n",
       "      <th>pred_4785</th>\n",
       "      <th>pred_4786</th>\n",
       "      <th>pred_4787</th>\n",
       "      <th>pred_4788</th>\n",
       "      <th>pred_4789</th>\n",
       "      <th>pred_4790</th>\n",
       "      <th>pred_4791</th>\n",
       "      <th>pred_4792</th>\n",
       "      <th>pred_4793</th>\n",
       "      <th>pred_4794</th>\n",
       "      <th>pred_4795</th>\n",
       "      <th>pred_4796</th>\n",
       "      <th>pred_4797</th>\n",
       "      <th>pred_4798</th>\n",
       "      <th>pred_4799</th>\n",
       "      <th>pred_4800</th>\n",
       "      <th>pred_4801</th>\n",
       "      <th>pred_4802</th>\n",
       "      <th>pred_4803</th>\n",
       "      <th>pred_4804</th>\n",
       "      <th>pred_4805</th>\n",
       "      <th>pred_4806</th>\n",
       "      <th>pred_4807</th>\n",
       "      <th>pred_4808</th>\n",
       "      <th>pred_4809</th>\n",
       "      <th>pred_4810</th>\n",
       "      <th>pred_4811</th>\n",
       "      <th>pred_4812</th>\n",
       "      <th>pred_4813</th>\n",
       "      <th>pred_4814</th>\n",
       "      <th>pred_4815</th>\n",
       "      <th>pred_4816</th>\n",
       "      <th>pred_4817</th>\n",
       "      <th>pred_4818</th>\n",
       "      <th>pred_4819</th>\n",
       "      <th>pred_4820</th>\n",
       "      <th>pred_4821</th>\n",
       "      <th>pred_4822</th>\n",
       "      <th>pred_4823</th>\n",
       "      <th>pred_4824</th>\n",
       "      <th>pred_4825</th>\n",
       "      <th>pred_4826</th>\n",
       "      <th>pred_4827</th>\n",
       "      <th>pred_4828</th>\n",
       "      <th>pred_4829</th>\n",
       "      <th>pred_4830</th>\n",
       "      <th>pred_4831</th>\n",
       "      <th>pred_4832</th>\n",
       "      <th>pred_4833</th>\n",
       "      <th>pred_4834</th>\n",
       "      <th>pred_4835</th>\n",
       "      <th>pred_4836</th>\n",
       "      <th>pred_4837</th>\n",
       "      <th>pred_4838</th>\n",
       "      <th>pred_4839</th>\n",
       "      <th>pred_4840</th>\n",
       "      <th>pred_4841</th>\n",
       "      <th>pred_4842</th>\n",
       "      <th>pred_4843</th>\n",
       "      <th>pred_4844</th>\n",
       "      <th>pred_4845</th>\n",
       "      <th>pred_4846</th>\n",
       "      <th>pred_4847</th>\n",
       "      <th>pred_4848</th>\n",
       "      <th>pred_4849</th>\n",
       "      <th>pred_4850</th>\n",
       "      <th>pred_4851</th>\n",
       "      <th>pred_4852</th>\n",
       "      <th>pred_4853</th>\n",
       "      <th>pred_4854</th>\n",
       "      <th>pred_4855</th>\n",
       "      <th>pred_4856</th>\n",
       "      <th>pred_4857</th>\n",
       "      <th>pred_4858</th>\n",
       "      <th>pred_4859</th>\n",
       "      <th>pred_4860</th>\n",
       "      <th>pred_4861</th>\n",
       "      <th>pred_4862</th>\n",
       "      <th>pred_4863</th>\n",
       "      <th>pred_4864</th>\n",
       "      <th>pred_4865</th>\n",
       "      <th>pred_4866</th>\n",
       "      <th>pred_4867</th>\n",
       "      <th>pred_4868</th>\n",
       "      <th>pred_4869</th>\n",
       "      <th>pred_4870</th>\n",
       "      <th>pred_4871</th>\n",
       "      <th>pred_4872</th>\n",
       "      <th>pred_4873</th>\n",
       "      <th>pred_4874</th>\n",
       "      <th>pred_4875</th>\n",
       "      <th>pred_4876</th>\n",
       "      <th>pred_4877</th>\n",
       "      <th>pred_4878</th>\n",
       "      <th>pred_4879</th>\n",
       "      <th>pred_4880</th>\n",
       "      <th>pred_4881</th>\n",
       "      <th>pred_4882</th>\n",
       "      <th>pred_4883</th>\n",
       "      <th>pred_4884</th>\n",
       "      <th>pred_4885</th>\n",
       "      <th>pred_4886</th>\n",
       "      <th>pred_4887</th>\n",
       "      <th>pred_4888</th>\n",
       "      <th>pred_4889</th>\n",
       "      <th>pred_4890</th>\n",
       "      <th>pred_4891</th>\n",
       "      <th>pred_4892</th>\n",
       "      <th>pred_4893</th>\n",
       "      <th>pred_4894</th>\n",
       "      <th>pred_4895</th>\n",
       "      <th>pred_4896</th>\n",
       "      <th>pred_4897</th>\n",
       "      <th>pred_4898</th>\n",
       "      <th>pred_4899</th>\n",
       "      <th>pred_4900</th>\n",
       "      <th>pred_4901</th>\n",
       "      <th>pred_4902</th>\n",
       "      <th>pred_4903</th>\n",
       "      <th>pred_4904</th>\n",
       "      <th>pred_4905</th>\n",
       "      <th>pred_4906</th>\n",
       "      <th>pred_4907</th>\n",
       "      <th>pred_4908</th>\n",
       "      <th>pred_4909</th>\n",
       "      <th>pred_4910</th>\n",
       "      <th>pred_4911</th>\n",
       "      <th>pred_4912</th>\n",
       "      <th>pred_4913</th>\n",
       "      <th>pred_4914</th>\n",
       "      <th>pred_4915</th>\n",
       "      <th>pred_4916</th>\n",
       "      <th>pred_4917</th>\n",
       "      <th>pred_4918</th>\n",
       "      <th>pred_4919</th>\n",
       "      <th>pred_4920</th>\n",
       "      <th>pred_4921</th>\n",
       "      <th>pred_4922</th>\n",
       "      <th>pred_4923</th>\n",
       "      <th>pred_4924</th>\n",
       "      <th>pred_4925</th>\n",
       "      <th>pred_4926</th>\n",
       "      <th>pred_4927</th>\n",
       "      <th>pred_4928</th>\n",
       "      <th>pred_4929</th>\n",
       "      <th>pred_4930</th>\n",
       "      <th>pred_4931</th>\n",
       "      <th>pred_4932</th>\n",
       "      <th>pred_4933</th>\n",
       "      <th>pred_4934</th>\n",
       "      <th>pred_4935</th>\n",
       "      <th>pred_4936</th>\n",
       "      <th>pred_4937</th>\n",
       "      <th>pred_4938</th>\n",
       "      <th>pred_4939</th>\n",
       "      <th>pred_4940</th>\n",
       "      <th>pred_4941</th>\n",
       "      <th>pred_4942</th>\n",
       "      <th>pred_4943</th>\n",
       "      <th>pred_4944</th>\n",
       "      <th>pred_4945</th>\n",
       "      <th>pred_4946</th>\n",
       "      <th>pred_4947</th>\n",
       "      <th>pred_4948</th>\n",
       "      <th>pred_4949</th>\n",
       "      <th>pred_4950</th>\n",
       "      <th>pred_4951</th>\n",
       "      <th>pred_4952</th>\n",
       "      <th>pred_4953</th>\n",
       "      <th>pred_4954</th>\n",
       "      <th>pred_4955</th>\n",
       "      <th>pred_4956</th>\n",
       "      <th>pred_4957</th>\n",
       "      <th>pred_4958</th>\n",
       "      <th>pred_4959</th>\n",
       "      <th>pred_4960</th>\n",
       "      <th>pred_4961</th>\n",
       "      <th>pred_4962</th>\n",
       "      <th>pred_4963</th>\n",
       "      <th>pred_4964</th>\n",
       "      <th>pred_4965</th>\n",
       "      <th>pred_4966</th>\n",
       "      <th>pred_4967</th>\n",
       "      <th>pred_4968</th>\n",
       "      <th>pred_4969</th>\n",
       "      <th>pred_4970</th>\n",
       "      <th>pred_4971</th>\n",
       "      <th>pred_4972</th>\n",
       "      <th>pred_4973</th>\n",
       "      <th>pred_4974</th>\n",
       "      <th>pred_4975</th>\n",
       "      <th>pred_4976</th>\n",
       "      <th>pred_4977</th>\n",
       "      <th>pred_4978</th>\n",
       "      <th>pred_4979</th>\n",
       "      <th>pred_4980</th>\n",
       "      <th>pred_4981</th>\n",
       "      <th>pred_4982</th>\n",
       "      <th>pred_4983</th>\n",
       "      <th>pred_4984</th>\n",
       "      <th>pred_4985</th>\n",
       "      <th>pred_4986</th>\n",
       "      <th>pred_4987</th>\n",
       "      <th>pred_4988</th>\n",
       "      <th>pred_4989</th>\n",
       "      <th>pred_4990</th>\n",
       "      <th>pred_4991</th>\n",
       "      <th>pred_4992</th>\n",
       "      <th>pred_4993</th>\n",
       "      <th>pred_4994</th>\n",
       "      <th>pred_4995</th>\n",
       "      <th>pred_4996</th>\n",
       "      <th>pred_4997</th>\n",
       "      <th>pred_4998</th>\n",
       "      <th>pred_4999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709336</td>\n",
       "      <td>0.799007</td>\n",
       "      <td>0.851891</td>\n",
       "      <td>0.537158</td>\n",
       "      <td>0.623930</td>\n",
       "      <td>0.705970</td>\n",
       "      <td>0.503437</td>\n",
       "      <td>0.633185</td>\n",
       "      <td>0.641550</td>\n",
       "      <td>0.666604</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.494577</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.586738</td>\n",
       "      <td>0.801957</td>\n",
       "      <td>0.562042</td>\n",
       "      <td>0.607146</td>\n",
       "      <td>0.723824</td>\n",
       "      <td>0.514653</td>\n",
       "      <td>0.698785</td>\n",
       "      <td>0.648393</td>\n",
       "      <td>0.847155</td>\n",
       "      <td>0.504999</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.494180</td>\n",
       "      <td>0.654680</td>\n",
       "      <td>0.423318</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.772409</td>\n",
       "      <td>0.657442</td>\n",
       "      <td>0.652088</td>\n",
       "      <td>0.535287</td>\n",
       "      <td>0.589636</td>\n",
       "      <td>0.641365</td>\n",
       "      <td>0.606017</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.845207</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.568964</td>\n",
       "      <td>0.909303</td>\n",
       "      <td>0.466230</td>\n",
       "      <td>0.505583</td>\n",
       "      <td>0.508293</td>\n",
       "      <td>0.696233</td>\n",
       "      <td>0.898834</td>\n",
       "      <td>0.914714</td>\n",
       "      <td>0.922075</td>\n",
       "      <td>0.479519</td>\n",
       "      <td>0.937982</td>\n",
       "      <td>0.566443</td>\n",
       "      <td>0.811661</td>\n",
       "      <td>0.714225</td>\n",
       "      <td>0.725077</td>\n",
       "      <td>0.922891</td>\n",
       "      <td>0.921742</td>\n",
       "      <td>0.594629</td>\n",
       "      <td>0.932837</td>\n",
       "      <td>0.599946</td>\n",
       "      <td>0.606418</td>\n",
       "      <td>0.930759</td>\n",
       "      <td>0.930242</td>\n",
       "      <td>0.941618</td>\n",
       "      <td>0.957463</td>\n",
       "      <td>0.906037</td>\n",
       "      <td>0.922421</td>\n",
       "      <td>0.906153</td>\n",
       "      <td>0.945167</td>\n",
       "      <td>0.892739</td>\n",
       "      <td>0.945352</td>\n",
       "      <td>0.960757</td>\n",
       "      <td>0.956259</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.872427</td>\n",
       "      <td>0.729955</td>\n",
       "      <td>0.929035</td>\n",
       "      <td>0.844362</td>\n",
       "      <td>0.697281</td>\n",
       "      <td>0.921738</td>\n",
       "      <td>0.799486</td>\n",
       "      <td>0.919839</td>\n",
       "      <td>0.945280</td>\n",
       "      <td>0.902676</td>\n",
       "      <td>0.666626</td>\n",
       "      <td>0.768229</td>\n",
       "      <td>0.945016</td>\n",
       "      <td>0.963822</td>\n",
       "      <td>0.897716</td>\n",
       "      <td>0.537010</td>\n",
       "      <td>0.643323</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.675474</td>\n",
       "      <td>0.895324</td>\n",
       "      <td>0.832749</td>\n",
       "      <td>0.769671</td>\n",
       "      <td>0.623374</td>\n",
       "      <td>0.956150</td>\n",
       "      <td>0.907764</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.705692</td>\n",
       "      <td>0.644098</td>\n",
       "      <td>0.930951</td>\n",
       "      <td>0.772919</td>\n",
       "      <td>0.812400</td>\n",
       "      <td>0.650367</td>\n",
       "      <td>0.696069</td>\n",
       "      <td>0.931176</td>\n",
       "      <td>0.700183</td>\n",
       "      <td>0.646789</td>\n",
       "      <td>0.708291</td>\n",
       "      <td>0.938083</td>\n",
       "      <td>0.976355</td>\n",
       "      <td>0.948648</td>\n",
       "      <td>0.832077</td>\n",
       "      <td>0.627968</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.810878</td>\n",
       "      <td>0.880978</td>\n",
       "      <td>0.675629</td>\n",
       "      <td>0.843527</td>\n",
       "      <td>0.956883</td>\n",
       "      <td>0.673548</td>\n",
       "      <td>0.662422</td>\n",
       "      <td>0.785180</td>\n",
       "      <td>0.896610</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.812889</td>\n",
       "      <td>0.695166</td>\n",
       "      <td>0.667115</td>\n",
       "      <td>0.908483</td>\n",
       "      <td>0.733079</td>\n",
       "      <td>0.904345</td>\n",
       "      <td>0.892627</td>\n",
       "      <td>0.874332</td>\n",
       "      <td>0.770953</td>\n",
       "      <td>0.814974</td>\n",
       "      <td>0.794214</td>\n",
       "      <td>0.906117</td>\n",
       "      <td>0.771051</td>\n",
       "      <td>0.730623</td>\n",
       "      <td>0.645044</td>\n",
       "      <td>0.926714</td>\n",
       "      <td>0.746078</td>\n",
       "      <td>0.905658</td>\n",
       "      <td>0.844268</td>\n",
       "      <td>0.850759</td>\n",
       "      <td>0.904881</td>\n",
       "      <td>0.890427</td>\n",
       "      <td>0.825087</td>\n",
       "      <td>0.852848</td>\n",
       "      <td>0.577451</td>\n",
       "      <td>0.456252</td>\n",
       "      <td>0.916432</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.906898</td>\n",
       "      <td>0.929678</td>\n",
       "      <td>0.906078</td>\n",
       "      <td>0.887494</td>\n",
       "      <td>0.924072</td>\n",
       "      <td>0.787867</td>\n",
       "      <td>0.818566</td>\n",
       "      <td>0.969202</td>\n",
       "      <td>0.936387</td>\n",
       "      <td>0.893934</td>\n",
       "      <td>0.971786</td>\n",
       "      <td>0.858574</td>\n",
       "      <td>0.895418</td>\n",
       "      <td>0.902283</td>\n",
       "      <td>0.920882</td>\n",
       "      <td>0.934658</td>\n",
       "      <td>0.935486</td>\n",
       "      <td>0.927940</td>\n",
       "      <td>0.931465</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.919990</td>\n",
       "      <td>0.900218</td>\n",
       "      <td>0.893556</td>\n",
       "      <td>0.896251</td>\n",
       "      <td>0.755341</td>\n",
       "      <td>0.824287</td>\n",
       "      <td>0.803321</td>\n",
       "      <td>0.907727</td>\n",
       "      <td>0.641035</td>\n",
       "      <td>0.797494</td>\n",
       "      <td>0.941171</td>\n",
       "      <td>0.871997</td>\n",
       "      <td>0.865994</td>\n",
       "      <td>0.920065</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>0.843785</td>\n",
       "      <td>0.890857</td>\n",
       "      <td>0.795824</td>\n",
       "      <td>0.672107</td>\n",
       "      <td>0.804113</td>\n",
       "      <td>0.790379</td>\n",
       "      <td>0.790415</td>\n",
       "      <td>0.617612</td>\n",
       "      <td>0.828683</td>\n",
       "      <td>0.924688</td>\n",
       "      <td>0.795053</td>\n",
       "      <td>0.648085</td>\n",
       "      <td>0.667586</td>\n",
       "      <td>0.767689</td>\n",
       "      <td>0.649592</td>\n",
       "      <td>0.864491</td>\n",
       "      <td>0.656478</td>\n",
       "      <td>0.727041</td>\n",
       "      <td>0.648350</td>\n",
       "      <td>0.659398</td>\n",
       "      <td>0.652276</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>0.905867</td>\n",
       "      <td>0.879130</td>\n",
       "      <td>0.693787</td>\n",
       "      <td>0.653076</td>\n",
       "      <td>0.642931</td>\n",
       "      <td>0.769356</td>\n",
       "      <td>0.657665</td>\n",
       "      <td>0.655031</td>\n",
       "      <td>0.680468</td>\n",
       "      <td>0.654141</td>\n",
       "      <td>0.888045</td>\n",
       "      <td>0.663639</td>\n",
       "      <td>0.648532</td>\n",
       "      <td>0.943179</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>0.657922</td>\n",
       "      <td>0.739452</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>0.849011</td>\n",
       "      <td>0.901647</td>\n",
       "      <td>0.868586</td>\n",
       "      <td>0.867358</td>\n",
       "      <td>0.918989</td>\n",
       "      <td>0.655847</td>\n",
       "      <td>0.656866</td>\n",
       "      <td>0.944366</td>\n",
       "      <td>0.836214</td>\n",
       "      <td>0.862387</td>\n",
       "      <td>0.890369</td>\n",
       "      <td>0.936063</td>\n",
       "      <td>0.657963</td>\n",
       "      <td>0.829295</td>\n",
       "      <td>0.867263</td>\n",
       "      <td>0.842680</td>\n",
       "      <td>0.670228</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>0.953470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744596</td>\n",
       "      <td>0.789606</td>\n",
       "      <td>0.822831</td>\n",
       "      <td>0.752506</td>\n",
       "      <td>0.763859</td>\n",
       "      <td>0.792185</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.869214</td>\n",
       "      <td>0.748611</td>\n",
       "      <td>0.743209</td>\n",
       "      <td>0.802502</td>\n",
       "      <td>0.728472</td>\n",
       "      <td>0.790256</td>\n",
       "      <td>0.825258</td>\n",
       "      <td>0.872288</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>0.762307</td>\n",
       "      <td>0.726273</td>\n",
       "      <td>0.776793</td>\n",
       "      <td>0.759087</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.734118</td>\n",
       "      <td>0.803793</td>\n",
       "      <td>0.732907</td>\n",
       "      <td>0.745979</td>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.775466</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.680466</td>\n",
       "      <td>0.699379</td>\n",
       "      <td>0.795242</td>\n",
       "      <td>0.799246</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>0.827740</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.792859</td>\n",
       "      <td>0.856979</td>\n",
       "      <td>0.746108</td>\n",
       "      <td>0.766509</td>\n",
       "      <td>0.819130</td>\n",
       "      <td>0.795080</td>\n",
       "      <td>0.751392</td>\n",
       "      <td>0.758484</td>\n",
       "      <td>0.450801</td>\n",
       "      <td>0.796515</td>\n",
       "      <td>0.744912</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>0.768739</td>\n",
       "      <td>0.819312</td>\n",
       "      <td>0.808605</td>\n",
       "      <td>0.760954</td>\n",
       "      <td>0.836624</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.822643</td>\n",
       "      <td>0.611131</td>\n",
       "      <td>0.767637</td>\n",
       "      <td>0.788689</td>\n",
       "      <td>0.739138</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.767082</td>\n",
       "      <td>0.753414</td>\n",
       "      <td>0.801072</td>\n",
       "      <td>0.741112</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.788995</td>\n",
       "      <td>0.789473</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.789505</td>\n",
       "      <td>0.857225</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.731786</td>\n",
       "      <td>0.766275</td>\n",
       "      <td>0.788488</td>\n",
       "      <td>0.790706</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.787668</td>\n",
       "      <td>0.785096</td>\n",
       "      <td>0.831133</td>\n",
       "      <td>0.799774</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.793660</td>\n",
       "      <td>0.752367</td>\n",
       "      <td>0.777987</td>\n",
       "      <td>0.806303</td>\n",
       "      <td>0.766487</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>0.724557</td>\n",
       "      <td>0.809020</td>\n",
       "      <td>0.790488</td>\n",
       "      <td>0.740934</td>\n",
       "      <td>0.757600</td>\n",
       "      <td>0.838907</td>\n",
       "      <td>0.664264</td>\n",
       "      <td>0.844789</td>\n",
       "      <td>0.761397</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.788785</td>\n",
       "      <td>0.765805</td>\n",
       "      <td>0.719217</td>\n",
       "      <td>0.663273</td>\n",
       "      <td>0.790739</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.735948</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.643394</td>\n",
       "      <td>0.778507</td>\n",
       "      <td>0.748442</td>\n",
       "      <td>0.836666</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.809759</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.776348</td>\n",
       "      <td>0.820329</td>\n",
       "      <td>0.754561</td>\n",
       "      <td>0.779653</td>\n",
       "      <td>0.786898</td>\n",
       "      <td>0.818111</td>\n",
       "      <td>0.750967</td>\n",
       "      <td>0.788298</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>0.882778</td>\n",
       "      <td>0.740910</td>\n",
       "      <td>0.805058</td>\n",
       "      <td>0.539312</td>\n",
       "      <td>0.834274</td>\n",
       "      <td>0.773189</td>\n",
       "      <td>0.771674</td>\n",
       "      <td>0.77566</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.833338</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.785218</td>\n",
       "      <td>0.769817</td>\n",
       "      <td>0.774337</td>\n",
       "      <td>0.790061</td>\n",
       "      <td>0.788713</td>\n",
       "      <td>0.743855</td>\n",
       "      <td>0.746083</td>\n",
       "      <td>0.811458</td>\n",
       "      <td>0.828661</td>\n",
       "      <td>0.755482</td>\n",
       "      <td>0.787360</td>\n",
       "      <td>0.864917</td>\n",
       "      <td>0.797303</td>\n",
       "      <td>0.802966</td>\n",
       "      <td>0.705644</td>\n",
       "      <td>0.790439</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.816518</td>\n",
       "      <td>0.728475</td>\n",
       "      <td>0.789816</td>\n",
       "      <td>0.852823</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.724836</td>\n",
       "      <td>0.678887</td>\n",
       "      <td>0.872183</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.778658</td>\n",
       "      <td>0.706696</td>\n",
       "      <td>0.801668</td>\n",
       "      <td>0.747840</td>\n",
       "      <td>0.829977</td>\n",
       "      <td>0.714481</td>\n",
       "      <td>0.735582</td>\n",
       "      <td>0.692817</td>\n",
       "      <td>0.675287</td>\n",
       "      <td>0.792170</td>\n",
       "      <td>0.687298</td>\n",
       "      <td>0.823327</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.757718</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.810692</td>\n",
       "      <td>0.764609</td>\n",
       "      <td>0.780869</td>\n",
       "      <td>0.711543</td>\n",
       "      <td>0.756985</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>0.735119</td>\n",
       "      <td>0.810028</td>\n",
       "      <td>0.765535</td>\n",
       "      <td>0.789920</td>\n",
       "      <td>0.802327</td>\n",
       "      <td>0.329250</td>\n",
       "      <td>0.862750</td>\n",
       "      <td>0.867296</td>\n",
       "      <td>0.798853</td>\n",
       "      <td>0.742752</td>\n",
       "      <td>0.751270</td>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.804625</td>\n",
       "      <td>0.772256</td>\n",
       "      <td>0.735407</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>0.884420</td>\n",
       "      <td>0.721145</td>\n",
       "      <td>0.784553</td>\n",
       "      <td>0.716269</td>\n",
       "      <td>0.707415</td>\n",
       "      <td>0.765097</td>\n",
       "      <td>0.800922</td>\n",
       "      <td>0.839562</td>\n",
       "      <td>0.787619</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.759822</td>\n",
       "      <td>0.776343</td>\n",
       "      <td>0.782595</td>\n",
       "      <td>0.766008</td>\n",
       "      <td>0.618374</td>\n",
       "      <td>0.767504</td>\n",
       "      <td>0.790324</td>\n",
       "      <td>0.732125</td>\n",
       "      <td>0.815167</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.828574</td>\n",
       "      <td>0.713297</td>\n",
       "      <td>0.829415</td>\n",
       "      <td>0.793753</td>\n",
       "      <td>0.808062</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.669220</td>\n",
       "      <td>0.753454</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.783564</td>\n",
       "      <td>0.819630</td>\n",
       "      <td>0.762424</td>\n",
       "      <td>0.790193</td>\n",
       "      <td>0.794981</td>\n",
       "      <td>0.781625</td>\n",
       "      <td>0.804431</td>\n",
       "      <td>0.808977</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.769207</td>\n",
       "      <td>0.750250</td>\n",
       "      <td>0.663370</td>\n",
       "      <td>0.739333</td>\n",
       "      <td>0.822384</td>\n",
       "      <td>0.749498</td>\n",
       "      <td>0.729800</td>\n",
       "      <td>0.867847</td>\n",
       "      <td>0.745888</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452988</td>\n",
       "      <td>0.364453</td>\n",
       "      <td>0.567582</td>\n",
       "      <td>0.354468</td>\n",
       "      <td>0.513818</td>\n",
       "      <td>0.584119</td>\n",
       "      <td>0.454809</td>\n",
       "      <td>0.238501</td>\n",
       "      <td>0.472171</td>\n",
       "      <td>0.522314</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.666009</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.732957</td>\n",
       "      <td>0.714976</td>\n",
       "      <td>0.419134</td>\n",
       "      <td>0.404536</td>\n",
       "      <td>0.539501</td>\n",
       "      <td>0.637878</td>\n",
       "      <td>0.466280</td>\n",
       "      <td>0.438964</td>\n",
       "      <td>0.473790</td>\n",
       "      <td>0.177996</td>\n",
       "      <td>0.506920</td>\n",
       "      <td>0.504273</td>\n",
       "      <td>0.398968</td>\n",
       "      <td>0.597034</td>\n",
       "      <td>0.294240</td>\n",
       "      <td>0.435329</td>\n",
       "      <td>0.417415</td>\n",
       "      <td>0.362844</td>\n",
       "      <td>0.604260</td>\n",
       "      <td>0.571773</td>\n",
       "      <td>0.515101</td>\n",
       "      <td>0.478809</td>\n",
       "      <td>0.555008</td>\n",
       "      <td>0.414648</td>\n",
       "      <td>0.602281</td>\n",
       "      <td>0.670183</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.494151</td>\n",
       "      <td>0.613548</td>\n",
       "      <td>0.595513</td>\n",
       "      <td>0.445120</td>\n",
       "      <td>0.483932</td>\n",
       "      <td>0.599259</td>\n",
       "      <td>0.601485</td>\n",
       "      <td>0.602389</td>\n",
       "      <td>0.604563</td>\n",
       "      <td>0.258524</td>\n",
       "      <td>0.661866</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.640667</td>\n",
       "      <td>0.601536</td>\n",
       "      <td>0.712083</td>\n",
       "      <td>0.668786</td>\n",
       "      <td>0.619580</td>\n",
       "      <td>0.552569</td>\n",
       "      <td>0.637539</td>\n",
       "      <td>0.593669</td>\n",
       "      <td>0.488146</td>\n",
       "      <td>0.644062</td>\n",
       "      <td>0.629101</td>\n",
       "      <td>0.628834</td>\n",
       "      <td>0.647618</td>\n",
       "      <td>0.658552</td>\n",
       "      <td>0.644813</td>\n",
       "      <td>0.573348</td>\n",
       "      <td>0.647081</td>\n",
       "      <td>0.661094</td>\n",
       "      <td>0.679846</td>\n",
       "      <td>0.651932</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.512870</td>\n",
       "      <td>0.578207</td>\n",
       "      <td>0.555843</td>\n",
       "      <td>0.644829</td>\n",
       "      <td>0.631186</td>\n",
       "      <td>0.808865</td>\n",
       "      <td>0.647233</td>\n",
       "      <td>0.642972</td>\n",
       "      <td>0.621325</td>\n",
       "      <td>0.652881</td>\n",
       "      <td>0.624169</td>\n",
       "      <td>0.602384</td>\n",
       "      <td>0.497198</td>\n",
       "      <td>0.655108</td>\n",
       "      <td>0.656787</td>\n",
       "      <td>0.627654</td>\n",
       "      <td>0.502368</td>\n",
       "      <td>0.584159</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.573083</td>\n",
       "      <td>0.648244</td>\n",
       "      <td>0.568334</td>\n",
       "      <td>0.583181</td>\n",
       "      <td>0.625131</td>\n",
       "      <td>0.611957</td>\n",
       "      <td>0.640366</td>\n",
       "      <td>0.661202</td>\n",
       "      <td>0.505585</td>\n",
       "      <td>0.289171</td>\n",
       "      <td>0.627038</td>\n",
       "      <td>0.635627</td>\n",
       "      <td>0.554886</td>\n",
       "      <td>0.562929</td>\n",
       "      <td>0.501377</td>\n",
       "      <td>0.682853</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>0.494124</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>0.624901</td>\n",
       "      <td>0.673024</td>\n",
       "      <td>0.633642</td>\n",
       "      <td>0.621477</td>\n",
       "      <td>0.528351</td>\n",
       "      <td>0.694932</td>\n",
       "      <td>0.682610</td>\n",
       "      <td>0.666823</td>\n",
       "      <td>0.602497</td>\n",
       "      <td>0.625227</td>\n",
       "      <td>0.608956</td>\n",
       "      <td>0.579682</td>\n",
       "      <td>0.511741</td>\n",
       "      <td>0.486436</td>\n",
       "      <td>0.689482</td>\n",
       "      <td>0.621342</td>\n",
       "      <td>0.687989</td>\n",
       "      <td>0.435278</td>\n",
       "      <td>0.539069</td>\n",
       "      <td>0.712965</td>\n",
       "      <td>0.644455</td>\n",
       "      <td>0.643942</td>\n",
       "      <td>0.709303</td>\n",
       "      <td>0.637611</td>\n",
       "      <td>0.668925</td>\n",
       "      <td>0.549318</td>\n",
       "      <td>0.618010</td>\n",
       "      <td>0.650828</td>\n",
       "      <td>0.573493</td>\n",
       "      <td>0.450846</td>\n",
       "      <td>0.541993</td>\n",
       "      <td>0.619029</td>\n",
       "      <td>0.637448</td>\n",
       "      <td>0.604204</td>\n",
       "      <td>0.638032</td>\n",
       "      <td>0.669435</td>\n",
       "      <td>0.594310</td>\n",
       "      <td>0.596047</td>\n",
       "      <td>0.616601</td>\n",
       "      <td>0.657313</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>0.543961</td>\n",
       "      <td>0.627445</td>\n",
       "      <td>0.636621</td>\n",
       "      <td>0.585731</td>\n",
       "      <td>0.642914</td>\n",
       "      <td>0.560543</td>\n",
       "      <td>0.640902</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.674142</td>\n",
       "      <td>0.690330</td>\n",
       "      <td>0.627449</td>\n",
       "      <td>0.543489</td>\n",
       "      <td>0.609602</td>\n",
       "      <td>0.692161</td>\n",
       "      <td>0.611896</td>\n",
       "      <td>0.525594</td>\n",
       "      <td>0.577745</td>\n",
       "      <td>0.657326</td>\n",
       "      <td>0.619196</td>\n",
       "      <td>0.634477</td>\n",
       "      <td>0.568215</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>0.629806</td>\n",
       "      <td>0.579136</td>\n",
       "      <td>0.607440</td>\n",
       "      <td>0.564160</td>\n",
       "      <td>0.640586</td>\n",
       "      <td>0.606747</td>\n",
       "      <td>0.667866</td>\n",
       "      <td>0.612748</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.620910</td>\n",
       "      <td>0.643053</td>\n",
       "      <td>0.599508</td>\n",
       "      <td>0.613284</td>\n",
       "      <td>0.560798</td>\n",
       "      <td>0.677245</td>\n",
       "      <td>0.613026</td>\n",
       "      <td>0.637778</td>\n",
       "      <td>0.577172</td>\n",
       "      <td>0.607995</td>\n",
       "      <td>0.539117</td>\n",
       "      <td>0.611351</td>\n",
       "      <td>0.692691</td>\n",
       "      <td>0.735494</td>\n",
       "      <td>0.578681</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>0.678320</td>\n",
       "      <td>0.705907</td>\n",
       "      <td>0.556968</td>\n",
       "      <td>0.541232</td>\n",
       "      <td>0.701840</td>\n",
       "      <td>0.534387</td>\n",
       "      <td>0.602506</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.588982</td>\n",
       "      <td>0.551651</td>\n",
       "      <td>0.536717</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>0.526458</td>\n",
       "      <td>0.636615</td>\n",
       "      <td>0.595467</td>\n",
       "      <td>0.541926</td>\n",
       "      <td>0.546837</td>\n",
       "      <td>0.547003</td>\n",
       "      <td>0.612151</td>\n",
       "      <td>0.539560</td>\n",
       "      <td>0.544701</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>0.679799</td>\n",
       "      <td>0.542618</td>\n",
       "      <td>0.543866</td>\n",
       "      <td>0.680749</td>\n",
       "      <td>0.564064</td>\n",
       "      <td>0.522136</td>\n",
       "      <td>0.656444</td>\n",
       "      <td>0.549582</td>\n",
       "      <td>0.588881</td>\n",
       "      <td>0.648029</td>\n",
       "      <td>0.632580</td>\n",
       "      <td>0.669941</td>\n",
       "      <td>0.630683</td>\n",
       "      <td>0.557115</td>\n",
       "      <td>0.550999</td>\n",
       "      <td>0.637534</td>\n",
       "      <td>0.589501</td>\n",
       "      <td>0.569580</td>\n",
       "      <td>0.721865</td>\n",
       "      <td>0.637924</td>\n",
       "      <td>0.544955</td>\n",
       "      <td>0.630034</td>\n",
       "      <td>0.619004</td>\n",
       "      <td>0.656982</td>\n",
       "      <td>0.556974</td>\n",
       "      <td>0.648987</td>\n",
       "      <td>0.648320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788690</td>\n",
       "      <td>0.616180</td>\n",
       "      <td>0.827795</td>\n",
       "      <td>0.737427</td>\n",
       "      <td>0.686645</td>\n",
       "      <td>0.708316</td>\n",
       "      <td>0.817641</td>\n",
       "      <td>0.757236</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.839523</td>\n",
       "      <td>0.724937</td>\n",
       "      <td>0.799671</td>\n",
       "      <td>0.809862</td>\n",
       "      <td>0.773093</td>\n",
       "      <td>0.752800</td>\n",
       "      <td>0.807330</td>\n",
       "      <td>0.599772</td>\n",
       "      <td>0.803634</td>\n",
       "      <td>0.681727</td>\n",
       "      <td>0.582038</td>\n",
       "      <td>0.667205</td>\n",
       "      <td>0.808840</td>\n",
       "      <td>0.575069</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.856404</td>\n",
       "      <td>0.698707</td>\n",
       "      <td>0.722883</td>\n",
       "      <td>0.820609</td>\n",
       "      <td>0.692309</td>\n",
       "      <td>0.715915</td>\n",
       "      <td>0.688091</td>\n",
       "      <td>0.678089</td>\n",
       "      <td>0.594253</td>\n",
       "      <td>0.587398</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.676032</td>\n",
       "      <td>0.494506</td>\n",
       "      <td>0.818950</td>\n",
       "      <td>0.797526</td>\n",
       "      <td>0.662398</td>\n",
       "      <td>0.600031</td>\n",
       "      <td>0.770656</td>\n",
       "      <td>0.612303</td>\n",
       "      <td>0.507133</td>\n",
       "      <td>0.690067</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.60500</td>\n",
       "      <td>0.641385</td>\n",
       "      <td>0.659656</td>\n",
       "      <td>0.634422</td>\n",
       "      <td>0.663740</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.681780</td>\n",
       "      <td>0.637879</td>\n",
       "      <td>0.765696</td>\n",
       "      <td>0.559711</td>\n",
       "      <td>0.655060</td>\n",
       "      <td>0.702855</td>\n",
       "      <td>0.554488</td>\n",
       "      <td>0.566536</td>\n",
       "      <td>0.522473</td>\n",
       "      <td>0.695330</td>\n",
       "      <td>0.793034</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.591842</td>\n",
       "      <td>0.687549</td>\n",
       "      <td>0.559970</td>\n",
       "      <td>0.560146</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>0.624769</td>\n",
       "      <td>0.834789</td>\n",
       "      <td>0.613291</td>\n",
       "      <td>0.567477</td>\n",
       "      <td>0.660968</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.609750</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>0.785988</td>\n",
       "      <td>0.580263</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.551481</td>\n",
       "      <td>0.817990</td>\n",
       "      <td>0.625254</td>\n",
       "      <td>0.551368</td>\n",
       "      <td>0.620339</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.603782</td>\n",
       "      <td>0.689245</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.555615</td>\n",
       "      <td>0.196101</td>\n",
       "      <td>0.577267</td>\n",
       "      <td>0.571527</td>\n",
       "      <td>0.733769</td>\n",
       "      <td>0.553858</td>\n",
       "      <td>0.839782</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.656690</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.532639</td>\n",
       "      <td>0.675301</td>\n",
       "      <td>0.659970</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.685178</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.516099</td>\n",
       "      <td>0.713553</td>\n",
       "      <td>0.789445</td>\n",
       "      <td>0.555181</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.567262</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.789391</td>\n",
       "      <td>0.466068</td>\n",
       "      <td>0.584493</td>\n",
       "      <td>0.791817</td>\n",
       "      <td>0.698266</td>\n",
       "      <td>0.701015</td>\n",
       "      <td>0.843445</td>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.779182</td>\n",
       "      <td>0.756273</td>\n",
       "      <td>0.613947</td>\n",
       "      <td>0.630173</td>\n",
       "      <td>0.593991</td>\n",
       "      <td>0.614041</td>\n",
       "      <td>0.607984</td>\n",
       "      <td>0.925653</td>\n",
       "      <td>0.56562</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>0.680271</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.790298</td>\n",
       "      <td>0.844437</td>\n",
       "      <td>0.637616</td>\n",
       "      <td>0.622595</td>\n",
       "      <td>0.783105</td>\n",
       "      <td>0.764523</td>\n",
       "      <td>0.639816</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.535052</td>\n",
       "      <td>0.765851</td>\n",
       "      <td>0.644280</td>\n",
       "      <td>0.550574</td>\n",
       "      <td>0.626481</td>\n",
       "      <td>0.654301</td>\n",
       "      <td>0.748443</td>\n",
       "      <td>0.705750</td>\n",
       "      <td>0.821382</td>\n",
       "      <td>0.668149</td>\n",
       "      <td>0.474381</td>\n",
       "      <td>0.631520</td>\n",
       "      <td>0.755675</td>\n",
       "      <td>0.620640</td>\n",
       "      <td>0.527393</td>\n",
       "      <td>0.673709</td>\n",
       "      <td>0.585480</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.764359</td>\n",
       "      <td>0.615756</td>\n",
       "      <td>0.649969</td>\n",
       "      <td>0.765076</td>\n",
       "      <td>0.566324</td>\n",
       "      <td>0.793590</td>\n",
       "      <td>0.702215</td>\n",
       "      <td>0.559875</td>\n",
       "      <td>0.657938</td>\n",
       "      <td>0.570594</td>\n",
       "      <td>0.855491</td>\n",
       "      <td>0.513806</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.590176</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.514427</td>\n",
       "      <td>0.837213</td>\n",
       "      <td>0.765428</td>\n",
       "      <td>0.705154</td>\n",
       "      <td>0.649341</td>\n",
       "      <td>0.594490</td>\n",
       "      <td>0.129141</td>\n",
       "      <td>0.606811</td>\n",
       "      <td>0.784151</td>\n",
       "      <td>0.636025</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.335895</td>\n",
       "      <td>0.524583</td>\n",
       "      <td>0.728891</td>\n",
       "      <td>0.537487</td>\n",
       "      <td>0.591161</td>\n",
       "      <td>0.612110</td>\n",
       "      <td>0.534904</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.728319</td>\n",
       "      <td>0.843295</td>\n",
       "      <td>0.801448</td>\n",
       "      <td>0.722251</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.567012</td>\n",
       "      <td>0.619222</td>\n",
       "      <td>0.857886</td>\n",
       "      <td>0.818352</td>\n",
       "      <td>0.825970</td>\n",
       "      <td>0.543566</td>\n",
       "      <td>0.567665</td>\n",
       "      <td>0.493301</td>\n",
       "      <td>0.797206</td>\n",
       "      <td>0.480500</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.740490</td>\n",
       "      <td>0.760884</td>\n",
       "      <td>0.549819</td>\n",
       "      <td>0.608901</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.618532</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.604327</td>\n",
       "      <td>0.543064</td>\n",
       "      <td>0.721973</td>\n",
       "      <td>0.660949</td>\n",
       "      <td>0.636353</td>\n",
       "      <td>0.576666</td>\n",
       "      <td>0.664133</td>\n",
       "      <td>0.701665</td>\n",
       "      <td>0.167135</td>\n",
       "      <td>0.682181</td>\n",
       "      <td>0.819425</td>\n",
       "      <td>0.763671</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.723470</td>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.558871</td>\n",
       "      <td>0.748712</td>\n",
       "      <td>0.620492</td>\n",
       "      <td>0.720902</td>\n",
       "      <td>0.620868</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.827551</td>\n",
       "      <td>0.738751</td>\n",
       "      <td>0.640052</td>\n",
       "      <td>0.794052</td>\n",
       "      <td>0.721298</td>\n",
       "      <td>0.804369</td>\n",
       "      <td>0.620626</td>\n",
       "      <td>0.733606</td>\n",
       "      <td>0.816942</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>0.598331</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.675462</td>\n",
       "      <td>0.842260</td>\n",
       "      <td>0.800013</td>\n",
       "      <td>0.525229</td>\n",
       "      <td>0.692071</td>\n",
       "      <td>0.715418</td>\n",
       "      <td>0.651008</td>\n",
       "      <td>0.609124</td>\n",
       "      <td>0.691198</td>\n",
       "      <td>0.609994</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.748037</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.669469</td>\n",
       "      <td>0.788335</td>\n",
       "      <td>0.394662</td>\n",
       "      <td>0.574383</td>\n",
       "      <td>0.717165</td>\n",
       "      <td>0.765810</td>\n",
       "      <td>0.656733</td>\n",
       "      <td>0.641200</td>\n",
       "      <td>0.644853</td>\n",
       "      <td>0.366641</td>\n",
       "      <td>0.698106</td>\n",
       "      <td>0.656238</td>\n",
       "      <td>0.559506</td>\n",
       "      <td>0.706054</td>\n",
       "      <td>0.380290</td>\n",
       "      <td>0.436985</td>\n",
       "      <td>0.778724</td>\n",
       "      <td>0.507844</td>\n",
       "      <td>0.698322</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.596451</td>\n",
       "      <td>0.645121</td>\n",
       "      <td>0.645856</td>\n",
       "      <td>0.512432</td>\n",
       "      <td>0.803193</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.719212</td>\n",
       "      <td>0.816767</td>\n",
       "      <td>0.482021</td>\n",
       "      <td>0.485455</td>\n",
       "      <td>0.605928</td>\n",
       "      <td>0.744988</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>0.781854</td>\n",
       "      <td>0.814117</td>\n",
       "      <td>0.490606</td>\n",
       "      <td>0.790689</td>\n",
       "      <td>0.564994</td>\n",
       "      <td>0.807724</td>\n",
       "      <td>0.696787</td>\n",
       "      <td>0.716777</td>\n",
       "      <td>0.809696</td>\n",
       "      <td>0.832032</td>\n",
       "      <td>0.622356</td>\n",
       "      <td>0.811664</td>\n",
       "      <td>0.641584</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>0.810776</td>\n",
       "      <td>0.809876</td>\n",
       "      <td>0.811948</td>\n",
       "      <td>0.818143</td>\n",
       "      <td>0.816159</td>\n",
       "      <td>0.806781</td>\n",
       "      <td>0.867544</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>0.813695</td>\n",
       "      <td>0.794572</td>\n",
       "      <td>0.822299</td>\n",
       "      <td>0.795874</td>\n",
       "      <td>0.768272</td>\n",
       "      <td>0.819478</td>\n",
       "      <td>0.739492</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.790021</td>\n",
       "      <td>0.707139</td>\n",
       "      <td>0.811145</td>\n",
       "      <td>0.860909</td>\n",
       "      <td>0.832409</td>\n",
       "      <td>0.799195</td>\n",
       "      <td>0.823453</td>\n",
       "      <td>0.658420</td>\n",
       "      <td>0.604025</td>\n",
       "      <td>0.820993</td>\n",
       "      <td>0.814296</td>\n",
       "      <td>0.823566</td>\n",
       "      <td>0.448933</td>\n",
       "      <td>0.682090</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.707723</td>\n",
       "      <td>0.822082</td>\n",
       "      <td>0.825743</td>\n",
       "      <td>0.794294</td>\n",
       "      <td>0.669156</td>\n",
       "      <td>0.829765</td>\n",
       "      <td>0.796169</td>\n",
       "      <td>0.825571</td>\n",
       "      <td>0.794276</td>\n",
       "      <td>0.664967</td>\n",
       "      <td>0.827944</td>\n",
       "      <td>0.787310</td>\n",
       "      <td>0.707549</td>\n",
       "      <td>0.717424</td>\n",
       "      <td>0.796097</td>\n",
       "      <td>0.812508</td>\n",
       "      <td>0.704367</td>\n",
       "      <td>0.712928</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>0.837944</td>\n",
       "      <td>0.821771</td>\n",
       "      <td>0.815776</td>\n",
       "      <td>0.770536</td>\n",
       "      <td>0.653857</td>\n",
       "      <td>0.823259</td>\n",
       "      <td>0.849905</td>\n",
       "      <td>0.802251</td>\n",
       "      <td>0.650613</td>\n",
       "      <td>0.816146</td>\n",
       "      <td>0.833861</td>\n",
       "      <td>0.676217</td>\n",
       "      <td>0.662334</td>\n",
       "      <td>0.812814</td>\n",
       "      <td>0.785306</td>\n",
       "      <td>0.849646</td>\n",
       "      <td>0.852297</td>\n",
       "      <td>0.568925</td>\n",
       "      <td>0.737468</td>\n",
       "      <td>0.820915</td>\n",
       "      <td>0.785100</td>\n",
       "      <td>0.796107</td>\n",
       "      <td>0.821535</td>\n",
       "      <td>0.795397</td>\n",
       "      <td>0.819162</td>\n",
       "      <td>0.773409</td>\n",
       "      <td>0.820803</td>\n",
       "      <td>0.800624</td>\n",
       "      <td>0.779749</td>\n",
       "      <td>0.729107</td>\n",
       "      <td>0.691039</td>\n",
       "      <td>0.834565</td>\n",
       "      <td>0.785142</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.811273</td>\n",
       "      <td>0.829589</td>\n",
       "      <td>0.831566</td>\n",
       "      <td>0.825430</td>\n",
       "      <td>0.786754</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>0.590588</td>\n",
       "      <td>0.457862</td>\n",
       "      <td>0.837226</td>\n",
       "      <td>0.833258</td>\n",
       "      <td>0.842586</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.817439</td>\n",
       "      <td>0.821279</td>\n",
       "      <td>0.808627</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.844756</td>\n",
       "      <td>0.837281</td>\n",
       "      <td>0.811220</td>\n",
       "      <td>0.848504</td>\n",
       "      <td>0.816399</td>\n",
       "      <td>0.809840</td>\n",
       "      <td>0.821926</td>\n",
       "      <td>0.844702</td>\n",
       "      <td>0.834022</td>\n",
       "      <td>0.843441</td>\n",
       "      <td>0.838973</td>\n",
       "      <td>0.842829</td>\n",
       "      <td>0.840506</td>\n",
       "      <td>0.782444</td>\n",
       "      <td>0.841735</td>\n",
       "      <td>0.833383</td>\n",
       "      <td>0.826798</td>\n",
       "      <td>0.830551</td>\n",
       "      <td>0.781691</td>\n",
       "      <td>0.860410</td>\n",
       "      <td>0.810261</td>\n",
       "      <td>0.801572</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>0.806115</td>\n",
       "      <td>0.828846</td>\n",
       "      <td>0.830342</td>\n",
       "      <td>0.828998</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>0.827238</td>\n",
       "      <td>0.846826</td>\n",
       "      <td>0.805064</td>\n",
       "      <td>0.825498</td>\n",
       "      <td>0.712260</td>\n",
       "      <td>0.820578</td>\n",
       "      <td>0.780879</td>\n",
       "      <td>0.839275</td>\n",
       "      <td>0.612763</td>\n",
       "      <td>0.799409</td>\n",
       "      <td>0.821824</td>\n",
       "      <td>0.786143</td>\n",
       "      <td>0.706309</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.838994</td>\n",
       "      <td>0.717417</td>\n",
       "      <td>0.831552</td>\n",
       "      <td>0.710438</td>\n",
       "      <td>0.746410</td>\n",
       "      <td>0.714187</td>\n",
       "      <td>0.718964</td>\n",
       "      <td>0.710050</td>\n",
       "      <td>0.708915</td>\n",
       "      <td>0.801613</td>\n",
       "      <td>0.808007</td>\n",
       "      <td>0.746493</td>\n",
       "      <td>0.706783</td>\n",
       "      <td>0.709442</td>\n",
       "      <td>0.839370</td>\n",
       "      <td>0.712780</td>\n",
       "      <td>0.714048</td>\n",
       "      <td>0.620456</td>\n",
       "      <td>0.708657</td>\n",
       "      <td>0.810277</td>\n",
       "      <td>0.704058</td>\n",
       "      <td>0.711560</td>\n",
       "      <td>0.809795</td>\n",
       "      <td>0.713560</td>\n",
       "      <td>0.714919</td>\n",
       "      <td>0.748179</td>\n",
       "      <td>0.704518</td>\n",
       "      <td>0.824189</td>\n",
       "      <td>0.819809</td>\n",
       "      <td>0.805986</td>\n",
       "      <td>0.817669</td>\n",
       "      <td>0.832476</td>\n",
       "      <td>0.712902</td>\n",
       "      <td>0.712985</td>\n",
       "      <td>0.838412</td>\n",
       "      <td>0.848718</td>\n",
       "      <td>0.834407</td>\n",
       "      <td>0.789999</td>\n",
       "      <td>0.819978</td>\n",
       "      <td>0.717289</td>\n",
       "      <td>0.821735</td>\n",
       "      <td>0.794855</td>\n",
       "      <td>0.821442</td>\n",
       "      <td>0.734239</td>\n",
       "      <td>0.806486</td>\n",
       "      <td>0.835932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833733</td>\n",
       "      <td>0.867279</td>\n",
       "      <td>0.792864</td>\n",
       "      <td>0.817235</td>\n",
       "      <td>0.836795</td>\n",
       "      <td>0.839837</td>\n",
       "      <td>0.811626</td>\n",
       "      <td>0.861086</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.810708</td>\n",
       "      <td>0.915166</td>\n",
       "      <td>0.806079</td>\n",
       "      <td>0.778209</td>\n",
       "      <td>0.859528</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.783879</td>\n",
       "      <td>0.799467</td>\n",
       "      <td>0.845666</td>\n",
       "      <td>0.803778</td>\n",
       "      <td>0.832472</td>\n",
       "      <td>0.854549</td>\n",
       "      <td>0.796741</td>\n",
       "      <td>0.827498</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.775167</td>\n",
       "      <td>0.819868</td>\n",
       "      <td>0.799665</td>\n",
       "      <td>0.826630</td>\n",
       "      <td>0.770814</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.863464</td>\n",
       "      <td>0.792679</td>\n",
       "      <td>0.916225</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.829712</td>\n",
       "      <td>0.857718</td>\n",
       "      <td>0.811211</td>\n",
       "      <td>0.803838</td>\n",
       "      <td>0.851415</td>\n",
       "      <td>0.812615</td>\n",
       "      <td>0.771278</td>\n",
       "      <td>0.811052</td>\n",
       "      <td>0.466107</td>\n",
       "      <td>0.831474</td>\n",
       "      <td>0.808645</td>\n",
       "      <td>0.75597</td>\n",
       "      <td>0.812604</td>\n",
       "      <td>0.850112</td>\n",
       "      <td>0.902232</td>\n",
       "      <td>0.788274</td>\n",
       "      <td>0.816282</td>\n",
       "      <td>0.844858</td>\n",
       "      <td>0.817831</td>\n",
       "      <td>0.812758</td>\n",
       "      <td>0.761620</td>\n",
       "      <td>0.834849</td>\n",
       "      <td>0.842131</td>\n",
       "      <td>0.761716</td>\n",
       "      <td>0.800135</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.814351</td>\n",
       "      <td>0.790766</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.768449</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.860261</td>\n",
       "      <td>0.762042</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.810291</td>\n",
       "      <td>0.800215</td>\n",
       "      <td>0.777837</td>\n",
       "      <td>0.763021</td>\n",
       "      <td>0.865179</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.763506</td>\n",
       "      <td>0.834542</td>\n",
       "      <td>0.879926</td>\n",
       "      <td>0.773690</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.766484</td>\n",
       "      <td>0.824966</td>\n",
       "      <td>0.833263</td>\n",
       "      <td>0.806821</td>\n",
       "      <td>0.802969</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.785951</td>\n",
       "      <td>0.810785</td>\n",
       "      <td>0.815267</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.244916</td>\n",
       "      <td>0.635200</td>\n",
       "      <td>0.851291</td>\n",
       "      <td>0.851375</td>\n",
       "      <td>0.869997</td>\n",
       "      <td>0.806950</td>\n",
       "      <td>0.857001</td>\n",
       "      <td>0.838171</td>\n",
       "      <td>0.777705</td>\n",
       "      <td>0.850673</td>\n",
       "      <td>0.816125</td>\n",
       "      <td>0.869490</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.873623</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.807142</td>\n",
       "      <td>0.832326</td>\n",
       "      <td>0.799489</td>\n",
       "      <td>0.901490</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.761563</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.815443</td>\n",
       "      <td>0.808879</td>\n",
       "      <td>0.765085</td>\n",
       "      <td>0.811335</td>\n",
       "      <td>0.849873</td>\n",
       "      <td>0.809702</td>\n",
       "      <td>0.874429</td>\n",
       "      <td>0.809987</td>\n",
       "      <td>0.780178</td>\n",
       "      <td>0.816781</td>\n",
       "      <td>0.760290</td>\n",
       "      <td>0.758154</td>\n",
       "      <td>0.846034</td>\n",
       "      <td>0.816993</td>\n",
       "      <td>0.852314</td>\n",
       "      <td>0.718455</td>\n",
       "      <td>0.74054</td>\n",
       "      <td>0.785248</td>\n",
       "      <td>0.819280</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>0.817271</td>\n",
       "      <td>0.782533</td>\n",
       "      <td>0.767001</td>\n",
       "      <td>0.814296</td>\n",
       "      <td>0.814460</td>\n",
       "      <td>0.771962</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.824891</td>\n",
       "      <td>0.847480</td>\n",
       "      <td>0.837735</td>\n",
       "      <td>0.899689</td>\n",
       "      <td>0.877098</td>\n",
       "      <td>0.843772</td>\n",
       "      <td>0.825508</td>\n",
       "      <td>0.845480</td>\n",
       "      <td>0.821133</td>\n",
       "      <td>0.816518</td>\n",
       "      <td>0.733961</td>\n",
       "      <td>0.801066</td>\n",
       "      <td>0.781489</td>\n",
       "      <td>0.758760</td>\n",
       "      <td>0.681881</td>\n",
       "      <td>0.691394</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.812678</td>\n",
       "      <td>0.721722</td>\n",
       "      <td>0.875097</td>\n",
       "      <td>0.814717</td>\n",
       "      <td>0.763716</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.802439</td>\n",
       "      <td>0.829966</td>\n",
       "      <td>0.675287</td>\n",
       "      <td>0.793588</td>\n",
       "      <td>0.836022</td>\n",
       "      <td>0.765381</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.766319</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.795367</td>\n",
       "      <td>0.827362</td>\n",
       "      <td>0.826671</td>\n",
       "      <td>0.798308</td>\n",
       "      <td>0.784337</td>\n",
       "      <td>0.801270</td>\n",
       "      <td>0.908334</td>\n",
       "      <td>0.866742</td>\n",
       "      <td>0.796605</td>\n",
       "      <td>0.809023</td>\n",
       "      <td>0.756403</td>\n",
       "      <td>0.335933</td>\n",
       "      <td>0.767750</td>\n",
       "      <td>0.881718</td>\n",
       "      <td>0.784379</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.756409</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.777487</td>\n",
       "      <td>0.814384</td>\n",
       "      <td>0.850060</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.837291</td>\n",
       "      <td>0.763026</td>\n",
       "      <td>0.859538</td>\n",
       "      <td>0.810234</td>\n",
       "      <td>0.845462</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>0.783185</td>\n",
       "      <td>0.801309</td>\n",
       "      <td>0.822254</td>\n",
       "      <td>0.818665</td>\n",
       "      <td>0.909256</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.791050</td>\n",
       "      <td>0.807334</td>\n",
       "      <td>0.799644</td>\n",
       "      <td>0.765985</td>\n",
       "      <td>0.887590</td>\n",
       "      <td>0.745804</td>\n",
       "      <td>0.771311</td>\n",
       "      <td>0.740030</td>\n",
       "      <td>0.755516</td>\n",
       "      <td>0.726684</td>\n",
       "      <td>0.838977</td>\n",
       "      <td>0.757930</td>\n",
       "      <td>0.864480</td>\n",
       "      <td>0.850818</td>\n",
       "      <td>0.861696</td>\n",
       "      <td>0.688795</td>\n",
       "      <td>0.797739</td>\n",
       "      <td>0.802361</td>\n",
       "      <td>0.799406</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.833259</td>\n",
       "      <td>0.766999</td>\n",
       "      <td>0.871960</td>\n",
       "      <td>0.833062</td>\n",
       "      <td>0.820837</td>\n",
       "      <td>0.825308</td>\n",
       "      <td>0.753659</td>\n",
       "      <td>0.862965</td>\n",
       "      <td>0.843876</td>\n",
       "      <td>0.758391</td>\n",
       "      <td>0.812841</td>\n",
       "      <td>0.779859</td>\n",
       "      <td>0.865657</td>\n",
       "      <td>0.828493</td>\n",
       "      <td>0.763010</td>\n",
       "      <td>0.802883</td>\n",
       "      <td>0.806891</td>\n",
       "      <td>0.896058</td>\n",
       "      <td>0.855776</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481046</td>\n",
       "      <td>0.577118</td>\n",
       "      <td>0.683032</td>\n",
       "      <td>0.541356</td>\n",
       "      <td>0.630088</td>\n",
       "      <td>0.664514</td>\n",
       "      <td>0.413373</td>\n",
       "      <td>0.508210</td>\n",
       "      <td>0.526140</td>\n",
       "      <td>0.584565</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.602584</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.723010</td>\n",
       "      <td>0.744109</td>\n",
       "      <td>0.445748</td>\n",
       "      <td>0.527325</td>\n",
       "      <td>0.659311</td>\n",
       "      <td>0.628628</td>\n",
       "      <td>0.578022</td>\n",
       "      <td>0.651041</td>\n",
       "      <td>0.763677</td>\n",
       "      <td>0.246666</td>\n",
       "      <td>0.636066</td>\n",
       "      <td>0.557556</td>\n",
       "      <td>0.442559</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>0.271324</td>\n",
       "      <td>0.388045</td>\n",
       "      <td>0.459540</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.706474</td>\n",
       "      <td>0.625842</td>\n",
       "      <td>0.401996</td>\n",
       "      <td>0.661254</td>\n",
       "      <td>0.660611</td>\n",
       "      <td>0.512026</td>\n",
       "      <td>0.713758</td>\n",
       "      <td>0.701065</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.454009</td>\n",
       "      <td>0.788229</td>\n",
       "      <td>0.701358</td>\n",
       "      <td>0.488401</td>\n",
       "      <td>0.498188</td>\n",
       "      <td>0.704769</td>\n",
       "      <td>0.812791</td>\n",
       "      <td>0.808457</td>\n",
       "      <td>0.817518</td>\n",
       "      <td>0.269944</td>\n",
       "      <td>0.846012</td>\n",
       "      <td>0.470940</td>\n",
       "      <td>0.761170</td>\n",
       "      <td>0.671712</td>\n",
       "      <td>0.697359</td>\n",
       "      <td>0.794734</td>\n",
       "      <td>0.808295</td>\n",
       "      <td>0.619221</td>\n",
       "      <td>0.794573</td>\n",
       "      <td>0.648007</td>\n",
       "      <td>0.595589</td>\n",
       "      <td>0.833290</td>\n",
       "      <td>0.842175</td>\n",
       "      <td>0.832319</td>\n",
       "      <td>0.828162</td>\n",
       "      <td>0.796764</td>\n",
       "      <td>0.796910</td>\n",
       "      <td>0.772370</td>\n",
       "      <td>0.841927</td>\n",
       "      <td>0.801842</td>\n",
       "      <td>0.795921</td>\n",
       "      <td>0.836183</td>\n",
       "      <td>0.814228</td>\n",
       "      <td>0.699543</td>\n",
       "      <td>0.771656</td>\n",
       "      <td>0.709940</td>\n",
       "      <td>0.837596</td>\n",
       "      <td>0.767667</td>\n",
       "      <td>0.741908</td>\n",
       "      <td>0.835854</td>\n",
       "      <td>0.798775</td>\n",
       "      <td>0.800614</td>\n",
       "      <td>0.800496</td>\n",
       "      <td>0.798642</td>\n",
       "      <td>0.620422</td>\n",
       "      <td>0.640642</td>\n",
       "      <td>0.812928</td>\n",
       "      <td>0.813396</td>\n",
       "      <td>0.795305</td>\n",
       "      <td>0.550577</td>\n",
       "      <td>0.682164</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.624312</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.782254</td>\n",
       "      <td>0.684842</td>\n",
       "      <td>0.639165</td>\n",
       "      <td>0.805773</td>\n",
       "      <td>0.735762</td>\n",
       "      <td>0.738148</td>\n",
       "      <td>0.707363</td>\n",
       "      <td>0.420592</td>\n",
       "      <td>0.812870</td>\n",
       "      <td>0.725034</td>\n",
       "      <td>0.649688</td>\n",
       "      <td>0.641956</td>\n",
       "      <td>0.653415</td>\n",
       "      <td>0.807791</td>\n",
       "      <td>0.581839</td>\n",
       "      <td>0.657398</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.841285</td>\n",
       "      <td>0.803446</td>\n",
       "      <td>0.774044</td>\n",
       "      <td>0.607572</td>\n",
       "      <td>0.829502</td>\n",
       "      <td>0.777233</td>\n",
       "      <td>0.787668</td>\n",
       "      <td>0.601734</td>\n",
       "      <td>0.772266</td>\n",
       "      <td>0.818436</td>\n",
       "      <td>0.642467</td>\n",
       "      <td>0.502177</td>\n",
       "      <td>0.699828</td>\n",
       "      <td>0.750935</td>\n",
       "      <td>0.767647</td>\n",
       "      <td>0.780387</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.667945</td>\n",
       "      <td>0.775577</td>\n",
       "      <td>0.740513</td>\n",
       "      <td>0.760938</td>\n",
       "      <td>0.811425</td>\n",
       "      <td>0.782130</td>\n",
       "      <td>0.823712</td>\n",
       "      <td>0.594568</td>\n",
       "      <td>0.816994</td>\n",
       "      <td>0.742521</td>\n",
       "      <td>0.692432</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.625204</td>\n",
       "      <td>0.789999</td>\n",
       "      <td>0.741557</td>\n",
       "      <td>0.813469</td>\n",
       "      <td>0.816949</td>\n",
       "      <td>0.792266</td>\n",
       "      <td>0.826473</td>\n",
       "      <td>0.797684</td>\n",
       "      <td>0.787640</td>\n",
       "      <td>0.805438</td>\n",
       "      <td>0.419299</td>\n",
       "      <td>0.576001</td>\n",
       "      <td>0.788663</td>\n",
       "      <td>0.796805</td>\n",
       "      <td>0.797416</td>\n",
       "      <td>0.818054</td>\n",
       "      <td>0.772680</td>\n",
       "      <td>0.772307</td>\n",
       "      <td>0.770783</td>\n",
       "      <td>0.816315</td>\n",
       "      <td>0.727651</td>\n",
       "      <td>0.798872</td>\n",
       "      <td>0.743749</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>0.814499</td>\n",
       "      <td>0.800906</td>\n",
       "      <td>0.744299</td>\n",
       "      <td>0.795583</td>\n",
       "      <td>0.784950</td>\n",
       "      <td>0.789155</td>\n",
       "      <td>0.790752</td>\n",
       "      <td>0.777197</td>\n",
       "      <td>0.813260</td>\n",
       "      <td>0.806738</td>\n",
       "      <td>0.780352</td>\n",
       "      <td>0.812616</td>\n",
       "      <td>0.823892</td>\n",
       "      <td>0.779928</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.760749</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>0.816370</td>\n",
       "      <td>0.574678</td>\n",
       "      <td>0.752739</td>\n",
       "      <td>0.840623</td>\n",
       "      <td>0.787268</td>\n",
       "      <td>0.829737</td>\n",
       "      <td>0.791476</td>\n",
       "      <td>0.726902</td>\n",
       "      <td>0.784755</td>\n",
       "      <td>0.775541</td>\n",
       "      <td>0.849387</td>\n",
       "      <td>0.646182</td>\n",
       "      <td>0.861718</td>\n",
       "      <td>0.818949</td>\n",
       "      <td>0.821602</td>\n",
       "      <td>0.585408</td>\n",
       "      <td>0.802717</td>\n",
       "      <td>0.786148</td>\n",
       "      <td>0.810796</td>\n",
       "      <td>0.632478</td>\n",
       "      <td>0.652753</td>\n",
       "      <td>0.785789</td>\n",
       "      <td>0.637340</td>\n",
       "      <td>0.781532</td>\n",
       "      <td>0.642239</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>0.646462</td>\n",
       "      <td>0.652006</td>\n",
       "      <td>0.649111</td>\n",
       "      <td>0.638410</td>\n",
       "      <td>0.793840</td>\n",
       "      <td>0.803732</td>\n",
       "      <td>0.697936</td>\n",
       "      <td>0.652164</td>\n",
       "      <td>0.654680</td>\n",
       "      <td>0.774072</td>\n",
       "      <td>0.654834</td>\n",
       "      <td>0.646500</td>\n",
       "      <td>0.574347</td>\n",
       "      <td>0.648150</td>\n",
       "      <td>0.799521</td>\n",
       "      <td>0.650404</td>\n",
       "      <td>0.660998</td>\n",
       "      <td>0.855050</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.666165</td>\n",
       "      <td>0.750642</td>\n",
       "      <td>0.656215</td>\n",
       "      <td>0.755086</td>\n",
       "      <td>0.794556</td>\n",
       "      <td>0.810863</td>\n",
       "      <td>0.804009</td>\n",
       "      <td>0.812419</td>\n",
       "      <td>0.660469</td>\n",
       "      <td>0.661335</td>\n",
       "      <td>0.853465</td>\n",
       "      <td>0.792250</td>\n",
       "      <td>0.823491</td>\n",
       "      <td>0.756946</td>\n",
       "      <td>0.757464</td>\n",
       "      <td>0.658542</td>\n",
       "      <td>0.818652</td>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.779496</td>\n",
       "      <td>0.677362</td>\n",
       "      <td>0.791830</td>\n",
       "      <td>0.862109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895749</td>\n",
       "      <td>0.495273</td>\n",
       "      <td>0.727701</td>\n",
       "      <td>0.737130</td>\n",
       "      <td>0.770261</td>\n",
       "      <td>0.745426</td>\n",
       "      <td>0.791546</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.836438</td>\n",
       "      <td>0.859333</td>\n",
       "      <td>0.778238</td>\n",
       "      <td>0.719437</td>\n",
       "      <td>0.704034</td>\n",
       "      <td>0.852542</td>\n",
       "      <td>0.725081</td>\n",
       "      <td>0.794922</td>\n",
       "      <td>0.784087</td>\n",
       "      <td>0.763167</td>\n",
       "      <td>0.754036</td>\n",
       "      <td>0.754880</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.730753</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.903751</td>\n",
       "      <td>0.787788</td>\n",
       "      <td>0.769423</td>\n",
       "      <td>0.792511</td>\n",
       "      <td>0.729369</td>\n",
       "      <td>0.745348</td>\n",
       "      <td>0.704907</td>\n",
       "      <td>0.743061</td>\n",
       "      <td>0.592622</td>\n",
       "      <td>0.646493</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.750476</td>\n",
       "      <td>0.737157</td>\n",
       "      <td>0.821953</td>\n",
       "      <td>0.831909</td>\n",
       "      <td>0.706013</td>\n",
       "      <td>0.707603</td>\n",
       "      <td>0.810687</td>\n",
       "      <td>0.768139</td>\n",
       "      <td>0.472390</td>\n",
       "      <td>0.734369</td>\n",
       "      <td>0.842692</td>\n",
       "      <td>0.62250</td>\n",
       "      <td>0.795059</td>\n",
       "      <td>0.710628</td>\n",
       "      <td>0.743347</td>\n",
       "      <td>0.679919</td>\n",
       "      <td>0.724956</td>\n",
       "      <td>0.793494</td>\n",
       "      <td>0.752820</td>\n",
       "      <td>0.823539</td>\n",
       "      <td>0.675959</td>\n",
       "      <td>0.740678</td>\n",
       "      <td>0.775825</td>\n",
       "      <td>0.677309</td>\n",
       "      <td>0.647469</td>\n",
       "      <td>0.571968</td>\n",
       "      <td>0.660585</td>\n",
       "      <td>0.806148</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.710808</td>\n",
       "      <td>0.756050</td>\n",
       "      <td>0.808471</td>\n",
       "      <td>0.659310</td>\n",
       "      <td>0.691916</td>\n",
       "      <td>0.743097</td>\n",
       "      <td>0.769087</td>\n",
       "      <td>0.695552</td>\n",
       "      <td>0.653594</td>\n",
       "      <td>0.786262</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.695713</td>\n",
       "      <td>0.652606</td>\n",
       "      <td>0.814796</td>\n",
       "      <td>0.706355</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.654540</td>\n",
       "      <td>0.750803</td>\n",
       "      <td>0.779488</td>\n",
       "      <td>0.650661</td>\n",
       "      <td>0.803833</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.615119</td>\n",
       "      <td>0.733666</td>\n",
       "      <td>0.740296</td>\n",
       "      <td>0.620272</td>\n",
       "      <td>0.241752</td>\n",
       "      <td>0.637474</td>\n",
       "      <td>0.665255</td>\n",
       "      <td>0.816195</td>\n",
       "      <td>0.725132</td>\n",
       "      <td>0.770546</td>\n",
       "      <td>0.670477</td>\n",
       "      <td>0.698782</td>\n",
       "      <td>0.702367</td>\n",
       "      <td>0.613917</td>\n",
       "      <td>0.744487</td>\n",
       "      <td>0.775870</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.774351</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.707573</td>\n",
       "      <td>0.758477</td>\n",
       "      <td>0.726191</td>\n",
       "      <td>0.697942</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.652148</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.715608</td>\n",
       "      <td>0.763292</td>\n",
       "      <td>0.686879</td>\n",
       "      <td>0.727256</td>\n",
       "      <td>0.685293</td>\n",
       "      <td>0.748288</td>\n",
       "      <td>0.811393</td>\n",
       "      <td>0.662890</td>\n",
       "      <td>0.734988</td>\n",
       "      <td>0.863463</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.715934</td>\n",
       "      <td>0.776586</td>\n",
       "      <td>0.805371</td>\n",
       "      <td>0.818851</td>\n",
       "      <td>0.734592</td>\n",
       "      <td>0.65372</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.712176</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.733031</td>\n",
       "      <td>0.724473</td>\n",
       "      <td>0.693260</td>\n",
       "      <td>0.716155</td>\n",
       "      <td>0.731427</td>\n",
       "      <td>0.727283</td>\n",
       "      <td>0.704681</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.796517</td>\n",
       "      <td>0.774780</td>\n",
       "      <td>0.814016</td>\n",
       "      <td>0.762711</td>\n",
       "      <td>0.873457</td>\n",
       "      <td>0.685968</td>\n",
       "      <td>0.750630</td>\n",
       "      <td>0.705484</td>\n",
       "      <td>0.889912</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.570358</td>\n",
       "      <td>0.694653</td>\n",
       "      <td>0.800916</td>\n",
       "      <td>0.687705</td>\n",
       "      <td>0.714742</td>\n",
       "      <td>0.692404</td>\n",
       "      <td>0.716626</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.694464</td>\n",
       "      <td>0.789942</td>\n",
       "      <td>0.721255</td>\n",
       "      <td>0.701537</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>0.770761</td>\n",
       "      <td>0.675287</td>\n",
       "      <td>0.714994</td>\n",
       "      <td>0.837553</td>\n",
       "      <td>0.736147</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.656738</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.628795</td>\n",
       "      <td>0.581039</td>\n",
       "      <td>0.729520</td>\n",
       "      <td>0.748986</td>\n",
       "      <td>0.749680</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>0.601509</td>\n",
       "      <td>0.538543</td>\n",
       "      <td>0.714939</td>\n",
       "      <td>0.820410</td>\n",
       "      <td>0.668162</td>\n",
       "      <td>0.338749</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.832265</td>\n",
       "      <td>0.701073</td>\n",
       "      <td>0.715576</td>\n",
       "      <td>0.751954</td>\n",
       "      <td>0.688012</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.809385</td>\n",
       "      <td>0.829437</td>\n",
       "      <td>0.878710</td>\n",
       "      <td>0.741166</td>\n",
       "      <td>0.724611</td>\n",
       "      <td>0.710051</td>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.867617</td>\n",
       "      <td>0.844242</td>\n",
       "      <td>0.728528</td>\n",
       "      <td>0.685292</td>\n",
       "      <td>0.692359</td>\n",
       "      <td>0.694486</td>\n",
       "      <td>0.687283</td>\n",
       "      <td>0.664667</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.804032</td>\n",
       "      <td>0.706274</td>\n",
       "      <td>0.705306</td>\n",
       "      <td>0.697015</td>\n",
       "      <td>0.853246</td>\n",
       "      <td>0.691722</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.677103</td>\n",
       "      <td>0.683902</td>\n",
       "      <td>0.795511</td>\n",
       "      <td>0.589118</td>\n",
       "      <td>0.736120</td>\n",
       "      <td>0.777212</td>\n",
       "      <td>0.700488</td>\n",
       "      <td>0.753324</td>\n",
       "      <td>0.146649</td>\n",
       "      <td>0.691117</td>\n",
       "      <td>0.774402</td>\n",
       "      <td>0.785284</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.830470</td>\n",
       "      <td>0.673529</td>\n",
       "      <td>0.829291</td>\n",
       "      <td>0.812907</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.744348</td>\n",
       "      <td>0.717934</td>\n",
       "      <td>0.811482</td>\n",
       "      <td>0.791431</td>\n",
       "      <td>0.733034</td>\n",
       "      <td>0.824703</td>\n",
       "      <td>0.799698</td>\n",
       "      <td>0.800130</td>\n",
       "      <td>0.716604</td>\n",
       "      <td>0.603779</td>\n",
       "      <td>0.708499</td>\n",
       "      <td>0.844837</td>\n",
       "      <td>0.853057</td>\n",
       "      <td>0.850657</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.957339</td>\n",
       "      <td>0.910337</td>\n",
       "      <td>0.917322</td>\n",
       "      <td>0.874487</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.854273</td>\n",
       "      <td>0.843846</td>\n",
       "      <td>0.876749</td>\n",
       "      <td>0.821128</td>\n",
       "      <td>0.913054</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.917918</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.879352</td>\n",
       "      <td>0.935055</td>\n",
       "      <td>0.895198</td>\n",
       "      <td>0.862470</td>\n",
       "      <td>0.855158</td>\n",
       "      <td>0.881489</td>\n",
       "      <td>0.784991</td>\n",
       "      <td>0.909883</td>\n",
       "      <td>0.928098</td>\n",
       "      <td>0.792752</td>\n",
       "      <td>0.777533</td>\n",
       "      <td>0.812564</td>\n",
       "      <td>0.785255</td>\n",
       "      <td>0.831690</td>\n",
       "      <td>0.804061</td>\n",
       "      <td>0.868174</td>\n",
       "      <td>0.945780</td>\n",
       "      <td>0.645846</td>\n",
       "      <td>0.911603</td>\n",
       "      <td>0.888005</td>\n",
       "      <td>0.793007</td>\n",
       "      <td>0.893517</td>\n",
       "      <td>0.578045</td>\n",
       "      <td>0.730208</td>\n",
       "      <td>0.962325</td>\n",
       "      <td>0.848295</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.814630</td>\n",
       "      <td>0.956217</td>\n",
       "      <td>0.706360</td>\n",
       "      <td>0.695954</td>\n",
       "      <td>0.836541</td>\n",
       "      <td>0.919095</td>\n",
       "      <td>0.947666</td>\n",
       "      <td>0.943528</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.487857</td>\n",
       "      <td>0.950953</td>\n",
       "      <td>0.677409</td>\n",
       "      <td>0.964349</td>\n",
       "      <td>0.831906</td>\n",
       "      <td>0.837142</td>\n",
       "      <td>0.964467</td>\n",
       "      <td>0.942013</td>\n",
       "      <td>0.741847</td>\n",
       "      <td>0.935458</td>\n",
       "      <td>0.704322</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.956573</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.958250</td>\n",
       "      <td>0.942714</td>\n",
       "      <td>0.944545</td>\n",
       "      <td>0.963526</td>\n",
       "      <td>0.949687</td>\n",
       "      <td>0.954702</td>\n",
       "      <td>0.943751</td>\n",
       "      <td>0.948903</td>\n",
       "      <td>0.940670</td>\n",
       "      <td>0.945268</td>\n",
       "      <td>0.925191</td>\n",
       "      <td>0.948105</td>\n",
       "      <td>0.914014</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.963517</td>\n",
       "      <td>0.742667</td>\n",
       "      <td>0.967229</td>\n",
       "      <td>0.941201</td>\n",
       "      <td>0.958791</td>\n",
       "      <td>0.950246</td>\n",
       "      <td>0.964796</td>\n",
       "      <td>0.740754</td>\n",
       "      <td>0.915171</td>\n",
       "      <td>0.961564</td>\n",
       "      <td>0.951278</td>\n",
       "      <td>0.966022</td>\n",
       "      <td>0.569731</td>\n",
       "      <td>0.736556</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.810732</td>\n",
       "      <td>0.964930</td>\n",
       "      <td>0.950813</td>\n",
       "      <td>0.905852</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.948717</td>\n",
       "      <td>0.963048</td>\n",
       "      <td>0.930563</td>\n",
       "      <td>0.927922</td>\n",
       "      <td>0.900101</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.960217</td>\n",
       "      <td>0.821655</td>\n",
       "      <td>0.778938</td>\n",
       "      <td>0.882111</td>\n",
       "      <td>0.931933</td>\n",
       "      <td>0.792044</td>\n",
       "      <td>0.814025</td>\n",
       "      <td>0.796209</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>0.967537</td>\n",
       "      <td>0.930748</td>\n",
       "      <td>0.961782</td>\n",
       "      <td>0.714929</td>\n",
       "      <td>0.964749</td>\n",
       "      <td>0.966250</td>\n",
       "      <td>0.946063</td>\n",
       "      <td>0.669736</td>\n",
       "      <td>0.934874</td>\n",
       "      <td>0.948343</td>\n",
       "      <td>0.768843</td>\n",
       "      <td>0.818818</td>\n",
       "      <td>0.954254</td>\n",
       "      <td>0.976487</td>\n",
       "      <td>0.962730</td>\n",
       "      <td>0.965765</td>\n",
       "      <td>0.804748</td>\n",
       "      <td>0.836092</td>\n",
       "      <td>0.975497</td>\n",
       "      <td>0.974534</td>\n",
       "      <td>0.956940</td>\n",
       "      <td>0.949187</td>\n",
       "      <td>0.934028</td>\n",
       "      <td>0.959145</td>\n",
       "      <td>0.938189</td>\n",
       "      <td>0.956034</td>\n",
       "      <td>0.965899</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>0.947873</td>\n",
       "      <td>0.743857</td>\n",
       "      <td>0.945213</td>\n",
       "      <td>0.977032</td>\n",
       "      <td>0.948939</td>\n",
       "      <td>0.965122</td>\n",
       "      <td>0.959891</td>\n",
       "      <td>0.951876</td>\n",
       "      <td>0.950310</td>\n",
       "      <td>0.963896</td>\n",
       "      <td>0.951072</td>\n",
       "      <td>0.639456</td>\n",
       "      <td>0.587150</td>\n",
       "      <td>0.957015</td>\n",
       "      <td>0.946867</td>\n",
       "      <td>0.951096</td>\n",
       "      <td>0.947651</td>\n",
       "      <td>0.962276</td>\n",
       "      <td>0.941339</td>\n",
       "      <td>0.958501</td>\n",
       "      <td>0.957956</td>\n",
       "      <td>0.970960</td>\n",
       "      <td>0.945001</td>\n",
       "      <td>0.965298</td>\n",
       "      <td>0.954260</td>\n",
       "      <td>0.950065</td>\n",
       "      <td>0.951122</td>\n",
       "      <td>0.963175</td>\n",
       "      <td>0.952976</td>\n",
       "      <td>0.951355</td>\n",
       "      <td>0.944987</td>\n",
       "      <td>0.936911</td>\n",
       "      <td>0.953394</td>\n",
       "      <td>0.943872</td>\n",
       "      <td>0.950627</td>\n",
       "      <td>0.952285</td>\n",
       "      <td>0.955480</td>\n",
       "      <td>0.933447</td>\n",
       "      <td>0.953413</td>\n",
       "      <td>0.982246</td>\n",
       "      <td>0.967559</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>0.949907</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.960187</td>\n",
       "      <td>0.958420</td>\n",
       "      <td>0.943152</td>\n",
       "      <td>0.961092</td>\n",
       "      <td>0.954184</td>\n",
       "      <td>0.958137</td>\n",
       "      <td>0.960213</td>\n",
       "      <td>0.968665</td>\n",
       "      <td>0.954888</td>\n",
       "      <td>0.782735</td>\n",
       "      <td>0.955005</td>\n",
       "      <td>0.948306</td>\n",
       "      <td>0.957123</td>\n",
       "      <td>0.676376</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>0.943204</td>\n",
       "      <td>0.954072</td>\n",
       "      <td>0.776319</td>\n",
       "      <td>0.776692</td>\n",
       "      <td>0.953599</td>\n",
       "      <td>0.777384</td>\n",
       "      <td>0.953905</td>\n",
       "      <td>0.778458</td>\n",
       "      <td>0.863547</td>\n",
       "      <td>0.775349</td>\n",
       "      <td>0.777345</td>\n",
       "      <td>0.777881</td>\n",
       "      <td>0.778211</td>\n",
       "      <td>0.922320</td>\n",
       "      <td>0.952621</td>\n",
       "      <td>0.825842</td>\n",
       "      <td>0.779045</td>\n",
       "      <td>0.775611</td>\n",
       "      <td>0.966923</td>\n",
       "      <td>0.779222</td>\n",
       "      <td>0.778177</td>\n",
       "      <td>0.772809</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.965871</td>\n",
       "      <td>0.779475</td>\n",
       "      <td>0.778538</td>\n",
       "      <td>0.940145</td>\n",
       "      <td>0.777498</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>0.863089</td>\n",
       "      <td>0.778143</td>\n",
       "      <td>0.954092</td>\n",
       "      <td>0.953081</td>\n",
       "      <td>0.951770</td>\n",
       "      <td>0.958379</td>\n",
       "      <td>0.940364</td>\n",
       "      <td>0.773112</td>\n",
       "      <td>0.778073</td>\n",
       "      <td>0.940602</td>\n",
       "      <td>0.958745</td>\n",
       "      <td>0.953006</td>\n",
       "      <td>0.950656</td>\n",
       "      <td>0.966904</td>\n",
       "      <td>0.780241</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>0.902674</td>\n",
       "      <td>0.964108</td>\n",
       "      <td>0.809438</td>\n",
       "      <td>0.948075</td>\n",
       "      <td>0.945511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.952009</td>\n",
       "      <td>0.924867</td>\n",
       "      <td>0.965829</td>\n",
       "      <td>0.920804</td>\n",
       "      <td>0.930917</td>\n",
       "      <td>0.929818</td>\n",
       "      <td>0.979089</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.931732</td>\n",
       "      <td>0.954809</td>\n",
       "      <td>0.938110</td>\n",
       "      <td>0.924876</td>\n",
       "      <td>0.934840</td>\n",
       "      <td>0.981173</td>\n",
       "      <td>0.925483</td>\n",
       "      <td>0.957305</td>\n",
       "      <td>0.932651</td>\n",
       "      <td>0.945458</td>\n",
       "      <td>0.940641</td>\n",
       "      <td>0.959966</td>\n",
       "      <td>0.931819</td>\n",
       "      <td>0.964703</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.955012</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.949040</td>\n",
       "      <td>0.933638</td>\n",
       "      <td>0.914358</td>\n",
       "      <td>0.904968</td>\n",
       "      <td>0.954356</td>\n",
       "      <td>0.922749</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.948393</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.905919</td>\n",
       "      <td>0.966503</td>\n",
       "      <td>0.922379</td>\n",
       "      <td>0.941679</td>\n",
       "      <td>0.937840</td>\n",
       "      <td>0.935648</td>\n",
       "      <td>0.908894</td>\n",
       "      <td>0.944376</td>\n",
       "      <td>0.858483</td>\n",
       "      <td>0.921305</td>\n",
       "      <td>0.940255</td>\n",
       "      <td>0.96000</td>\n",
       "      <td>0.934891</td>\n",
       "      <td>0.938110</td>\n",
       "      <td>0.941676</td>\n",
       "      <td>0.929199</td>\n",
       "      <td>0.969335</td>\n",
       "      <td>0.959914</td>\n",
       "      <td>0.944421</td>\n",
       "      <td>0.950431</td>\n",
       "      <td>0.933564</td>\n",
       "      <td>0.935508</td>\n",
       "      <td>0.931652</td>\n",
       "      <td>0.933683</td>\n",
       "      <td>0.947941</td>\n",
       "      <td>0.879953</td>\n",
       "      <td>0.930539</td>\n",
       "      <td>0.927920</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.935210</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>0.973037</td>\n",
       "      <td>0.934454</td>\n",
       "      <td>0.951877</td>\n",
       "      <td>0.935977</td>\n",
       "      <td>0.945510</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.942843</td>\n",
       "      <td>0.949085</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.935028</td>\n",
       "      <td>0.921131</td>\n",
       "      <td>0.947241</td>\n",
       "      <td>0.937358</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.935124</td>\n",
       "      <td>0.933135</td>\n",
       "      <td>0.956872</td>\n",
       "      <td>0.923821</td>\n",
       "      <td>0.938291</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.958800</td>\n",
       "      <td>0.964427</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>0.931617</td>\n",
       "      <td>0.680464</td>\n",
       "      <td>0.922207</td>\n",
       "      <td>0.931885</td>\n",
       "      <td>0.916316</td>\n",
       "      <td>0.949368</td>\n",
       "      <td>0.930651</td>\n",
       "      <td>0.936535</td>\n",
       "      <td>0.920323</td>\n",
       "      <td>0.931514</td>\n",
       "      <td>0.983698</td>\n",
       "      <td>0.967124</td>\n",
       "      <td>0.949272</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.951796</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.953323</td>\n",
       "      <td>0.937281</td>\n",
       "      <td>0.941442</td>\n",
       "      <td>0.950565</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.937592</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.924668</td>\n",
       "      <td>0.939884</td>\n",
       "      <td>0.939709</td>\n",
       "      <td>0.937779</td>\n",
       "      <td>0.921181</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.958235</td>\n",
       "      <td>0.893659</td>\n",
       "      <td>0.946999</td>\n",
       "      <td>0.957776</td>\n",
       "      <td>0.936169</td>\n",
       "      <td>0.941485</td>\n",
       "      <td>0.936649</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>0.962152</td>\n",
       "      <td>0.970359</td>\n",
       "      <td>0.93780</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>0.912734</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.937157</td>\n",
       "      <td>0.943892</td>\n",
       "      <td>0.933907</td>\n",
       "      <td>0.944612</td>\n",
       "      <td>0.927684</td>\n",
       "      <td>0.932256</td>\n",
       "      <td>0.932845</td>\n",
       "      <td>0.953958</td>\n",
       "      <td>0.961658</td>\n",
       "      <td>0.937017</td>\n",
       "      <td>0.950575</td>\n",
       "      <td>0.965865</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.935402</td>\n",
       "      <td>0.901300</td>\n",
       "      <td>0.906814</td>\n",
       "      <td>0.916661</td>\n",
       "      <td>0.958190</td>\n",
       "      <td>0.916060</td>\n",
       "      <td>0.950381</td>\n",
       "      <td>0.974851</td>\n",
       "      <td>0.935239</td>\n",
       "      <td>0.595583</td>\n",
       "      <td>0.774454</td>\n",
       "      <td>0.980777</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.930837</td>\n",
       "      <td>0.854952</td>\n",
       "      <td>0.958083</td>\n",
       "      <td>0.931717</td>\n",
       "      <td>0.932412</td>\n",
       "      <td>0.952583</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>0.969987</td>\n",
       "      <td>0.697208</td>\n",
       "      <td>0.927489</td>\n",
       "      <td>0.967159</td>\n",
       "      <td>0.949621</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.940259</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.934430</td>\n",
       "      <td>0.981714</td>\n",
       "      <td>0.934403</td>\n",
       "      <td>0.935743</td>\n",
       "      <td>0.863703</td>\n",
       "      <td>0.881873</td>\n",
       "      <td>0.972271</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.922039</td>\n",
       "      <td>0.967649</td>\n",
       "      <td>0.928029</td>\n",
       "      <td>0.344151</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.983632</td>\n",
       "      <td>0.951695</td>\n",
       "      <td>0.942845</td>\n",
       "      <td>0.953762</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.976591</td>\n",
       "      <td>0.933966</td>\n",
       "      <td>0.933172</td>\n",
       "      <td>0.931840</td>\n",
       "      <td>0.964148</td>\n",
       "      <td>0.936838</td>\n",
       "      <td>0.912548</td>\n",
       "      <td>0.934099</td>\n",
       "      <td>0.946673</td>\n",
       "      <td>0.920494</td>\n",
       "      <td>0.949425</td>\n",
       "      <td>0.945415</td>\n",
       "      <td>0.967463</td>\n",
       "      <td>0.923194</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.929723</td>\n",
       "      <td>0.915569</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>0.935026</td>\n",
       "      <td>0.954800</td>\n",
       "      <td>0.935549</td>\n",
       "      <td>0.940336</td>\n",
       "      <td>0.929120</td>\n",
       "      <td>0.936355</td>\n",
       "      <td>0.849463</td>\n",
       "      <td>0.920010</td>\n",
       "      <td>0.936611</td>\n",
       "      <td>0.955951</td>\n",
       "      <td>0.909035</td>\n",
       "      <td>0.945011</td>\n",
       "      <td>0.926108</td>\n",
       "      <td>0.958017</td>\n",
       "      <td>0.898938</td>\n",
       "      <td>0.915973</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.946283</td>\n",
       "      <td>0.943757</td>\n",
       "      <td>0.974282</td>\n",
       "      <td>0.945445</td>\n",
       "      <td>0.938059</td>\n",
       "      <td>0.923524</td>\n",
       "      <td>0.935912</td>\n",
       "      <td>0.959907</td>\n",
       "      <td>0.970689</td>\n",
       "      <td>0.942653</td>\n",
       "      <td>0.934803</td>\n",
       "      <td>0.900150</td>\n",
       "      <td>0.960911</td>\n",
       "      <td>0.906037</td>\n",
       "      <td>0.961240</td>\n",
       "      <td>0.935608</td>\n",
       "      <td>0.889757</td>\n",
       "      <td>0.978505</td>\n",
       "      <td>0.953681</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_0    pred_1    pred_2    pred_3    pred_4    pred_5    pred_6  \\\n",
       "id                                                                         \n",
       "0   0.709336  0.799007  0.851891  0.537158  0.623930  0.705970  0.503437   \n",
       "1   0.452988  0.364453  0.567582  0.354468  0.513818  0.584119  0.454809   \n",
       "2   0.675462  0.842260  0.800013  0.525229  0.692071  0.715418  0.651008   \n",
       "3   0.481046  0.577118  0.683032  0.541356  0.630088  0.664514  0.413373   \n",
       "4   0.957339  0.910337  0.917322  0.874487  0.787595  0.854273  0.843846   \n",
       "\n",
       "      pred_7    pred_8    pred_9  pred_10   pred_11  pred_12  pred_13  \\\n",
       "id                                                                      \n",
       "0   0.633185  0.641550  0.666604     0.55  0.494577    0.470     0.59   \n",
       "1   0.238501  0.472171  0.522314     0.45  0.666009    0.475     0.56   \n",
       "2   0.609124  0.691198  0.609994     0.66  0.748037    0.525     0.69   \n",
       "3   0.508210  0.526140  0.584565     0.58  0.602584    0.520     0.51   \n",
       "4   0.876749  0.821128  0.913054     0.84  0.917918    0.700     0.87   \n",
       "\n",
       "     pred_14   pred_15   pred_16   pred_17   pred_18   pred_19   pred_20  \\\n",
       "id                                                                         \n",
       "0   0.586738  0.801957  0.562042  0.607146  0.723824  0.514653  0.698785   \n",
       "1   0.732957  0.714976  0.419134  0.404536  0.539501  0.637878  0.466280   \n",
       "2   0.669469  0.788335  0.394662  0.574383  0.717165  0.765810  0.656733   \n",
       "3   0.723010  0.744109  0.445748  0.527325  0.659311  0.628628  0.578022   \n",
       "4   0.879352  0.935055  0.895198  0.862470  0.855158  0.881489  0.784991   \n",
       "\n",
       "     pred_21   pred_22   pred_23   pred_24   pred_25   pred_26   pred_27  \\\n",
       "id                                                                         \n",
       "0   0.648393  0.847155  0.504999  0.651316  0.635714  0.494180  0.654680   \n",
       "1   0.438964  0.473790  0.177996  0.506920  0.504273  0.398968  0.597034   \n",
       "2   0.641200  0.644853  0.366641  0.698106  0.656238  0.559506  0.706054   \n",
       "3   0.651041  0.763677  0.246666  0.636066  0.557556  0.442559  0.535435   \n",
       "4   0.909883  0.928098  0.792752  0.777533  0.812564  0.785255  0.831690   \n",
       "\n",
       "     pred_28   pred_29   pred_30   pred_31   pred_32   pred_33   pred_34  \\\n",
       "id                                                                         \n",
       "0   0.423318  0.518875  0.696630  0.772409  0.657442  0.652088  0.535287   \n",
       "1   0.294240  0.435329  0.417415  0.362844  0.604260  0.571773  0.515101   \n",
       "2   0.380290  0.436985  0.778724  0.507844  0.698322  0.755622  0.596451   \n",
       "3   0.271324  0.388045  0.459540  0.515625  0.706474  0.625842  0.401996   \n",
       "4   0.804061  0.868174  0.945780  0.645846  0.911603  0.888005  0.793007   \n",
       "\n",
       "     pred_35   pred_36   pred_37   pred_38   pred_39  pred_40   pred_41  \\\n",
       "id                                                                        \n",
       "0   0.589636  0.641365  0.606017  0.778243  0.845207   0.6550  0.568964   \n",
       "1   0.478809  0.555008  0.414648  0.602281  0.670183   0.5150  0.494151   \n",
       "2   0.645121  0.645856  0.512432  0.803193  0.730882   0.7050  0.719212   \n",
       "3   0.661254  0.660611  0.512026  0.713758  0.701065   0.5800  0.454009   \n",
       "4   0.893517  0.578045  0.730208  0.962325  0.848295   0.9025  0.814630   \n",
       "\n",
       "     pred_42   pred_43   pred_44   pred_45   pred_46   pred_47   pred_48  \\\n",
       "id                                                                         \n",
       "0   0.909303  0.466230  0.505583  0.508293  0.696233  0.898834  0.914714   \n",
       "1   0.613548  0.595513  0.445120  0.483932  0.599259  0.601485  0.602389   \n",
       "2   0.816767  0.482021  0.485455  0.605928  0.744988  0.825288  0.781854   \n",
       "3   0.788229  0.701358  0.488401  0.498188  0.704769  0.812791  0.808457   \n",
       "4   0.956217  0.706360  0.695954  0.836541  0.919095  0.947666  0.943528   \n",
       "\n",
       "     pred_49   pred_50   pred_51   pred_52   pred_53   pred_54   pred_55  \\\n",
       "id                                                                         \n",
       "0   0.922075  0.479519  0.937982  0.566443  0.811661  0.714225  0.725077   \n",
       "1   0.604563  0.258524  0.661866  0.401900  0.640667  0.601536  0.712083   \n",
       "2   0.814117  0.490606  0.790689  0.564994  0.807724  0.696787  0.716777   \n",
       "3   0.817518  0.269944  0.846012  0.470940  0.761170  0.671712  0.697359   \n",
       "4   0.951825  0.487857  0.950953  0.677409  0.964349  0.831906  0.837142   \n",
       "\n",
       "     pred_56   pred_57   pred_58   pred_59   pred_60   pred_61   pred_62  \\\n",
       "id                                                                         \n",
       "0   0.922891  0.921742  0.594629  0.932837  0.599946  0.606418  0.930759   \n",
       "1   0.668786  0.619580  0.552569  0.637539  0.593669  0.488146  0.644062   \n",
       "2   0.809696  0.832032  0.622356  0.811664  0.641584  0.625621  0.810776   \n",
       "3   0.794734  0.808295  0.619221  0.794573  0.648007  0.595589  0.833290   \n",
       "4   0.964467  0.942013  0.741847  0.935458  0.704322  0.980000  0.956573   \n",
       "\n",
       "     pred_63   pred_64   pred_65   pred_66   pred_67   pred_68   pred_69  \\\n",
       "id                                                                         \n",
       "0   0.930242  0.941618  0.957463  0.906037  0.922421  0.906153  0.945167   \n",
       "1   0.629101  0.628834  0.647618  0.658552  0.644813  0.573348  0.647081   \n",
       "2   0.809876  0.811948  0.818143  0.816159  0.806781  0.867544  0.799864   \n",
       "3   0.842175  0.832319  0.828162  0.796764  0.796910  0.772370  0.841927   \n",
       "4   0.964983  0.958250  0.942714  0.944545  0.963526  0.949687  0.954702   \n",
       "\n",
       "     pred_70   pred_71   pred_72   pred_73   pred_74   pred_75   pred_76  \\\n",
       "id                                                                         \n",
       "0   0.892739  0.945352  0.960757  0.956259  0.646067  0.872427  0.729955   \n",
       "1   0.661094  0.679846  0.651932  0.642106  0.512870  0.578207  0.555843   \n",
       "2   0.813695  0.794572  0.822299  0.795874  0.768272  0.819478  0.739492   \n",
       "3   0.801842  0.795921  0.836183  0.814228  0.699543  0.771656  0.709940   \n",
       "4   0.943751  0.948903  0.940670  0.945268  0.925191  0.948105  0.914014   \n",
       "\n",
       "     pred_77   pred_78   pred_79   pred_80   pred_81   pred_82   pred_83  \\\n",
       "id                                                                         \n",
       "0   0.929035  0.844362  0.697281  0.921738  0.799486  0.919839  0.945280   \n",
       "1   0.644829  0.631186  0.808865  0.647233  0.642972  0.621325  0.652881   \n",
       "2   0.804766  0.790021  0.707139  0.811145  0.860909  0.832409  0.799195   \n",
       "3   0.837596  0.767667  0.741908  0.835854  0.798775  0.800614  0.800496   \n",
       "4   0.957280  0.963517  0.742667  0.967229  0.941201  0.958791  0.950246   \n",
       "\n",
       "     pred_84   pred_85   pred_86   pred_87   pred_88   pred_89   pred_90  \\\n",
       "id                                                                         \n",
       "0   0.902676  0.666626  0.768229  0.945016  0.963822  0.897716  0.537010   \n",
       "1   0.624169  0.602384  0.497198  0.655108  0.656787  0.627654  0.502368   \n",
       "2   0.823453  0.658420  0.604025  0.820993  0.814296  0.823566  0.448933   \n",
       "3   0.798642  0.620422  0.640642  0.812928  0.813396  0.795305  0.550577   \n",
       "4   0.964796  0.740754  0.915171  0.961564  0.951278  0.966022  0.569731   \n",
       "\n",
       "     pred_91  pred_92   pred_93   pred_94   pred_95   pred_96   pred_97  \\\n",
       "id                                                                        \n",
       "0   0.643323    0.642  0.675474  0.895324  0.832749  0.769671  0.623374   \n",
       "1   0.584159    0.614  0.573083  0.648244  0.568334  0.583181  0.625131   \n",
       "2   0.682090    0.704  0.707723  0.822082  0.825743  0.794294  0.669156   \n",
       "3   0.682164    0.572  0.624312  0.798200  0.782254  0.684842  0.639165   \n",
       "4   0.736556    0.878  0.810732  0.964930  0.950813  0.905852  0.705403   \n",
       "\n",
       "     pred_98   pred_99  pred_100  pred_101  pred_102  pred_103  pred_104  \\\n",
       "id                                                                         \n",
       "0   0.956150  0.907764  0.879518  0.705692  0.644098  0.930951  0.772919   \n",
       "1   0.611957  0.640366  0.661202  0.505585  0.289171  0.627038  0.635627   \n",
       "2   0.829765  0.796169  0.825571  0.794276  0.664967  0.827944  0.787310   \n",
       "3   0.805773  0.735762  0.738148  0.707363  0.420592  0.812870  0.725034   \n",
       "4   0.948717  0.963048  0.930563  0.927922  0.900101  0.939247  0.960217   \n",
       "\n",
       "    pred_105  pred_106  pred_107  pred_108  pred_109  pred_110  pred_111  \\\n",
       "id                                                                         \n",
       "0   0.812400  0.650367  0.696069  0.931176  0.700183  0.646789  0.708291   \n",
       "1   0.554886  0.562929  0.501377  0.682853  0.533531  0.494124  0.580500   \n",
       "2   0.707549  0.717424  0.796097  0.812508  0.704367  0.712928  0.747083   \n",
       "3   0.649688  0.641956  0.653415  0.807791  0.581839  0.657398  0.724100   \n",
       "4   0.821655  0.778938  0.882111  0.931933  0.792044  0.814025  0.796209   \n",
       "\n",
       "    pred_112  pred_113  pred_114  pred_115  pred_116  pred_117  pred_118  \\\n",
       "id                                                                         \n",
       "0   0.938083  0.976355  0.948648  0.832077  0.627968  0.974728  0.810878   \n",
       "1   0.624901  0.673024  0.633642  0.621477  0.528351  0.694932  0.682610   \n",
       "2   0.837944  0.821771  0.815776  0.770536  0.653857  0.823259  0.849905   \n",
       "3   0.792929  0.841285  0.803446  0.774044  0.607572  0.829502  0.777233   \n",
       "4   0.930603  0.967537  0.930748  0.961782  0.714929  0.964749  0.966250   \n",
       "\n",
       "    pred_119  pred_120  pred_121  pred_122  pred_123  pred_124  pred_125  \\\n",
       "id                                                                         \n",
       "0   0.880978  0.675629  0.843527  0.956883  0.673548  0.662422  0.785180   \n",
       "1   0.666823  0.602497  0.625227  0.608956  0.579682  0.511741  0.486436   \n",
       "2   0.802251  0.650613  0.816146  0.833861  0.676217  0.662334  0.812814   \n",
       "3   0.787668  0.601734  0.772266  0.818436  0.642467  0.502177  0.699828   \n",
       "4   0.946063  0.669736  0.934874  0.948343  0.768843  0.818818  0.954254   \n",
       "\n",
       "    pred_126  pred_127  pred_128  pred_129  pred_130  pred_131  pred_132  \\\n",
       "id                                                                         \n",
       "0   0.896610  0.839888  0.812889  0.695166  0.667115  0.908483  0.733079   \n",
       "1   0.689482  0.621342  0.687989  0.435278  0.539069  0.712965  0.644455   \n",
       "2   0.785306  0.849646  0.852297  0.568925  0.737468  0.820915  0.785100   \n",
       "3   0.750935  0.767647  0.780387  0.531579  0.667945  0.775577  0.740513   \n",
       "4   0.976487  0.962730  0.965765  0.804748  0.836092  0.975497  0.974534   \n",
       "\n",
       "    pred_133  pred_134  pred_135  pred_136  pred_137  pred_138  pred_139  \\\n",
       "id                                                                         \n",
       "0   0.904345  0.892627  0.874332  0.770953  0.814974  0.794214  0.906117   \n",
       "1   0.643942  0.709303  0.637611  0.668925  0.549318  0.618010  0.650828   \n",
       "2   0.796107  0.821535  0.795397  0.819162  0.773409  0.820803  0.800624   \n",
       "3   0.760938  0.811425  0.782130  0.823712  0.594568  0.816994  0.742521   \n",
       "4   0.956940  0.949187  0.934028  0.959145  0.938189  0.956034  0.965899   \n",
       "\n",
       "    pred_140  pred_141  pred_142  pred_143  pred_144  pred_145  pred_146  \\\n",
       "id                                                                         \n",
       "0   0.771051  0.730623  0.645044  0.926714  0.746078  0.905658  0.844268   \n",
       "1   0.573493  0.450846  0.541993  0.619029  0.637448  0.604204  0.638032   \n",
       "2   0.779749  0.729107  0.691039  0.834565  0.785142  0.831311  0.811273   \n",
       "3   0.692432  0.604938  0.625204  0.789999  0.741557  0.813469  0.816949   \n",
       "4   0.903624  0.947873  0.743857  0.945213  0.977032  0.948939  0.965122   \n",
       "\n",
       "    pred_147  pred_148  pred_149  pred_150  pred_151  pred_152  pred_153  \\\n",
       "id                                                                         \n",
       "0   0.850759  0.904881  0.890427  0.825087  0.852848  0.577451  0.456252   \n",
       "1   0.669435  0.594310  0.596047  0.616601  0.657313  0.426250  0.543961   \n",
       "2   0.829589  0.831566  0.825430  0.786754  0.770663  0.590588  0.457862   \n",
       "3   0.792266  0.826473  0.797684  0.787640  0.805438  0.419299  0.576001   \n",
       "4   0.959891  0.951876  0.950310  0.963896  0.951072  0.639456  0.587150   \n",
       "\n",
       "    pred_154  pred_155  pred_156  pred_157  pred_158  pred_159  pred_160  \\\n",
       "id                                                                         \n",
       "0   0.916432  0.956820  0.906898  0.929678  0.906078  0.887494  0.924072   \n",
       "1   0.627445  0.636621  0.585731  0.642914  0.560543  0.640902  0.537879   \n",
       "2   0.837226  0.833258  0.842586  0.820717  0.817439  0.821279  0.808627   \n",
       "3   0.788663  0.796805  0.797416  0.818054  0.772680  0.772307  0.770783   \n",
       "4   0.957015  0.946867  0.951096  0.947651  0.962276  0.941339  0.958501   \n",
       "\n",
       "    pred_161  pred_162  pred_163  pred_164  pred_165  pred_166  pred_167  \\\n",
       "id                                                                         \n",
       "0   0.787867  0.818566  0.969202  0.936387  0.893934  0.971786  0.858574   \n",
       "1   0.674142  0.690330  0.627449  0.543489  0.609602  0.692161  0.611896   \n",
       "2   0.807502  0.844756  0.837281  0.811220  0.848504  0.816399  0.809840   \n",
       "3   0.816315  0.727651  0.798872  0.743749  0.758500  0.814499  0.800906   \n",
       "4   0.957956  0.970960  0.945001  0.965298  0.954260  0.950065  0.951122   \n",
       "\n",
       "    pred_168  pred_169  pred_170  pred_171  pred_172  pred_173  pred_174  \\\n",
       "id                                                                         \n",
       "0   0.895418  0.902283  0.920882  0.934658  0.935486  0.927940  0.931465   \n",
       "1   0.525594  0.577745  0.657326  0.619196  0.634477  0.568215  0.647845   \n",
       "2   0.821926  0.844702  0.834022  0.843441  0.838973  0.842829  0.840506   \n",
       "3   0.744299  0.795583  0.784950  0.789155  0.790752  0.777197  0.813260   \n",
       "4   0.963175  0.952976  0.951355  0.944987  0.936911  0.953394  0.943872   \n",
       "\n",
       "    pred_175  pred_176  pred_177  pred_178  pred_179  pred_180  pred_181  \\\n",
       "id                                                                         \n",
       "0   0.859700  0.919990  0.900218  0.893556  0.896251  0.755341  0.824287   \n",
       "1   0.629806  0.579136  0.607440  0.564160  0.640586  0.606747  0.667866   \n",
       "2   0.782444  0.841735  0.833383  0.826798  0.830551  0.781691  0.860410   \n",
       "3   0.806738  0.780352  0.812616  0.823892  0.779928  0.744609  0.760749   \n",
       "4   0.950627  0.952285  0.955480  0.933447  0.953413  0.982246  0.967559   \n",
       "\n",
       "    pred_182  pred_183  pred_184  pred_185  pred_186  pred_187  pred_188  \\\n",
       "id                                                                         \n",
       "0   0.803321  0.907727  0.641035  0.797494  0.941171  0.871997  0.865994   \n",
       "1   0.612748  0.644660  0.620910  0.643053  0.599508  0.613284  0.560798   \n",
       "2   0.810261  0.801572  0.655297  0.806115  0.828846  0.830342  0.828998   \n",
       "3   0.846805  0.816370  0.574678  0.752739  0.840623  0.787268  0.829737   \n",
       "4   0.954645  0.949907  0.801615  0.960187  0.958420  0.943152  0.961092   \n",
       "\n",
       "    pred_189  pred_190  pred_191  pred_192  pred_193  pred_194  pred_195  \\\n",
       "id                                                                         \n",
       "0   0.920065  0.917456  0.843785  0.890857  0.795824  0.672107  0.804113   \n",
       "1   0.677245  0.613026  0.637778  0.577172  0.607995  0.539117  0.611351   \n",
       "2   0.838250  0.827238  0.846826  0.805064  0.825498  0.712260  0.820578   \n",
       "3   0.791476  0.726902  0.784755  0.775541  0.849387  0.646182  0.861718   \n",
       "4   0.954184  0.958137  0.960213  0.968665  0.954888  0.782735  0.955005   \n",
       "\n",
       "    pred_196  pred_197  pred_198  pred_199  pred_200  pred_201  pred_202  \\\n",
       "id                                                                         \n",
       "0   0.790379  0.790415  0.617612  0.828683  0.924688  0.795053  0.648085   \n",
       "1   0.692691  0.735494  0.578681  0.658800  0.678320  0.705907  0.556968   \n",
       "2   0.780879  0.839275  0.612763  0.799409  0.821824  0.786143  0.706309   \n",
       "3   0.818949  0.821602  0.585408  0.802717  0.786148  0.810796  0.632478   \n",
       "4   0.948306  0.957123  0.676376  0.956967  0.943204  0.954072  0.776319   \n",
       "\n",
       "    pred_203  pred_204  pred_205  pred_206  pred_207  pred_208  pred_209  \\\n",
       "id                                                                         \n",
       "0   0.667586  0.767689  0.649592  0.864491  0.656478  0.727041  0.648350   \n",
       "1   0.541232  0.701840  0.534387  0.602506  0.539332  0.588982  0.551651   \n",
       "2   0.714533  0.838994  0.717417  0.831552  0.710438  0.746410  0.714187   \n",
       "3   0.652753  0.785789  0.637340  0.781532  0.642239  0.701267  0.646462   \n",
       "4   0.776692  0.953599  0.777384  0.953905  0.778458  0.863547  0.775349   \n",
       "\n",
       "    pred_210  pred_211  pred_212  pred_213  pred_214  pred_215  pred_216  \\\n",
       "id                                                                         \n",
       "0   0.659398  0.652276  0.658532  0.905867  0.879130  0.693787  0.653076   \n",
       "1   0.536717  0.529723  0.526458  0.636615  0.595467  0.541926  0.546837   \n",
       "2   0.718964  0.710050  0.708915  0.801613  0.808007  0.746493  0.706783   \n",
       "3   0.652006  0.649111  0.638410  0.793840  0.803732  0.697936  0.652164   \n",
       "4   0.777345  0.777881  0.778211  0.922320  0.952621  0.825842  0.779045   \n",
       "\n",
       "    pred_217  pred_218  pred_219  pred_220  pred_221  pred_222  pred_223  \\\n",
       "id                                                                         \n",
       "0   0.642931  0.769356  0.657665  0.655031  0.680468  0.654141  0.888045   \n",
       "1   0.547003  0.612151  0.539560  0.544701  0.560440  0.529293  0.679799   \n",
       "2   0.709442  0.839370  0.712780  0.714048  0.620456  0.708657  0.810277   \n",
       "3   0.654680  0.774072  0.654834  0.646500  0.574347  0.648150  0.799521   \n",
       "4   0.775611  0.966923  0.779222  0.778177  0.772809  0.776765  0.965871   \n",
       "\n",
       "    pred_224  pred_225  pred_226  pred_227  pred_228  pred_229  pred_230  \\\n",
       "id                                                                         \n",
       "0   0.663639  0.648532  0.943179  0.645842  0.657922  0.739452  0.639472   \n",
       "1   0.542618  0.543866  0.680749  0.564064  0.522136  0.656444  0.549582   \n",
       "2   0.704058  0.711560  0.809795  0.713560  0.714919  0.748179  0.704518   \n",
       "3   0.650404  0.660998  0.855050  0.653092  0.666165  0.750642  0.656215   \n",
       "4   0.779475  0.778538  0.940145  0.777498  0.779536  0.863089  0.778143   \n",
       "\n",
       "    pred_231  pred_232  pred_233  pred_234  pred_235  pred_236  pred_237  \\\n",
       "id                                                                         \n",
       "0   0.849011  0.901647  0.868586  0.867358  0.918989  0.655847  0.656866   \n",
       "1   0.588881  0.648029  0.632580  0.669941  0.630683  0.557115  0.550999   \n",
       "2   0.824189  0.819809  0.805986  0.817669  0.832476  0.712902  0.712985   \n",
       "3   0.755086  0.794556  0.810863  0.804009  0.812419  0.660469  0.661335   \n",
       "4   0.954092  0.953081  0.951770  0.958379  0.940364  0.773112  0.778073   \n",
       "\n",
       "    pred_238  pred_239  pred_240  pred_241  pred_242  pred_243  pred_244  \\\n",
       "id                                                                         \n",
       "0   0.944366  0.836214  0.862387  0.890369  0.936063  0.657963  0.829295   \n",
       "1   0.637534  0.589501  0.569580  0.721865  0.637924  0.544955  0.630034   \n",
       "2   0.838412  0.848718  0.834407  0.789999  0.819978  0.717289  0.821735   \n",
       "3   0.853465  0.792250  0.823491  0.756946  0.757464  0.658542  0.818652   \n",
       "4   0.940602  0.958745  0.953006  0.950656  0.966904  0.780241  0.954455   \n",
       "\n",
       "    pred_245  pred_246  pred_247  pred_248  pred_249  ...  pred_4750  \\\n",
       "id                                                    ...              \n",
       "0   0.867263  0.842680  0.670228  0.880774  0.953470  ...   0.744596   \n",
       "1   0.619004  0.656982  0.556974  0.648987  0.648320  ...   0.788690   \n",
       "2   0.794855  0.821442  0.734239  0.806486  0.835932  ...   0.833733   \n",
       "3   0.785362  0.779496  0.677362  0.791830  0.862109  ...   0.895749   \n",
       "4   0.902674  0.964108  0.809438  0.948075  0.945511  ...   0.973737   \n",
       "\n",
       "    pred_4751  pred_4752  pred_4753  pred_4754  pred_4755  pred_4756  \\\n",
       "id                                                                     \n",
       "0    0.789606   0.822831   0.752506   0.763859   0.792185   0.749771   \n",
       "1    0.616180   0.827795   0.737427   0.686645   0.708316   0.817641   \n",
       "2    0.867279   0.792864   0.817235   0.836795   0.839837   0.811626   \n",
       "3    0.495273   0.727701   0.737130   0.770261   0.745426   0.791546   \n",
       "4    0.952009   0.924867   0.965829   0.920804   0.930917   0.929818   \n",
       "\n",
       "    pred_4757  pred_4758  pred_4759  pred_4760  pred_4761  pred_4762  \\\n",
       "id                                                                     \n",
       "0    0.869214   0.748611   0.743209   0.802502   0.728472   0.790256   \n",
       "1    0.757236   0.510000   0.839523   0.724937   0.799671   0.809862   \n",
       "2    0.861086   0.510000   0.810708   0.915166   0.806079   0.778209   \n",
       "3    0.851800   0.510000   0.836438   0.859333   0.778238   0.719437   \n",
       "4    0.979089   0.510000   0.931732   0.954809   0.938110   0.924876   \n",
       "\n",
       "    pred_4763  pred_4764  pred_4765  pred_4766  pred_4767  pred_4768  \\\n",
       "id                                                                     \n",
       "0    0.825258   0.872288   0.784399   0.762307   0.726273   0.776793   \n",
       "1    0.773093   0.752800   0.807330   0.599772   0.803634   0.681727   \n",
       "2    0.859528   0.851190   0.783879   0.799467   0.845666   0.803778   \n",
       "3    0.704034   0.852542   0.725081   0.794922   0.784087   0.763167   \n",
       "4    0.934840   0.981173   0.925483   0.957305   0.932651   0.945458   \n",
       "\n",
       "    pred_4769  pred_4770  pred_4771  pred_4772  pred_4773  pred_4774  \\\n",
       "id                                                                     \n",
       "0    0.759087   0.743924   0.734118   0.803793   0.732907   0.745979   \n",
       "1    0.582038   0.667205   0.808840   0.575069   0.500000   0.856404   \n",
       "2    0.832472   0.854549   0.796741   0.827498   0.500000   0.827637   \n",
       "3    0.754036   0.754880   0.790625   0.730753   0.500000   0.903751   \n",
       "4    0.940641   0.959966   0.931819   0.964703   0.500000   0.955012   \n",
       "\n",
       "    pred_4775  pred_4776  pred_4777  pred_4778  pred_4779  pred_4780  \\\n",
       "id                                                                     \n",
       "0    0.775035   0.775466   0.745852   0.680466   0.699379   0.795242   \n",
       "1    0.698707   0.722883   0.820609   0.692309   0.715915   0.688091   \n",
       "2    0.775167   0.819868   0.799665   0.826630   0.770814   0.819777   \n",
       "3    0.787788   0.769423   0.792511   0.729369   0.745348   0.704907   \n",
       "4    0.925349   0.949040   0.933638   0.914358   0.904968   0.954356   \n",
       "\n",
       "    pred_4781  pred_4782  pred_4783  pred_4784  pred_4785  pred_4786  \\\n",
       "id                                                                     \n",
       "0    0.799246   0.784781   0.827740       0.71   0.792859   0.856979   \n",
       "1    0.678089   0.594253   0.587398       0.67   0.676032   0.494506   \n",
       "2    0.863464   0.792679   0.916225       0.82   0.829712   0.857718   \n",
       "3    0.743061   0.592622   0.646493       0.76   0.750476   0.737157   \n",
       "4    0.922749   0.974094   0.948393       0.97   0.905919   0.966503   \n",
       "\n",
       "    pred_4787  pred_4788  pred_4789  pred_4790  pred_4791  pred_4792  \\\n",
       "id                                                                     \n",
       "0    0.746108   0.766509   0.819130   0.795080   0.751392   0.758484   \n",
       "1    0.818950   0.797526   0.662398   0.600031   0.770656   0.612303   \n",
       "2    0.811211   0.803838   0.851415   0.812615   0.771278   0.811052   \n",
       "3    0.821953   0.831909   0.706013   0.707603   0.810687   0.768139   \n",
       "4    0.922379   0.941679   0.937840   0.935648   0.908894   0.944376   \n",
       "\n",
       "    pred_4793  pred_4794  pred_4795  pred_4796  pred_4797  pred_4798  \\\n",
       "id                                                                     \n",
       "0    0.450801   0.796515   0.744912    0.79750   0.768739   0.819312   \n",
       "1    0.507133   0.690067   0.843137    0.60500   0.641385   0.659656   \n",
       "2    0.466107   0.831474   0.808645    0.75597   0.812604   0.850112   \n",
       "3    0.472390   0.734369   0.842692    0.62250   0.795059   0.710628   \n",
       "4    0.858483   0.921305   0.940255    0.96000   0.934891   0.938110   \n",
       "\n",
       "    pred_4799  pred_4800  pred_4801  pred_4802  pred_4803  pred_4804  \\\n",
       "id                                                                     \n",
       "0    0.808605   0.760954   0.836624   0.775000   0.822643   0.611131   \n",
       "1    0.634422   0.663740   0.699158   0.681780   0.637879   0.765696   \n",
       "2    0.902232   0.788274   0.816282   0.844858   0.817831   0.812758   \n",
       "3    0.743347   0.679919   0.724956   0.793494   0.752820   0.823539   \n",
       "4    0.941676   0.929199   0.969335   0.959914   0.944421   0.950431   \n",
       "\n",
       "    pred_4805  pred_4806  pred_4807  pred_4808  pred_4809  pred_4810  \\\n",
       "id                                                                     \n",
       "0    0.767637   0.788689   0.739138   0.771369   0.767082   0.753414   \n",
       "1    0.559711   0.655060   0.702855   0.554488   0.566536   0.522473   \n",
       "2    0.761620   0.834849   0.842131   0.761716   0.800135   0.664103   \n",
       "3    0.675959   0.740678   0.775825   0.677309   0.647469   0.571968   \n",
       "4    0.933564   0.935508   0.931652   0.933683   0.947941   0.879953   \n",
       "\n",
       "    pred_4811  pred_4812  pred_4813  pred_4814  pred_4815  pred_4816  \\\n",
       "id                                                                     \n",
       "0    0.801072   0.741112      0.806   0.788995   0.789473   0.868293   \n",
       "1    0.695330   0.793034      0.658   0.591842   0.687549   0.559970   \n",
       "2    0.814351   0.790766      0.790   0.768449   0.845878   0.860261   \n",
       "3    0.660585   0.806148      0.772   0.710808   0.756050   0.808471   \n",
       "4    0.930539   0.927920      0.950   0.935210   0.958554   0.973037   \n",
       "\n",
       "    pred_4817  pred_4818  pred_4819  pred_4820  pred_4821  pred_4822  \\\n",
       "id                                                                     \n",
       "0    0.789505   0.857225   0.781116   0.731786   0.766275   0.788488   \n",
       "1    0.560146   0.564810   0.624769   0.834789   0.613291   0.567477   \n",
       "2    0.762042   0.779221   0.810291   0.800215   0.777837   0.763021   \n",
       "3    0.659310   0.691916   0.743097   0.769087   0.695552   0.653594   \n",
       "4    0.934454   0.951877   0.935977   0.945510   0.929168   0.942843   \n",
       "\n",
       "    pred_4823  pred_4824  pred_4825  pred_4826  pred_4827  pred_4828  \\\n",
       "id                                                                     \n",
       "0    0.790706       0.84   0.787668   0.785096   0.831133   0.799774   \n",
       "1    0.660968       0.58   0.609750   0.692875   0.785988   0.580263   \n",
       "2    0.865179       0.82   0.763506   0.834542   0.879926   0.773690   \n",
       "3    0.786262       0.63   0.695713   0.652606   0.814796   0.706355   \n",
       "4    0.949085       0.94   0.935028   0.921131   0.947241   0.937358   \n",
       "\n",
       "    pred_4829  pred_4830  pred_4831  pred_4832  pred_4833  pred_4834  \\\n",
       "id                                                                     \n",
       "0       0.808      0.804   0.793660   0.752367   0.777987   0.806303   \n",
       "1       0.829      0.637   0.551481   0.817990   0.625254   0.551368   \n",
       "2       0.831      0.827   0.766484   0.824966   0.833263   0.806821   \n",
       "3       0.742      0.706   0.654540   0.750803   0.779488   0.650661   \n",
       "4       0.932      0.936   0.935124   0.933135   0.956872   0.923821   \n",
       "\n",
       "    pred_4835  pred_4836  pred_4837  pred_4838  pred_4839  pred_4840  \\\n",
       "id                                                                     \n",
       "0    0.766487      0.788   0.816800   0.724557   0.809020   0.790488   \n",
       "1    0.620339      0.604   0.603782   0.689245   0.638889   0.555615   \n",
       "2    0.802969      0.814   0.785951   0.810785   0.815267   0.756544   \n",
       "3    0.803833      0.584   0.615119   0.733666   0.740296   0.620272   \n",
       "4    0.938291      0.954   0.958800   0.964427   0.896421   0.931617   \n",
       "\n",
       "    pred_4841  pred_4842  pred_4843  pred_4844  pred_4845  pred_4846  \\\n",
       "id                                                                     \n",
       "0    0.740934   0.757600   0.838907   0.664264   0.844789   0.761397   \n",
       "1    0.196101   0.577267   0.571527   0.733769   0.553858   0.839782   \n",
       "2    0.244916   0.635200   0.851291   0.851375   0.869997   0.806950   \n",
       "3    0.241752   0.637474   0.665255   0.816195   0.725132   0.770546   \n",
       "4    0.680464   0.922207   0.931885   0.916316   0.949368   0.930651   \n",
       "\n",
       "    pred_4847  pred_4848  pred_4849  pred_4850  pred_4851  pred_4852  \\\n",
       "id                                                                     \n",
       "0    0.766823   0.788785   0.765805   0.719217   0.663273   0.790739   \n",
       "1    0.633441   0.656690   0.538377   0.532639   0.675301   0.659970   \n",
       "2    0.857001   0.838171   0.777705   0.850673   0.816125   0.869490   \n",
       "3    0.670477   0.698782   0.702367   0.613917   0.744487   0.775870   \n",
       "4    0.936535   0.920323   0.931514   0.983698   0.967124   0.949272   \n",
       "\n",
       "    pred_4853  pred_4854  pred_4855  pred_4856  pred_4857  pred_4858  \\\n",
       "id                                                                     \n",
       "0       0.734   0.735948      0.800   0.643394   0.778507   0.748442   \n",
       "1       0.604   0.685178      0.745   0.516099   0.713553   0.789445   \n",
       "2       0.822   0.873623      0.880   0.807142   0.832326   0.799489   \n",
       "3       0.604   0.774351      0.713   0.707573   0.758477   0.726191   \n",
       "4       0.950   0.951796      0.926   0.953323   0.937281   0.941442   \n",
       "\n",
       "    pred_4859  pred_4860  pred_4861  pred_4862  pred_4863  pred_4864  \\\n",
       "id                                                                     \n",
       "0    0.836666      0.864   0.809759       0.78   0.776348   0.820329   \n",
       "1    0.555181      0.406   0.567262       0.47   0.789391   0.466068   \n",
       "2    0.901490      0.830   0.761563       0.90   0.815443   0.808879   \n",
       "3    0.697942      0.506   0.652148       0.62   0.715608   0.763292   \n",
       "4    0.950565      0.962   0.937592       0.93   0.924668   0.939884   \n",
       "\n",
       "    pred_4865  pred_4866  pred_4867  pred_4868  pred_4869  pred_4870  \\\n",
       "id                                                                     \n",
       "0    0.754561   0.779653   0.786898   0.818111   0.750967   0.788298   \n",
       "1    0.584493   0.791817   0.698266   0.701015   0.843445   0.625465   \n",
       "2    0.765085   0.811335   0.849873   0.809702   0.874429   0.809987   \n",
       "3    0.686879   0.727256   0.685293   0.748288   0.811393   0.662890   \n",
       "4    0.939709   0.937779   0.921181   0.936715   0.958235   0.893659   \n",
       "\n",
       "    pred_4871  pred_4872  pred_4873  pred_4874  pred_4875  pred_4876  \\\n",
       "id                                                                     \n",
       "0    0.812081   0.882778   0.740910   0.805058   0.539312   0.834274   \n",
       "1    0.779182   0.756273   0.613947   0.630173   0.593991   0.614041   \n",
       "2    0.780178   0.816781   0.760290   0.758154   0.846034   0.816993   \n",
       "3    0.734988   0.863463   0.688112   0.715934   0.776586   0.805371   \n",
       "4    0.946999   0.957776   0.936169   0.941485   0.936649   0.959280   \n",
       "\n",
       "    pred_4877  pred_4878  pred_4879  pred_4880  pred_4881  pred_4882  \\\n",
       "id                                                                     \n",
       "0    0.773189   0.771674    0.77566   0.802000   0.833338      0.598   \n",
       "1    0.607984   0.925653    0.56562   0.606000   0.680271      0.662   \n",
       "2    0.852314   0.718455    0.74054   0.785248   0.819280      0.584   \n",
       "3    0.818851   0.734592    0.65372   0.623000   0.712176      0.664   \n",
       "4    0.962152   0.970359    0.93780   0.951000   0.912734      0.604   \n",
       "\n",
       "    pred_4883  pred_4884  pred_4885  pred_4886  pred_4887  pred_4888  \\\n",
       "id                                                                     \n",
       "0    0.785218   0.769817   0.774337   0.790061   0.788713   0.743855   \n",
       "1    0.790298   0.844437   0.637616   0.622595   0.783105   0.764523   \n",
       "2    0.814253   0.817271   0.782533   0.767001   0.814296   0.814460   \n",
       "3    0.733031   0.724473   0.693260   0.716155   0.731427   0.727283   \n",
       "4    0.937157   0.943892   0.933907   0.944612   0.927684   0.932256   \n",
       "\n",
       "    pred_4889  pred_4890  pred_4891  pred_4892  pred_4893  pred_4894  \\\n",
       "id                                                                     \n",
       "0    0.746083   0.811458   0.828661   0.755482   0.787360   0.864917   \n",
       "1    0.639816   0.658333   0.535052   0.765851   0.644280   0.550574   \n",
       "2    0.771962   0.777500   0.824891   0.847480   0.837735   0.899689   \n",
       "3    0.704681   0.529167   0.796517   0.774780   0.814016   0.762711   \n",
       "4    0.932845   0.953958   0.961658   0.937017   0.950575   0.965865   \n",
       "\n",
       "    pred_4895  pred_4896  pred_4897  pred_4898  pred_4899  pred_4900  \\\n",
       "id                                                                     \n",
       "0    0.797303   0.802966   0.705644   0.790439   0.733961   0.816518   \n",
       "1    0.626481   0.654301   0.748443   0.705750   0.821382   0.668149   \n",
       "2    0.877098   0.843772   0.825508   0.845480   0.821133   0.816518   \n",
       "3    0.873457   0.685968   0.750630   0.705484   0.889912   0.891304   \n",
       "4    0.968121   0.935402   0.901300   0.906814   0.916661   0.958190   \n",
       "\n",
       "    pred_4901  pred_4902  pred_4903  pred_4904  pred_4905  pred_4906  \\\n",
       "id                                                                     \n",
       "0    0.728475   0.789816   0.852823   0.723630   0.724836   0.678887   \n",
       "1    0.474381   0.631520   0.755675   0.620640   0.527393   0.673709   \n",
       "2    0.733961   0.801066   0.781489   0.758760   0.681881   0.691394   \n",
       "3    0.570358   0.694653   0.800916   0.687705   0.714742   0.692404   \n",
       "4    0.916060   0.950381   0.974851   0.935239   0.595583   0.774454   \n",
       "\n",
       "    pred_4907  pred_4908  pred_4909  pred_4910  pred_4911  pred_4912  \\\n",
       "id                                                                     \n",
       "0    0.872183       0.52   0.778658   0.706696   0.801668   0.747840   \n",
       "1    0.585480       0.44   0.764359   0.615756   0.649969   0.765076   \n",
       "2    0.826544       0.50   0.812678   0.721722   0.875097   0.814717   \n",
       "3    0.716626       0.42   0.722992   0.694464   0.789942   0.721255   \n",
       "4    0.980777       0.70   0.930837   0.854952   0.958083   0.931717   \n",
       "\n",
       "    pred_4913  pred_4914  pred_4915  pred_4916  pred_4917  pred_4918  \\\n",
       "id                                                                     \n",
       "0    0.829977   0.714481   0.735582   0.692817   0.675287   0.792170   \n",
       "1    0.566324   0.793590   0.702215   0.559875   0.657938   0.570594   \n",
       "2    0.763716   0.844262   0.802439   0.829966   0.675287   0.793588   \n",
       "3    0.701537   0.819965   0.797841   0.770761   0.675287   0.714994   \n",
       "4    0.932412   0.952583   0.947509   0.969987   0.697208   0.927489   \n",
       "\n",
       "    pred_4919  pred_4920  pred_4921  pred_4922  pred_4923  pred_4924  \\\n",
       "id                                                                     \n",
       "0    0.687298   0.823327      0.786   0.757718      0.795   0.810692   \n",
       "1    0.855491   0.513806      0.664   0.590176      0.665   0.514427   \n",
       "2    0.836022   0.765381      0.820   0.766319      0.865   0.795367   \n",
       "3    0.837553   0.736147      0.586   0.656738      0.590   0.628795   \n",
       "4    0.967159   0.949621      0.938   0.940259      0.895   0.934430   \n",
       "\n",
       "    pred_4925  pred_4926  pred_4927  pred_4928  pred_4929  pred_4930  \\\n",
       "id                                                                     \n",
       "0    0.764609   0.780869   0.711543   0.756985   0.804600   0.735119   \n",
       "1    0.837213   0.765428   0.705154   0.649341   0.594490   0.129141   \n",
       "2    0.827362   0.826671   0.798308   0.784337   0.801270   0.908334   \n",
       "3    0.581039   0.729520   0.748986   0.749680   0.685625   0.601509   \n",
       "4    0.981714   0.934403   0.935743   0.863703   0.881873   0.972271   \n",
       "\n",
       "    pred_4931  pred_4932  pred_4933  pred_4934  pred_4935  pred_4936  \\\n",
       "id                                                                     \n",
       "0    0.810028   0.765535   0.789920   0.802327   0.329250   0.862750   \n",
       "1    0.606811   0.784151   0.636025   0.613333   0.335895   0.524583   \n",
       "2    0.866742   0.796605   0.809023   0.756403   0.335933   0.767750   \n",
       "3    0.538543   0.714939   0.820410   0.668162   0.338749   0.676500   \n",
       "4    0.981000   0.922039   0.967649   0.928029   0.344151   0.924667   \n",
       "\n",
       "    pred_4937  pred_4938  pred_4939  pred_4940  pred_4941  pred_4942  \\\n",
       "id                                                                     \n",
       "0    0.867296   0.798853   0.742752   0.751270   0.751917      0.731   \n",
       "1    0.728891   0.537487   0.591161   0.612110   0.534904      0.822   \n",
       "2    0.881718   0.784379   0.799987   0.852030   0.756409      0.816   \n",
       "3    0.832265   0.701073   0.715576   0.751954   0.688012      0.699   \n",
       "4    0.983632   0.951695   0.942845   0.953762   0.952153      0.929   \n",
       "\n",
       "    pred_4943  pred_4944  pred_4945  pred_4946  pred_4947  pred_4948  \\\n",
       "id                                                                     \n",
       "0    0.866667   0.804625   0.772256   0.735407   0.775943   0.884420   \n",
       "1    0.610000   0.728319   0.843295   0.801448   0.722251   0.674815   \n",
       "2    0.840000   0.777487   0.814384   0.850060   0.821101   0.837291   \n",
       "3    0.490000   0.809385   0.829437   0.878710   0.741166   0.724611   \n",
       "4    0.990000   0.976591   0.933966   0.933172   0.931840   0.964148   \n",
       "\n",
       "    pred_4949  pred_4950  pred_4951  pred_4952  pred_4953  pred_4954  \\\n",
       "id                                                                     \n",
       "0    0.721145   0.784553   0.716269   0.707415   0.765097   0.800922   \n",
       "1    0.567012   0.619222   0.857886   0.818352   0.825970   0.543566   \n",
       "2    0.763026   0.859538   0.810234   0.845462   0.815690   0.783185   \n",
       "3    0.710051   0.672039   0.867617   0.844242   0.728528   0.685292   \n",
       "4    0.936838   0.912548   0.934099   0.946673   0.920494   0.949425   \n",
       "\n",
       "    pred_4955  pred_4956  pred_4957  pred_4958  pred_4959  pred_4960  \\\n",
       "id                                                                     \n",
       "0    0.839562   0.787619   0.698392   0.884000      0.694   0.759822   \n",
       "1    0.567665   0.493301   0.797206   0.480500      0.626   0.740490   \n",
       "2    0.801309   0.822254   0.818665   0.909256      0.838   0.791050   \n",
       "3    0.692359   0.694486   0.687283   0.664667      0.558   0.804032   \n",
       "4    0.945415   0.967463   0.923194   0.985833      0.930   0.929723   \n",
       "\n",
       "    pred_4961  pred_4962  pred_4963  pred_4964  pred_4965  pred_4966  \\\n",
       "id                                                                     \n",
       "0    0.776343   0.782595   0.766008   0.618374   0.767504   0.790324   \n",
       "1    0.760884   0.549819   0.608901   0.719402   0.618532   0.627737   \n",
       "2    0.807334   0.799644   0.765985   0.887590   0.745804   0.771311   \n",
       "3    0.706274   0.705306   0.697015   0.853246   0.691722   0.679012   \n",
       "4    0.915569   0.953891   0.935026   0.954800   0.935549   0.940336   \n",
       "\n",
       "    pred_4967  pred_4968  pred_4969  pred_4970  pred_4971  pred_4972  \\\n",
       "id                                                                     \n",
       "0    0.732125   0.815167   0.738000   0.828574   0.713297   0.829415   \n",
       "1    0.604327   0.543064   0.721973   0.660949   0.636353   0.576666   \n",
       "2    0.740030   0.755516   0.726684   0.838977   0.757930   0.864480   \n",
       "3    0.677103   0.683902   0.795511   0.589118   0.736120   0.777212   \n",
       "4    0.929120   0.936355   0.849463   0.920010   0.936611   0.955951   \n",
       "\n",
       "    pred_4973  pred_4974  pred_4975  pred_4976  pred_4977  pred_4978  \\\n",
       "id                                                                     \n",
       "0    0.793753   0.808062   0.739437   0.669220   0.753454   0.755920   \n",
       "1    0.664133   0.701665   0.167135   0.682181   0.819425   0.763671   \n",
       "2    0.850818   0.861696   0.688795   0.797739   0.802361   0.799406   \n",
       "3    0.700488   0.753324   0.146649   0.691117   0.774402   0.785284   \n",
       "4    0.909035   0.945011   0.926108   0.958017   0.898938   0.915973   \n",
       "\n",
       "    pred_4979  pred_4980  pred_4981  pred_4982  pred_4983  pred_4984  \\\n",
       "id                                                                     \n",
       "0       0.721   0.834615   0.783564   0.819630   0.762424   0.790193   \n",
       "1       0.719   0.723470   0.636667   0.558871   0.748712   0.620492   \n",
       "2       0.787   0.833259   0.766999   0.871960   0.833062   0.820837   \n",
       "3       0.740   0.830470   0.673529   0.829291   0.812907   0.782994   \n",
       "4       0.883   0.946283   0.943757   0.974282   0.945445   0.938059   \n",
       "\n",
       "    pred_4985  pred_4986  pred_4987  pred_4988  pred_4989  pred_4990  \\\n",
       "id                                                                     \n",
       "0    0.794981   0.781625   0.804431   0.808977   0.484293   0.769207   \n",
       "1    0.720902   0.620868   0.695261   0.827551   0.738751   0.640052   \n",
       "2    0.825308   0.753659   0.862965   0.843876   0.758391   0.812841   \n",
       "3    0.744348   0.717934   0.811482   0.791431   0.733034   0.824703   \n",
       "4    0.923524   0.935912   0.959907   0.970689   0.942653   0.934803   \n",
       "\n",
       "    pred_4991  pred_4992  pred_4993  pred_4994  pred_4995  pred_4996  \\\n",
       "id                                                                     \n",
       "0    0.750250   0.663370   0.739333   0.822384   0.749498   0.729800   \n",
       "1    0.794052   0.721298   0.804369   0.620626   0.733606   0.816942   \n",
       "2    0.779859   0.865657   0.828493   0.763010   0.802883   0.806891   \n",
       "3    0.799698   0.800130   0.716604   0.603779   0.708499   0.844837   \n",
       "4    0.900150   0.960911   0.906037   0.961240   0.935608   0.889757   \n",
       "\n",
       "    pred_4997  pred_4998  pred_4999  \n",
       "id                                   \n",
       "0    0.867847   0.745888      0.787  \n",
       "1    0.814229   0.598331      0.547  \n",
       "2    0.896058   0.855776      0.667  \n",
       "3    0.853057   0.850657      0.622  \n",
       "4    0.978505   0.953681      0.934  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#for idx, file in enumerate(tqdm(file_list)):\n",
    "#    df_pred[f'pred_{idx}'] = pd.read_csv(file)[\"pred\"].to_numpy()  \n",
    "    \n",
    "#df_pred.set_index('id', inplace=True)\n",
    "df_pred = jb.load(path + path_data + 'pkl/df_pred_nb_02_n1.pkl.z')\n",
    "\n",
    "utility.free_gpu_cache()\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c080c84",
   "metadata": {
    "id": "7c080c84"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb7ca1",
   "metadata": {
    "id": "f0bb7ca1"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 2. Modelo linha de base  </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fb4a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:28:07.844748Z",
     "start_time": "2022-11-25T01:28:05.567907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1669318037069,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "e1fb4a73",
    "outputId": "bccce1e9-431d-4c84-ece1-54e8336cfadf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 5000), (20000, 5000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed      = 12359\n",
    "df2_train = df_pred[:df1_train.shape[0]].copy() \n",
    "df2_test  = df_pred[df1_train.shape[0]:].reset_index(drop=True)\n",
    "\n",
    "df2_train.shape, df2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203c4a4",
   "metadata": {
    "id": "2203c4a4"
   },
   "source": [
    "## 2.2. Split Treino/Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a754c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:28:15.760652Z",
     "start_time": "2022-11-25T01:28:15.366998Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1669318047730,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "53a754c5",
    "outputId": "4e4c7d33-2b12-4dbc-ef91-a49bcad95cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 391 ms\n",
      "Wall time: 384 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 5000), (20000, 5000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X      = df2_train.copy()\n",
    "y      = df1_train[target]\n",
    "X_test = df2_test.copy()\n",
    "\n",
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5764e09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T00:27:12.178880Z",
     "start_time": "2022-11-26T00:27:11.913269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 1123), (4000, 1123), (20000, 5000))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X[feature_selec_fsm], \n",
    "                                                  y, \n",
    "                                                  test_size    = .2, \n",
    "                                                  shuffle      = True, \n",
    "                                                  stratify     = y, \n",
    "                                                  random_state = seed\n",
    "                                                 )\n",
    "\n",
    "X_train.shape,  X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1236abf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T00:27:20.039229Z",
     "start_time": "2022-11-26T00:27:19.991229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3600, 1123), (400, 1123))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, X_ts_final, y_val, y_ts_final = train_test_split(X_val, y_val, \n",
    "                                                        test_size    = .1, \n",
    "                                                        shuffle      = True, \n",
    "                                                        stratify     = y_val, \n",
    "                                                        random_state = seed\n",
    "                                                     )\n",
    "\n",
    "X_val.shape, X_ts_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734642b",
   "metadata": {
    "id": "6734642b"
   },
   "source": [
    "## 2.3. Modelo\n",
    "\n",
    "Primeira coisa que vamos fazer é selecionar as melhores variáveis com o objeto do <b>SelectFromModel</b> do sklearn, vamos utilizar o melhor modelo do primeiro notebook, o <b>LGBM</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724f26e",
   "metadata": {
    "id": "e724f26e"
   },
   "source": [
    "### 2.3.1. Pipeline de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc8cd4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T01:58:21.147315Z",
     "start_time": "2022-11-26T01:58:21.127942Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1669318042000,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "fc8cd4cc"
   },
   "outputs": [],
   "source": [
    "param_lgbm  = {\n",
    "    'objective'         : 'binary',\n",
    "    'metric'            : 'binary_logloss',\n",
    "    'colsample_bytree'  : 0.5139258065278501,\n",
    "    'learning_rate'     : 0.02,\n",
    "    'max_depth'         : 6,\n",
    "    'min_child_samples' : 219,\n",
    "    'min_child_weight'  : 1e-05,\n",
    "    'n_estimators'      : 300,\n",
    "    'num_leaves'        : 128,\n",
    "    'reg_alpha'         : 1,\n",
    "    'reg_lambda'        : 0,\n",
    "    'subsample'         : 0.8116483602711031,         \n",
    "    #'device'            : 'gpu',    \n",
    "    'random_state'      : seed}\n",
    "\n",
    "model_lgbm = lgb.LGBMClassifier(**param_lgbm)\n",
    "\n",
    "# Processamento\n",
    "processar         = ('preprocessor', StandardScaler())\n",
    "variancethreshold = ('variancethreshold', VarianceThreshold(threshold=1.0e-03)) \n",
    "selectpercentile  = ('selectpercentile', SelectPercentile(f_classif, percentile=98))\n",
    "\n",
    "# Pipelne \n",
    "#model_pipeline_lgbm = Pipeline(steps=[processar, variancethreshold, selectpercentile, ('model', model_lgbm)])\n",
    "\n",
    "# Pipelne \n",
    "pipeline_process = Pipeline(steps=[processar, variancethreshold, selectpercentile])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97200c79",
   "metadata": {},
   "source": [
    "Vamos processar os dados de treino e teste para seleção de parametros da rede. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef20229",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-28T00:28:00.647Z"
    }
   },
   "outputs": [],
   "source": [
    "col = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8a065ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T01:59:56.557779Z",
     "start_time": "2022-11-26T01:59:54.105410Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_logit    = scipy.special.logit(X_train.clip(clip, 1-clip))\n",
    "X_val_logit      = scipy.special.logit(X_val.clip(clip, 1-clip))\n",
    "X_ts_final_logit = scipy.special.logit(X_ts_final.clip(clip, 1-clip))\n",
    "X_test_logit     = scipy.special.logit(X_test[feature_selec_fsm].clip(clip, 1-clip))\n",
    "\n",
    "\n",
    "pipeline_process.fit(X_train_logit, y_train)\n",
    "                    \n",
    "X_train_sc    = pipeline_process.transform(X_train_logit) \n",
    "X_val_sc      = pipeline_process.transform(X_val_logit)  \n",
    "X_ts_final_sc = pipeline_process.transform(X_ts_final_logit) \n",
    "X_test_sc     = pipeline_process.transform(X_test_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209df00",
   "metadata": {},
   "source": [
    "### 2.3.2. Seleção de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4f90eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-25T01:33:00.441462Z",
     "start_time": "2022-11-25T01:28:21.787429Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81724,
     "status": "ok",
     "timestamp": 1669318131831,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "be4f90eb",
    "outputId": "76f4d8ab-ea1f-44de-c90b-662de3064665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados originais com (20000, 5000) variáveis.\n",
      "Foram selecionados (20000, 1123) variáveis.\n",
      "\n",
      "CPU times: total: 5min 10s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "_ = pd.DataFrame(processar[1].fit_transform(X.clip(clip, 1-clip)), columns=X.columns) \n",
    "mdl_fs_FromModel = fs.SelectFromModel(model_lgbm.fit(_, y), prefit=True)\n",
    "X_fs = mdl_fs_FromModel.transform(_)\n",
    "\n",
    "print(\"Dados originais com {} variáveis.\".format(X.shape))\n",
    "print(\"Foram selecionados {} variáveis.\".format(X_fs.shape))\n",
    "print()\n",
    "\n",
    "del X_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "761cbf18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T02:29:43.117133Z",
     "start_time": "2022-11-26T02:29:43.096523Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1669318134581,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "761cbf18",
    "outputId": "dd82ed12-78a1-42b5-bf01-5adae2b13897",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selec_fsm = X.columns[mdl_fs_FromModel.get_support(indices=True)].to_list()\n",
    "feature_all       = X.columns.to_list()\n",
    "len(feature_selec_fsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdfff1d",
   "metadata": {
    "id": "5cdfff1d"
   },
   "source": [
    "### 2.3.3. Estrutura da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706e03e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    reg1 = 1e-06\n",
    "    reg2 = 1e-07 \n",
    "    REG1 = tf.keras.regularizers.l2(reg1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg2)\n",
    "    UNITS = 128\n",
    "    DROP = 0.3\n",
    "    activation = tfa.activations.mish \n",
    "    \n",
    "    inputs = Input(shape=(X.shape[1],))\n",
    "\n",
    "    x0 = Dense(UNITS, kernel_regularizer=REG1, activation=activation)(inputs)\n",
    "    x0 = Dropout(DROP)(x0)\n",
    "    x0 = BatchNormalization()(x0)\n",
    "    \n",
    "    x1 = Dense(UNITS, kernel_regularizer=REG1,activation=activation,)(x0)\n",
    "    x1 = Dropout(DROP)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    \n",
    "    x = Concatenate()([x0,x1])\n",
    "    x = Dense(1, kernel_regularizer=REG2,activation='sigmoid',)(x)\n",
    "    \n",
    "    model = Model(inputs, x)    \n",
    "    model.compile(\n",
    "        optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=tf.keras.metrics.BinaryCrossentropy())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "89975197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T22:17:43.605434Z",
     "start_time": "2022-11-26T22:17:43.578440Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape_, activation_layer_='swish', activation_='sigmoid', \n",
    "                 learning_rate_=0.00001, dropout_=0.3, type_model_=4, seed_=12359):\n",
    "\n",
    "    tf.random.set_seed(seed_)\n",
    "    \n",
    "    units      = int((input_shape_/2))\n",
    "    reg_1      = 1e-06  #1e-04 \n",
    "    reg_2      = 1e-05\n",
    "    REG1 = tf.keras.regularizers.l2(reg_1)\n",
    "    REG2 = tf.keras.regularizers.l2(reg_2)\n",
    "    \n",
    "    #activity_r = tf.keras.regularizers.L1L2(l1=1e-06, l2=1e-07)  \n",
    "    activity_r = tf.keras.regularizers.L1L2(l1=1e-04, l2=1e-05)  \n",
    "        \n",
    "    if type_model_==1:\n",
    "        model = keras.Sequential([    \n",
    "            layers.BatchNormalization(input_shape=[input_shape_]), \n",
    "            layers.Dense(1024, activation=activation_layer_),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.6), \n",
    "            layers.Dense(512, activation=activation_layer_),    \n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(512, activation=activation_layer_),    \n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(256, activation=activation_layer_),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(128, activation=activation_layer_),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation=activation_layer_),\n",
    "            #layers.Dropout(0.3),\n",
    "            layers.Dropout(0.4),   ### 0.52014\n",
    "            layers.Dense(32, activation=activation_layer_),        \n",
    "            layers.Dropout(0.3),  ### 0.52014\n",
    "            layers.Dense(1, activation=activation_)     \n",
    "        ])\n",
    "    \n",
    "    if type_model_==2:\n",
    "        model = keras.Sequential([    \n",
    "            layers.BatchNormalization(input_shape=[input_shape_]), \n",
    "            layers.Dense(units, activation=activation_layer_, activity_regularizer=activity_r),\n",
    "            layers.Dropout(0.6), \n",
    "            layers.BatchNormalization(),        \n",
    "            layers.Dense(512, activation=activation_layer_),    \n",
    "            layers.Dropout(0.3),    \n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, activation=activation_layer_),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(128, activation=activation_layer_),\n",
    "            layers.Dropout(0.3),   \n",
    "            layers.Dense(32, activation=activation_layer_),        \n",
    "            layers.Dropout(0.3),   \n",
    "            layers.Dense(1, activation=activation_)     \n",
    "        ])\n",
    "    \n",
    "    if type_model_==3:\n",
    "        model = keras.Sequential([    \n",
    "            layers.BatchNormalization(input_shape=[input_shape_]), \n",
    "            layers.Dense(units, activation=activation_layer_, activity_regularizer=activity_r),\n",
    "            layers.Dense(int(units/2), activation=activation_layer_),    \n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout_),    \n",
    "            layers.Dense(int(units/2/2), activation=activation_layer_),\n",
    "            layers.Dropout(dropout_),\n",
    "            layers.Dense(int(units/2/2/2), activation=activation_layer_),\n",
    "            layers.Dropout(dropout_),   \n",
    "            layers.Dense(int(units/2/2/2/2), activation=activation_layer_),        \n",
    "            layers.Dropout(dropout_),   \n",
    "            layers.Dense(1, activation=activation_, name='output')     \n",
    "        ])\n",
    "\n",
    "    if type_model_==4:\n",
    "        \n",
    "        inputs = Input(shape=(input_shape_,))\n",
    "\n",
    "        x0 = Dense(units, kernel_regularizer=REG1, activation=activation_layer_)(inputs)\n",
    "        x0 = Dropout(dropout_)(x0)\n",
    "        x0 = BatchNormalization()(x0)\n",
    "\n",
    "        x1 = Dense(units, kernel_regularizer=REG1,activation=activation_layer_,)(x0)\n",
    "        x1 = Dropout(dropout_)(x1)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "\n",
    "        x = Concatenate()([x0,x1])\n",
    "        x = Dense(1, kernel_regularizer=REG1,activation=activation_,)(x)\n",
    "\n",
    "        model = Model(inputs, x)\n",
    "    \n",
    "    model.compile(loss      = tf.keras.losses.BinaryCrossentropy(),     # binary_crossentropy  \n",
    "                  optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_), # 'adam',\n",
    "                  metrics   = ['AUC']) \n",
    "    \n",
    "    early_stopping = callbacks.EarlyStopping(monitor              = 'val_loss', \n",
    "                                             patience             = 20,  \n",
    "                                             min_delta            = 0.0001,  \n",
    "                                             mode                 = 'min',  \n",
    "                                             baseline             = None,    \n",
    "                                             restore_best_weights = True)\n",
    "    \n",
    "    plateau = ReduceLROnPlateau(monitor   = 'val_loss', \n",
    "                                factor    = 0.9, # .95\n",
    "                                patience  = 20,\n",
    "                                verbose   = False,\n",
    "                                mode      = 'min')\n",
    "    \n",
    "    return model, early_stopping, plateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcc42a",
   "metadata": {},
   "source": [
    "### 2.3.4. Criar modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2a6a4a3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T22:17:48.844733Z",
     "start_time": "2022-11-26T22:17:48.688647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_43 (InputLayer)          [(None, 1100)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_596 (Dense)              (None, 550)          605550      ['input_43[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_469 (Dropout)          (None, 550)          0           ['dense_596[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 550)         2200        ['dropout_469[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_597 (Dense)              (None, 550)          303050      ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " dropout_470 (Dropout)          (None, 550)          0           ['dense_597[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 550)         2200        ['dropout_470[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 1100)         0           ['batch_normalization_296[0][0]',\n",
      "                                                                  'batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " dense_598 (Dense)              (None, 1)            1101        ['concatenate_42[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 914,101\n",
      "Trainable params: 911,901\n",
      "Non-trainable params: 2,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, early_stopping, plateau = create_model(input_shape_=len(X_train_sc[0]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2549635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, early_stopping, plateau = create_model(input_shape_=len(X_train_sc[0]), learning_rate_=0.00001)\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1eafdad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T21:49:17.362116Z",
     "start_time": "2022-11-27T21:46:59.562639Z"
    },
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "executionInfo": {
     "elapsed": 16633,
     "status": "ok",
     "timestamp": 1669321135571,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "1eafdad7",
    "outputId": "dcf7fc73-ab0d-4d59-b516-66796e674d35",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L.Loss: 0.49903 - AUC:0.82985\n",
      "\n",
      "CPU times: total: 5min 45s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit(X_train_sc,\n",
    "                    y_train,\n",
    "                    epochs          = 1000, \n",
    "                    batch_size      = 256*2*2*2,\n",
    "                    callbacks       = [early_stopping, plateau],\n",
    "                    validation_data = (X_val_sc, y_val), \n",
    "                    shuffle         = True, \n",
    "                    verbose         = False)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "plot_hist(history)\n",
    "\n",
    "_lloss , _auc = model.evaluate(X_train_sc, y_train,  verbose=False)\n",
    "print('L.Loss: {:2.5f} - AUC:{:2.5f}'.format(_lloss, _auc))\n",
    "print()\n",
    "\n",
    "# - https://www.kaggle.com/code/pourchot/tps-11-2022-neural-network\n",
    "# - https://www.kaggle.com/code/teckmengwong/tps22novdummy \n",
    "\n",
    "# L.Loss: 0.50982 - AUC:0.83879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b3240931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T21:44:32.885901Z",
     "start_time": "2022-11-27T21:42:20.749137Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1669321063225,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "b3240931",
    "outputId": "ab1183bd-a8cc-4e38-912f-4a793fa7026a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 30ms/step\n",
      "625/625 [==============================] - 6s 9ms/step\n",
      "\n",
      "\n",
      "AUC: 0.74000 - F1-score: 0.74000 L.Loss: 0.51296\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAFjCAYAAAAn71y7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLTklEQVR4nO3deXRU9f3/8dfcyU4SE5AktClCo4EvVfYA+R2hNlpKqW1ZugqiFBC1SkVZilBZFERJAZciICrKUpeiiFUr1e5WVmv1K5v6RQQkCQIhiSHbzPz+8GR0zDJzkzu5k7nPxzmcQ+79zL3v+57JnU/e997Px+Xz+XwCAAAAAAAAHMywOwAAAAAAAADAbhTJAAAAAAAA4HgUyQAAAAAAAOB4FMkAAAAAAADgeBTJAAAAAAAA4HgUyQAAAAAAAOB4FMkAAAAAAADgeBTJAAAAAAAA4HgUyQAAAAAAAOB4MXYHEA4+n09ery9s2zcMV1i3j+aRf3uRf3uRf3uRf3uFM/+G4ZLL5QrLtmEt+nnRjfzbi/zbi/zbi/zbLxL6elFZJPN6fTp9+tOwbDsmxlB6egeVlVWqrs4bln2gaeTfXuTfXuTfXuTfXuHOf8eOHeR2UyRrD+jnRS/yby/yby/yby/yb79I6evxuCUAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHC/G7gAAAAAMwyXDcDW53u3muh4AAEB7FKyfJ0VOXy8yogAAAI5lGC6lpSUpPb1Dk/9SUxPl9frkcjXfwULLrVmzRldffXXAsv3792v8+PHq27evCgoK9MQTTwSs93q9uv/++zV06FD17dtXU6ZM0dGjR01tAwAARK9Q+nmR1NfjTjIAAGArw3DJ7TZUuGmvjhWXN9omOzNFM8YNCHoVEi2zadMmrVy5UgMHDvQvO3PmjCZOnKiCggItXLhQb731lhYuXKgOHTpo7NixkqRVq1Zp8+bNWrp0qbKysrRs2TJNnjxZL7zwguLi4kLaBgAAiF6h9POkyOnrUSQDAAAR4VhxuT44ftbuMByluLhY8+fP186dO9WtW7eAdU8//bRiY2O1aNEixcTEKCcnR0eOHNHatWs1duxY1dTU6NFHH9WMGTN02WWXSZJWrFihoUOHavv27bryyiuDbgMAADhDe+nn8bglAACAQ7377ruKjY3Vtm3b1KdPn4B1e/bs0aBBgxQT8/k11SFDhujDDz/UJ598ogMHDujTTz9Vfn6+f31qaqp69eql3bt3h7QNAACASMKdZAAAAA5VUFCggoKCRtcVFRUpNzc3YFlGRoYk6cSJEyoqKpIkdenSpUGb+nXBtnH++ee3KO6YmPBc560fNDhSBg92GvJvL/JvL/JvL/IfPmZzahiusH3Ph4IiGQAAABqoqqpSXFxcwLL4+HhJUnV1tc6dOydJjbY5e/ZsSNtoCcNwKT29Q4teG6rU1MSwbh/NI//2Iv/2Iv/2Iv/2S05OsHX/FMkAAADQQEJCgmpqagKW1Re2kpKSlJDwWSe2pqbG///6NomJiSFtoyW8Xp/Kyipb9Npg3G5DqamJKis7J4/HG5Z9oGnk317k317k317kP3zqcxuqiooq1dZ6LI8jNTUxpLvaKJIBAACggaysLJWUlAQsq/85MzNTdXV1/mVdu3YNaNOjR4+QttFSdXXh/QPG4/GGfR9oGvm3F/m3F/m3F/m3n9frs/U94IFbAAAANJCXl6e9e/fK4/n8au6OHTvUvXt3derUST179lRycrJ27tzpX19WVqZ9+/YpLy8vpG0AAABEEopkAAAAaGDs2LGqqKjQ3Llz9f777+vZZ5/V+vXrNXXqVEmfjUU2fvx4FRYW6rXXXtOBAwc0ffp0ZWVlafjw4SFtAwAAIJLwuCUAAAAa6NSpk9atW6fFixdr9OjR6ty5s2bNmqXRo0f720ybNk11dXWaN2+eqqqqlJeXp0ceeUSxsbEhbwMAACBSUCQDAACAli5d2mBZ79699dRTTzX5GrfbrZkzZ2rmzJlNtgm2DQAAgEjB45YAAAAAAABwPIpkAAAAAAAAcDyKZAAAAAAAAHA8xiRrIbc7eH3R6/XJ6/W1QTQAAAAAAABoDYpkJrlcLnm9PqWmJgZt6/F4VVpaSaEMAAAAAAAgwlEkM8kwXDIMlwo37dWx4vIm22VnpmjGuAEyDBdFMgAAAAAAgAjXqiLZmjVr9K9//UsbNmyQJF199dXatWtXo23vuecejRo1qtF1EydO1L///e+AZYMGDfJvNxIdKy7XB8fP2h0GAAAAAAAALNDiItmmTZu0cuVKDRw40L/sgQceUG1trf9nn8+n6dOn6+zZs/r2t7/d5LYOHjyoBQsW6IorrvAvi42NbWloAAAAAAAAgCmmi2TFxcWaP3++du7cqW7dugWsS0tLC/h548aNevvtt/X888+rQ4cOjW7v1KlTOnXqlPr06aPOnTubDQcAAAAAAABoteBTNH7Ju+++q9jYWG3btk19+vRpst3p06e1cuVK3XDDDfr617/eZLuDBw/K5XKpe/fuZkMBAAAAAAAALGH6TrKCggIVFBQEbffwww8rISFBkyZNarbdoUOHlJKSokWLFun1119XUlKSRowYoRtvvFFxcXFmwwMAAABaxe0Ofh3Z6/UxORMAAFEmLLNbVlRU6Omnn9ZNN92k+Pj4ZtseOnRI1dXV6t27tyZOnKj9+/fr3nvv1ccff6x77723xTHExJi+SS4khuEy1T6UThZCV59P8moP8m8v8m8v8h8+ZnJqGK6wfccDLtdns5KnpiYGbevxeFVaWkmhDACAKBKWItmrr76qmpoajR07NmjbRYsWafbs2TrvvPMkSbm5uYqNjdX06dM1a9YsnX/++ab3bxgupac3PgZaWwulkwXzyKu9yL+9yL+9yL+9kpMT7A4BUcwwXDIMlwo37dWx4vIm22VnpmjGuAEyDBdFMgAAokjYimTf/OY3lZqaGjyAmBh/gazeRRddJEkqKipqUZHM6/WprKzS9OtCERvrNtVBLys7J4/HG5ZYnMjtNpSamkhebUL+7UX+7UX+w6c+t6GoqKhSba3H8hhSUxO5SxB+x4rL9cHxs3aHAQAA2lhYimR79uzRzTffHFLbq6++WtnZ2br77rv9y9555x3FxsY2mD3TjLq68PwBY7YD7fF4wxaLk5FXe5F/e5F/e5F/e3m9PvIPAACAsLD8kumJEyd05swZ9ezZs9H1n376qU6ePOn/+Tvf+Y6ef/55/f73v9fRo0f10ksv6d5779WkSZOUnJxsdXgAAAAAAABAA5bfSVZfAEtLS2t0/aOPPqoHH3xQBw8elCSNHz9eLpdLGzZs0JIlS9S5c2dde+21uu6666wODQAAAAAAAGhUq4pkS5cubbCsd+/e/gJYY26++eYGj2KOGzdO48aNa00oAAAAAAAAQIuFZUwyAK1XP8NWc7xeH7NqAQAAAABgAYpkQAQyDJfS0pKCThTh8XhVWlpJoQwAAAAAgFaiSAZEIMNwye02VLhpr44VlzfaJjszRTPGDZBhuCiSAQAAAADQShTJgAh2rLhcHxw/a3cYAAAAAABEveaf5QIAAAAAAAAcgCIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHK9VRbI1a9bo6quvDlg2b9489ejRI+BfQUFBs9t5+eWXNXLkSPXu3VujRo3SG2+80ZqwAAAAAAAAAFNaXCTbtGmTVq5c2WD5wYMHdf311+tf//qX/98f/vCHJrezY8cOzZw5Uz/72c/03HPPKT8/X9ddd50++OCDloYGAAAAC9TV1em+++7Tt771LfXr10/jxo3TW2+95V+/f/9+jR8/Xn379lVBQYGeeOKJgNd7vV7df//9Gjp0qPr27aspU6bo6NGjbXwUAAAAoTFdJCsuLtb111+vwsJCdevWLWCdz+fT+++/r4svvlidO3f2/+vYsWOT23v44Yd1xRVXaMKECcrJydHs2bP1jW98Q48//rjpgwEAAIB1HnroIT3zzDO68847tXXrVnXv3l2TJ09WSUmJzpw5o4kTJ6pr167asmWLfvnLX6qwsFBbtmzxv37VqlXavHmz7rzzTj355JPyer2aPHmyampqbDwqAACAxpkukr377ruKjY3Vtm3b1KdPn4B1H330kSorK/X1r389pG15vV69+eabys/PD1g+ePBg7d6922xoAAAAsNCrr76qK6+8UpdeeqkuuOAC/frXv1Z5ebneeustPf3004qNjdWiRYuUk5OjsWPH6tprr9XatWslSTU1NXr00Uc1bdo0XXbZZerZs6dWrFihoqIibd++3eYjAwAAaCjG7AsKCgqaHGPs0KFDkqQNGzboH//4hwzD0LBhwzR9+nSlpKQ0aF9WVqbKykplZWUFLM/IyFBRUZHZ0ALExIRnTgLDcJlq73YzN4KV6vMZ7Xk1c3xtmQun5D9SkX97kf/wMZNTw3CF7TseDXXq1El//etfNX78eHXp0kVPPfWU4uLi1LNnTz3zzDMaNGiQYmI+704OGTJEa9as0SeffKKPP/5Yn376acDF0NTUVPXq1Uu7d+/WlVdeacchAQAANMl0kaw5hw4dkmEYysjI0OrVq/XRRx/p3nvv1XvvvafHH39chhHYqa2qqpIkxcXFBSyPj49XdXV1i+MwDJfS0zu0+PVWSk1NtDuEqEReP2dHLsi/vci/vci/vZKTE+wOwVHmzp2rX/3qV7r88svldrtlGIYeeOABde3aVUVFRcrNzQ1on5GRIUk6ceKE/4Jnly5dGrThYigaw8UIe5F/e5F/e5H/8DGbU7sviFpaJLvhhht01VVXKT09XZKUm5urzp076yc/+YneeeedBo9nxsfHS1KDcSmqq6uVmNjyP0K8Xp/Kyipb/PrmxMa6TXXQy8rOyePxhiUWJ3K7DaWmJkZ9XuuPMxRtmQun5D9SkX97kf/wMXPOq6ioUm2tx/IYUlMT6Rg34v3331dKSop+97vfKTMzU88884xmzJihjRs3qqqqqtELndJnfblz585Javxi6NmzZ1scExdDox95tRf5txf5txf5t5/dF0QtLZIZhuEvkNW76KKLJElFRUUNimRpaWlKSkpSSUlJwPKSkhJlZma2Kpa6uvD8AWO2A+3xeMMWi5OR18/ZkQvyby/yby/yby+v10f+28iJEyd02223af369Ro4cKAk6ZJLLtH777+vBx54QAkJCY1e6JSkpKQkJSR81smtqanx/7++DRdD0RguRtiL/NuL/NuL/IePmYuhkv0XRC0tks2aNUslJSVav369f9k777wjSbrwwgsbtHe5XOrfv7927dqlH//4x/7lO3fu9HfGAAAA0Pb++9//qra2VpdccknA8j59+ugf//iHvvKVrzR6oVOSMjMzVVdX51/WtWvXgDY9evRoVWxcDI1u5NVe5N9e5N9e5N9+dl8QtfS5gu985zt644039OCDD+qjjz7S3//+d91+++268sorlZOTI0kqLy/X6dOn/a+ZOHGiXnzxRT322GP64IMPdO+992r//v265pprrAwNAAAAJtRPrHTw4MGA5YcOHVK3bt2Ul5envXv3yuP5/Grvjh071L17d3Xq1Ek9e/ZUcnKydu7c6V9fVlamffv2KS8vr20OAgAAwARLi2SXX365Vq5cqddee03f//73NXfuXA0fPlxLlizxt1m8eLF+9KMf+X++9NJLtWTJEv3+97/X6NGjtWPHDq1evdpfVAMAAEDb6927twYMGKDZs2drx44d+vDDD7Vy5Uq98cYbuu666zR27FhVVFRo7ty5ev/99/Xss89q/fr1mjp1qqTPxiIbP368CgsL9dprr+nAgQOaPn26srKyNHz4cJuPDgAAoKFWPW65dOnSBsu++93v6rvf/a6p14waNUqjRo1qTSgAAACwkGEYeuihh7Ry5UrNmTNHZ8+eVW5urtavX+8fZ3bdunVavHixRo8erc6dO2vWrFkaPXq0fxvTpk1TXV2d5s2bp6qqKuXl5emRRx5RbGysXYcFAADQJEvHJAMAAED0OO+88zR//nzNnz+/0fW9e/fWU0891eTr3W63Zs6cqZkzZ4YrRAAAAMsw1zkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcjyIZAAAAAAAAHI8iGQAAAAAAAByPIhkAAAAAAAAcL8buAACgLRmGS4bhCtrO6/XJ6/W1QUQAAAAAgEhAkQyAYxiGS2lpSXK7g99E6/F4VVpaSaEMAAAAAByCIhkAxzAMl9xuQ4Wb9upYcXmT7bIzUzRj3AAZhosiGQAAAAA4BEUyAI5zrLhcHxw/a3cYAAAAAIAIwsD9AAAAAAAAcDyKZAAAAAAAAHA8imQAAAAAAABwPIpkAAAAAAAAcDyKZAAAAAAAAHA8imQAAAAAAABwPIpkAAAAAAAAcDyKZAAAAAAAAHA8imQAAAAAAABwPIpkAAAAAAAAcDyKZAAAAAAAAHC8GLsDAACrGIZLhuFqcr3bzXUBAAAAAEDjKJIBiAqG4VJaWhKFMAAAAABAi1AkAxAVDMMlt9tQ4aa9OlZc3mib/j0zNGFkrzaODAAAAADQHlAkAxBVjhWX64PjZxtdl52R3MbRAAAAAADai1Y9l7RmzRpdffXVAcv+8pe/aOzYserXr58KCgp0zz33qKqqqslteDwe9e7dWz169Aj498ADD7QmNAAAAAAAACBkLb6TbNOmTVq5cqUGDhzoX7Znzx7ddNNNmjZtmkaMGKEjR47ojjvuUGlpqe6+++5Gt/Phhx+qurpazz//vDp16uRfnpSU1NLQAAAAAAAAAFNMF8mKi4s1f/587dy5U926dQtY9+STT2rw4MG6/vrrJUndunXT9OnTNW/ePC1cuFBxcXENtnfw4EElJyerZ8+eLTsCAAAAAAAAoJVMF8neffddxcbGatu2bfrd736n48eP+9f94he/kGEEPsFpGIZqa2tVUVGhjh07NtjewYMHlZOT04LQAQAAAAAAAGuYLpIVFBSooKCg0XW9egXOGldbW6v169fr4osvbrRAJkmHDh1SXV2dJk2apAMHDigzM1PXXHONfvjDH5oNLUBMTKuGW2uSYbhMtXe7wxOHU9XnM9rzaub42jIXkZz/cMQUaccZyfl3AvIfPmZyahiusH3HAwAAwNnCNrtlXV2dZs2apffee0+bNm1qst17770nr9eradOmKSsrS3//+981Z84c1dbW6kc/+lGL9m0YLqWnd2hp6JZKTU20O4SoRF4/Z0cunJL/SD3OSI3LKci/vZKTE+wOAQAAAFEqLEWyiooK3XLLLdq1a5cefPBB9e7du8m2f/zjH+XxeNShw2dFrZ49e+rjjz/WI4880uIimdfrU1lZZYteG0xsrNtUB72s7Jw8Hm9YYnEit9tQampi1Oe1/jhD0Za5iOT8m8lZqCLtOCM5/05A/sPHzO9vRUWVams9lseQmprIXYIAAAAOZ3mRrKSkRFOmTNHx48f1yCOPKC8vr9n2CQkNC065ubnatm1bq+KoqwvPHzBmO9AejzdssTgZef2cHblwSv4j9TgjNS6nIP/28np95B8AAABhYekl07Nnz+qaa67R6dOntWnTpqAFsrKyMg0aNEjPPvtswPJ33nlHF110kZWhAQAAAAAAAE2y9E6yu+++W0ePHtW6devUsWNHnTx50r+uY8eOcrvdKi0tlSSlpaUpNTVVQ4YM0YoVK9SpUyddcMEF2r59u7Zt26Y1a9ZYGRoAAAAAAADQJMuKZB6PRy+99JJqa2t1zTXXNFj/2muvKTs7WzfffLMkacOGDZKkJUuW6IEHHtD8+fN16tQp5eTk6P7779fQoUOtCg0AAAAAAABoVquKZEuXLvX/3+126+233w76mvriWL3k5GTNmTNHc+bMaU0oAAAAAAAAQIuFZXZLALCSYbhkGK5m2zArHQAAAACgNSiSAYhohuFSWloSRTAAAAAAQFhRJAMQ0QzDJbfbUOGmvTpWXN5ku/49MzRhZK82jAwAAAAAEE0okgFoF44Vl+uD42ebXJ+dkdyG0QAAAAAAog3PLwEAAAAAAMDxKJIBAAAAAADA8XjcEgAAAACiXLDZwpkkCQC4kwwAAADN2Lp1q0aOHKlLLrlE3/ve9/Tyyy/71x07dkxTp05V//79demll2rlypXyeDwBr9+0aZMuv/xy9e7dW1dddZX27dvX1ocAOF79bOHp6R2a/Jeamiiv1yeXq+lCGgBEO+4kAwAAQKOef/55zZ07V7fffruGDh2qF198UbfeequysrJ08cUXa9KkSerWrZuefPJJffTRR5o7d64Mw9C0adMkSc8995zuvfde3XnnnerVq5fWrl2riRMn6uWXX1bHjh1tPjrAOUKZLTw7M0Uzxg1o9m6zL24vlHZer09er890vABgF4pkAAAAaMDn8+m+++7ThAkTNG7cOEnSDTfcoD179mjXrl06fvy4Pv74Yz399NM677zzlJubq1OnTunee+/V9ddfr7i4OK1evVrjx4/XD37wA0nSkiVLdMUVV+iZZ57R1KlT7Tw8wJGCzRYeivq70kJ5PNPj8aq0tJJCGYB2gyIZAAAAGjh8+LCOHz+u73//+wHLH3nkEUnSggUL9I1vfEPnnXeef92QIUNUUVGh/fv3Kzs7Wx9++KHy8/P962NiYjRw4EDt3r2bIhnQToVyV5oUeGcaRTIA7QVFMgAAADRw+PBhSVJlZaUmTZqkffv2KTs7WzfccIMKCgpUVFSkrKysgNdkZGRIkk6cOKGYmM+6mV26dGnQ5sCBA21wBADCyYq70gAg0lAkAwAAQAMVFRWSpNmzZ+umm27SjBkz9Morr+jGG2/UY489pqqqKqWmpga8Jj4+XpJUXV2tc+fOSZLi4uIatKmurm5VbDEx4Zl7KpQxlr6I2QCtVZ9P8mo9Mzk1DFezv2Nm3x/ez9Dw+bcX+Q8fszkNdg4KN4pkAAAAaCA2NlaSNGnSJI0ePVqS9D//8z/at2+fHnvsMSUkJKimpibgNfXFr6SkJCUkJEhSo20SExNbHJdhuJSe3qHFr7dSamrLjwNNI6/2Sk5OsHR7vJ/mkC97kX/7WX0OMosiGQAAABrIzMyUJOXm5gYsv/DCC/W3v/1NgwYN0qFDhwLWlZSU+F9b/5hlSUmJcnJyAtrUb7slvF6fysoqW/z65sTGuk11zsvKzsnj8YYlFidyuw2lpiaSVxNcLpdSUhIsvfuloqJKtbWeJtfXv0+h4v0MDZ9/e5H/8DF7zgh2Dmqp1NTEkM6VFMkAB2CabrQGnx+0RiifHx5tiEzf+MY31KFDB/33v//VwIED/csPHTqkrl27Ki8vT1u3blVFRYWSk5MlSTt27FCHDh3Us2dPxcXFqXv37tq5c6d/8P66ujrt2bNHV111Vatiq6sLzx8wZj+LHo83bLE4GXkNXUyMEdIg+v17ZmjCyF5tGNnneD/NIV/2Iv/283p9tr4HFMmAKMc03WgNPj9oDTOfH0SehIQETZ48Wb/73e+UmZmp3r1768UXX9Trr7+u9evXq2/fvlq5cqVuueUWzZgxQ8eOHdPy5cv1i1/8wj8O2S9+8QstXrxYF1xwgS655BKtXbtWVVVV+tGPfmTz0QHRJdgg+tkZyUG3kZYSL6/XZ/ujTgBgJ4pkQJRjmm60Bp8ftEaonx8773BA82688UYlJiZqxYoVKi4uVk5Ojh544AENHjxYkrRu3TotXLhQP/nJT3Teeefpqquu0o033uh//U9+8hOVl5dr5cqVKi0t1cUXX6zHHntMHTt2tOuQADQhOTFWhuHinA3A0SiSAQ7BNN1oDT4/aA0r7nCAfSZOnKiJEyc2uu6CCy7Qo48+2uzrJ02apEmTJoUjNABhwDkbgJNRJAMAAAAA2IKxTwFEEopkAAAAAIA2x9inACINRTIAAAAAQJtj7FMAkYYiGQAAAABEoGCPIkbL7MGMfQogUlAkAwAAAIAIY+ZRRACANSiSAQAAAECECeVRxP49MzRhZK82jgwAohdFMgAAAACIUM09ipidkdzG0QBAdGvVvbtr1qzR1VdfHbBs//79Gj9+vPr27auCggI98cQTQbfz8ssva+TIkerdu7dGjRqlN954ozVhAQAAAAAAAKa0uEi2adMmrVy5MmDZmTNnNHHiRHXt2lVbtmzRL3/5SxUWFmrLli1NbmfHjh2aOXOmfvazn+m5555Tfn6+rrvuOn3wwQctDQ0AAAAAIpZhuBQTYzT7j7HIAKDtmX7csri4WPPnz9fOnTvVrVu3gHVPP/20YmNjtWjRIsXExCgnJ0dHjhzR2rVrNXbs2Ea39/DDD+uKK67QhAkTJEmzZ8/Wf/7zHz3++ONatGiR+SMCAAAAgAjFgPwAELlMF8neffddxcbGatu2bfrd736n48eP+9ft2bNHgwYNUkzM55sdMmSI1qxZo08++UTnn39+wLa8Xq/efPNN/frXvw5YPnjwYG3fvt1saAAAAAAQ0UIZkF9iUH4AsIPpIllBQYEKCgoaXVdUVKTc3NyAZRkZGZKkEydONCiSlZWVqbKyUllZWQ1eU1RUZDa0ADEx4bkyYxguU+25QmSt+nyGkleXyxX0/fJ6ffL5fJbEZiUzn5tgbc1+Bptrb0f+7fwdCrbvUI5Rsu5zZib/oQp2DJzzPheO/Ee7cOSq/hElAGjvmhuQX4qeQflD6VsCQKSwdHbLqqoqxcXFBSyLj4+XJFVXVzfaXlKjr2msfagMw6X09A4tfr2VUlMT7Q4hKoWSV6/XF1KRxmwRINJY/RkLZXtOyX+w4ww1fquP08r3PJJji1ROOMZIlpycYHcIAIAQpKXEy+v1ten3pmGEfgHT6428C+UA7GdpkSwhIUE1NTUBy+qLXUlJSQ3a1xfQGntNYmLLT6Zer09lZZUtfn1zYmPdpjroZWXn5PF4wxKLE7ndhlJTE4Pmtb5dc7exZ2emaMa4ARH5HtXHH4pQcxGq5rZnR/7Nxm+lUHIR7FEJKz9noebf7PaaOwazj3pE4u+TVazOvxOE4/e3oqJKtbUeS7cpfVb85I4GALBOcmKsDMNlaT+jOWbGevN4vCotraRQBqABS4tkWVlZKikpCVhW/3NmZmaD9mlpaUpKSmr0NY21N6OuLjx/wJjtQHs83rDF4mSh5jXYbexmthWprI4/lO05Jf+hxBbKMYa6LSvjMqO5YzD7qEckv59WccIxRjKv10f+AaAdsbKfEezRzVDGequ/gGkYLopkABqwtEiWl5enJ598Uh6PR263W5K0Y8cOde/eXZ06dWrQ3uVyqX///tq1a5d+/OMf+5fv3LlTAwcOtDI0AAAAAEA7ZObRzVAvYAJAYywtko0dO1br1q3T3LlzNXnyZL399ttav369Fi5c6G9TXl6u2tpadezYUZI0ceJEXXfdderVq5eGDRumLVu2aP/+/Vq8eLGVoQEAAAAA2qG2fnQTgHNZWiTr1KmT1q1bp8WLF2v06NHq3LmzZs2apdGjR/vbLF68WLt27dJf/vIXSdKll16qJUuWaNWqVVqxYoUuvPBCrV69Wjk5OVaGBgAAAABox6x8dBMAGtOqItnSpUsbLOvdu7eeeuopU68ZNWqURo0a1ZpQAAAAAAAAgBZjGicAAAAAAAA4HkUyAAAAAAAAOB5FMgAAAAAAADgeRTIAAAAAAAA4nqWzWwIAAAAAEA0MwyXDcDXbxuv1yev1tVFEAMKNIhkAAAAAAF9gGC6lpSXJ7W7+4SuPx6vS0koKZUCUoEgGAAAAAMAXGIZLbrehwk17day4vNE22ZkpmjFugAzDRZEMiBIUyQAAAAAAaMSx4nJ9cPys3WEAaCMUyYAQhDIeQagifdyC5m4pD3a7OZoWSu5C/WxY9T7wfgIAYK1Q+ox8/wJA5KJIBgQR6ngEkuTx+uQO0jGK1HEL0lLi5fX6lJqa2Gw7r9cnl8uagqEThJpXKfhnw+Vyhb6tED6LAADAOmb6jACAyESRDAgilPEIJKl/zwxNGNmr3Y5bkJwYK8NwhRw/QhNKXqXQPhv1V6et+Cx+sR0AAGg9s31GAEDkoUgGhCjYeATZGckhtYt07T3+SGVlXq36LNa3AwAA1uH7FwDaL+4FBgAAAAAAgONxJxkAAAAAwFGCjR1nZmw5KydoAmAvimQAAAAAAEcwM6mSlduK1Mm7AASiSAYAAAAAcIRQJ1UKZYIFsxM0xca65fF4G23DrKhAZKBIBgAAAABwFCsnWAi2rVDvOPN6fXK5mEUesBNFMgAAAACOZRguGUbwwgRjSqGlQrnjrP5us1A+iwDChyIZAAAAAEcyDJfS0pJCetSNMaXQWsHuOANgP4pkAAAAABzJMFxyu42Qx5QyDBdFMgCIYhTJAAAAADgad/gAACSJKTQAAAAAAADgeBTJAAAAAAAA4Hg8bol2KdjgqqEMvhotyEX4NJc78toy0TCDWCjvfSTHDwAAAKBxFMnQrrhcnw2WmpqaaHcotktLiScXYUJuw6O9zyBm5vwTifEDAFqPC2gAEN0okqFdqb8LJdgMRP17ZmjCyF5tGFnbS06MJRdhEkpuyat57X0GsVDPP5EaPwCg5biAhrZiGC7FxDRfcOWOdSB8KJKhXQo2A1F2RnIbRmMvchE+zeWWvLZce59BrL3HDwAwjwtoCLf6QmxyckLQttyxDoSPpUWynTt3asKECY2uy87O1muvvdZg+d69e3XVVVc1WP7EE09o8ODBVoYHAACAFjp8+LDGjBmj3/zmNxozZowkaf/+/Vq8eLH+93//Vx07dtS1114b0Bf0er168MEH9cwzz6i8vFx5eXm644479LWvfc2uwwBahQtoCJdQnxLhjnUgvCwtkvXr10//+te/Apa99dZbuvnmm3XjjTc2+pqDBw+qa9eu2rx5c8Dy8847z8rQAAAA0EK1tbWaMWOGKisr/cvOnDmjiRMnqqCgQAsXLtRbb72lhQsXqkOHDho7dqwkadWqVdq8ebOWLl2qrKwsLVu2TJMnT9YLL7yguLg4uw4HACIWd6wD9rK0SBYXF6fOnTv7f66srNTdd9+t0aNH+ztLX3bo0CFdeOGFAa8DAABA5HjggQeUnBx4l8zTTz+t2NhYLVq0SDExMcrJydGRI0e0du1ajR07VjU1NXr00Uc1Y8YMXXbZZZKkFStWaOjQodq+fbuuvPJKG44EAACgaWGdgmX16tU6d+6cZs+e3WSbgwcPKicnJ5xhAAAAoIV2796tp556SkuXLg1YvmfPHg0aNEgxMZ9fcx0yZIg+/PBDffLJJzpw4IA+/fRT5efn+9enpqaqV69e2r17d5vFDwAAEKqwDdx/+vRprV+/XrfddpvS0tKabPfee+8pPT1dY8aMUXFxsXJzczV9+nT17t27VfsPNiNISxmGy1R7poK2ltn8hyLYexSO99COfVop2Kw7ZuJv77mwWnPHG47Pv9Wai9/sexlp7z3nf/PCkYNQZv2CdcrKyjRr1izNmzdPXbp0CVhXVFSk3NzcgGUZGRmSpBMnTqioqEiSGrwuIyPDv66l6OdFp/p8tmVeeQ/RXvHZtZYd5x+nMJtTu/t6YSuSbd68WSkpKfrpT3/aZJsTJ06ovLxclZWVmjdvntxutzZu3Kjx48fr2Wef1YUXXtiifRuGS+npHVoauqWYJjry2fEetffPRSiz7oSqvefCau09H1bGTy7QGCvPPwhuwYIF6tevn77//e83WFdVVdVgXLH4+HhJUnV1tc6dOydJjbY5e7bl4+3Qz4t+5BUIjt+T8CCv9rO7rxe2ItnWrVs1atQoJSQ0fYBdunTR7t27lZiYqNjYWEnSJZdcon379mnDhg1auHBhi/bt9fpUVlYZvGELxMa6Tb1pZWXn5PF4wxKLE5nNfyiCvUdut2H5ydKOfVqpoqJKtbWeJtebib+958JqzeUjHJ9/qzUXv9n3MtLOn5z/zQvH72+w809LpaYmcvX4S7Zu3ao9e/bohRdeaHR9QkKCampqApZVV1dLkpKSkvx9wJqamoD+YHV1tRITW/65oJ8XverPGW2ZV6f1MxA9OP9Yy47zj1OYPc/a3dcLS5HswIEDOnr0aKNXHb8sNTU14GfDMJSTk6Pi4uJWxVBXF54PttkOtMfjDVssThSOP2DseI/a++fC6/VZFn97z4XVmstHe/gD3sr3M9I+G5z/I4OV5x80b8uWLTp16pR/0P168+fP10svvaSsrCyVlJQErKv/OTMzU3V1df5lXbt2DWjTo0ePVsVGPy+6kVcgOH5PwoO82s/uvl5YimR79uxRp06d1LNnz2bb/eMf/9CvfvUrbdu2TV/72tckSXV1dTpw4ICGDx8ejtAAAAAQgsLCQlVVVQUsGz58uKZNm6Yf/OAHev755/Xkk0/K4/HI7XZLknbs2KHu3burU6dOSklJUXJysnbu3OkvkpWVlWnfvn0aP358mx8PAESTUIr6Xq9PXq+vDaIBokdYimT79u1r8grhyZMnlZSUpA4dOqh///5KT0/X7Nmzdfvttys2NlZr165VaWmprr322nCEBgAAgBBkZmY2urxTp07KzMzU2LFjtW7dOs2dO1eTJ0/W22+/rfXr1/uHy4iLi9P48eNVWFiojh076qtf/aqWLVumrKwsLoYCQAulpcTL6/WF9Piax+NVaWklhTLAhLAUyU6ePNnkjJaXXnqpbrrpJt18881KTk7W+vXrVVhYqEmTJqm6uloDBgzQxo0bdf7554cjNAAAAFigU6dOWrdunRYvXqzRo0erc+fOmjVrlkaPHu1vM23aNNXV1WnevHmqqqpSXl6eHnnkEf9YtAAAc5ITY2UYLhVu2qtjxeVNtsvOTNGMcQNkGC6KZIAJYSmSPfzww02uO3jwYMDPXbt21f333x+OMAAAAGChL/fjevfuraeeeqrJ9m63WzNnztTMmTPDHRoAOMqx4nJ9cLzlMwUDVjAMlwzD1Wyb9jCu8heFbXZLOEMovxQSz8OjacFOmu3tpOp0zb1fdr2X7f08ZUf87T1nAAAACC/DcCktLSnq/l6jSIYWM/NLwfPw+DIz4ykg8kXq+9nez1N2xN/ecwYAAIDwMwyX3G4j6KO//XtmaMLIXm0YWetQJEOLhfpLwfPwaEyo4ym0t5OqU4XyftrxXrb385Qd8bf3nAFAvWh8DAgAIk2wR3+zM5LbMJrWo0iGVuN5eLRGtJ1Una6599PO97K9n6fsiL+95wyAs0XrY0AAgPCiSAYAAAAgqkTrY0AAgPCiSAYAAAAgKnHHOgDADIpkAAAAAABEoWCPHDNTNRCIIhkAAAAAAFEk1JnHmakaCESRDAAAAACAKBLKzOPMVA00RJEMAAAAAIAoxGzVgDnMiQwAAAAAAADH404yAAAAAAAcKtjg/qEKdRIAw3DJMFyWbQ/hEex9supzE2kokgEAAAAA4DChDu4vSR6vT+4gha1QJgEwDJfS0pJCKrAwqYB9zLxP0YYiGQAAAIB2xal3OABWCmVwf0nq3zNDE0b2CmkSgNhYtzweb5PbcrsNud1G0H0yqYC9DMMV9H2q/1xEG4pkAAAAANoNJ9/hAIRDsMH9szOSg7Yzc1daKPtEZGjufar/XEQbimRhFuzLm+esAwW7KhjKs+tmBXuP6IA1ZBguxcQ0nRdy1nLN5S4cn/9IFsrnKJLPoVb8HvC7BAANOfkOByBSmb0rDYhUFMnCJNRKOs9Zf66trwqavdqBz3OWnJxgdyhRh8/j50yNjxGB51Crx/cAADTOiXc4AJEu1LvSgEhFkSxMQqmk85x1oLa+KsjVDvPIWfiEklun5DXUz1mknkOtHN/DKe85AAAAEAkokoUZz1qb19ZXBbnaYR45Cx+uin+uvZ8/rRjfw2nvOQAAAGAnBjsBAAAAAACA43EnGQAAAAAAcLz2PnEUWo8iGQAAAICIwczjANqay+Vq1xNH1TMMl4wgk0JR5GseRTIAAACgBYIVa/hDxBwzf6QCcIa2Os/WF5fa68RR0mfHkJaWFDRnkVzkiwQUyQAAAAAT0lLiQyrm8IeIOaH+kcrMv0D0s+s8254njjIMl9xuo9lzaCQX+SIFRTIAAADAhOTE2KDFHP4QaTlm0QZg5jwbG+uWx+Nt1f6CPaL4ZW09dlkoj1HWxxRKoY/H2ptGkQwAAABogfZ8xwEAtAfNnWdDvdtMkjxen9wmC2Gt3qdFd7mF+hhlKMzE71SWF8mKi4s1bNiwBsvvvvtujRkzpsHyM2fO6K677tI//vEPuVwufe9739OsWbOUmMibBgAAAAAAGgrlbjPp80e0m2sX6mPcoe7TyruJQ3mMUgrtGMzmzIksL5IdOHBA8fHxevXVV+VyfV6pTUlJabT9tGnTdO7cOa1fv15lZWWaO3euKisrdc8991gdGgAAAACLhfIYkMREBgDCI9RHtJtrZ/YxbjvuJLbyUXQea2+a5UWyQ4cOqVu3bsrIyAja9j//+Y927dqll156STk5OZKkRYsWafLkybr11luVmZlpdXgAAAAALGLmMSAmMgAARDrLi2QHDx70F7yC2bNnjzp37hzQftCgQXK5XNq7d69GjhxpdXgAAAAALBLqY0BMZAAAaA/CcidZenq6xo0bp8OHD+uCCy7QDTfc0Og4ZcXFxerSpUvAsri4OKWlpenEiRNWhwYAAAAgDJjEAAAQDSwtktXV1en//u//dOGFF+rXv/61kpOT9eKLL+q6667TY489pvz8/ID2586dU1xcXIPtxMfHq7q6ulWxxMSEZ8pSs1PDhqK9Tq9qNu7YWHezrwlHbiMVuQCs09zvk5XTebeH38tg52WXK/i4QWaP08r8h8IwXGH7jgcAAICzWVoki4mJ0c6dO+V2u5WQkCBJuvjii/Xee+/pkUceaVAkS0hIUE1NTYPtVFdXKykpqcVxGIZL6ekdWvz6thbt06/WTzObnJxgdyi2IxeAdcLx+9Tez8fB4vd6fZYVruw6n3H+BAAA0SKUiU/a60017ZXlj1t26NCwOHXRRRfpX//6V4PlWVlZevXVVwOW1dTUqLS0NKSB/5vi9fpUVlbZ4tc3JzbWbXkHvazsnDwer6XbbAtutxHSH5RMM/s5cgFYJ5TfJ7O/S82dj8Nx/rdac/HXn7OtOv+EI/+hqKioUm2tx9JtSp8VGOmEAgCAtmJm4hO0HUuLZO+9955++tOf6qGHHtLgwYP9y//3f/9XF154YYP2eXl5Kiws1JEjR3TBBRdIknbt2iVJGjBgQKtiqasLT9EpHB9gj8cbtngjCdPMfo5cANaxcjrv5s7H7aEDE8r3idXnHyvzHwqv1+eI70wgWrX3x9oBwCqhTnzCDRRty9IiWU5Ojr7+9a9r0aJFWrhwodLT0/X000/rrbfe0pYtW+TxeHT69GmlpKQoISFBffr0Uf/+/TV9+nQtWLBAlZWVuuOOOzRq1ChlZmZaGRoAAAAAm9Q/ot3eH2sHAKtxA0VksbRIZhiGVq9erd/+9re65ZZbVFZWpl69eumxxx5Tbm6ujh07pssvv1x33323xowZI5fLpQcffFALFy7UNddco/j4eI0YMUJz5syxMiwAAAAANrLrEW0AsFNzd8+2h6cUnMjyMcnOP/983X333Y2uy87O1sGDBwOWderUSffff7/VYQAAAACIMG39iDYA2IG7Z9svy4tkAAAAACJbKDOqhYI7IQCgIe6ebb8okgEAAAAOEuqMah6vT24G0weAFuPu2faHIhkAAADgIKHMqFZ/hwOzrgEAnIQiGQAAAOBAodzhwKxrAAAnYRABAAAAAAAAOB5FMgAAAAAAADgeRTIAAAAAAAA4HkUyAAAAAAAAOB5FsnbCMFyKiTEs+WeEOJV3sH0GmzYcANC23G7O2bBWaWmp7rjjDg0bNkz9+/fXz3/+c+3Zs8e//o033tCYMWPUp08fjRgxQi+++GLA66urq7Vw4ULl5+erX79+uu2223T69Om2PgxbNfd7abZvBgAAwovZLdsBw3ApLS0ppD9wPF6f3EE6Wh6PV6WllfJ6fZbsEwBgr7SUeHm9PqWmJtodCqLMrbfeqpMnT2r58uXq1KmTNmzYoEmTJum5556Tz+fT1KlTNXHiRC1btkx/+9vfNGvWLHXs2FH5+fmSpAULFmjPnj164IEHFBcXp/nz52vatGnauHGjzUcWfmZ+L0PpmwEAgPCjSNYOGIZLbrehwk17day4vMl2/XtmaMLIXs22y85M0YxxA2QYrqBFsmD7rN8fAMBeyYmxMgwX52xY6siRI3r99de1efNmDRgwQJL0m9/8Rv/85z/1wgsv6NSpU+rRo4emT58uScrJydG+ffu0bt065efnq7i4WFu3btXq1as1cOBASdLy5cs1YsQI/ec//1G/fv1sO7a2EMrvpRR63wwAAIQfRbJ25FhxuT44frbJ9dkZySG1s2qf9fsDAEQGztmwUnp6utauXatLLrnEv8zlcsnlcqmsrEx79uzRFVdcEfCaIUOGaPHixfL5fNq7d69/Wb3u3bsrMzNTu3fvjvoiWT0r+2UAACC8KJIBAACggdTUVH3zm98MWPbKK6/oyJEjuv322/Xcc88pKysrYH1GRobOnTunM2fOqLi4WOnp6YqPj2/QpqioqFWxxcSEZzgIO8cGa8shLhhOAwAQqerHRrcLRTIAAAAE9eabb2rOnDkaPny4LrvsMlVVVSkuLi6gTf3PNTU1OnfuXIP1khQfH6/q6uoWx2EYLqWnd2jx6yMVYwoCACAlJyfYun+KZAAAAGjWq6++qhkzZqh///4qLCyU9Fmxq6amJqBd/c+JiYlKSEhosF76bMbLxMSWF4S8Xp/Kyipb/PrmxMa6beucl5Wdk8fjbZN9ud0GRTkAQESqqKhSba3H8u2mpiaGdCc1RTIAAAA0aePGjVq8eLFGjBihe+65x393WJcuXVRSUhLQtqSkRElJSUpJSVFWVpZKS0tVU1MTcEdZSUmJMjMzWxVTXV14ikl2Pobo8XjDdlwAALQXXq/P1u9DBiQAAABAozZv3qw777xT48aN0/LlywOKXQMHDtSuXbsC2u/YsUP9+/eXYRgaMGCAvF6vfwB/STp8+LCKi4uVl5fXZscAAAAQKopkAAAAaODw4cNasmSJvv3tb2vq1Kn65JNPdPLkSZ08eVLl5eW6+uqr9fbbb6uwsFAffPCBHn30Uf3pT3/S5MmTJUmZmZn63ve+p3nz5mnnzp16++23deutt2rQoEHq27evvQcHAADQCB63BAAAQAOvvPKKamtr9ec//1l//vOfA9aNHj1aS5cu1apVq7Rs2TI9/vjjys7O1rJly5Sfn+9vd+edd2rJkiW66aabJEnDhg3TvHnz2vQ4nMYwXEFn6WR2SwAAGkeRDAAAAA1cf/31uv7665ttM2zYMA0bNqzJ9UlJSbrrrrt01113WR0eGmEYLqWlJVEEAwCghSiSAQAAADYLpbDl9frk9fqaXG8YLrndhgo37dWx4vIm2/XvmaEJI3u1KE4AAKIZRTIAAADAJmkp8fJ6fUpNTQza1uPxqry8Sj5f44Wy+kLbseJyfXD8bJPbyc5IblmwAABEOYpkAAAAgE2SE2NlGK6gd3/9T/eOmvLDS5SWltSG0QEA4CwUySJAsNvrwzGuhB37BIBI19y5L9hA2ADQGqHc/RWsmMZjlAAAtA5FMhuZub2+Pe8TACId50YA7UVzxTQeowQAoHUoktko1NvrrbwqaMc+ASDShXJu5LwIAAAARDeKZBHAjsFVGdAVABriDg0AAADAuSwvkpWWlmr58uX629/+poqKCvXo0UO33XabBg4c2Gj7hx56SCtXrmyw/ODBg1aHBgAAAAAAADTK8iLZrbfeqpMnT2r58uXq1KmTNmzYoEmTJum5557T17/+9QbtDx48qB/+8IeaOXOm1aEAAAAAAAAAIbF0CsMjR47o9ddf14IFCzRw4EB1795dv/nNb5SRkaEXXnih0dccOnRIvXr1UufOnQP+AQAAAAAAAG3F0iJZenq61q5dq0suucS/zOVyyeVyqaysrEH7mpoaffjhh43eYQYAAAAAAAC0FUsft0xNTdU3v/nNgGWvvPKKjhw5ottvv71B+/fff18ej0evvPKKFi9erOrqauXl5WnmzJnKyMhoVSwxMZbW//wMwxWW7QIAgOAMwxW273gAAAA4W1hnt3zzzTc1Z84cDR8+XJdddlmD9YcOHZIkJSYm6r777tOpU6e0fPlyTZgwQVu3blVCQkKL9msYLqWnd2hN6AAAIAIlJ7esbwAAAAAEE7Yi2auvvqoZM2aof//+KiwsbLTNqFGjNGzYMHXs2NG/7KKLLtKwYcP0l7/8RSNHjmzRvr1en8rKKlv02mBiY9100AEAsElFRZVqaz2Wbzc1NVFuN3eoAQAAOFlYimQbN27U4sWLNWLECN1zzz2Ki4trsu0XC2SSlJGRobS0NBUVFbUqhro6b6te3xQ60AAA2Mfr9YXtOx4AAADOZnnFZ/Pmzbrzzjs1btw4LV++vNkC2YoVK/Sd73xHPp/Pv+zYsWM6c+aMLrzwQqtDAwAAAAAAABplaZHs8OHDWrJkib797W9r6tSp+uSTT3Ty5EmdPHlS5eXlqqmp0cmTJ1VTUyNJ+va3v63jx49rwYIFOnz4sHbv3q2bb75Z/fv319ChQ60MDQAAAAAAAGiSpY9bvvLKK6qtrdWf//xn/fnPfw5YN3r0aI0ePVoTJkzQE088ocGDB+viiy/Www8/rPvuu09jxoxRXFycLr/8cs2ePVsuF7NIAgAAAAAAoG1YWiS7/vrrdf311zfb5uDBgwE/5+fnKz8/38owAAAAAAAAAFMYhR4AAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5HkQwAAAAAAACOR5EMAAAAAAAAjkeRDAAAAAAAAI5neZHM6/Xq/vvv19ChQ9W3b19NmTJFR48ebbL9mTNndNtttykvL0+DBg3SwoULde7cOavDAgAAgA3M9g0BAADsYnmRbNWqVdq8ebPuvPNOPfnkk/J6vZo8ebJqamoabT9t2jQdOXJE69ev13333ae///3vWrBggdVhAQAAwAZm+4YAAAB2sbRIVlNTo0cffVTTpk3TZZddpp49e2rFihUqKirS9u3bG7T/z3/+o127dumee+7RN77xDeXn52vRokV6/vnnVVxcbGVoAAAAaGNm+4YAAAB2srRIduDAAX366afKz8/3L0tNTVWvXr20e/fuBu337Nmjzp07Kycnx79s0KBBcrlc2rt3r5WhAQAAoI2Z7RsCAADYyeXz+XxWbWz79u26+eab9d///lcJCQn+5b/61a9UVVWlNWvWBLS/66679N///lfPPPNMwPL8/HxNnjxZkyZNalEcPp9PXq9lhxXA5ZIMw1BpebXqPN4m28XHuZWSFNdsu1DaWN0uUrdF/MRP/NG/T+In/tZsK8ZtKC0lXl6vV9b1XD5nGC65XC7rN+xwZvuGoaCfxznDCfHbsU/iJ/5I2Rbxt499Wh1/pPT1Yqzcaf2A+3FxcQHL4+Pjdfbs2Ubbf7ltffvq6uoWx+FyueR2h7ejm5YSb1k7K7dlxz6J3959Er+9+2zv8duxT+K3d5/tPX7DYGLu9sRs3zAU9PM4Z9i1Lafsk/jt3Sfx27vP9h6/Hfu0On67+3qW7r3+CuGXB2Ktrq5WYmJio+0bG7S1urpaSUlJVoYGAACANma2bwgAAGAnS4tkXbp0kSSVlJQELC8pKVFmZmaD9llZWQ3a1tTUqLS0VBkZGVaGBgAAgDZmtm8IAABgJ0uLZD179lRycrJ27tzpX1ZWVqZ9+/YpLy+vQfu8vDwVFRXpyJEj/mW7du2SJA0YMMDK0AAAANDGzPYNAQAA7GTpmGRxcXEaP368CgsL1bFjR331q1/VsmXLlJWVpeHDh8vj8ej06dNKSUlRQkKC+vTpo/79+2v69OlasGCBKisrdccdd2jUqFFcXQQAAGjngvUNAQAAIomls1tKksfj0fLly/Xss8+qqqpKeXl5uuOOO5Sdna1jx47p8ssv1913360xY8ZIkk6dOqWFCxfqn//8p+Lj4zVixAjNmTNH8fGhDeoGAACAyNVc3xAAACCSWF4kAwAAAAAAANob5lEHAAAAAACA41EkAwAAAAAAgONRJAMAAAAAAIDjUSQDAAAAAACA41EkAwAAAAAAgONRJAMAAAAAAIDjUST7Eq/Xq/vvv19Dhw5V3759NWXKFB09erTJ9mfOnNFtt92mvLw8DRo0SAsXLtS5c+faMOLoYjb/7733nq677joNHjxY+fn5mjZtmj7++OM2jDi6mM3/F23btk09evTQsWPHwhxl9DKb/9raWv32t7/1tx8/frz279/fhhFHF7P5P3XqlG677TYNGTJEgwcP1vTp01VcXNyGEUe3NWvW6Oqrr262Dd/BMIt+nr3o59mLfp696OfZi35eZInkfh5Fsi9ZtWqVNm/erDvvvFNPPvmkvF6vJk+erJqamkbbT5s2TUeOHNH69et133336e9//7sWLFjQtkFHETP5P3PmjCZOnKiEhARt2LBBDz/8sE6fPq3JkyerurrahujbP7Of/3rHjx/XokWL2ijK6GU2/wsWLNCzzz6rJUuWaMuWLerYsaOmTJmi8vLyNo48OpjN/y233KKPP/5Yjz32mB577DF9/PHH+uUvf9nGUUenTZs2aeXKlUHb8R0Ms+jn2Yt+nr3o59mLfp696OdFjojv5/ngV11d7evXr59v06ZN/mVnz5719e7d2/fCCy80aP/mm2/6cnNzfe+//75/2T//+U9fjx49fEVFRW0SczQxm/+nn37a169fP9+5c+f8yz7++GNfbm6u79///nebxBxNzOa/nsfj8f385z/3TZgwwZebm+s7evRoW4Qbdczm/6OPPvL16NHD99e//jWg/be+9S0+/y1gNv9nz5715ebm+l577TX/sldffdWXm5vrO3PmTFuEHJWKiop8U6dO9fXt29c3YsQI3/jx45tsy3cwzKKfZy/6efain2cv+nn2op8XGdpLP487yb7gwIED+vTTT5Wfn+9flpqaql69emn37t0N2u/Zs0edO3dWTk6Of9mgQYPkcrm0d+/eNok5mpjNf35+vlatWqWEhAT/MsP47CNdVlYW/oCjjNn811u9erVqa2s1derUtggzapnN/+uvv66UlBQNGzYsoP1f/vKXgG0gNGbzn5CQoA4dOmjr1q2qqKhQRUWFnn/+eXXv3l2pqaltGXpUeffddxUbG6tt27apT58+zbblOxhm0c+zF/08e9HPsxf9PHvRz4sM7aWfFxPWrbczRUVFkqQuXboELM/IyPCv+6Li4uIGbePi4pSWlqYTJ06EL9AoZTb/2dnZys7ODli2du1aJSQkKC8vL3yBRimz+Zekt99+W48++qj+8Ic/8Ix+K5nN/+HDh/W1r31N27dv19q1a1VcXKxevXrp17/+dcCXCUJjNv9xcXFaunSp7rjjDg0cOFAul0sZGRnauHGj/484mFdQUKCCgoKQ2vIdDLPo59mLfp696OfZi36evejnRYb20s/jHf6C+kHg4uLiApbHx8c3OvbBuXPnGrRtrj2aZzb/X7ZhwwZt3LhRM2bMUMeOHcMSYzQzm//KykrNmDFDM2bMULdu3doixKhmNv8VFRU6cuSIVq1apVtvvVUPPfSQYmJidNVVV+nUqVNtEnM0MZt/n8+n/fv3q1+/ftq0aZMef/xxfeUrX9GNN96oioqKNonZ6fgOhln08+xFP89e9PPsRT/PXvTz2h87v4Mpkn1B/e3cXx68r7q6WomJiY22b2ygv+rqaiUlJYUnyChmNv/1fD6fVq5cqbvuuks33HBD0Fky0Diz+b/rrrvUvXt3/exnP2uT+KKd2fzHxMSooqJCK1as0KWXXqrevXtrxYoVkqTnnnsu/AFHGbP5f/nll7Vx40YtW7ZMAwYM0KBBg7R69WodP35cf/jDH9okZqfjOxhm0c+zF/08e9HPsxf9PHvRz2t/7PwOpkj2BfW385WUlAQsLykpUWZmZoP2WVlZDdrW1NSotLRUGRkZ4Qs0SpnNv/TZ1MgzZ87U6tWrNWfOHN1yyy3hDjNqmc3/li1b9O9//1v9+vVTv379NGXKFEnSlVdeqdWrV4c/4CjTkvNPTExMwC33CQkJ+trXvsb07C1gNv979uxR9+7dlZyc7F923nnnqXv37jpy5Eh4g4UkvoNhHv08e9HPsxf9PHvRz7MX/bz2x87vYIpkX9CzZ08lJydr586d/mVlZWXat29fo2Mf5OXlqaioKOAXZdeuXZKkAQMGhD/gKGM2/5I0a9Ys/elPf9Jvf/tbXXvttW0UaXQym//t27frj3/8o7Zu3aqtW7fqrrvukvTZeCFcdTSvJeefuro6vfPOO/5lVVVVOnr0qC644II2iTmamM1/VlaWjhw5EnC7d2VlpY4dO8ZjKW2E72CYRT/PXvTz7EU/z1708+xFP6/9sfM7mIH7vyAuLk7jx49XYWGhOnbsqK9+9atatmyZsrKyNHz4cHk8Hp0+fVopKSlKSEhQnz591L9/f02fPl0LFixQZWWl7rjjDo0aNarJK2Jomtn8P/vss3rppZc0a9YsDRo0SCdPnvRvq74NQmc2/1/+gq4f9PIrX/mK0tLSbDiC9s1s/gcOHKj/9//+n2bPnq1FixYpLS1N999/v9xut374wx/afTjtjtn8jxo1So888ohuueUW/epXv5IkrVy5UvHx8RozZozNRxOd+A5Ga9HPsxf9PHvRz7MX/Tx70c+LfBH1HexDgLq6Ot+9997rGzJkiK9v376+KVOm+I4ePerz+Xy+o0eP+nJzc31btmzxt//kk098N998s69v376+wYMH++bPn++rqqqyK/x2z0z+J06c6MvNzW303xffI4TO7Of/i3bs2OHLzc31t4d5ZvNfXl7umz9/vm/w4MG+Pn36+CZOnOh777337Aq/3TOb//fff983depU36BBg3xDhgzx3XTTTXz+LTR79mzf+PHj/T/zHQwr0M+zF/08e9HPsxf9PHvRz4sskdzPc/l8Pl94y3AAAAAAAABAZGNMMgAAAAAAADgeRTIAAAAAAAA4HkUyAAAAAAAAOB5FMgAAAAAAADgeRTIAAAAAAAA4HkUyAAAAAAAAOB5FMgAAAAAAADgeRTIAAAAAAAA4HkUyAAAAAAAAOB5FMgAAAAAAADgeRTIAAAAAAAA4HkUyAAAAAAAAON7/BwgBqXmUnwdlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_val  = model.predict(X_ts_final_sc)\n",
    "y_pred_test = model.predict(X_test_sc)\n",
    "\n",
    "y_pred = (y_pred_val>.5).astype(int) \n",
    "print()\n",
    "#print(classification_report(y_ts_final, y_pred))\n",
    "#print(confusion_matrix(y_ts_final, y_pred))    \n",
    "\n",
    "print()\n",
    "\n",
    "# https://www.kaggle.com/code/mehrankazeminia/tps22aug-logisticr-lgbm-keras\n",
    "f1    = f1_score(y_ts_final, y_pred)\n",
    "auc   = roc_auc_score(y_ts_final, y_pred) \n",
    "lloss = log_loss(y_ts_final, y_pred_val)\n",
    "\n",
    "print('AUC: {:2.5f} - F1-score: {:2.5f} L.Loss: {:2.5f}'.format(auc, f1, lloss))\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_pred_val, bins=50)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_pred_test, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['pred'] = y_pred_test\n",
    "df_submission.to_csv(path+path_data+'/submission/kara_20_score_{:2.5f}.csv'.format(lloss), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d43fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "eb908a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T12:07:59.558981Z",
     "start_time": "2022-11-26T12:07:56.322969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAO/CAYAAACweN6UAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdf5AbZ30/8LccO0BMq6sTzj/SmEw6YwiBuTYk4UyA1BdTD4ZVBnrns5wYt3Axe53AJPGVplepxonH33ZGRzKFkkM6wrgCS7o4AaQWMx3fFZup7zAEpPCj3LW41SVxIxFAS6eUxCTP9w/zrFfSSlpJK+1Ker9mbhKvHu1+9tlndz/77LMrjxBCgIiIiHraKqcDICIiIucxISAiIiImBERERMSEgIiIiACsdjoAIitGRkacDoGIyBaPP/640yGYYg8BdYTjx4/j2WefdToMKvHss8/i+PHjTofhemy/BLh/f/HwsUPqBB6PB4lEArt27XI6FDKYnZ3F6OgoeBipju2XAPfvL+whICIiIiYERERExISAiIiIwISAiIiIwISAiIiIwISASBcMBhEMBp0Ooyex7ot5PJ6iPzP5fB5TU1Ntjqw3TE1NQdM008+sbJtOxYSAyCU0TWvoAKNpGhYXFxGJRODz+VoQWfdrtO5bTQhh+ohaPp/HwYMHsXbtWv3EVCmhKj2BuXE9AWvt2GpbT6VS8Pl88Pl8SKVSdZfZvn079u7di3w+X/a9StukG/BNhUS/8dBDDzm6/NOnTzf0vVAoBAA4fPiwneG0VafWvRM0TcPY2BgmJycxODgIv9+PEydOwO/3AyivSyEE8vk81q9fj1wuh/7+fifCrslKO7ZSJh6P49ixY4hGowCABx54AM8//zzuvvtuy2UGBgYwOTmJsbExRKNReL3e5lauUwiiDgBAJBIJp8NomUKhIBRFEc3skgCa+n4jEolE25dpNzvqvpZ622+1bRkKhUQgEKj4nVgsVnGencBKO65UJpvNCgBiYWFBn5ZOpwUAkU6nLZeRVFUVoVCo4ThLuX1/4S0DIlzsgo3H40XdkKXTUqkUPB4PfD4fVlZW9DKy6xEAIpEIPB4PxsfHsby8DACmXbWl00KhkN5t6eZu3VZwa927cVxDPp/HxMQEtm3bZvp5KBSC3+9HPB63ND9N0xCPx/X1jkQieje5lW1gjGtqakr/fH5+vom1bNyZM2cAAJs2bdKnbdy4EQBw9uxZy2WkkZERTExMmN466EpOZyREVqDFPQTyCtG4SxinyasJeXWhqqoeV2mZQqEgVFUVAMTS0pLI5XJl85bzMU4r/Xe9mv1+I+y44nFr3QcCAdMr8UbU234rbctkMikAiGw2a/odIS7GDZOrXbP5KYoiwuGwEEKIXC4nFEURiqIU9ZpU2wbG78meibm5OdPlN7vuVsrIbW9WXlEUy2Ukub7JZLKhOEu5vYfAvZERGbQ6IZDLKN1ZrUwzKyO7IGV3Y6PzaTb+VrPrANfpdV+LXQmBPNlX+o4QxbdAlpaWyj6X5Ik7l8vp0xYWFopuO1ipu1gsZlqm0WSqmYTAyvR6vlsoFIraUr1xlnJ7QsBbBkQtMDAwAACYmJhwOJLe0811b2XgqNfrxczMDABU7e6WP8FrHGR4/fXXAwCOHTtmOSZZtvRWTCcPcpXkYMJubEtmmBAQEXWZ/v5+pNNppFIpjI2NmT5TPz09XTZNngArPapnRpYVv3kcz/jXboqiVPxMVVXLZXoVEwKiFur1A4yTer3uBwYGkEwmkUql9Mf1jOSJ0awHoZG6kwM5nWS2TnIA5I033mi5TK9iQkDUAvLguHPnTocj6T3dXPfyxF7pLXqlFEVBLBYz7b7fs2cPAODcuXP6NDnfkZERyzGFw2EAQDQa1b/v1FsUd+zYAaB4nc6fP1/0mZUypQKBgP3BuhATAiIUXy0YH7uS5IHOeCAuvbKSj3ppmoZoNApFUfSrEXnFJU9Wi4uL+vfGx8cBFF+51HswNcZl9WThFm6tezc+drhlyxYA5dvYrN6k3bt3m57Q3vOe90BRFBw5ckT/3okTJ6CqKoaGhixvgzvuuAPAxTEDfX198Hg8WL9+vZ5UyMcRM5lMzfWz0o6rldm8eTPC4TCOHj0KTdOgaRqOHj2KcDiMzZs3Wy4jyZ6DW265pWbsXcHRIY1EFqHFTxnA8AgbSkYjW52WTqf10d3hcFgUCgV9/tlsVv9MPsIkH9WSo7zl6PhAIFA08rve2NHA6OdG2TFq2q1178bHDuVjlMaX6ljd9qWP1Mn5hcNh/XuxWEyvO6vbQIiLdSyfgFBVteixyEAgIFRVNV2+2TpXWxerbV0+nqkoipibmzNdnpUy8qkLs/2xkf3M7U8ZeITo0pcyU1fxeDxIJBLYtWuX06GUkaOqe3FXmp2dxejoqGPr3il1X2/7rbZesgfjwIED9gXYBj6fD8lk0ukw6hIMBtHX12da1420Paf3l1p4y4CIqIOMjY3h1KlTRbc+3G5xcRGTk5NOh1GXTCaDTCaDsbExp0NpGyYERE0wu/9N7dGrdS/fM3DkyBFL9+WdNj8/j3Xr1mFwcNDpUCxbXl7G9PQ0ZmZmeueHjcCEgKgp69evN/1/O5j9bG2n/JRtO7Sy7t2i0jbu7+9HNBrFyZMnHYiqPkNDQ/pgyE6RSqVw6NAh01+G7Ob9jj9/TNSEVt4LdOt9Rrfo5vqxsm5er7fjxhF0imr12s3tjj0ERERExISAiIiImBAQERERmBAQERERmBAQERERAL6pkDpCtz7mQ0S9x62nXT52SB3j3nvvxdatW50OgwwWFhbwyCOPIJFIOB2Kq42OjrL9kr6/uBUTAuoYW7dudeVvGfS6Rx55hNulhtHRUbZfAgBXJwQcQ0BERERMCIiIiIgJAREREYEJAREREYEJAREREYEJARGR61j5iet8Po+pqak2R9YbpqamoGma6Wfd/PPjTAio65TusE7tuJqmFS3XLXF1i9L67ZR510MIYfoSm3w+j4MHD2Lt2rV6OwoGg6bz6JQ2p2kaFhcXEYlE4PP5Gi4DAKlUCj6fDz6fD6lUqu4y27dvx969e5HP58u+V2mbdAO+h4C6jhACmqahr68PAFAoFOD1etsex+nTp8viyufzWL9+vaNxdYvS+u2UeTdL0zSMjY1hcnISg4OD8Pv9OHHiBPx+PwDgoYceKipvbHe5XA79/f1OhF1TKBQCABw+fLipMvF4HMeOHUM0GgUAPPDAA3j++edx9913Wy4zMDCAyclJjI2NIRqN9s5+Kog6AACRSCTq/o5TTbxQKAhFUUyX72RcdkskEo6sS7X6deO8622/1dpIKBQSgUCg4ndisVjFeXYCK/tHpTLZbFYAEAsLC/q0dDotAIh0Om25jKSqqgiFQg3HWcqp/cUq3jKgnpHP5xGPx/WuxlQqBY/HA5/Ph5WVFb2M7EoEgEgkAo/Hg/HxcSwvLwOAaddr6bRQKKR3QzbaTatpmr582SUs7xsbl2e8j2z8zLhOcrrP58P8/HzZumqahvHx8YrdznbTNA3xeFyPNRKJ6N2zjdZvq7ddMBhsW/1Uks/nMTExgW3btpl+HgqF4Pf7EY/HLc2v2nawsr8Y4zJrY+125swZAMCmTZv0aRs3bgQAnD171nIZaWRkBBMTE6a3DrqS0xkJkRWwoYdAXvXBcHUgrxZUVS36jrFMoVAQqqoKAGJpaUnkcrmyecv5GKeV/rvW9FJymblcrizOhYWFon8bKYoicrmcEEKIXC4nFEXRrxrn5ub0K6HS+kin06bzq6bRKx5FUUQ4HC6KUVEUUSgUGq7fVm+7QCBgemVuRb3tt1IbSSaTAoDIZrOm35Fxym1s9rlRte1gZX8xfs+sjTXCyv5RqYzc1mblFUWxXEaS65tMJhuKs5TbewjcGxmRgR0JgdVpZmVkl6LsPmx0PtWmlwoEAkUH3tLvhUKhspNDOp0u6jKOxWKmccoTm5xnoVCoGY+ZRg5w8oQhkxYhLiU4MvZG67fV265RdiUE8mRf6TtCFN/yWFpaKvtcsms71Gpj9WomIbAyvZ7vFgqForZTb5ylmBAQ2cDphKB0ejsSAimbzeonf+P35IlOXuEJcTFJMCYIxqu80r9GYinVyAHO7ApNHnjlFZqdCUHp9E5OCKrFZZwue0KMvUWl37NrO9RqY/VyU0LQyPRq3J4QcAwBkYtFIhHcc889UBSl7LOBgQGoqor9+/dD0zRomob/+I//wObNm/Uy8l64+M2jUsY/p0xPT5dNk6O4Kz0iRvXp7+9HOp1GKpXC2NiY6TP1dm0HN7Uxs/1EUlXVcplexYSAqA7tOGCMj48DuPho1P79+/HpT38aW7ZsqRrPiRMncPr0aezbt8+0nBxU5wbygGw2UKuV9dtrB/uBgQEkk0mkUin9cT0ju7eDG9qY2TrJAZA33nij5TK9igkBkQXyYLdz586WLmdxcRG33XYbAOjPlRuv+EvJXgK/349IJILBwcGiz8PhMAAgGo3qV4lOv+Fuz549AIBz587p02RsIyMjti+vXduuHeSJvdJb9EopioJYLGb63L5d28FNbWzHjh0Aitfp/PnzRZ9ZKVMqEAjYH6wbOXWvgqgeqPMerLwXClwaMGccYS6nGcsZ77XCMLCqUCiIQCBQNALZOHJdiEuDsYBLI7DlvdVcLqcPSjIb5S7JecjR2fL72WxWLC0tlcVZ+j3jWALJuDzjXzabrRqLVY3cE5WD3oz3t2OxWNEAykbrt5Xbzs1PGchtWdo2JLPBiLW2g9X9pVobE+LS4FcrTx2Y7bf1lgmHw0JVVVEoFPSnTEr3DStlhOBTBkSuVM8B1ezgZPZnVtY4zfhoXjgcLjr4ZLNZ/TN5sJCPXskDpRz0FwgEKh40zf7kckq/L586MHvkTFGUohHlRtlsVj8hGL9vXGbp41ZWNXqAy+VyIhwOF53Am61f4zrZve2EcEdCINuR8aU6ldp2KbNtXG07WN1fhKjcxoS49LRMrTZWbT+tp4wQlxInRVHE3Nyc6fKslJHJolmi1Y0JgUcIB0cXEVnk8XiQSCSwa9eutiwLgKMD7+qhaRoeeOABPProo21f9uzsLEZHR11TV27ddvW232rrIbviDxw4YF+AbeDz+ZBMJp0Ooy7BYBB9fX2mdd1IW3Pb/lKKYwiIOtzs7GxL7r2TO42NjeHUqVNYXFx0OhTLFhcXMTk56XQYdclkMshkMhgbG3M6lLZhQkBkYBx57ObXlQaDwaJXFA8NDTkdkuM6Zds1y+v1YmZmBkeOHEEmk3E6nJrm5+exbt26sgGvbra8vIzp6WnMzMz0zg8bgQkBURH5S4Sl/+828smDcDhc9ut2vapTtl09Kv0ORn9/P6LRKE6ePOlAVPUZGhqq+NisW6VSKRw6dMj0lyHd/BPSzeLPHxMZuPXeXqm777676OdcqXO2nRVW1sXr9XbcOIJOUa1eu6mdlWIPARERETEhICIiIiYEREREBCYEREREBA4qpA6ysLDgdAhUQm6T2dlZhyNxP7Zfcnsb4JsKqSN062M+RNR73HraZQ8BdQS37kDUPeRrhdnbQb2KYwiIiIiICQERERExISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAiIiIAq50OgIio3U6fPo2FhYWiaT/60Y8AAH/7t39bNH3r1q1417ve1bbYiJziEUIIp4MgImqnubk5bN++HWvWrMGqVeYdpa+88gouXLiAkydP4vbbb29zhETtx4SAiHrOK6+8gg0bNuAnP/lJ1XJXXXUVnn/+eVx22WVtiozIORxDQEQ9Z9WqVbjzzjtx+eWXVyxz+eWX46677mIyQD2DCQER9SS/34+XXnqp4ucvvfQS/H5/GyMichZvGRBRz7r22muRzWZNP7vmmmuQzWbh8XjaHBWRM9hDQEQ9a+/evVizZk3Z9DVr1uBP/uRPmAxQT2EPARH1rB/96Ee4/vrrTT/7/ve/jxtuuKHNERE5hz0ERNSz3vjGN+KGG24o6wl405vexGSAeg4TAiLqaR/84AeLniRYs2YN9u3b52BERM7gLQMi6mnPPPMMXv/610MeCj0eD86dO4drr73W2cCI2ow9BETU06655hq87W1vw6pVq7Bq1Sq87W1vYzJAPYkJARH1vL1798Lj8WDVqlXYu3ev0+EQOYK3DIio573wwgvYsGEDAOD8+fPo7+93OCKi9mNCQF2Jz48TUbt0y2mUP39MXevee+/F1q1bnQ6jqy0sLOCRRx5BIpFwOpSmnT59Gh6PB+985zttn/fo6CjbYxeS7b9bsIeAupLH40EikcCuXbucDqWrzc7OYnR0tCuukP7nf/4HAPBbv/Vbts+b7bE7dVP7B9hDQEQEoDWJAFEn4VMGRERExISAiIiImBAQERERmBAQERERmBAQVZTP5xGPx+Hz+ZwOpesFg0EEg0Gnw3ClfD6Pqakpp8PoSlNTU9A0zekwXIMJAVEFBw8ehN/vRyqVcjoUyzRNw+LiIiKRSMVExkqZXqNpmitfZpXP53Hw4EGsXbsWHo8HHo+nYuIkPzf+uZGdbTSVSsHn88Hn81XcT6uV2b59O/bu3Yt8Pt/4CnUTQdSFAIhEImHLfDppNwkEAiIQCFSN20oZqxKJREfVTyXJZLKl69FIeywUCkJRFLGwsKD/OxaLCQAiEAiYfieXywkAIpfLNR1zq9jVRmOxmFAURRQKBVEoFISqqiIcDtddZmFhQS9Tr25p/1L3rAmRQa8mBJKVuJkQXCRPvG5LCEKhkOmJX263WCxWcVmdoJk2ms1mBQA9WRJCiHQ6LQCIdDptuYykqqoIhUJ1r0M3tH8j3jIg+g1N0xCPx+HxeODz+bC8vFxWRt7PlWXm5+f16cbxBqlUSi+zsrJSNA/5/Ugkgnw+X9S1W2n+3cxsrIaV+szn83p3MABEIhF4PB6Mj4/r286s+7x0WigU0ruSjdOdHNeQz+cxMTGBbdu2mX4eCoXg9/sRj8ctzc/Yto1tTy7Latt1S/s8c+YMAGDTpk36tI0bNwIAzp49a7mMNDIygomJCd46cDojIWoFNHBFpiiKUFVV7zqU3bNyN8nlckJRFP3KbG5uTr/akFeYMFyRyCsUVVX1ZYRCIZHNZoUQF69MZbdorfk3sv61dm8rZWqx4wrJWHdm0yrVp/zcWEZ2CwMQS0tLehe6cd5yPsZpZnUhu63tUG97lLcwZFspnZeMz6x9mG0PRVH0rnLZzmQ3udW2a2f7lHE22kblNjYrryiK5TKSXN9kMlnPKnRdD0H3rAmRQaMH4KWlJX1aoVAoOiDJBKF0OfKkYXbwMjvxGO/vyhOWlfnXo5MSgkqxWK3P0jKyW1h2ATc6HzvV2x6NiaLZvIQovtVhbLel35MnbmO7W1hYKLrtYKWO7GyflZZptYyV6fV8V+7r9d42YEJA1AHqPQBXu5qQ041XUqV/pWXNvm9cTiwWKxvEVGv+9ejlhKB0eicmBNXiMU6XCaWiKPoJv/R7Zm1bngDllbKVOrKzfdZax1pl7E4IrMZTqtsSAo4hIAIwPT1ds4y8zywuJtJFf1bdd999UBQFfr8ffX19Rc+X2zF/6i39/f1Ip9NIpVIYGxszfaberG17vV4AqOuRWje1T0VRKn6mqqrlMlSMCQFRncwGG1q1ZcsWJJNJpNNpqKqKiYmJspfONDN/uqRXDvoDAwNIJpNIpVIIhUJln8sTo9mAuUbqyA3t02yd5ADIG2+80XIZKsaEgAhAOBwGAGQymZplotGofiVW71vkPB4PNE3DwMAAHn30UaTTaUxMTNg2f7p0wtq5c6fDkTROntitvkVPURTEYjEcPny47LM9e/YAAM6dO6dPk/MdGRmxHJOb2ueOHTsAFK/T+fPniz6zUqZUIBCwP9hO4sBtCqKWQ533bOUoY0VR9JHdcjAWcHG0tXHEuvEvm80WfSbHBhgHJRrv7wYCAX0Z2WxWH8hUbf71MC630stWrJSxwo57qMb1lvVUT30ClwbHySc3jKPIjU8dCHFpQJ3crkJcuj+ey+X07eHGpwxqvXjIbDCiHHxoHGcQi8X0dbda17XaZygUEoC1pw7saKPhcFh/KqjSS4eslBGCTxlI3bMmRAb1HoCFuHhQkCcPmQDIx6zkQTGbzeoHXVVV9YNh6UGy2jR50gHKRzVXmn896232V28Zq+w4INZTd5WmGR/9DIfDRSeQbDarfyYP+KXbVT6ZEAgE9GlOJgTy5Gt8qY7VbVb6SJ2cXzgcLkqgZB1ZrWshqrfPQCAgVFU1XX5pXdjVRmXipCiKmJubM12elTIySaz3DY/dlhB4hOCIJeo+Ho8HiUQCu3btcjqUrjY7O4vR0VHHBj7Klwi5/TDWSHuUXfEHDhxoVVgt4fP5kEwmnQ6jLsFgEH19fXXXtdPt324cQ0BE5EJjY2M4deoUFhcXnQ7FssXFRUxOTjodRl0ymQwymQzGxsacDsVxTAiIqCMZR4934ytnvV4vZmZmcOTIkaqDXd1ifn4e69atw+DgoNOhWLa8vIzp6WnMzMzoj2L2MiYERB3A7KdtO+Xnbltl/fr1pv/fTfr7+xGNRnHy5EmnQ6lpaGgIW7ZscTqMuqRSKRw6dAj9/f1Oh+IKq50OgIhq65Z7lHbqlTrxer0dN46gU7Bei7GHgIiIiJgQEBERERMCIiIiAhMCIiIiAgcVUhdbWFhwOoSuJ+t4dnbW4Ujcj+2x+3TbNuWbCqkr9dojeETknG45jfKWAXWtRCJh+tvt/LPvL5FIAIDjcbj9j+2xO/9k++8WTAiIiIiICQERERExISAiIiIwISAiIiIwISAiIiIwISAiIiIwISAi6ij5fB5TU1NOh9FxpqamoGma02G4GhMCojp5PJ6Kf1NTU0ilUjzwtIGmaS17AVUr592MfD6PgwcPYu3atXqbCwaDpmXN2qdbZTKZojjHx8cbKpNKpeDz+eDz+ZBKpYo+2759O/bu3Yt8Pt+y9eh0TAiI6iSEQC6X0/9dKBT0F5Vs374dkUiEB542OH36dEfOu1GapmFsbAz79u2DqqooFAqIxWI4fPiwaVJgbKe5XE5/QZIbnT17tujfO3furLtMPB5HJBJBNBpFNBrFV7/6VUQiEf3zgYEBTE5OYmxsjAl7BUwIiBrQ39+v/7/X69X/f2BgADMzMwDAA08LaZpWdLDvlHk3Y2ZmBgMDAxgcHARwsd3t3r0bAHD48GHE4/Gy78h2amyvbrRhw4aiNwAqilJXmZWVFfj9fkxOTsLr9cLr9UJVVezfvx+ZTEYvNzg4iKuvvlrfR6kYEwIim/X39+Pee+9FKpUqu9KU9389Hg98Ph/m5+f16fF4HD6fD8DFrk9ZZmVlpWge8vuRSAT5fL6oK7jS/N1G0zTE43G9+1euCwDTLu7SaaFQSO8SltPz+bzeZQwAkUhE71peXl5uat4AEAwGK3bPt1o+n8fExAS2bdtm+nkoFILf7zdNCsxUq/962qId7W1lZQU+nw/BYBCLi4sNlTlz5gwAYNOmTfq0jRs3AijvWRgZGcHExAR78MwIoi4EQCQSiZYvo9IuVCgUBAChqqo+LZfLCUVRRCwWE0IIMTc3JwCIdDotFEXR57ewsCCEECKbzZbNIxQKiWw2qy8jEAjoMVSbf6skEomKdVCNoigiHA4LIS7FrSiKKBQKIpfLldWtrAvjtEr/NtZhoVAQqqoKAGJpaanheQshRCAQEIFAoO51lfNrpj0mk0kBQN/2pfOW8Zltb7PtU63+rbZFu9qbXDf5pyiKyOVydZWR29isbhRFKZom1yWZTNYVp5lG279bdc+aEBk4nRCYfR6LxcrKA9BPMmbzMztRGQ+E8gRnZf6t0MgBUZ44jOuxsLAgAOgnF6t1UauMEEKk02kBQIRCoabm3Yxm26Mx8TObtxCi6GS+tLRU9rlkV/3b2d4KhYJIp9P6espkxWqZStvLbLpM1mV7aAYTAqIO4MaEwHjlVfpXaX6l0+SVUCwWE4VCoahsrfm3QiMHRLOrOXmQlldzdiYEpdM7MSGoFo9xukwQjVfQpd+zq/5b1d7C4XDZVX2tMvUkBNWm14sJAVEHcDohkAdY49VSvQmE2bSlpaWiA7HxKqfVJ38zjRwQW3nS7vWEQIhLPSLyFkCn1JFkFnOtMnKfKAUU3+YwTmdCUI6DCola4KmnngIA00FgcoBbI7Zs2YJkMol0Og1VVTExMVH2kppm5t8OcnS42aAuVVVbttxWzttNBgYGkEwmkUqlEAqFyj63u/7tbm/yCYF6ypitkxwAeeONN9oaXzdjQkBks3w+j0ceeQSKomBoaEifHg6HAQDRaFR/HLHet855PB5omoaBgQE8+uijSKfTmJiYsG3+7bBnzx4AwLlz5/RpMt6RkRHblydPWGbPtncKeWK3+hiroij6OwpK2VX/rWpvmqbVjKO0zI4dOwAUr9P58+eLPisVCASairMrOd1FQdQKaPEtA9llCaDoXr58YsBspLRxhLvxL5vNFn0m52dchvF+cCAQ0EebZ7NZ/bZBtfm3SiNdpnLwm7GOYrFYUdeu8ckAIS4NeoOhC1h2E+dyubIBg3JwnHwSw3i/udF5u/EpA7nNS9uaZDYYsVb9W22LtdpbKBQSQPWnDmKxmJibm9P/nc1my0b/WykjxMVxBaqqikKhoD9dYjY4kU8ZVNY9a0Jk0MqEwOwgKP9CoZD+qJaZbDarH6RVVdUPnqXzqTZNnqTk8qzMv1UaPSDmcjkRDoeLTuDGxCqbzeonZXnglo+4yROSvFceCASKEiZ5EpLfD4fDtszbyYRAnnyNbcus/ZkxG6BXrf6ttkUhqre3QCAgVFWtOkDQ+DhhIBAwTR6slCktqyhKURJhJBPASklUPbotIfAI4eL3WTMO7HMAACAASURBVBI1yOPxIJFIYNeuXU6H0tVmZ2cxOjrqmtfiypcIuSUeyY72KLviDxw4YFdYbeHz+ZBMJp0OQxcMBtHX12dLPbqt/TeLYwiIiDrA2NgYTp06VfFtfm60uLiIyclJp8PQZTIZZDIZjI2NOR2KKzEhIKKuYBxh3o2vpfV6vZiZmcGRI0eK3s/vVvPz81i3bp3+2wtOW15exvT0NGZmZop+f4QuYUJARF1h/fr1pv/fTfr7+xGNRnHy5EmnQ6lpaGgIW7ZscToMXSqVwqFDh1z/Q09OWu10AEREduiW+7i1eL3ejhtH4Aass9rYQ0BERERMCIiIiIgJAREREYEJAREREQHgi4moK3k8HgwODuJ3f/d3nQ6lqz377LNYXFzE8PCw06G42vHjx9keu5Bs/91yGmVCQF2pFT+SQ93te9/7HgDgLW95i8ORUKd5/PHHnQ7BFkwIiIgA/bXCs7OzDkdC5AyOISAiIiImBERERMSEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiMCEgIiIiAB4hBDC6SCIiNrpH/7hH/DJT34SL7/8sj7thRdeAABcddVV+rTLLrsM999/Pz74wQ+2PUaidmNCQEQ9Z3l5GW94wxsslV1aWsKWLVtaHBGR83jLgIh6zpYtWzAwMACPx1OxjMfjwcDAAJMB6hlMCIioJ33wgx/EZZddVvHz1atXY9++fW2MiMhZvGVARD3p/PnzuOaaa/DKK6+Yfu7xePDMM8/g6quvbnNkRM5gDwER9aRNmzbh7W9/O1atKj8Mrlq1CrfeeiuTAeopTAiIqGft3bvXdLrH4+GTBdRzeMuAiHrWz3/+c6xfvx4XLlwomr569Wo8//zzuPLKKx2KjKj92ENARD3rd37nd/Dud7+7aHDhZZddhh07djAZoJ7DhICIetpdd91VNLBQCIG77rrLwYiInMFbBkTU0375y1/iyiuvxK9+9SsAwKtf/Wq88MILWLt2rcOREbUXewiIqKddccUVeP/73481a9ZgzZo1eP/7389kgHoSEwIi6nl79uzBhQsXcOHCBezZs8fpcIgcsdrpAIhaZWFhAc8884zTYVAHePnll3HFFVdACIFf/OIXmJ2ddTok6gDXXHMNtm7d6nQYtuEYAupaIyMjOH78uNNhEFGXGh4exuOPP+50GLZhDwF1tW7bYTvJyMgIAHRM/Z86dQoejwfvete72rbM2dlZjI6OgtdlnUe2727ChICICMA73/lOp0MgchQTAiIiwPQ3DYh6CfcAIiIiYkJARERETAiIiIgITAiIiIgITAiIasrn84jH4/D5fE6H0nOCwSCCwaDTYbhWPp/H1NSU02F0nKmpKWia5nQYrsOEgKiGgwcPwu/3I5VKOR1KXTRNg8fjqft7+XwekUgEHo8HHo8H8Xi8BdF1hkbrsB3y+TwOHjyItWvX6tuqUvIkPzf+uVUmkymKc3x8vKEyqVQKPp8PPp+vbN/dvn079u7di3w+37L16ERMCIhqePTRR50OoSGnT5+u+zuapmFsbAzAxZ8BzuVyOHbsmGNX6Q899BAeeughR5YNNFaH7SC30759+6CqKgqFAmKxGA4fPmy6reS2BIBcLufqFyGdPXu26N87d+6su0w8HkckEkE0GkU0GsVXv/pVRCIR/fOBgQFMTk5ibGyMPQUGTAiIupCmaUUHQKtOnDiBVCqFXbt2AQD6+/vx0EMP4fDhw5ifn7c7TFdrtA7bYWZmBgMDAxgcHAQAeL1e7N69GwBw+PBh016d/v7+ov+61YYNGyCE0P8URamrzMrKCvx+PyYnJ+H1euH1eqGqKvbv349MJqOXGxwcxNVXX42ZmZm2rFcnYEJAVELTNMTjcXg8Hvh8PiwvL+uf5fN5vStS0zSMj48XXZEZv+vxeBCJRPRuSeN3Aejd8uPj40XLqDUfs27f0mmhUEjvJq2ni/jYsWMALp5gpGuvvRZA+19BbDZ2o3RaKpXSt9PKyopeplY9N1OHTo9ryOfzmJiYwLZt20w/D4VC8Pv9lm/11GqzterbGNfU1JT+eSMJ5MrKCnw+H4LBIBYXFxsqc+bMGQDApk2b9GkbN24EUN6zMDIygomJCd46kARRlxoeHhbDw8N1f09RFKGqqigUCkIIIWKxmAAgAAhFUfT/X1hYEOl0WqiqWvTdcDgshBAil8sJRVGEoiiiUCjo35PfFUKIQqEgVFUVAMTS0pKl+eRyOX0+UjabLZtW+m8rKn2nkXk1Wv+Ssa7Npsk6lOsut4OVem6mDgOBgAgEAg2vl1Eikai7XpPJpAAgstls2WdyXoFAQAAQ6XTa9HOjam3NSn0bvxeLxYQQQszNzZku3+q6Gfe3XC5XVxm5nc3qRlGUomlyXZLJZF1xCtF8+3YjJgTUtRrZYeXBxnhyNp7Mhbh0kpAJgyQPgsaD08LCggCgHyjNTjDpdFoAEKFQqKn52JEQmCUnjc7LjgOmlfU0m2alnltVh/VoJCGQJ3szcrrxZG7clqXfs6utyaS5tEwjiVOhUBDpdFpfT5msWC1TT1Ir923ZJurBhICogzSyw1a7uihNCKx8Vx5w5JWJlYNVo/Ox42QmTwbGHpLSE6lVbksISqd3akJQLSbjdNkLYryCLv2eXW3N2JNQ+teMcDhcdlVfq0w9CUG16bV0Y0LAMQREBtPT07Z+V96Lr+eRRbvm04jBwUHMzc3hueeeQ19fHyKRCH76058CuPioFnWO/v5+pNNppFKpiqPp7WprsqwwDPSTf83YtWtXzThKy5gNQpRUVW0qnm7HhIDIJvJAZDZAycqBSJZpdj7NGhoaQjKZhBACd999N7773e8iEAhgYGCg5ctuh146KQwMDCCZTCKVSiEUCpV9bndbKx0c2yz5hEA9ZczWSQ6AvPHGG22Nr9swISAyCIfDAFD0eJJVe/bsAQCcO3dOnyavykZGRip+Tx5E5bPUjc6nFeLxOE6dOoWJiYm2LrcVSuu5U8kTu9Xn5xVF0d9RUMqutib3m2g0qn/fjrcoappWM47SMjt27ABQvE7nz58v+qxUIBBoKs5uwYSAyEAeMILBoH5VYXx86o//+I8rfvc973kPFEXBkSNH9KuTEydOQFVVDA0NFZWVj4RpmoZoNApFUfQrGyvzkVdE8iRnfPxKvrXNeKVUz4FZ0zRkMhmMj4/jueeeQzKZLHoMsV2MV3jGx+CMcRr/W/o5UL2eG61Dpx873LJlC4DyhMCsjqTdu3ebnvRqtTWr9X3HHXcAuPgOhL6+Png8Hqxfv14/UcvHEasl2vF4vGhfW1lZwenTp4v2HStlNm/ejHA4jKNHj0LTNGiahqNHjyIcDmPz5s1Fy5T7+C233FIxrp7i5AAGolZqdNBPNpvVB1upqlr0SBVKHncqlcvlRDgc1svEYrGipxHk9HQ6rQ/ECofDZU8s1JpPNpvVvy8fmZIxygFkcjBgIBAoe3SrErm8cDhc9yNjpZoddAWTwWn1TqtWz43WodOPHcrBgvIxQCHK66DSPOtts1brW4iL9SlH/auqWvRYZCAQEKqqVh0gaHycMBAImLY/K2VKyyqKIubm5kzLyEG0VvcPo24cVOgRwsXvsCRqgrw6afcLdaqRL7fphd3OyfrvlHqenZ3F6Oho3XHK3ooDBw60IqyW8fl8SCaTToehCwaD6Ovra6ge3Xh8aRZvGRARdZixsTGcOnWq4tv83GhxcRGTk5NOh6HLZDLIZDL6b3cQEwKitjG7J07264V69nq9mJmZwZEjRxoaANtu8/PzWLdunf7bC05bXl7G9PQ0ZmZmHBkf41ZMCIjaZP369ab/3y5mP4HbST+La5XT9dwu/f39iEajOHnypNOh1DQ0NKQPhnSDVCqFQ4cOuf6HntpttdMBEPUKp+9nO738dumV9QQu9hR02jgCN2CdmWMPARERETEhICIiIiYEREREBCYEREREBA4qpC63uLjY9vf/00XyGXnWf2XPPvssANZRJ1pcXHTNY5R2YQ8BERERsYeAutvg4GBXvVq0k3Tjq13tJl9dzDrqPN3Yq8MeAiIiImJCQEREREwIiIiICEwIiIiICEwIiIiICEwIiIg6Vj6fx9TUlNNhdJypqSlomuZ0GK7DhICohmo/FTw1NYVUKtXRBxdN07riZ4+NWrlObqmvfD6PgwcPYu3atXp7DAaDpmU76WeuM5lMUZzj4+MNlUmlUvD5fPD5fEilUkWfbd++HXv37kU+n2/ZenQiJgRENQghkMvl9H8XCgUIISCEwPbt2xGJRDr64HL69GmnQ7BdK9fJDfWlaRrGxsawb98+qKqKQqGAWCyGw4cPmyYFxjacy+Vc/RPRZ8+eLfr3zp076y4Tj8cRiUQQjUYRjUbx1a9+FZFIRP98YGAAk5OTGBsb6+hk3m5MCIgs6O/v1//f6/Xq/z8wMICZmRkA6MiDi6ZpRQfKbtDKdXJLfc3MzGBgYEB/da7X68Xu3bsBAIcPH0Y8Hi/7jmzDxrbsRhs2bNATbiEEFEWpq8zKygr8fj8mJyfh9Xrh9Xqhqir279+PTCajlxscHMTVV1+t77/EhICoaf39/bj33nuRSqX0q8d8Pq93WWqahvHx8aIrN03TEI/H9S7PSCSi9zAYvwsAkUhE7xZdXl4uWna1+Zh1D5dOC4VCeneqW7qSW7FOVuq0mfoKBoMVu+vtls/nMTExgW3btpl+HgqF4Pf7TZMCM7XaYjwe1+stlUrB4/HA5/NhZWWlLK6pqSn98/n5+brXbWVlBT6fD8FgUP8tjHrLnDlzBgCwadMmfdrGjRsBlPcsjIyMYGJiomN792wniLrU8PCwGB4etm1+AESlXaZQKAgAQlVVIYQQiqLo5RcWFkQ6ndY/k5+Hw2EhhBC5XE4oiiIURdHnY/yunL+qqgKAWFpasjSfXC5XFnM2my2bVm29mtFo/bdinazUaTP1FQgERCAQqHtdE4lE3XWfTCYFAJHNZss+k/MKBAICgEin06afG1Wr79J2LMSlOjG2Z/m9WCwmhBBibm7OdPlW103+KYoicrlcXWXkNjWrG0VRiqbJdUkmk3XFKYT9xxc3YEJAXaudCYHZ5/LfhUKhqJw8WBoPYgsLCwKAfkA1W1Y6nRYARCgUamo+bk4IWrlOVuq03fXVSEIgT/Zm5HTjydyYQJZ+z676jsVipmUaSZIKhYJIp9P6espkxWqZStvHbLpMwOX2rwcTAqIO4paEoJTZFYw8MMkrGCsHtUbn4+aEoJXrZKVOOyEhqLZ843TZ42G8gi79nl31bexJKP1rRjgcLruqr1WmnoSg2vRamBAQdRAnbhkYr4iaOTC1soybE4JWrpMb66uVCYEQl3pAjLejrMzLLW3ILOZaZWRyUgoovs1hnM6E4CIOKiSywVNPPQUAFQd6GckR0WYDmVRVrfl9WabZ+biRU+vUqfVVy8DAAJLJJFKpFEKhUNnndtd36aDXZsknBOopY7ZOcgDkjTfeaGt83YYJAVGT8vk8HnnkESiKgqGhoZrl9+zZAwA4d+6cPk0+rljtN9blwVY+c93ofNys3etUWqedQJ7YrT7iqiiK/o6CUnbVdzgcBgBEo1H9+3a8RVHTtJpxlJbZsWMHgOJ1On/+fNFnpQKBQFNxdgsmBEQWGA++xv/PZDIYGxsDgKLnmas9xvSe97wHiqLgyJEjerkTJ05AVdWyhEI+OqZpGqLRKBRF0a+ArMxHXjnJE5/xMS35djfjFZXTr8FtxzpVq9NG593Oxw63bNmix29kfFSw1O7du01PerXq2zgvuTzjcuXnd9xxB4CL70Do6+uDx+PB+vXr9RO1fBzR+B6AUvF4vOhRxZWVFZw+fbpon7BSZvPmzQiHwzh69Cg0TYOmaTh69CjC4TA2b95ctEzZc3DLLbdUjKunOH3PgqhV7LrHhwqDpYCLo5Pl41iVvmM2KCqXy4lwOKyXicViRU8jyOnpdFq/JxoOh8ueWKg1n2w2q39fPlolHw+TA83kfeZAIFD2iFczGq3/Vq2TlTptdN7tfOxQDhY0tjuztmmm3rZoNs9Ky8lms/qof1VVix6LDAQCQlXVqgMEjY8TBgIB00cWrZQpLasoipibmzMtI5+oaKTdd+MYAo8QLn6HJVET5NXJ448/7nAk9ZMvvOnk3dNt9e/GOp2dncXo6GjdMcmeiQMHDrQirJbx+XxIJpNOh6ELBoPo6+trqB7d1r7twFsGREQdZmxsDKdOnar4Nj83WlxcxOTkpNNh6DKZTNEtP2JCQOQ6xvu2fKWqPbqtTr1eL2ZmZnDkyJGq9+XdYn5+HuvWrdN/e8Fpy8vLmJ6exszMTNFvk/Q6JgRELrN+/XrT/6fGdWOd9vf3IxqN4uTJk06HUtPQ0JA+GNINUqkUDh065Pofemq31U4HQETF3HSPu1t0a516vd6OG0fgBqwzc+whICIiIiYERERExISAiIiIwISAiIiIwISAiIiIwKcMqMsdP35cf0MdOYP1XxvrqDMNDw87HYKt+Opi6loLCwt45plnnA6DOsTDDz8MALjvvvscjoQ6xTXXXIOtW7c6HYZtmBAQEQHYtWsXgIu/L0DUiziGgIiIiJgQEBERERMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiAhMCIiIiArDa6QCIiNrthRdewC9+8Yuiaf/7v/8LADh37lzR9N/+7d/GVVdd1bbYiJziEUIIp4MgImqnz3/+8/jQhz5kqexjjz2GP/3TP21xRETOY0JARD1H0zS87nWvw4ULF6qWW7NmDX7yk5/A6/W2KTIi53AMARH1HK/Xi507d2L16sp3TVevXo33vve9TAaoZzAhIKKedNddd+Hll1+u+Pkrr7yCu+66q40RETmLtwyIqCf96le/wlVXXaUPJix1xRVX4IUXXsBrXvOaNkdG5Az2EBBRT3r1q1+ND3zgA1izZk3ZZ2vWrMHw8DCTAeopTAiIqGft2bPHdGDhhQsXsGfPHgciInIObxkQUc/69a9/jfXr1+NnP/tZ0fS+vj785Cc/qTrokKjbsIeAiHrW6tWr4ff7i24brFmzBnfddReTAeo5TAiIqKf5/f6i2wYXLlyA3+93MCIiZ/CWARH1NCEErrnmGjz33HMAgI0bN+K5556Dx+NxODKi9mIPARH1NI/Hg7179+Lyyy/H5Zdfjn379jEZoJ7EHgIi6nlPP/00BgYG9P9/y1ve4nBERO3HUTNU1cLCAj75yU86HQZRy732ta8FADz44IMOR0LUevfffz+2bt1aNI23DKiqZ555BsePH3c6DKKWe/3rX49rr70WAHD8+HE8++yzzgbkcouLi1hcXHQ6DGrA8ePH8cwzz5RNZw8BWfL44487HQJRS507dw4AcN1118Hj8eC+++7Drl27HI7KvUZGRgDw2NCJKo2RYUJARISLiQBRL+MtAyIiImJCQEREREwIiIiICEwIiIiICEwIyGb5fB7xeBw+n68nlusmleogGAwiGAy2fPntWk6nYH1Ul8/nMTU15XQYHWdqagqaprVk3kwIyFYHDx6E3+9HKpVqaj6aptX1+li7ltvJ2lkH9W6fdslkMvB4PPrf+Pi40yE5xq3bCLiYDBw8eBBr167Vt1Wl5Mm4PeWfW1lpf1bKpFIp+Hw++Hy+sv15+/bt2Lt3L/L5vP0rIIiqSCQSot5mAqDu75RKJpOOLLfTtasOGtk+7RAOh/U6ACCSyWRD8wEgEomEzdG1V6u30fDwsBgeHq77e4VCQSiKIhYWFvR/x2IxAUAEAgHT7+RyOQFA5HK5pmJuNSvtr1aZWCwmFEURhUJBFAoFoaqqCIfDRWUWFhb0Mo2o1L75HgJyHU3TEIlEnA6DKnDz9tmwYQMEf57F1dtoZmYGAwMDGBwcBAB4vV7s3r0bfr8fhw8fxg033IDdu3cXfae/v7/ov25lpf1VK7OysgK/34+FhQV4vV4AgKqq+P3f/33ccsst+u9tDA4O4uqrr8bMzAwOHDhgW/y8ZUAtI+8Rym6xlZUV/TN5wDJ2F8ousFAopHeTlXYRapqGeDyuT6900EulUvpy6+laK70PL+fj8/mK4q8Ui1xWPp/Xu/00TcP4+Li+jmbzN9aPnGdpndWqNyvrI5l1w8r1rLUcs+1TbQxHrXqyWt+1rKyswOfzIRgMOv5KXbP6sLKuxnYDQN8G4+PjWF5eBlC87aTSaZX2IafHNeTzeUxMTGDbtm2mn4dCIfj9fsTjcUvzs6ttGY9VPp8P8/Pzda+blfZXq8yZM2cAAJs2bdKnbdy4EQBw9uzZorIjIyOYmJiw99ZBQ/0N1DOauWUguwRzuZxQFKWoy09VVf3f2WxWABCqqpbNo5SiKEXdiqqq6v8uXe7S0lLZfGuRcRrnYxafLCu78uQ6ym680vmk02mhqmrR9HQ6LYS42P0n519rmfXWm3F5RsZtIcSl7uVsNmvrcuqtp2rrXotcB/mnKErDXcxo8paBWX1YWVdj/MYudbk9lpaW9O5z47zlfIzTzLZHIBCo2C1fr0ZuGZS2MyMZayAQKNo/Sj83sqNtye/FYjEhhBBzc3Omy7e6btXaX60ycjub1Y2iKEXT5Lo0clusUvtmQkBV2TWGQJ6c5c4bCASqnmDM5iHvMxp3IHkvrdJ3Kp2k6o2/dJo8aJTGAkA/sMjvlN7nsxpnpQN6vfVWqw7ktpmbm7N9OfXUUz0xV1IoFEQ6ndZPKqX3Xq1qNiGQ82hkO5uVSafTAoAIhUJNzcdOjSQEcruYkdONJ/OlpaWyzyW72pY8rpSWaSRxstL+qpWptM3MphcKhaI2UQ8mBNQQOwcVmk3PZrMiFApZOpjJg0Q9y21VQmCWycsdtFqCUk+c1WKvp96qzUdeHVU6qDS7nEbryY6TWTgcLruqssptCUHp9E5NCKrFZJwue0GMV9CtalvGnoTSv2ZYaX+lZeo5ZlSbXgsTAmpIKxMCuTPIK9RmTmyNfqfR+TR60K4nzkrft7PeAoFAxYOWHcux6+TWCHlyaAQTgtpamRAIcalXRN4CaFXbalU9WWl/pWUqXfQA5rfQ7E4IOKiQ2kpVVQAXB87t378fn/70p7FlyxZL31UUBcDF53idJmMxG9Aj17EVGqm3SiKRCA4fPoxPf/rTLVuOU/UEXBy93upltFu3rU81AwMDSCaTSKVSCIVCZZ/b3bbkoE27WGl/pWXM1kkOgLzxxhttjc8MEwJqC3kSv+222wAAfr8fALB582bL85A7y/T0tP6mrpWVFUdePrNnzx4AwLlz5/RpMib5O/Gt0Ei9mVlcXMT+/fsxNzdnOi+7luNUPcnltHoZ7SJPVjt37nQ4kubIE7vVN+0pioJYLIbDhw+XfWZX2wqHwwCAaDSqf9+OtyhaaX+lZXbs2AGgeJ3Onz9f9FmpQCDQVJxF6u5roJ7SyC0D2e0lB6mZ3aeWZbLZbFGXtLxfaHwqQX7P+LSC/FNVtWzktZyH7I4zTqvFOB85GNBsPnLgk/EeZywW07v1zEaCV5q/Wexm02rVm9X5yNHJpeMGZNlGtk+leOupp2r1XUssFisaFJnNZht+KZEQzd8yqLUtqq2r/LccGFcoFMpu7RifOhDi0mA6uU8IYb4PufUpg1ovHjIbjGhX2zKWM/7JGOUYmmpPHVhpf1bbaDgcFqqqVn0xkfw+wKcMqI0aSQiEuDgCWB6QVFUt2hGEuHR/MBAIiFwup49qlzth6eeSLCs/kwfE0p250rRa6plPLpcreutYLBbTDzzG8maDhmrNv9Iyq9Wb1flUG0Qly9S7farVtdV6ama7GR/nCgQCdT8yVqrZhKCZ7Sz/P51O69sqHA4XPa2SzWb1z+QJQT46J/cXs33I6YRAthX5GKAQ5XVQaZubjXWxq21ls1n9uGJs50JceuKm2gBBK+2vnjYqyyqKUnbslGQS2MijtZXat+c3HxKZmp2dxejoKNhMqJd4PB4kEgns2rXLkWUDcP0+J7u6H3/88bq+J7vi7XzDXjv4fD4kk0mnw9AFg0H09fU1VI+V2jfHEBARUduMjY3h1KlTjr9Nsh6Li4uYnJx0OgxdJpNBJpPB2NiYrfNlQkBE5BLG0eUt+TU7F/B6vZiZmcGRI0dc8cRQLfPz81i3bp3+2wtOW15exvT0NGZmZvTfO7ALEwLqGZXe398pP63aq3ppu61fv970/7tNf38/otEoTp486XQoNQ0NDTX9iK+dUqkUDh061JIfeuKvHVLPcPs9WTLXS9utl9bV6/V23DgCN2hlnbGHgIiIiJgQEBERERMCIiIiAhMCIiIiAhMCIiIiAp8yIIu65bEuIqtGR0cxOjrqdBiux2ND92BCQJYkEgmnQyBqm9HRUdx7773YunWr06G41sMPPwwAuO+++xyOhOpVKdFlQkCWOPFOdyKnjI6OYuvWrWz3VcjfMGAddZ5KCQHHEBARERETAiIiImJCQERERGBCQERERGBCQERERGBCQD0sn88jHo/D5/M5HUpbVFrfYDCIYDDY8uW3aznUGfL5PKamppwOo+NMTU1B07SWzJsJATmi2u/aWofItwAAIABJREFUT01NIRKJ1D1PTdPqeknKwYMH4ff7kUqlTD+fn5/XY6p0IjOL361qra+d6t0WdFEr681N2ySfz+PgwYNYu3ZtV+1jmUymKM7x8fGGyqRSKfh8Pvh8vrL9dfv27di7dy/y+bz9KyCIqkgkEqJVzSSXywkAZfOfm5sTAEQsFqtrfslksu5YzZZvVCgURCwWEwBEIBAwLSPXI5fL1bVsJ9RaX7s0si3cBIBIJBJtX24r683ueQ8PD4vh4eG6v1coFISiKGJhYUH/d7fsY+FwWN/HAIhkMll3mVgsJhRFEYVCQRQKBaGqqgiHw0VlFhYW9DKNqNS+2UNAjunv7zedPjQ0BAA4duyY5XlpmtZQr0ItXq8Xu3fvBgAcPnwY8Xi8rIxcj0rr02tatS26XSvrzU3bZGZmBgMDAxgcHATQXfvYhg0bIITQ/xRFqavMysoK/H4/Jicn4fV64fV6oaoq9u/fj0wmo5cbHBzE1VdfjZmZGVvjZ0JArlXaVSYPasYuRtltFgqF9PKl3YqapiEej+vTKx0YU6mU3oVn1h0XCoXg9/tND1hmzJYr55vP5/VuQU3TMD4+rq+P8T6/MaaVlRUA0OdpnGaljsxUGldQ6XaOLFfvtqg2XqNWPZnVh8/nK1t3p1VbD7Pu7tJplepNthMAep2Pj49jeXm5qXkD7R/Xkc/nMTExgW3btpl+bvc+ZrXtyPEM8vP5+fm6121lZQU+nw/BYBCLi4sNlTlz5gwAYNOmTfq0jRs3AgDOnj1bVHZkZAQTExP23jpoqL+BekYrbxkIUbkLGya3DFRV1bsNs9msACBUVa05L0VRiroiVVXV/y2/I7svl5aWyuYrywkhRCAQEABEOp02/bx0ubKrL5fLCUVR9G4+RVGKlp1Op4WqqkXT5TIWFhb0mGScZuvfSB0Zl1e6PsbuWdndnM1mbV1OvfVUbd3thAZuGVRbD7PbY3I9jNMq/du4/rIbGYBYWlpqeN5CXGzPlbrpa2nklkFpOzJq9T4mhHnbkd+Txxt5y7J0+VbXTf4pilJ2i6NWGbldzepGUZSiaXJdzG5L1FKpfTMhoKralRCU/gUCgbL7Y4FAoOpJx+yAJ+9NGnc6ef+t0ncqTRNCFB1olpaWyj6X5EGldLnGREcup3Q964nJ7ABfbx1VOlFLMkmam5uzfTn11FM9MTer3oTArvWwuq7pdFoAEKFQqKl5N6ORhECe7M20ch8rXY5xmjxGlJZpJFEqFAoinU7r61l6779WmUrbyGx6oVAoagP1YEJADXGihyCXy4lAIGCaYQtxMTMOhUKWDnjywFLP8qslBDK+0uy+tLxZpi934GrJSL0xVVq3euqo2nzk1VOlg06zy2m0ntyWENi1HvWsq3F6pyQE1WJo1z5WOs3Yk1D614xwOFx2VV+rTD3HhGrTa2FCQA1x6paBPCCUZulyB5JXrc2c7Or5TqUrNNk9addBvN6YzL5vZx3JxMyMHcux62Rnt3oTglaetHsxIRCidftYq+tFMou5VplKFzCA+S0yJgTUVk4lBGafya49ef/Ryo4td7BK9wMbTQiEuHQ/0KwbVC63tIfDuGO3IiFopI6qJRbGebViOY3Wk9sSArvWo96EoNl5N6PVCYEQrdnHKtWL8faEXayMczGWkfuccZ3kWAGz2w92JwR8yoBcSY4CVlVVn+b3+wEAmzdvtjwf+UjP9PS0/navlZUV05eB1EtRFMRiMRw+fLjssz179gAAzp07p0+Tyx8ZGWl62ZU0UkdmFhcXsX//fszNzZnOy67lOFVPdmv3esgnDHbu3Gn7vFspFAoBgOU37bVjHwuHwwCAaDSqf9+OtyhqmlYzjtIyO3bsAFC8TufPny/6rFQgEGgqziJ1pxbUU9r1YiLjwLqlpSX9isCYtcsrgmw2W9RNLbNp4xWDvOct74HLsvjN1UPp6Gw5D9mFZ5xW66UoZlcvcmCU8R5oLBbTrwYqvZTJrE7M4jSbVquOrM5HXpGUjhuQZRvZFpXiraeeZH2YbSO7oc4eglrrIYQoejJAiEsD4GSbFMK8DcsycqBcoVAou5XT6Lzd8pRBq/exam3HWM74J2OUY2SqPXUQi8WKBt1ms1nTFw7VKiPExV4CVVWrvphIfh/gUwbURq1KCMx2QPknHyUqPWjIe4qBQEAfeKiqql6u9HNJlpWfyYNm6XJrxWV2ApfM7rPncrmit5LFYjH9wFS6vpXqpZ5pterI6nyqDbKSZerdFtXq0Go91Vp3O9WbEAhRfT2EuHgAl3UrD+LycTfZXs3asJxfOp3Wvx8Oh22Zd7sTAtkW5GOAxvVr5T5Wq+1ks1n9GGFsx0JceqKm2gBB4+OEgUDANHmwUqa0rKIoRUmEkUz6GkmKK7Vvz28+JDI1OzuL0dFRsJlQL/F4PEgkEti1a5fToegvEXLbPii7uh9//PG6vie74g8cOGB7TK3k8/mQTCadDkMXDAbR19fXUD1Wat8cQ0BERG0zNjaGU6dOVXybnxstLi5icnLS6TB0mUwGmUwGY2Njts6XCQERkUsZX0vbkl+3c4DX68XMzAyOHDlS9H5+t5qfn8e6dev0315w2vLyMqanpzEzMwOv12vrvJkQEBG51Pr1603/v9P19/cjGo3i5MmTTodS09DQELZs2eJ0GLpUKoVDhw615IeeVts+RyIisoXbxg3Yyev1dtw4AjdoZZ2xh4CIiIiYEBARERETAiIiIgITAiIiIgIHFZJFs7OzTodA1FYLCwtOh+Bqzz77LAAeG7oJ31RIVck3FRIRUfcwe1MhEwIicr0nn3wSw8PDiEQi+PCHP+x0OC3x0Y9+FJ/73OcwNzeHrVu3Oh0O9SAmBETkak8//TTe/va340Mf+hD+7u/+zulwWubll1/G8PAwvvGNb+DMmTOuehkO9QYmBETkWj//+c9x8803Y8OGDZifn8fll1/udEgt9X//938YGhpCPp/HwsJCS95GR1QJnzIgIld65ZVXcOedd+Kll17Ck08+2fXJAAC85jWvQSqVwqpVq/C+970Pv/zlL50OiXoIEwIicqW/+Iu/wL/8y7/giSee6Kkr5auuugr/+I//iB//+MfYt29fV7++mNyFCQERuc4TTzyBqakpfOYzn8HNN9/sdDht94Y3vAFPPvkkvvKVr+DQoUNOh0M9gmMIiMhVMpkMbr31Vtx99914+OGHnQ7HUZ///Ofx4Q9/GLFYjI//UssxISAi1/jZz36Gm2++GZs2bcL8/DzWrFnjdEiOu+eee/DYY4/hG9/4Bt761rc6HQ51MSYEROQKL7/8Mt73vvfhhz/8Ib797W/jda97ndMhucKvf/1r7NixAz/+8Y9x9uzZnhpPQe3FMQRE5Ap//ud/jq9//et44oknmAwYrF69GolEAqtWrcLw8DBeeuklp0OiLsWEgIgc98UvfhEPP/wwHn30Udx0001Oh+M6V111FZLJJL773e/i4x//uNPhUJfiLQMiclQ6ncatt96K8fFxhEIhp8NxtUQigd27d+MLX/gC7rzzTqfDoS7DhICIHPPTn/4UN998M6677jp87Wtfw+rV/AHWWv7sz/4M0WgU3/rWt/DGN77R6XCoizAhICJH/PrXv8Yf/dEf4dy5c/j2t7+Nq666yumQOsKLL76Id7zjHXjxxRexuLiIK664wumQqEtwDAEROeLAgQNYXFzEE088wWSgDq961avwxBNP4Pz58/joRz/qdDjURZgQEFHbfeELX8CnPvUpPPbYY3y2vgGbN2/GY489hs9//vM4evSo0+FQl+AtAyJqq+9+97t4xzvegY9+9KP4m7/5G6fD6WgTExP47Gc/i3Q6jd/7vd9zOhzqcEwIiKhtcrkcbr75ZrzhDW/A1772NVx22WVOh9TRXnzxRbztbW/DmjVrcObMGb7ZkZrCWwZE1BYXLlzA6OgoLrvsMsRiMSYDNnjVq16FY8eO4Qc/+AF7W6hpTAiIqC3uu+8+PPXUU0gmkxxEaKM3velNOHLkCB588EF885vfdDoc6mC8ZUBELReNRrFv3z7E43Hs2rXL6XC6jhAC733ve7G8vIx0Oo3Xvva1TodEHYg9BETUUt/5znfwkY98BH/5l3/JZKBFPB4PwuEwfv7zn/PVxtQw9hAQUcvkcjncdNNNuP7663HixAmOG2ixWCyGO++8E1//+tfxrne9y+lwqMMwISCilrhw4QK2b9+OZ555Bt/61rdw5ZVXOh1ST7jjjjvwox/9CJlMBq9+9audDoc6CG8ZEFFLfOxjH8N3vvMdJJNJJgNt9KlPfQrnz5/nUwdUNyYERGS7o0eP4rOf/Swee+wxvPnNb3Y6nJ6yefNmPPjgg/h//+//4Yc//KHT4VAH4S0DIrLV4uIi/vAP/xAf//jH8eCDDzodTk965ZVXcOuttwIA/vVf/xWrVvHaj2pjQkBEtnn++edx00034c1vfjP+6Z/+iYMIHfT000/jpptuwqc+9Sl85CMfcToc6gBMCIjIFhcuXMDtt9+OXC6Hb37zm+jr63M6pJ738Y9/HJ/73Ofw7//+71i3bp3T4ZDLsR+JiGxxzz33IJ1O48knn2Qy4BJ//dd/jVe96lW8dUOWMCEgoqZNT08jEongscceww033OB0OPQbr33ta/GJT3wCn/nMZ7C8vOx0OORyvGVARE1ZWFjAtm3b8MADD+ATn/iE0+FQiZdffhl/8Ad/gOuuuw5f/vKXnQ6HXIwJARE17L//+79x8803461vfSu+9KUvcTS7S83Pz+P222/HP//zP+Pd73630+GQSzEhIKKGvPjii7jttttQKBTwzW9+E16v1+mQqIr3vve9eO655/DUU0/x6Q8yxXSeiKq6//77cf78+bLp99xzD374wx/iySefZDLQAUKhEH7wgx/gi1/8otOhkEuxh4CIKvqv//ovXHfddbjyyivxla98BW9/+9sBAH//93+Pj33sY/jKV76C973vfQ5HSVZ9+MMfxje+8Q3827/9G3sJqAx7CIioolgshtWrV+NnP/sZbrvtNoTDYZw5cwb3338/PvGJTzAZ6DCTk5P4z//8TyQSCadDIRdiDwERVfTGN74RS0tL+r89Hg+uuOIK3H777fjyl78Mj8fjYHTUiLvuugvf+c538P3vf5+DQKkIWwMRmXr66aeLkgEAEELgV7/6FZ599lk8//zzDkVGzfirv/orLC0t4Utf+pLToZDLMCEgIlPHjh3DmjVryqa//PLL+N73voeBgQEsLi46EBk14/rrr8cHPvABPPTQQ2AHMRnxlgERlfn/7N17eBTV/T/w92ICKugiaggX8YaxXtoUrDb0AjXGItbZVklIglq/tSnP0qut9PKjm1Ir5fHbbnqzKt2krTatmwCtbbYWVIIP6JdEFNxotSYqdYNFd710V6mgAc7vD3qG2c3sNbt7Znffr+fJo8yeOfOZM7MznzlzZlYIgRkzZuCVV16JW2bcuHEYN24cfvWrX+HGG2/MY3Q0VgMDA5gzZw7+8pe/QNM01eGQRbCHgIhGefTRRxMmAwBwzDHHwGazYXh4GIcOHcpTZJQN1dXV+NSnPoW2tjbVoZCFMCEgolHuvfdejB8/Pu7nNpsNH/rQhzAwMIDvf//7fIStAH3pS1/C1q1b8cwzz6gOhSyCtwyIKMrIyAhOPfVURCKRUZ+Vl5fj2GOPhdvtxhe+8AU+ZVDAhBCoqqrCVVddhZ/+9KeqwyELYA8BEUXZtGnTqGRA9gAsWbIEL774IpYtW8ZkoMDZbDbceOONuPvuu/HOO++oDocsgAkBEUX5wx/+EPV0QVlZGWbOnImHHnoIv//973HqqacqjI6yqaWlBfv378f69etVh0IWwFsGRKTbt28fTj31VBw4cEBPClwuF7797W9jwoQJiqOjXGhqasLw8DC2b9+uOhRSjD0ERKT7y1/+ggMHDgAAampq8Pe//x3f+973mAwUMafTib6+Pjz11FOqQyHF2ENgIQ0NDdiwYYPqMIioCHR3d2PJkiVJy8nBhQ6Hg48hlrgy1QFQtJqaGnz9619XHUbRa2xsxE033YR58+apDsUy3n77bfzhD3/AtddeixNOOEEfec79sfA0NjamXNZms+Haa6+Fx+PBj370Iz5CWsLYQ2AhDQ0NAMABPnlgs9lSvoIqFUKIqCcHuD8WrnT37xdeeAFVVVV48MEHUVdXl+PoyKo4hoCIAICPEZaw2bNn4+KLL8Yf/vAH1aGQQkwIiIgI1157Lf74xz/ynQQljAkBERGhubkZ+/fvh8/nUx0KKcKEgIiIcOqpp+Lyyy/nbYMSxoSAiIgAHLltsGnTJrz++uuqQyEFmBAUoVAohK6uLjgcDtWhFLXW1la0traqDsOyQqEQn2vPQFtbm+kPS+XD1VdfjQkTJmDdunVKlk9qMSEoQqtWrUJzc3NB3QuMRCLo7+9He3t73ERmeHgYy5cvh81mw/Lly7Fly5Y8R2ktkUjEsk8GhEIhrFq1ChMnToTNZoPNZoubPMnPjX9WNTAwEBXn8uXLMyrj8/ngcDjgcDhGfU/r6upw/fXXIxQK5Ww94jn++OPxmc98hrcNShQTgiJ01113qQ4hbW63G/fffz+WLVtmmshEIhEMDAzgrrvuQjgcxoIFC3DZZZcpTXpuvfVW3HrrrcqWv23bNmXLTiQSiaClpQU33HADnE4nwuEwvF4vVq9ebZoUCCEQDAYBAMFgEFZ+NcqOHTui/n3llVemXaarqwvt7e3o7OxEZ2cn/va3v6G9vV3/vLq6GitXrkRLS4uSnoJrr70W27dvx/PPP5/3ZZNaTAjIEpKdXLdt2wZN0wAAdrsdTU1NAFCyt0UikUjUScRKOjo6UF1djZqaGgDR22v16tXo6uoaNU9FRUXUf62qsrISQgj9T+6TqZYZHh5Gc3MzVq5cCbvdDrvdDqfTiWXLlmFgYEAvV1NTgxkzZqCjoyMv62VUV1eHyspK0+1ExY0JQRGIRCLo6uqCzWaDw+HA0NDQqDLyfq4sI7vbY8cb+Hw+vczw8HBUHXL+9vZ2hEKhqK7dePVni9mBFzjywywqmI3TSKUtQ6GQ3l0MAO3t7Xq3stxuZl3nsdPcbrfeO2KcrnpcQygUwooVK3DppZeafu52u9Hc3Jzyyca4bxv3PbmsVPfdbOyfw8PDcDgcaG1tRX9/f0Zl5C8KTp8+XZ82bdo0AKN7FhoaGrBixYq83zooKytDY2MjOjs787pcsgBBllFfXy/q6+vTnk/TNOF0OkU4HBZCCOH1egUAITdvMBgUmqYJr9crhBCit7dXABB+v19omqaX7evrE0IIEQgEBADhdDr1ZbjdbhEIBIQQQoTDYeFyuVKqP13GuBMJh8MCgOjp6Ul7GXI53d3dGc0rhIhqN7Np8dpSfm4sEw6HhdPpFADE4OCgCAaDo+qW9RinmbWVy+USLpcr4/UyymR/7OnpEQD0fcVIxir3ndj9w2y7a5omPB6PEOLofqZpmgiHwynvu9naP+W6yT9N00QwGEyrjNzOZm2jaVrUNLkumezjY92/d+zYIQCIHTt2ZFwHFR4mBBYylgPw4OCgPk2eLOWBRyYIRgD0E4fZicXs5GM8sMmTVir1pyPVhKC3t1c/MWRirAdMWUeydjObZlbG7/cLAMLtdo+pnmzKZH80Joqx5HTjydy438bOJ0/cxv2ur69PANBP7qm0Uzb3z3A4LPx+v76eMllJtUy8bWY2XX6P5T6Rjmzs3+eee6742te+NqY6qLAwIbCQTA7Aia445HTjlVTsX2xZs/mNy/F6vaNOwsnqT0eq82mapl8VZsJqCUHs9EJNCBLFZJwuE0rjFXTsfGb7tjxJyqvpVNopm/unkcfjGXVVn6xMOglBounJZGP/vuWWW0RFRYUYGRkZUz1UOJgQWEg2D8DJTi7J6oidNjg4GHVgNV61ZPPElEpdXq/X9Mos3eUwIUgslwmBEEd7RWRPTyptGTtdZTuZxZysjPwOxQKib3MYp6tKCF544QVhs9nExo0bx1QPFQ4OKiwhZoMNU1VVVYWenh74/X44nU6sWLFi1EtnxlJ/qgYGBvDMM8/gC1/4Qs6XpYKqQZIqVFdXo6enBz6fD263e9TnciCp2aC6TNop2/unfEIgnTJm6yQHQM6dOzer8Y3V2WefjZqaGr6ToIQwIShwHo8HAKIeWYpXprOzU3+uOd23yNlsNkQiEVRXV+Ouu+6C3+/HihUrslZ/KkKhEDZv3hz1eOLAwIDpi18KjTxZmT3XXkjkiT3V5+c1TdPfURBr6dKlAIDdu3fr02S9DQ0NKceUq/0zEokkjSO2zMKFCwFEr9PevXujPovlcrnGFOdYXHvttbjvvvuwb98+ZTFQHqnuoqCjMumilSORNU3TR3bLwVj4bzekcdS68S8QCER9JscGGAclGu/vulwufRmBQEC/bZCo/nQYlxs7TkGOFDdbjopR2MZ1lm2UTlsCRwfGyac2jPeajU8dCHF0MJ3cpkIc7X4OBoP6trDqUwaybWJH5UtmgxHl4EPjOAOv16uvf6rtnWz/dLvdAkj81IHX6xW9vb36vwOBwKj9LpUyQhwZVyCfCpJPmJjdAlP5lIEUCoVEeXm5+P3vfz/musj6mBBYSKaPHQYCAf0EIhMA+ZiVPCgGAgH9oOt0OvWDYexBMtE0eeIBRo98jld/qswO2MYThFw/sz/jSPV0ljeWA2Y67RZvmvGxT4/HE5UEBQIB/TN5QojdpvIevMvl0qepTgjkydc44DPRdjUyG6AXDAaFx+OJSqJkO6Xa3kIk3j9dLpdwOp0JBwgaHyd0uVymyUMqZWLLapoWlUQYySQwXhKVSLYSAiGE+NSnPiUWLVqUlbrI2mxCWPg9oSVGdi2uX79ecSTFz2azobu7G0uWLFGybACWfkUvkPn+KLvib7755qzHlEsOhwM9PT2qw9C1trZi8uTJGbVjNvfvrq4uXH/99fjXv/5l+TdJ0thwDAERZVVLSwu2bt0a921+VtTf34+VK1eqDkM3MDCAgYEBtLS0qA4FDocDxx57LDZs2KA6FMoxJgREeWQcXa7i1+zywW63o6OjA2vWrEk42NUqtmzZgilTpui/vaDa0NAQ1q5di46ODtjtdtXh4Pjjj4emafxtgxLAhIByyuynbQvp526zberUqab/X2wqKirQ2dmJzZs3qw4lqdraWlRVVakOQ+fz+XDLLbdYqnu+qakJjz76KAKBgOpQKIeYEFBOCcOvviX6KxWltN52u73gxhFYwc0332ypZAAArrjiCpx00km8bVDkmBAQEVFC48ePx2c+8xneNihyTAiIiCippqYmPPHEE3j++edVh0I5woSAiIiSqq2txdSpU9Hd3a06FMoRJgRERJTUMcccg/r6etx7772qQ6EcKVMdAEV7+eWXsW7dOtVhlIS+vj7VIVjayy+/DADcH0nX1NSEO+64A08//TTe//73qw6HsoxvKrSQhoYGjuIloqzIxZs4hRA488wzcd1115n+IBUVNt4ysJj6+vqUH9XjX+Z/wJEDpuo4rPxXX1/P/bFA/3LFZrOhoaEBXq83p8shNZgQEBFRypqamrB79248/vjjqkOhLGNCQEREKbvoootQVVXFpw2KEBMCIiJKS2NjI7q6unDo0CHVoVAWMSEgIqK0LF26FHv37sWjjz6qOhTKIiYERESUlve97334wAc+wNsGRYYJARERpa2xsRHr16/HyMiI6lAoS5gQEFFOhEIhtLW1qQ6j4LS1tSESiagOI6mmpia88cYb6O3tVR0KZQkTghJis9ni/rW1tcHn8xXEgaiQRSIR2Gy2gqs7XaFQCKtWrcLEiRP1fay1tdW0rNn+aFUDAwNRcS5fvjyjMj6fDw6HAw6HAz6fL+qzuro6XH/99QiFQjlbj2w466yzcMkll/C2QRFhQlBChBAIBoP6v8PhsP4ik7q6OrS3txfEgaiQbdu2rSDrTkckEkFLSwtuuOEGOJ1OhMNheL1erF692jQpMO6XwWDQ0i+82bFjR9S/r7zyyrTLdHV1ob29HZ2dnejs7MTf/vY3tLe3659XV1dj5cqVaGlpsXyC3tTUhPvuuw/vvvuu6lAoC5gQlJiKigr9/+12u/7/1dXV6OjoAICCOBAVokgkEnXgL5S609XR0YHq6mrU1NQAOLKfNTU1AQBWr16Nrq6uUfPI/dK4f1pRZWVl1BsBNU1Lq8zw8DCam5uxcuVK2O122O12OJ1OLFu2DAMDA3q5mpoazJgxQ/9OWlV9fT3eeust3jYoEkwISFdRUYGbbroJPp9v1NWmvB9ss9ngcDiwZcsWfXpXVxccDgeAI12hsszw8HBUHXL+9vZ2hEKhqK7hePVbSSQSQVdXl94VLNcDgGl3d+w0t9utdw/L6aFQSO8+BoD29na9m3loaGhMdQNAa2tr3K76XAiFQlixYgUuvfRS08/dbjeam5tNkwIzido8nX0vG/vX8PAwHA4HWltb0d/fn1GZ7du3AwCmT5+uT5s2bRqA0T0LDQ0NWLFihaV77GbOnImLL74Yf/zjH1WHQtkgyDLq6+tFfX19zpcDQMTb9OFwWAAQTqdTnxYMBoWmacLr9QohhOjt7RUAhN/vF5qm6fX19fUJIYQIBAKj6nC73SIQCOjLcLlcegyJ6s8VAKK7uzuteTRNEx6PRwhxNGZN00Q4HBbBYHBUu8p2ME6L929j+4XDYeF0OgUAMTg4mHHdQgjhcrmEy+VKaz2lTPbHnp4eAUDf1kYyNrntY7ev2T6ZqM1T3feytX/JdZN/mqaJYDCYVhm5Xc3aRtO0qGlyXXp6etKKU9aX7v6dqf/93/8VJ598shgZGcnL8ih3mBBYiBUSArPPvV7vqPIA9BONWX1mJyvjgVGe5FKpPxfSPWDKk4hxHfr6+gQA/USTajskKyOEEH6/XwAQbrd7THWPRSb7ozEq52GCAAAgAElEQVTRiyWnG0/mg4ODoz6XstXm2dy/wuGw8Pv9+nrKZCXVMvG2kdl0mZzLfSAd+UwIdu/eLQCIzZs352V5lDtMCCzEqgmB8Uos9i9efbHT5JWR1+sV4XA4qmyy+nMh3QOm2ZWdPGDLK7tsJgSx0wslIUgUg3G6TAiNV9Cx82WrzXO1f3k8nlFX9cnKpJMQJJqeTD4TAiGEqK6uFsuXL8/b8ig3mBBYiBUSAnnANV49pZtAmE0bHByMOjAbr3pyffI3k+4BM5cn7VJMCIQ42gsibwEUSrtIZjEnKyO/A7GA6NscxumFkBD84Ac/EFOnThUHDx7M2zIp+ziokKLs3LkTAEwHhclBbpmoqqpCT08P/H4/nE4nVqxYMeqlNWOpP9fkSHGzAV5OpzNny81l3apVV1ejp6cHPp8Pbrd71OfZbvNs71/yCYF0ypitkxwAOXfu3KzGl0+LFy9GMBhEX1+f6lBoDJgQkC4UCuFnP/sZNE1DbW2tPt3j8QAAOjs79ccR030Lnc1mQyQSQXV1Ne666y74/X6sWLEia/Xn2tKlSwEAu3fv1qfJWBsaGrK+PHnyMnvO3crkiT3Vx1Y1TdPfURArW22eq/0rEokkjSO2zMKFCwFEr9PevXujPovlcrnGFGc+nH/++TjvvPP4tEGhU91FQUfl45aB7MIEEHUvXz4xYDZy2jjK3fgXCASiPpP1GZdhvD/scrn00eeBQEC/bZCo/lxBml2qciCcsX28Xm9UN6/xyQAhjg6Ag6E7WHYZB4PBUQMG5UA5+RSG8d5zpnVb5SkDuY1j9y3JbDBisjZPdd9Ltn+53W4BJH7qwOv1it7eXv3fgUBg1Oj/VMoIcWRcgdPpFOFwWH+ixGxwYqE8ZSB997vfFTNnzhSHDx/O63Ipe5gQWEiuEwKzg6L8c7vd+qNbZgKBgH7Qdjqd+sE0tp5E0+SJSi4vlfpzJZMDZjAYFB6PJ+oEbkyqAoGAflKWB3H5uJs8Ocn75i6XKypZkickOb/H48lK3flOCOTJ17gvme1vZswG6CVq81T3PSES718ul0s4nc6EAwSNjxO6XC7T5CGVMrFlNU2LSiKMZNIXL4lKREVCsGvXLgFA7NixI6/LpeyxCWHh94SWGNm1uH79esWRFD+bzYbu7m4sWbJEdSj6S4Ss9lXMdH+UXfE333xz1mPKJYfDgZ6eHtVh6FpbWzF58uSM2lHV/j179mzU19fjtttuy+tyKTs4hoCIsqqlpQVbt26N+zY/K+rv78fKlStVh6EbGBjAwMAAWlpaVIeSlquvvprjCAoYEwIihYyjza38itp02O12dHR0YM2aNVHv57eqLVu2YMqUKfpvL6g2NDSEtWvXoqOjI+r3RgrB4sWL8cILL+Cpp55SHQplgAkBkUJTp041/f9CV1FRgc7OTmzevFl1KEnV1taiqqpKdRg6n8+HW265xfI/9GTmwx/+ME477TT2EhQoJgRECgnDr+JZbQzBWNnt9oIbR2AFN998c0EmA8CRsQuf+cxnmBAUKCYERESUNYsXL8YzzzyD5557TnUolCYmBERElDUf//jHUVlZiT/96U+qQ6E0MSEgIqKsGTduHBwOB28bFCAmBERElFXXXHMNdu3ahUAgoDoUSkOZ6gAoWn9/f07ejU+j/fSnP+VLoBKQ7xHg/kjpqq2thd1uh8/nw5e//GXV4VCK+KZCC/nJT37CXwsjHD58GA899BDmzp2LU089VXU4VKC+8Y1vYN68ecqWv2TJEkQiETzwwAPKYqD0MCEgspjHH38cl1xyCZ599lmcd955qsMhykhnZyc+//nP47XXXiu4FyyVKo4hILKYvr4+TJ48Geeee67qUIgy9qlPfQpCCDz44IOqQ6EUMSEgspj+/n7U1NRg3Dh+PalwTZkyBfPmzYPP51MdCqWIRxwii+nr61N675coWzRNw/3334+DBw+qDoVSwISAyEKCwSBeeuklJgRUFBwOB958800Oli4QTAiILGT79u0YN24cLr74YtWhEI3Zueeei6qqKt42KBBMCIgspK+vD+effz4mT56sOhSirNA0jQlBgWBCQGQhfX19qKmpUR0GUdYsWrQIzz33HHbv3q06FEqCCQGRRYyMjGDXrl0cP0BF5eMf/zhOOOEEvqCoADAhILIIv9+Pd955hwkBFZXx48ejtrYWGzduVB0KJcGEgMgi+EIiKlaLFi3Cli1bcODAAdWhUAJMCIgsgi8komJ15ZVX4j//+Q8eeeQR1aFQAjzyEFkEX0hExeq0007DBRdcwNsGFseEgMgC+EIiKnaLFi1iQmBxTAiILGD79u2w2Wx8IREVLfn44Ysvvqg6FIqDCQGRBfCFRFTsPvaxj2HSpEl46KGHVIdCcTAhILIAjh+gYjd+/HjMnz8fvb29qkOhOJgQECnGFxJRqbjsssvQ29uLQ4cOqQ6FTDAhIFJsYGCALySiklBXV4d///vfePLJJ1WHQiaYEBApxhcSUal4//vfj2nTpmHz5s2qQyETTAiIFJM/aMQXElGxs9lsqK2t5TgCi+IRiEgx/sIhlZLLLrsMjz76KPbv3686FIrBhIBIIb6QiErNJz/5SRw4cADbt29XHQrFYEJApBBfSESlZsaMGTj33HM5jsCCmBAQKdTf34/zzz8fJ510kupQiPLm0ksvxdatW1WHQTGYEBApxBcSUSmaP38+nnjiCfznP/9RHQoZMCEgUmRkZAQ7d+5kQkAl5xOf+ARGRkbQ39+vOhQyYEJApAhfSESlatq0aTj77LN528BimBAQKcIXElEpW7BgAbZt26Y6DDJgQkCkSF9fHz784Q/zhURUkubPn4/+/n4cOHBAdSj0XzwSESnCAYVUyubPn493330XO3bsUB0K/RcTAiIF+EIiKnVnnnkmZs2axdsGFsKEgEgBvpCICPj4xz+ORx99VHUY9F9MCIhy7L777oPb7Y56fztfSEQE1NTU4LHHHsPhw4dVh0IAylQHQFTsXn31VXzzm98EABxzzDG48MIL8cYbb2D27Nl46aWXcMYZZ6gNkEiRmpoahMNhDA4O4rzzzlMdTsljDwFRjp1++un6/x86dAgDAwMIBoPYunUrzjzzTJxyyin49Kc/jR//+Md45ZVXFEZKlF/V1dU4/vjj+YIii2BCQJRjs2bNGjVtZGQEQggAwBtvvAGfz4df/OIXOPHEE/MdHpEy5eXlmDt3Lh577DHVoRCYEBDlnFlCEEsIgTvuuAMTJ07MQ0RE1lFTU8MeAotgQkCUYyeeeCImTZoU9/Py8nI4HA44HI48RkVkDR/+8Ifx97//HW+99ZbqUEoeEwKiPJgxY0bcz8rKynDHHXfkMRoi6/jIRz6CQ4cO4YknnlAdSsljQkCUB2effbbp9GOOOQZr1qzBzJkz8xwRkTVMnz4dM2fO5BsLLYAJAVEenHnmmSgvL4+aVlZWhqqqKnz5y19WFBWRNcydOxdPPvmk6jBKHhMCojw47bTTRv2I0aFDh/Cb3/wGZWV8HQiVtjlz5mDXrl2qwyh5TAiI8uD000/HyMiI/u/y8nJ88YtfRE1NjcKoiKxh7ty5ePHFFxGJRFSHUtKYEBDlwaxZs/TXs9psNpx44olYvXq14qiIrGHOnDkQQmBgYEB1KCWNCQFRHhjfRSCEwF133YXJkycrjIjIOk477TSceuqpvG2gGBMCojyYPn06jjnmGNhsNlx++eVoaGhQHRKRpcyZM4cDCxXjaKYY69atUx0CFakTTzwRb7/9NjRN435GCZ122mmYN2+e6jDyas6cOfjb3/6mOoySZhPyheoE4Mj9XSIilerr67F+/XrVYeRVd3c3rrvuOrz99ts49thjVYdTknjLwER3dzeEEPyz6F99fT3q6+uVx5Hu32233YZ33303L8vq7u4GAOXrzL/0/+rr6xUfAdW44IILcPDgQQwNDakOpWQxISDKk29+85sYP3686jCILKmqqgplZWV49tlnVYdSspgQEOVJ7IuJiOio8ePHY/bs2fjHP/6hOpSSxSMUERFZwvnnn88eAoWYEBARkSUwIVCLCQEREVnCeeedh+effx7vvfee6lBKEhMCIiKyhPPPPx8jIyN44YUXVIdSkpgQ5EAoFEJXVxccDofqUCiO1tZWtLa2qg7DskKhENra2lSHUXDa2tr4Az1jcO6552LcuHEcWKgIE4IcWLVqFZqbm+Hz+VSHkpZIJJLRi5kikQj6+/vR3t6eMAny+XxwOBxwOBwF1zbZlmlb50MoFMKqVaswceJE2Gw22Gy2uMmT/Nz4Z1UDAwNRcS5fvjyjMon247q6Olx//fUIhUI5W49idtxxx2HGjBl48cUXVYdSkvjq4hy46667sHbtWtVhpG3btm0Zzed2uwEg4a/3dXV14d5770VnZycA4Dvf+Q5effVVfOELX8homWN16623KlmulGlb51okEkFLSwtWrlyJmpoaNDc3Y+PGjWhubgYwut2EEAiFQpg6dSqCwSAqKipUhJ2SHTt2RP37yiuvTLtMsv24uroaK1euREtLCzo7O2G327O5CiXhrLPOwj//+U/VYZQkJgQE4MiJoL29PaN55UkiXkIwPDyM5uZm9PX16QdIp9OJD37wg7jkkktQXV2dWdAFaixtnWsdHR2orq5GTU0NAMBut6OpqQnNzc1YvXo1LrjgAjQ1NUXNI5MAKycDAFBZWQkhEr+pPVGZVPfjmpoazJgxAx0dHbj55puzuxIl4KyzzsLu3btVh1GSeMsgCyKRCLq6umCz2eBwOKJevRkKhfQuxkgkguXLl0d1vxrntdlsaG9v17sbjfMCQHt7u96NGft6z0T1mHXnxk5zu91692e2u363b98O4Mgv/knTpk0DMPqKLB/MxnjETvP5fPr2HB4e1ssk2x5jaWvV4xpCoRBWrFiBSy+91PRzt9uN5uZmdHV1pVRfsn07WXsb42pra9M/37JlS9rrNjw8DIfDgdbWVvT392dUJp39uKGhAStWrOCtgwyceeaZTAhUERQFgOju7k5rHk3ThNPpFOFwWAghhNfrFQAEAKFpmv7/fX19wu/3C6fTGTWvx+MRQggRDAaFpmlC0zQRDof1+eS8QggRDoeF0+kUAMTg4GBK9QSDQb0eKRAIjJoW++90xZtfxmtWXtO0tJdTX18v6uvrM4pRCBG1TcymybaWbSS3VyrbYyxt7XK5hMvlyni9jLq7u9Pelj09PQKACAQCoz6TdblcLgFA+P1+08+NEu2TqbS3cT6v1yuEEKK3t9d0+amum/F7GQwG0yqTzn4s16WnpyetOIUY+/5d6H7/+9+L8vJycfDgQdWhlBwmBDHSTQjkQcR4cjaezGWdAPSEQZIHN+NBp6+vTwDQD4BmJw6/3y8ACLfbPaZ68pUQpDs9mWwcMFNpD7NpqWyPfLR1MpkkBPJkb0ZON57Mjft87HzZ2idlch1bJpPEKRwOC7/fr6+nTFZSLZPOfiyPAXKfSEepJwTbt28XAMQ///lP1aGUHCYEMdJNCBJdNcQmBKnMKw8k8oojlYNQpvUwIchOQhA7vVATgkQxGafLXhDjFXTsfNnaJ409CbF/Y+HxeJL2TsWWKaT9u5C9+uqrAoDo7e1VHUrJYUIQI92EINMTRDbntcpJKt788qBuVt7YPZwqJgTJ5TIhEOJor4jx9lYqdVmlncxiTlYm3f2YCUHmJk6cKDo6OlSHUXI4qFAhTdMAwHTgkdPpTDq/LDPWenLNLD45cGzu3LlKYsoFK7R1vlRXV6Onpwc+n09/7NQo2/tk7CDasbLb7UnjiC1TKvuxFcyYMQP/+te/VIdRcpgQjJHH4wFw5IUm6Vq6dCkARI2olW85a2hoiDufPDjKZ6QzrSdfFi5cCCA6vr1790Z9Vshit0ehkif2VN+0p2kavF6v6eOm2don5fers7NTnz8bb1GMRCJJ44gtk8l+7HK5xhRnqZo+fTpeeeUV1WGUHCYEYyQPBK2trfrVgvGxqMWLF8edd9GiRdA0DWvWrNGvOjZu3Ain04na2tqosvJRr0gkgs7OTmiapl+xpFKPvNKRJy/jY1XybWzGK6B0D7jGk0jsCWXWrFnweDy45557EIlEEIlEcM8998Dj8WDWrFlpLScbjFd4xsfgJBm/cT1ir3QTbY9M21r1Y4dVVVUARm8/szaSmpqaTE96yfbJVNv705/+NIAj77iYPHkybDYbpk6dqp+o5eOIiRLyrq6uqO/k8PAwtm3bFvUdS6VMOvuxPBZccsklceOi+KZPn64nW5RHqu9ZWA3SHEMgxJFHjOQgKqfTGfWoFAyDoMwGMQWDQeHxePQyXq836mkEOd3v9+v3MD0ez6gnFpLVEwgE9Pnlo1AyRjkwTN4Xdrlcox7JStZmZn+x5BMZmqaNacDQWO+xmsWZ7rRE2yPTtlb92KEcLCgfAxTCfNuaSXffTrW9hTjSnnLUv9PpjHos0uVyCafTmXCAoPFxQpfLZfrIYiplYssm2o/lExXpfI8kjiEQYsWKFeLiiy9WHUbJsQmR5NVdJcZms6G7uxtLlixRHQoA6C+t4WY6Sl4drl+/Pu/LLpTtsW7dOjQ2NqYdp+ytKLQ37DkcDvT09KgOQ9fa2orJkydn1I4q92+r+MlPfoKf/OQnePnll1WHUlJ4y4CIdC0tLdi6dWvct/lZUX9/P1auXKk6DN3AwAAGBgbQ0tKiOpSCNW3aNASDQRw6dEh1KCWFCYGFmd3rJnVKYXvY7XZ0dHRgzZo1GQ2UzbctW7ZgypQp+m8vqDY0NIS1a9eio6ODP2w0BtOnT8fBgwfx2muvqQ6lpDAhsLCpU6ea/n++mP20bSH93G22qd4e+VJRUYHOzk5s3rxZdShJ1dbW6oMhrcDn8+GWW26x/A89WZ38jYhgMKg4ktLCXzu0MNX3qVUv32pKqT3sdnvBjSOwArZZdkyZMgUA8OabbyqOpLSwh4CIiCxFPmL673//W3UoJYUJARERWUpZWRlOOOEEJgR5xoSAiIgs56STTuItgzxjQkBERJZz0kknsYcgzzio0MRPf/rTkn4piNXJZ+St8DsNViVf6MI2Kjz9/f2WeYxSpSlTpjAhyDP2EBARkeWwhyD/2ENg4utf/7plXl1Mo/HVrsnJVxezjQoPe3WOsNvt/MXDPGMPARERWc6xxx6LAwcOqA6jpDAhICIiy5kwYQLeffdd1WGUFCYERERkOewhyD8mBEREZDkTJkxgQpBnTAiIiMhy2EOQf0wIiGiUUCiEtrY21WEUnLa2NkQiEdVhFAX2EOQfE4I8SvQTwm1tbfD5fAV9MIlEIkX/c8i5XEertF8oFMKqVaswceJEff9sbW01LVtIP4c9MDAQFefy5cszKuPz+eBwOOBwOODz+aI+q6urw/XXX49QKJSz9SgV7CHIPyYEeSSEiPp973A4DCEEhBCoq6tDe3t7QR9Mtm3bpjqEnMvlOlqh/SKRCFpaWnDDDTfA6XQiHA7D6/Vi9erVpkmBcZ8OBoOW/onoHTt2RP37yiuvTLtMV1cX2tvb0dnZic7OTvztb39De3u7/nl1dTVWrlyJlpaWgk7uraC8vBwjIyOqwygpTAjyrKKiQv9/u92u/391dTU6OjoAoCAPJpFIJOrAWIxyuY5Wab+Ojg5UV1frr8612+1oamoCAKxevRpdXV2j5pH7tHHftqLKyko9ARdCQNO0tMoMDw+jubkZK1euhN1uh91uh9PpxLJlyzAwMKCXq6mpwYwZM/TvM2Xm8OHDGDeOp6h8YmtbSEVFBW666Sb4fD79ajEUCuldlJFIBMuXL4+6UotEIujq6tK7ONvb2/UeBuO8ANDe3q53gw4NDUUtO1E9Zt3BsdPcbrfefWrVruNcrGMqbTyW9mttbY3bXZ9toVAIK1aswKWXXmr6udvtRnNzs2lSYCbZvtnV1aW3m8/ng81mg8PhwPDw8Ki42tra9M+3bNmS9roNDw/D4XCgtbVV/y2MdMts374dADB9+nR92rRp0wCM7lloaGjAihUrCra3zwqEEJY8jhQ1QVEAiO7u7pwvI17Th8NhAUA4nU4hhBCapunl+/r6hN/v1z+Tn3s8HiGEEMFgUGiaJjRN0+sxzivrdzqdAoAYHBxMqZ5gMDgq5kAgMGpaovXKpvr6elFfX5/2fLlYx1TaeCzt53K5hMvlSntdu7u7094WPT09AoAIBAKjPpN1uVwuAUD4/X7Tz40StXfsfi3E0TYx7t9yPq/XK4QQore313T5qa6b/NM0TQSDwbTKyG1q1jaapkVNk+vS09OTVpxCZL5/F5u1a9eKk046SXUYJYUJQQzVCYHZ5/Lf4XA4qpw8OBoPWn19fQKAfgA1W5bf7xcAhNvtHlM9hZQQ5HIdU2njfLdfJgmBPNmbkdONJ3NjQhk7X7ba2+v1mpbJJEkKh8PC7/fr6ymTlVTLxNs+ZtNlQi63fzqYEBxx1113iSlTpqgOo6QwIYhh5YQgltkVizwQySuWVA5imdZTSAlBLtcxlTYuhIQg0fKN02WPh/EKOna+bLW3sSch9m8sPB7PqKv6ZGXSSQgSTU+GCcERd955pzj55JNVh1FSmBDEUJ0QyIOm8QpoLAeiXJYppIQgl+toxfbLZUIgxNEeEOPtqVTqsso+ZRZzsjIyOYkFRN/mME5nQpC5O+64Q5xyyimqwygpHFRoMTt37gSAuAO7jOQIaLOBS06nM+n8ssxY6ykEqtaxWNovVnV1NXp6euDz+eB2u0d9nu32jh0EO1byCYF0ypitkxwAOXfu3KzGR+CgQgWYEFhIKBTCz372M2iahtra2qTlly5dCgDYvXu3Pk0+rpjoN9XlwVU+Y51pPYUk3+sY28aFQJ7YU33kVdM0/R0FsbLV3h6PBwDQ2dmpz5+NtyhGIpGkccSWWbhwIYDoddq7d2/UZ7FcLteY4ixl7777LiZMmKA6jJLChCDPjAdb4/8PDAygpaUFAKKeX0702NKiRYugaRrWrFmjl9u4cSOcTueohEI+KhaJRNDZ2QlN0/QrnlTqkVdK8kRnfCxLvs3NeAVltdfe5mMdE7VxpnXn87HDqqoqPX4j46OCsZqamkxPesna21iXXJ5xufLzT3/60wCOvANh8uTJsNlsmDp1qn6ilo8jGt8DEKurqyvqUcXh4WFs27Yt6juSSplZs2bB4/HgnnvuQSQSQSQSwT333AOPx4NZs2ZFLVP2HFxyySVx46LE/vOf/2DixImqwygtqu9ZWA1yOIYAcQZHAUdGI8vHr+LNYzYIKhgMCo/Ho5fxer1RTyPI6X6/X78H6vF4Rj2xkKyeQCCgzy8fpZKPg8mBZfK+ssvlGvVIVzZleo81V+uYShtnWnc+HzuUgwWN+6HZvmom3X3TrM54ywkEAvqof6fTGfVYpMvlEk6nM+EAQePjhC6Xy/SRxVTKxJbVNE309vaalpFPVGTyPeAYgiO+853viLlz56oOo6TYhLDwu0YVsNls6O7uxpIlS1SHkhXyHlwxbWZ5dbh+/XrFkRxhxTZet24dGhsb045J9kzcfPPNuQgrZxwOB3p6elSHoWttbcXkyZMzaker7d+qfPWrX8WTTz6JRx55RHUoJYO3DIhI19LSgq1bt8Z9m58V9ff3Y+XKlarD0A0MDETdAqTMvPPOO7xlkGdMCIqY8T4tX6GaG8XWxna7HR0dHVizZk3C+/JWsWXLFkyZMkX/7QXVhoaGsHbtWnR0dET9Vgmlj2MI8o8JQRGbOnWq6f9T9hRjG1dUVKCzsxObN29WHUpStbW1+mBIK/D5fLjlllss/0NPhYA9BPlXpjoAyh0r3dMuVsXaxna7veDGEVgB2yx7/vOf/+g/HkX5wR4CIiKynDfffBNTpkxRHUZJYUJARESW8/rrr+Pkk09WHUZJYUJARESW8/rrr+OUU05RHUZJYUJARESWsn//fuzfv58JQZ4xISAiIkt57bXXAIC3DPKMTxmYaGxsRGNjo+owKAn+ElpybKPCVF9frzoEpV5//XUAYA9BnjEhiNHd3a06BCoATzzxBNxuN37zm9/g+OOPVx0OFZnTTjtNdQhKMSFQgwlBjGL5DQPKrWeeeQbnnHMO/ud//kd1KERF54033kBZWRnf9phnHENAlIFdu3bhoosuUh0GUVHas2cPpk+fzlteecaEgCgDO3fuxNy5c1WHQVSU9uzZU/K3TVRgQkCUpmAwiFdeeYUJAVGO7NmzB7NmzVIdRslhQkCUpieeeAI2mw0f/OAHVYdCVJSGh4eZECjAhIAoTTt37sRZZ53F96wT5QhvGajBhIAoTbt27eLtAqIc2b9/P9544w0mBAowISBK086dO/mEAVGO7NmzB0II3jJQgAkBURpef/11vPzyy+whIMqRPXv2AABmzpypOJLSw4SAKA1PPPEEAGDOnDmKIyEqTs8//zzsdjvfUqgAEwKiNOzcuRNnnHEGD1ZEOTI0NIRzzz1XdRgliQkBURo4oJAotwYHB1FVVaU6jJLEhIAoDUwIiHKLPQTqMCEgStGbb76JQCDAJwyIcuS9997DSy+9xB4CRZgQEKVo586dEEJwQCFRjrz44os4ePAgewgUYUJAlKKdO3fitNNOw9SpU1WHQlSUhoaGYLPZMHv2bNWhlCQmBEQp4vgBotwaGhrCzJkzMXHiRNWhlCQmBEQpYkJAlFtPP/00LrjgAtVhlCwmBEQpiEQi2L17NwcUEuWQ3+/nr4gqxISAKAVyQCF7CIhy491338Vzzz2H6upq1aGULCYERCnYtWsXKisrMW3aNNWhEBWlZ555BiMjI+whUIgJAVEKdu7ciQ996EOqwyAqWn6/H8cddxzOOecc1aGULCYERCnYtWsXxw8Q5dDAwAA+8IEP4JhjjlEdSsliQkCUxFtvvYUXXniB4weIcogDCtVjQkCUxJNPPonDhw8zISDKESEEnnrqKbeE0bsAACAASURBVA4oVIwJAVESu3btQkVFBWbOnKk6FKKi9OKLLyIcDvO14IoxISBKguMHiHKrr68PEyZMYEKgGBMCoiR27tzJ2wVEOfTYY49hzpw5mDBhgupQShoTAqIE9u3bh6GhIfYQEOVQf38/ampqVIdR8pgQECXg9/tx6NAh9hAQ5cj+/fvx1FNPMSGwACYERAns2rULJ598Mk4//XTVoRAVpccffxwjIyNMCCyACQFRAhxQSJRb/f39mDZtGpNuC2BCQJQABxQS5dZjjz3G3gGLKFMdAJFVfOQjH0FlZSU+9KEP4aKLLsL555+P5557Dt/73vdUh0ZUtPr7+/HVr35VdRgEJgREUe677z789a9/xcjICACgvLwcv/rVr/Dcc89h7ty5uOiii1BZWak4SqLiMDQ0hL1792L+/PmqQyEwISDSnX/++foAJ2lkZAQPP/wwHnnkEbz33nsAgMsuuwybN29WFSZR0Xj44YcxadIk/pKoRXAMAdF/zZ49G+PGjf5KHD58WE8GAODb3/52PsMiKloPP/wwPvaxj6G8vFx1KAQmBES62bNnR/UOxCovL4fD4cDll1+ex6iIipMQAlu3bsWll16qOhT6LyYERP81e/ZsCCESlvnZz36Wp2iIits//vEPvPrqq0wILIQJAdF/nXPOObDZbKaflZWV4f/9v/+HM888M89RERWnLVu2wG6387FeC7GJZJdERCXklFNOwRtvvBE1bdy4caioqMALL7yAiRMnKoqMqLgsXrwY7733Hnw+n+pQ6L/YQ0BkUFVVNWqaEAK33347kwGiLBFCYNu2bbxdYDFMCIgMzjvvPJSVHX0at7y8HB//+MdRX1+vMCqi4uL3+/H666+jtrZWdShkwISAyCD20cNDhw7h9ttvVxgRUfHZuHEjKisrUV1drToUMuCLiYgMzjnnnKi3FDqdTnzgAx9QHBVRcdm4cSOuuOKKuIN4SQ32EBAZnHPOOfqjhxMnTsQPfvADxRERFZe33noLjz32GBYtWqQ6FIrBhIDIYPbs2fpVy49//GNMnjxZcURExeXBBx/E4cOHUVdXpzoUijHqlkFfXx9+8pOfqIiFyBLGjx+PY489Fps2bcIDDzygOhyirPjGN76BefPmqQ4DGzduRE1NDaZMmaI6FIoxqodgz5492LBhg4pYiJTZsGEDXn75ZQDACSecgDlz5vD+Zoz+/n709/erDoMysGHDBuzZs0d1GBBC4IEHHsAVV1yhOhQyEXdQ4fr16/MZB5FSNpsNX//617FkyRI8/PDDfD7aRENDAwAeGwqRVZLbp59+Gv/61784fsCiOIaAKAaTAaLc2LRpE6ZOnYo5c+aoDoVMMCEgIqK88Pl8uOKKK0x/ZpzU41YhIqKcCwaD6Ovrw9VXX606FIqDCQEREeXcX/7yF0yYMAGXX3656lAoDiYERESUc3/+85+xcOFCHH/88apDoTjGnBCEQiF0dXXB4XBkIx7LL9dK4rVBa2srWltbc778fC2nULA9EguFQmhra1MdRsFpa2tDJBJRHcaYvP3223j44Yd5u8DixpwQrFq1Cs3NzWP+TetIJJLWozHZWm4hy2cbpLt98m1gYADt7e1wOByWjjOXrLyNQqEQVq1ahYkTJ8Jms8Fms8VNnuTnxj+rGhgYiIpz+fLlGZXx+XxwOBxwOByjvs91dXW4/vrrEQqFcrYeuXb//ffj4MGDuPLKK1WHQomIGN3d3cJkckIA0p4nVk9Pj5LlFrp8tUEm2ydf3G630DRN9PT0iEAgkFEdAER3d3eWI8uvXG+j+vp6UV9fn/Z84XBYaJom+vr69H97vV4BQLhcLtN5gsGgACCCweCYYs41j8ejfwcBiJ6enrTLeL1eoWmaCIfDIhwOC6fTKTweT1SZvr4+vUwmVO/fjY2N4rLLLlO2fEqNJX7tMBKJoL29XXUYFIeVt8/y5ctxyimnoLOzE3a7XXU4ylh5G3V0dKC6uho1NTUAALvdjqamJjQ3N2P16tW44IIL0NTUFDVPRUVF1H+tqrKyUv8xrEzKDA8Po7m5GX19ffr+63Q68cEPfhCXXHKJ/vPANTU1mDFjBjo6OnDzzTdndyVy7N1338XGjRvxwx/+UHUolERWBxXKe4SyW2x4eFj/TB6wjN2FsgvM7Xbr3WSxXYSRSARdXV369HgHPZ/Ppy83na612Pvwsh6HwxEVf7xY5LJCoZDe7ReJRLB8+XJ9Hc3qN7aPrDO2zZK1WyrrI5l1w8r1TLYcs+2TaAxHsnZKtb2TkV3Ot956q/JkwKw9UllX434DQN8Gy5cvx9DQEIDobSfFTov3HVI9riEUCmHFihVxX/bkdrvR3NyMrq6ulOrL1r5lPFY5HA5s2bIl7XUbHh6Gw+FAa2tr3Fc6Jyuzfft2AMD06dP1adOmTQMA7NixI6psQ0MDVqxYUXC3DrZs2YK3334bn/70p1WHQsnEdhmM5ZaB7BIMBoNC07SoLj+n06n/OxAICADC6XSOqiOWpmlR3YpOp1P/d+xyBwcHR9WbjIzTWI9ZfLKs7MqT6yi78WLr8fv9wul0Rk33+/1CiCPdf7L+ZMtMt92MyzMybgshjnYvyy72bC0n3XZKtO6J+P1+vftVdslqmiZ6e3tTrsMIY+xSNWuPVNZVfm4sI7uNAYjBwUG9+9xYt6zHOM1se7hcrrjd8unK5JZB7H5mJGN1uVxR34/Yz42ysW/J+bxerxBCiN7eXtPlp7pu8k/TtFG3OJKVkdvZrG00TYuaJtfF7LZEMmPdv8fi85//vLj44ouVLJvSk7MxBPLkLL+8Lpcr4QnGrA55n9H4BZL30uLNE+8klW78sdPkQSM2FgD6gUXOE3ufL9U44x3Q0223ZG0gt43x5Jmt5aTTTunEHMvtdkcdxI0nUXkySEc2DpiZbmezMjLhcbvdY6onmzJJCOTJ3oycbjyZDw4Ojvpcyta+JY8rsWUySZzC4bDw+/36esbe+09WJt42M5seDoej9ol0qEoI3nvvPTFlypSMYqb8y+mgQrPpgUBAP5gnO5jJg0Q6y81VQmCWycsvaKIEJZ04E8WeTrslqkdeHcX7go51OZm2U7rbLdFJNJ2eBmN9VkoIYqcXakKQKCbjdNkLYryCztW+ZexJiP0bC4/HM+qqPlmZdI4ZiaYnoyoh8Pl8wmaziZdeeinvy6b05TUhkF8GeYU6lhNbpvNkWk+mB+104ow3fzbbzeVyxT1oZWM52Tq5JWPFAyYTgtFSTQiEOJrQyVsAudq3ctVOZjEnKxPvogcwT2wLLSG47rrrxEc/+tG8L5cyk/M3FTqdTgBHBs4tW7YMv/zlL1FVVZXSvJqmATjyHK9qMhazAT1yHXMhk3aLp729HatXr8Yvf/nLnC0nX+0k6zJ7YYuMoRjkct+ymurqavT09MDn88Htdo/6PNv7lhy0mS12uz1pHLFlzNZJDoCcO3duVuPLtwMHDqCnpweNjY2qQ6EU5SwhkCfxBQsWAACam5sBALNmzUq5DvllWbt2rX7gHx4eNn2xR64tXboUALB79259moxJ/k58LmTSbmb6+/uxbNky9Pb2mtaVreXkq51kXS+99NKo5cgYCpk8WRX6i1zkiT3VN+1pmgav14vVq1eP+ixb+5bH4wEAdHZ26vNn4y2KkUgkaRyxZRYuXAggep327t0b9Vksl8s1pjjz5f7778e+ffuwePFi1aFQqmK7DDK5ZSC7veQgNbP71LJMIBCI6pKW9wuNTyXI+YxPK8g/p9M5auS1rEN2xxmnJWOsRw4GNKtHDnwy3uP0er16t57ZSPB49ZvFbjYtWbulWo8cnRw7bkCWzWT7xIs3nXZK1N6pkLc/5Dyp3MONB2PsUk22LRKtq/y3HBgXDodH3doxPnUgxNHBdPI7IYT5d8iqTxkke/GQ2WDEbO1bxnLGPxlj7IBVM16vN2pQbiAQMH3hULIyQhzZb51OZ8IXE8n5gcJ5yqChoUHU1tbmdZk0NllJCIQ4MgJYHpCcTueox7/k/UGXyyWCwaA+ql1+CWM/l2RZ+Zk8IMZ+meNNS9oAadQTDAaj3jrm9Xr1A4+xvNmgoWT1x1tmonZLtZ5Eg6hkmXS3T6K2TrWdxrLdJONyPB6Psje5jWU7y//3+/36topdl0AgoH8mTwjy0Tn5fTH7DqlOCOS+YnzyI94+GMssucvWvhUIBPTjinE/F+LoEzeJkkvj44Qul8s0eUilTGzZRI/OyiQwk7c35jsh2Ldvn5g4caL41a9+lbdl0tjZhBACBuvWrUNjYyNiJhMVNZvNhu7ubixZskTJsgFY/jsnu7rXr1+f1nyyK77Q3rDncDjQ09OjOgxda2srJk+enFE75nv/9nq9+OxnP4t//etfln/bJB3Fnz8mopxqaWnB1q1b477Nz4r6+/uxcuVK1WHoBgYGMDAwgJaWFtWhpKSrqwuXXXYZk4ECw4SASCHj6PJCeyVtqux2Ozo6OrBmzRpLPDGUzJYtWzBlyhT9txdUGxoawtq1a9HR0aH8Fd2peO2117Bx40Zcd911qkOhNBV1QhDv/f2F8tOqpaqUttvUqVNN/7/YVFRUoLOzE5s3b1YdSlK1tbVjfsQ3m3w+H2655ZaCudq+9957MWHCBHzmM59RHQqlyRK/dpgrVr8nS+ZKabuV0rra7faCG0dgBYXWZr/73e/Q0NCASZMmqQ6F0lTUPQRERJQ/zz77LHbt2oXPfvazqkOhDDAhICKirLj77rtx+umnY/78+apDoQwwISAiojE7fPgwvF4vrr/+eowbx1NLIeJWIyKiMXvooYfw8ssv49prr1UdCmWICQEREY3Z7373O8ybNw/ve9/7VIdCGYr7lEGxPNZFlKrGxkb+MlsKeGygWG+99Rb+/Oc/m/5KJRWOuAlBd3d3PuMgUqqxsRE33XQT5s2bpzoUy/rpT38KAPj617+uOBJKV64T3e7ubhw+fBhNTU05XQ7lVtyEQMU73YlUaWxsxLx587jfJyB/w4BtVHhynRC0t7dj8eLFOOmkk3K6HMotjiEgIqKMPf3003j88ccL5ncWKD4mBERElLH29nacddZZWLBggepQaIyYEBARUUYOHDiAP/zhD1i2bBkHmxYBJgRERJSRDRs24K233uKriosEEwIiIsrIr3/9a2iahmnTpqkOhbKgpBKCUCiErq4uOBwO1aHkRbz1bW1tRWtra86Xn6/lUGEIhUJoa2tTHUbBaWtrQyQSUR3GKLt378bWrVs5mLCI5C0hSPS79m1tbWhvb0+7zkgkktZ9q1WrVqG5uRk+n8/08y1btugxxTuRmcVvVcnWN5vS3RZ0RC7bzUrbJBQKYdWqVZg4cWJRfccGBgai4ly+fHlGZXw+HxwOBxwOx6jva11dHa6//nqEQqGcrUcmPB4PZsyYgYULF6oOhbJFxOju7hYmk7MiGAwKAKPq7+3tFQCE1+tNq76enp60YzVbvlE4HBZer1cAEC6Xy7SMXI9gMJjWslVItr7Zksm2sBIAoru7O+/LzWW7Zbvu+vp6UV9fn/Z84XBYaJom+vr69H8Xy3fM4/Ho3zEAoqenJ+0yXq9XaJomwuGwCIfDwul0Co/HE1Wmr69PL5OJbO/f7733nqisrBTf+973slYnqZfXhECI+CcoAELTtJTrkQeZbCcEseXiJSmFcvLLR0KQ6bawEhUJQS7bLRd1Z5oQuN1u0xN/MXzHzBKAdMoEAgEBQE+WhBDC7/cLAMLv90eVdTqdwu12ZxRntvfv9evXi2OOOUa89NJLWauT1LNUQhA7PRwOR2XXLpdLv2JwuVxRWbdxXuMVCICobNtYVl5BOZ3OUVciAITb7Y57wDJbB7PlynqDwaDo6enRs3yn06mvj7xCiI0pEAgIIYRep3FaKm1k1q6xy4stF/sny6W7LeItJ5V2MmsPTdNGrXs2ZXLATLQeZvtl7LR47Sb3EyGOXl06nU4xODg4prrl9HhX5clkkhDIK/3e3t5Rn+XiO5bqvhMMBvVla5pmGl8y8mTucrmiTujplJHrYoxPtllsL4HsSc2k1yTbCcEnPvEJ4XA4slYfWYOlEoLYg4LT6dS/APKL5XQ6k9alaVrUQU+efI3zyC/n4ODgqHplOSGOHlhjs/V4y5Vf4mAwKDRN0xMAebUml+33+4XT6YyaLpfR19enxyTjNFv/TNrIuLzY9TEeaOTBVB6osrWcdNsp0bpnUyYHzETrYXZ7TK6H2Yk89t/G9ZcJJAAxODiYcd1C5D8hiN2PjHL9HRPCfN+R88njjTzRxi4/1XUzJs+xJ+tkZeR2NWub2GRarksqvRJm9WUrIXj22WeFzWYTmzZtykp9ZB3KEoLYP5fLNer+mMvlSnjSMTvgyYzb+KWT99/izRNvmhDRXa/yCs34uWSWvcsTuzzwyOXErmc6MZkd4NNto3gnakkmScarpmwtJ512SifmsUr3gJmt9Uh1XWU3suwyzrTuscgkIZAnezO5/I7FLsc4TR4jYstkkiiFw2Hh9/v19Yy9qk9WJt42MpseDoej9oF0ZDMh+NKXviTOPvtscejQoazUR9ZhiR6CYDAoXC6XaYYtxJHMWHbvJTvgJbtvmm5CIOOLze5jy5tl+vILnCgZSTemeOuWThslqkdePcU76Ix1OZm2k9USgmytRzrrapxeKAlBohjy9R2LnWbsSYj9GwuPx5N0HFRsmXSOCYmmJ5OthODtt98WJ554YsZjGcjaLJEQCHH0gBCbpcsvkLxqHcvJLp154l2hye7JbB3E043JbP5stpFMzMxkYznZOtllW7oHzFyetEsxIRAid9+xXLeLZBZzsjLxLmAA81tkqhOCO++8Uxx33HHi9ddfH3NdZD2WSQjMPosdcJPKF1t+weLdD8w0IRDi6P1As25QuVyzwYnyi52LhCCTNkqUWBjrysVyMm0nqyUE2VqPdBOCsdY9FrlOCITIzXcsXrsYb09kSyrjXIxl5HfOuE5yrIDZ7QfVCcEHPvABceONN465HrImy7ypcHh4GADgdDr1ac3NzQCAWbNmpVyPpmkAgLVr1+pv9xoeHjZ9GUi6NE2D1+vF6tWrR322dOlSAEfe3iXJ5Tc0NIx52fFk0kZm+vv7sWzZMvT29prWla3lqGqnbMv3egwNDQEArrzyyqzXnUtutxsAUn7TXj6+Yx6PBwDQ2dmpz5+NtyhGIpGkccSWkS/1Ma7T3r17oz6L5XK5xhRnph555BE89dRTWTmWkkXFZgj5ejGRcWDd4OCgfkVgzNrlFUEgEIjqppbZtPGKQd7TkvfAZVng6CNbxuXLOmQXnnFaspeimF29yIFRxnugXq9XvxqI91ImszYxi9NsWrI2SrUeeUUSe19Qls1kW8SLN512ku1hto2yDWleQSVbDyFE1JMBQhwdACf3SSHM92FZRg6UC4fDo27lZFq3VZ4yyPV3LNG+Yyxn/JMxyjEyiZ468Hq9UYNuA4GA6QuHkpUR4kgvgdPpTPhiIjk/oO4pg6amJnHJJZeMqQ6ytrwlBGZfQPknHyWKPWjIe4rymXc50l2Wi/1ckmXlZ2bPb8t1TBSX2QlcMrvPHgwGo57V93q9+oEpdn3jtUs605K1Uar1JBpkJcukuy0StWGq7ZRs3bMpkwNmovUQ4sgBXLatPIjLx93k/mq2D8v6/H6/Pr/H48lK3areQ2B8Bj8f37Fk+04gENCPEbHv95D7dqIBgsbHCV0ul2nykEqZ2LKJ3okgkz4V7yF45ZVXxPjx48Xdd9+dcR1kfTYhhIDBunXr0NjYiJjJREXNZrOhu7sbS5YsUR2K/u5+q30HZVf3+vXr05pPdsXffPPNWY8plxwOB3p6elSHoWttbcXkyZMzasex7t+33norfv7zn2PPnj047rjjMqqDrM8yYwiIqDi1tLRg69at6O/vVx1Kyvr7+7Fy5UrVYegGBgYwMDCg5JcFR0ZG8Ktf/QrLli1jMlDkmBAQWYjxF+2s9ut2mbLb7ejo6MCaNWswMDCgOpyktmzZgilTpqCmpkZ1KACODChdu3YtOjo6YLfb8778rq4uBINBDiYsAUwIiCxk6tSppv9f6CoqKtDZ2YnNmzerDiWp2tpaVFVVqQ5D5/P5cMstt6CiokLJ8m+//XbU19fjtNNOU7J8yp8y1QEQ0VFWGzeQTXa7veDGEViByjZ79NFH8fjjj+MXv/iFshgof9hDQEREpn7+85/jQx/6kGVun1BusYeAiIhGGR4exp///Gf87ne/Ux0K5Ql7CIiIaJQ77rgDFRUVWLx4sepQKE+YEBARUZR33nkHv/71r/GlL30J48ePVx0O5UncWwbr1q3LZxxEyvX19akOwdJefvllADw2lIJ77rkH+/btU/LeA1In7psKiYioeKT6pkIhBC644AJ85CMfQUdHRx4iI6sYlRAQUe6tW7cO1113HW688UbceeedGDeOd+/IGu677z7U19fjqaeewgUXXKA6HMojJgREivz1r39FQ0MDFi9ejLvvvhtlZXzoh9S7+OKLcfrpp2PDhg2qQ6E84xGISJGrrroK9913H6655hocPHgQnZ2dKC8vVx0WlTCfz4edO3di7dq1qkMhBdhDQKTYtm3bcNVVV2HBggXYsGEDJkyYoDokKlEf/vCHUVlZib/85S+qQyEFeOOSSLH58+dj48aN2LZtG66++mrs379fdUhUgjZt2oQdO3bA5XKpDoUUYQ8BkUXs3LkTCxcuxIUXXoi//vWvmDRpkuqQqEQIIVBTU4MpU6Zg48aNqsMhRdhDQGQRF110ETZv3oxnn30WixYtwltvvaU6JCoRnZ2d2LlzJ2677TbVoZBC7CEgspjnnnsOdXV1qKysxAMPPICTTz5ZdUhUxN555x2cd955WLRoEQcTljj2EBBZzPve9z488sgjePPNN1FXV4fXXntNdUhUxG677TaEw2F8//vfVx0KKcaEgMiCzjzzTDz88MPYt28f5s+fj71796oOiYrQyy+/jLa2NqxatQqVlZWqwyHFeMuAyMJeffVV1NXVYWRkBL29vZg5c6bqkKiINDU1YdeuXfj73//OHzEi9hAQWVllZSV6e3tx7LHH4mMf+xhefPFF1SFRkfD5fOju7sbPf/5zJgMEgD0ERAXh3//+N6644grs2bMHmzdvxvnnn686JCpgkUgEF154Ierq6vDb3/5WdThkEewhICoAJ510Eh544AGcccYZqK2txdNPP606JCpgN910Ew4ePIi2tjbVoZCFMCEgKhCTJ0/GQw89hAsuuAALFizA448/rjokKkC9vb245557cMcdd2DKlCmqwyEL4S0DogLzzjvv4Oqrr8aOHTuwceNG1NTUqA6JCsRbb72F97///Zg3bx66urpUh0MWwx4CogJz/PHHw+fz4ROf+ATq6urw8MMPqw6JCoTT6cS7776L22+/XXUoZEFMCIgK0Pjx49Hd3Y1FixbhqquuwkMPPaQ6JLK4X//61+jq6kJHRwdOPfVU1eGQBTEhICpQ48ePR1dXFxoaGqBpGn+yluJ69tln8dWvfhXf+ta3cNVVV6kOhyyKYwiICtzhw4exbNkydHZ24t5778XixYtVh0QWcuDAAdTU1GD8+PF49NFH+c4BiqtMdQBENDbjxo1De3s7Jk2ahMbGRvzmN7/BZz/7WdVhkUV87WtfQyAQwJNPPslkgBJiQkBUBGw2G372s5/hhBNOwI033oiDBw/ixhtvVB0WKdbR0YH29nZs2LABZ5xxhupwyOKYEBAVkVtvvRWTJk1CS0sL9u3bh69+9auqQyJFtm/fji9/+cv47ne/i2uuuUZ1OFQAmBAQFZlvf/vbAI6+je4b3/iG4ogo34aHh3HNNdfgiiuuwC233KI6HCoQTAiIitC3v/1tnHDCCfjyl7+Mt99+G6tWrVIdEuXJ/v37UV9fjylTpuCee+7BuHF8mIxSw4SAqEh98YtfRFlZGZYvX479+/fjtttuUx0S5ZgQAp/73Oewe/duPPbYY7Db7apDogLChICoiC1btgyTJk3CDTfcgH379uH222+HzWZTHRblyLe+9S3cd9992LhxI84++2zV4VCBYUJAVOSWLl2KsrIyXHfddTh48CDuvPNOdiMXoTvvvBNtbW347W9/i9raWtXhUAFiQkBUApYsWYLjjz8eDQ0N2LdvH+6++26UlfHrXyzWrVuHr3zlK/jRj36EG264QXU4VKD4pkKiErJp0yZcc801cDgc6OzsRHl5ueqQaIy2bt2KhQsX4vOf/zzuuOMO1eFQAWNCQFRitm3bhquuugoLFizAhg0bMGHCBNUhUYZ27dqF2tpaLFy4EF6vl7eCaEyYEBCVoP/7v//DlVdeiY9+9KP44x//iOOOO051SJSmp59+Gpdeeikuuugi9PT0MLGjMWNCQFSidu7ciYULF+LCCy/EX//6V0yaNEl1SJSioaEhLFiwALNnz8amTZswceJE1SFREWBCQFTC/H4/PvnJT+Lcc8/F/fffjxNPPFF1SJTECy+8gAULFuD000/Hgw8+yESOsoYJAVGJe+6551BXV4fKyko88MADOPnkk03L7d+/n7cWFPvnP/+JBQsWYPr06XjwwQeZwFFWcQQKUYl73/veh0ceeQRvvvkm6urq8Nprr40q43a78ZWvfEVBdKXl7bffxve+9z3Tz+RtgoqKCmzatInJAGUdEwIiwplnnomHH34Y+/btw/z587F37179s1/+8pf45je/ibvvvhu7d+9WGGXx++EPf4hbb70VP/7xj6Om/+Mf/8Cll16KqVOn4sEHH8TkyZMVRUjFjLcMiEj36quvoq6uDiMjI9i8eTMefPBBfOELX4AQAuXl5Vi6dCnuvvtu1WEWpRdffBHnnXceRkZGYLPZsH79eixevBi7du3CwoULcd555+H+++/HCSecoDpUKlJMCIgoyquvvorLL78coVAIr7/+5qYpuwAAIABJREFUOg4fPqx/Nm7cOPzjH/9AVVWVwgiLk8PhwKZNm/SEoKysDGvXrsU3v/lNXHLJJfjTn/7EMRyUU0wIiGiUe+65B5/73OcAHPkFPam8vBxNTU343e9+pyq0orRlyxZcdtllUdOOOeYYjB8/Hh/72Mfg8/n4ngHKOSYERBTlgQcegKZpOHjwIMwOD+PGjcOzzz6Lc889V0F0xefQoUO48MIL8fzzz+PQoUNRn5WXl2PWrFl4/PHHcdJJJymKkEoFBxUSkW7z5s3QNA2HDh0yTQaAI1eut956a54jK15r167F0NDQqGQA/7+9Ow5x27rjAP5VkpbR/OEsLReadv1jjNv2R+bR/nPdGCMhWyBMHt3u0l1oWsa8ToH+0S73xzhk0pCQf6Zbyyj0Zt8/243ZTgoDu9v+yR1NGT2vY2CzwbhjZPMthEoUKhdWut66tz9uT5Ft2ZZs2ZJ93w8cJNLze096T9LPT08ygJ2dHWxvb+Mb3/gG/v3vf0dQO9pLOEJARACAP/7xj/jqV7+KDz/8sGMwIHGUIBzvvfcePv3pT8O27a7pDhw4gPn5efz85z+Hoigjqh3tNRwhICIAwGOPPYZf/vKXeOyxxwAA9957b8e0+/fvx4svvjiimk2uF198Ef/617+6plEUBUIIXLt2Devr6yOqGe1FHCEgoja///3v8fLLL+PXv/419u/fj52dnbY0+/btw1/+8hd8/vOfj6CG4++vf/0rjh075nmrANidP7Czs4PPfOYzSKfT+N73vocHHnhgxLWkvYQBARF19Le//Q0//elP8bOf/QxCiKbA4J577sG3vvUtFAqFCGs4vr7+9a/jjTfeaNqniqJg37592LdvH775zW/iBz/4AU6ePBlhLWkvYUBARD2ZpolXX30VL730Ej744AP85z//AbB7AavVajh27FjENRwvr7/+OlRVdf5/77334qOPPsKxY8fw3HPPYX5+ni8gopFjQEBEvr3//vvI5XL48Y9/DMuyIITAt7/9bbz22mtRV21sfPTRR/jc5z6Hv//979i3bx/uu+8+fPe730U6ncYXvvCFqKtHexgDghiam5vjCZaIiEIxOzuL69ev90x3YAR1oT7MzMzghRdeiLoaFNCTTz6J559/Ho8//njUVRkJIQRqtRpM08SpU6d8feall14CgD3Zv3d2dvD6669jZmYGDz74YNTVoT1AHm9+cIQghubm5gDAV0RH8aIoCorFIs6cORN1VWKL/ZtodIIcb3wPARERETEgICIiIgYEREREBAYEREREBAYEREREBAYERLGTyWSQyWSirkasKIrS9OfFsiwsLS2NuGbjb2lpCY1GI7T82A796dYOfvp/GBgQUCQajUYkP+MaVbnjJM77SAjh+dPMlmXh4sWLOHjwoHPS7BRUtZ5c47qtAFCr1Zrqef78+b7SlMtlpFIppFIplMvlpnUnT57EuXPnYFnWwPVlOwynHTr1+7AxIKBIvPnmm3uq3CAuX76My5cvR1b+OOwjt0ajgXQ6jWeeeQaapsG2beTzeVy5csXzYiSEgGmaAHZ/oyHOr2J5++23m/5/+vTpwGkKhQJyuRxWV1exurqK3/72t8jlcs76ZDKJxcVFpNPpgUYK2A7xaIeBCIqd2dlZMTs7G3U1hsa2baGqqhh19xtFuQBEsVgcWv7DNop91E//BtCxToZhCF3XO34mn893zDPuSqXSQGnq9boAIDY2Npxl1WpVABDVarUpraZpwjCMvuvKdhh+O3Q7DjoJcrxxhGACNRoNFAoFZ+jKHYV2Wi+HqSzLQqFQQCqVArA7xKUoClKpFLa3t32X02g0kMvlmoYNZRmGYTjDZa1DhfL+oyxzfX09UL3CLnfUWrfTa5nXtluW5QxHAnD2wfnz57G1tQUAnkOzrcs67aO4zmuwLAsLCws4fvy453rDMDA/P+/7J5rDOjbC6E/b29tIpVLIZDKoVCp9pXnrrbcAAEePHnWWyVcmt36jnZubw8LCQl+3DtgO8WiHgQUKNWgkBh0hUFW1KVLXNK3p/6qqimw2K4QQwjRNoaqqUFW16dshXNGsjG41TfNdjqZpAoAwTdPz8/CIdGVd5DeJtbU1J4L2W6+wyw0KA44QuLfTa1mnbZfr3Wls23b2x+bmpjBNsy1vmY97mdc+0nXd89tfP8IcISiVSgKAqNfrnp8RYrfuXu3plV8Yx0ZY/Ulum/xTVVWYphkojWx/r32jqmrTMrktfr4Nd6or22G47dDpOOgmyPHGgCCGBgkI8vm8c0GUNjY2nE4nD4rW9XAN6Xl1utZlvcrRdb3rhdirDJlna7nyQuSnXsMoN4hBA4JOdfSzzCuNHJaUQ5D95hOmMAMCeZHp9Bkhmm+DbG5utq2Xwj42WtP0059s2xbVatXZTnmR9Jum037zWm7bdlNfCYLtMJp2YECwBw0SEPS6/+sVqcoOKC/mfg42v/eZ6/W6MAzD10XHHfm3/vmt1zDKDSJuAUHr8kkLCLrV1b1cjo64v7m1fi7sYyOM/uSWzWbbvk32ShN0vw3S79kOndOE1Q4MCPagQQKCXh1mlBcNeVBsbm76+nw/dfdaFna5QTAg6C2KgECIu6MlcujZbz+Iy/7zqnOvNJ0Cd6D9FqBcPsyAQAi2g1vQdhh2QMBJhRNGVVUAu8/EdlvvNWFF07TQyikUCnj22WfxyiuvYHp62ne+AJxJcP2Iqty4C9K2kyqZTKJUKqFcLsMwjLb1YR0bUtj9KZFI9KxHaxqvbZIT7x599NFQ6+cX22FX1O3ghQHBhJEdb3l52XmWdXt723lJxtmzZwEAt27dcj4j08nfzQ6jnPn5eQDAI4884jvPbDYLAFhdXXXyDPrWs6jKjSt5MvR6bnoSyAuK3+e2VVV1no1vFdaxMaz+1Gg0etajNc2pU6cANG/TnTt3mta10nU9cN3YDt3TjKodBhZo7IFGYpBbBnJmLVz3yzRNcybxyIk97nt4+XzeGbZyz0S3bdv5jFwmP9OrHLmuXq83Dd3Lz8v1pmk6k2fcZbv/6vW673qFXW5QGPCWgbsu7n3tZ9vl/+XEK9u2ha7rTfcy3U8dCHF3spZsPyG899G4PWUg91nrbHDJaxJcmMdGt/4k57Z0m+2ez+fF2tqa8/96vd4269xPGiF2b6FpmiZs23aePPGaFOc1u91PXYVgOwy7HaROx0E3nEMw5gZ97NA0TedA03W9aUavXJ/NZpsuIPLAaj14Oi3rVY68T6jrupNO0zTnYGxdL9XrdSdPd3q/9Qq73KAGDQj8bme3Ze7HNLPZrNO2cjvlOnnCkY9myf3htY/iGhDIk777hS9eFwEvXhPDwjo2uvUn2Se7TUxzP8am67rnRctPmta0qqo2XbzcZHDoPi781FUItsOw20EadkCg/L8QihE51HT9+vWIa0JBKYqCYrGIM2fORFI2AMT9kO6nf3fbNjkEfOHChRBqNzqpVAqlUinqajgymQwOHTrkuR/91JXtEI5u7dDPMR7keOMcAiIaa+l0Gjdv3uz4Frk4qlQqWFxcjLoajlqthlqthnQ63bbOb13ZDoPr1g6jwICAaAK4Zy9H8srTCCUSCaysrODq1asdn3qJk/X1dRw+fBgzMzNRVwXA7sTT5eVlrKysIJFINK0LUle2w2C6tcOoMCAgmgBHjhzx/Pek6fQzuVNTU1hdXcWNGzciqFUwJ06cCPxI7DCVy2VcunQJU1NTbeuC1pXt0L9u7TCqn4c+MPQSiGjo4j5vYFB+ti+RSIzd/es4CHufsR36022fjer45ggBERERMSAgIiIiBgREREQEBgREREQETiqMrdu3b+PatWtRV4P6sLGxEXUVYu327dsAwP5NNAK3b9/Gww8/7Cst31QYQ3Nzc3jttdeirgYREU2A2dlZX28q5AhBTPltQIqXKF9dPC74am6i0QnyC5GcQ0BEREQMCIiIiIgBAREREYEBAREREYEBAREREYEBAREREYEBARFRJCzLwtLSUtTVmEhLS0toNBpRV2PsMCCYQJVKBZlMxvkN7Uwmg1qtBsuyRvKb2kE0Go1I6hRVucMyzO2ZtH0VB5Zl4eLFizh48GDTcepFrnf/xVGj0UClUkEul0Mqleo7DQCUy2WkUimkUimUy+XAaU6ePIlz587Bsqz+N2gP4ouJJkwmk8G7776LF154AZcvXwawe/L5wx/+gC9+8YsR167dm2++uafKHZZhbs+k7auoNRoNpNNpLC4uYmZmBvPz8/jd736H+fl5AHCOW0kIAcuycOTIEZimiampqSiq3ZNhGACAK1euDJSmUCjgV7/6FVZXVwEAP/rRj/DOO+/g+9//vu80yWQSi4uLSKfTWF1dRSKRGGzj9gpBsTM7OytmZ2cDf07XdaGqasf1GxsbIk5Nbtu2UFV15HUaZrkARLFYDD3fboa5PcPIu9/+PSkMwxC6rrctByAAiHw+7/m5OB273cjt6CdNvV4XAMTGxoazrFqtCgCiWq36TiNpmiYMwxhkc8ZekOONtwwmRKVSwZUrV7C4uNgxzczMTNP/G40GCoWCMwyZy+WcITbLslAoFJxhvXK5DEVRkEqlsL293TMf97pcLtc0LCrLMAzDGeprHQqV91dlmevr64HqFXa5w9StHbyGiVuXeW2PZVnOkCoAZ1+cP38eW1tbA+UN7I5EdRrips4sy8LCwgKOHz/uud4wDMzPz6NQKPjKL6xjOIp+7+Wtt94CABw9etRZ9uCDDwIA3n77bd9ppLm5OSwsLPDWgV9DDk6oD/18g9J1XQAQpmn6/oyqqiKbzQohhDBNU6iqKlRVbfpWCFckLiNzTdPa8nF/49E0zfm/pmlOvbw+D49vCrIu8pvS2tqaE/37rVfY5fqFPkYIurWDaZptdZXb417W6f/u/WTbtrNfNjc3+85biN3+5vUt14+9PEJQKpUEAFGv19vWyX0sj+XWfud1ug7jGA6j37fWs9elpVMa2T+90svRTz9pJLm9pVIpyCZMlCDHGwOCGOrnhOnnIHSTB707gJC3FOSJwSvP1mX5fN4zH3lg6rre9ULsVYbMs7VceQHyU69hlOtH0IAgrHbwk0aIu0Orchi137wHsZcDAnmx9yKXuy/mm5ubbeulsI/h1jT9BnyDBAR+lgf5rG3bTf19L2JAMOZGERB4Rdny4JEXcz8nE7/3l+v1ujAMw9fFxv3NpvXPb72GUa4fQQOCsNohyD4Jui8ZEISn2750L5ejN6qqOhf81s+FfQwP0u/9bmOvNGEHBH7rM8k4h2AP0jQNAHw/e7u8vNy2TM7E7fSYjxc/aXO5HJ577jmoqhooT7EbsDb9BRFVuUGE1Q40WaamplCtVlEul5FOpz2P67CP4VH2+066HavyHOcnDfWHAcGEOH36NADgH//4h6/08qDymmwT5KCS+dRqNc/1hUIBzz77LF555RVMT0/7zheAM/mtH1GVG1RY7RAUT5zxl0wmUSqVUC6Xncf13MLuO6Ps9514bZOcAPnoo4/6TkP9YUAwIVRVhaqqnt8apO3tbefNaGfPngUA3Lp1y1kvv4XMzc0FKhfY/bYiP7+9vY3z588DgPNs9SOPPOI7z2w2CwBYXV118gz6Vreoyg0qrHbwS570ZQBJoyUv7H5H8lRVRT6f93xuP6y+E0W/7+TUqVMAmrfpzp07Tev8pGml63r4lZ1EYd+voMH1e49VzhbWNK1pMpIQu/fS3fcj5cQl97J8Pu9MxHPPQLdt2/mMXCY/I8uE676ju3y5rl6vi83NzbbPy/WmaToTf9xlu//q9brveoVdrl8IOIegVzsIIZqeDBDi7sQxua87bY9MIyeY2bbd9q6KfvPmUwb96fSUgex7nZ4S8pqMGOYx3K3fyzk4fp46cOcvywyaJpvNCk3ThG3bzpMx8kmKIGmE4FMGQnBS4dgb5IRp27YolUrOiR7/n2CUzWY9T0LZbLbpwiEP0NaTQ6dlMh95wtJ1vSkYkbPadV130mma5tSldb1Ur9edPN3p/dYr7HL9ChoQyP3XqR1kneRFWZ7Y5GNisu5e2yPzcz+umc1mQ8mbAUF/5MXX/VIdr4uxF6+XjoV1DHfr9/LY6fbSs07b0botftIIcTdwUlVVrK2teZbnJ40McIM8jj1pghxvihARzByhruRw3/Xr1yOuCQWlKAqKxSLOnDkTdVWclwjF7RDf6/1bDsVfuHAh4poEk0qlUCqVoq5GIJlMBocOHRq7fR2mIMcb5xAQEY1QOp3GzZs3UalUoq6Kb5VKpetbUOOoVquhVqshnU5HXZWxwYCAaAK5Z2Dzta3xkkgksLKygqtXr3Z8OidO1tfXcfjw4bZXn8fZ1tYWlpeXsbKywh82CoABAdEEOnLkiOe/KR6mpqawurqKGzduRF2Vnk6cOBH40d2olctlXLp0Kba/DBlX/PljogkUt3kD1C6RSOzpe9vDxP3aH44QEBEREQMCIiIiYkBAREREYEBARERE4KTC2KpUKkN5lz0N30svvbRnX7rjh3z+nv2baPgqlYrvR0YZEMTQ448/HnUVqE+zs7NRVyH2wnqe/c9//jMA4NixY6HkRzSJZmZmfF9T+OpiIhpL8vXQ165di7gmRJOBcwiIiIiIAQERERExICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIwICAiIiIAihBCRF0JIqJufvGLX+AnP/kJPv74Y2fZu+++CwB44IEHnGX79+/HD3/4Qzz99NMjryPRuGNAQESxt7W1hc9+9rO+0m5ubmJ6enrINSKaPLxlQESxNz09jWQyCUVROqZRFAXJZJLBAFGfGBAQ0Vh4+umnsX///o7rDxw4gGeeeWaENSKaLLxlQERj4c6dO/jUpz6F//73v57rFUXBP//5Tzz00EMjrhnRZOAIARGNhaNHj+JLX/oS9u1rP23t27cPX/7ylxkMEA2AAQERjY1z5855LlcUhU8WEA2ItwyIaGy89957OHLkCHZ2dpqWHzhwAO+88w7uv//+iGpGNP44QkBEY+OTn/wkvva1rzVNLty/fz9OnTrFYIBoQAwIiGisPPXUU00TC4UQeOqppyKsEdFk4C0DIhorH3zwAe6//358+OGHAIBPfOITePfdd3Hw4MGIa0Y03jhCQERj5b777sMTTzyBe+65B/fccw+eeOIJBgNEIWBAQERj5+zZs9jZ2cHOzg7Onj0bdXWIJsKBqCtABADXrl2Lugo0Rj7++GPcd999EELg/fffZ/+hQM6cORN1FWKJcwgoFrq9o56IKEy87HnjLQOKjWKxCCEE/4b4VywWASDyeoTx98Ybb+DmzZtDyZv9cTL/ZP8nb7xlQERj6Stf+UrUVSCaKAwIiGgsef2mARH1j0cUERERMSAgIiIiBgREREQEBgREREQEBgQ0QSzLQqFQQCqViroqEy+TySCTyURdjViyLAtLS0tRV2MiLS0todFoRF2NicWAgCbGxYsXMT8/j3K5HHVVfGs0GqhUKsjlch0DGcuykMlkoCgKFEVBoVAYcS3jp9FoxPJlVpZl4eLFizh48KDTXp0CJ7ne/RdHfvqonzQAUC6XkUqlkEqlOh6n3dKcPHkS586dg2VZ/W8QdSaIYgCAKBaLoeQzTt1a13Wh63rHepumKTY2Npz/5/N5AUAYhtFXecVicaz2TyelUmmo29FPf7RtW6iq6rSXbdtOe+m67vkZ0zQFAGGa5sB1HpZefdRvmnw+L1RVFbZtC9u2haZpIpvNBk6zsbHhpAlqUvr/sHDPUCzs1YBA6lRvdzDQK60fk3BClBfeuAUEhmF4Xvhle+Xz+Y5ljQM//a5Tmnq9LgA09edqtSoAiGq16juNpGlaX0HxJPT/YeItAxpbjUYDhUIBiqIglUpha2urLY28nyvTrK+vO8vd8w3K5bKTZnt7uykP+flcLgfLspqGdjvlH5aZmZm2bQYAXddDLScIr7kafvanZVnOcDAA5HI5KIqC8+fPO23nNXzeuswwDGco2b08ynkNlmVhYWEBx48f91xvGAbm5+d93+5x921335Nl+e27w+6ffr311lsAgKNHjzrLHnzwQQDA22+/7TuNNDc3h4WFBd46CFvUEQmREP19I1NVVWia5gwdyuFZ2a1N0xSqqjrfzNbW1pxvG/IbJlzfSOQ3FE3TnDIMwxD1el0IsfvNVA6L9sq/n+3vdTjW63Wn/M3NzcBlCBHONyT3vvNa1ml/yvXuNHJYWG6THEJ35y3zcS/z2l9y2DoMQfujvIUh+0prXrJ+Xv3Dqz1UVXWGymU/k8PkfvtumP1T1rNX3+mURraxV3pVVX2nkeT2lkqlIJvAEYIeuGcoFvo9AbsvjLZtN52QZIDQWo68aHidvLwuPO77u/KC5Sf/IHqdbN0XRcRgDoGffee1zCuNHBaW29RvPmEK2h/dgaJXXkI03+pw99vWz8kLt7vfbWxsNN128LOPwuyfncr0m8bP8iCflcd60OOAAUF33DMUC0FPwN2+Tcjl7m9SrX+tab0+7y4nn8+3TWLqlX8Qfj9XrVadi0/rZCs/4hgQtC4fx4CgW33cy2VAqaqqc8Fv/ZxX35YXQPlN2c8+CrN/9trGXmnCDgj81qcVA4LuuGcoFsI6Afs5wXTLo3XZ5uZm04nV/Y0kzItSkLw2Nzf7LpsBgT/DCgiEuDsiIm8B+NmPrcuj2EeDBASdJoECd29z+EkTtD6tGBB0x0mFNPG8Jhv6NT09jVKphGq1Ck3TsLCw0PbSmUHy77dOk0jTtKirMBLJZBKlUgnlchmGYbStV1UVADwnzPWzj0bdP714bZOcAPnoo4/6TkPDxYCAxlI2mwUA1Gq1nmlWV1ed2flB3yKnKAoajQaSySReffVVVKtVLCwshJZ/P2RZ+Xx+qOWMirxgnT59OuKa9E9e2P2+RU9VVeTzeVy5cqVt3dmzZwEAt27dcpbJfOfm5nzXKar+6eXUqVMAmrfpzp07Tev8pGkV5dM2EynqIQoiIYIP0cpJdqqqOjO75WQs/H+I0T1j3f1Xr9eb1sm5Ae5Jie77u7quO2XU63XntkG3/INwl+s1T8HrSYd+J4aFMWTq3m65n4LsT+Du5Di5Pe5Z5O6nDoS4O6FOtqsQd4eXTdN02iOOTxn0evGQ12REOfnQPc8gn8872+53X/fqn4ZhCMDfUwfd+qjfNNls1nkqqNNLh/ykEYJPGQwL9wzFQtATsBC7JwV58ZABgHzMSp4U3Y/qaZrmnAxbT5LdlsmLDtA+q7lT/kG22+tPkhca+WcYhufLivwK44QYZN91WuZ+9DObzTZdQOr1urNOnvBb21Xeh9d13VkWZUAgL77utunWrm6tj9TJ/LLZbFMAJfeR330tRPf+qeu60DTNs/zWfdFrW/ykEeJuf1ZVVaytrXmW5yeNDBKDvuGRAUF3ihBCgChiiqKgWCzizJkzUVdlol27dg1PPvkkojrs5UuE4n7a6ac/yqH4CxcuDKtaQ5FKpVAqlaKuRiCZTAaHDh0KvK+j7v9xxzkEREQhSKfTuHnzJiqVStRV8a1SqWBxcTHqagRSq9VQq9WQTqejrsrEYUBARCPhnj0+ia+cTSQSWFlZwdWrV7tOdo2L9fV1HD58uO312HG2tbWF5eVlrKysIJFIRF2dicOAgGgIvH7adlx+7nZYjhw54vnvSTI1NYXV1VXcuHEj6qr0dOLEibF7hLVcLuPSpUuYmpqKuioT6UDUFSCaRLxH2W6v7JNEIjF28wjGBffrcHGEgIiIiBgQEBEREQMCIiIiAgMCIiIiAsAXE1EsKIqCmZkZPPzww1FXZaLdvn0blUoFs7OzUVcl1l577TX2xwkk+z8ve944QkBEREQcIaB44KuLR4OvbvWH/XEysf93xxECIiIiYkBAREREDAiIiIgIDAiIiIgIDAiIiIgIDAiIiGLBsiwsLS1FXY2RWVpaQqPRiLoa5MKAgCZet58fXlpaQrlc5olpBBqNxtB+8nmYeY+CZVm4ePEiDh486PTNTCbjmXZcfka70WigUqkgl8shlUq1rT958iTOnTsHy7IiqB15YUBAE08IAdM0nf/btg0hBIQQOHnyJHK5HE9MI/Dmm2+OZd7D1mg0kE6n8cwzz0DTNNi2jXw+jytXrngGBe7+bJpmbJ+pNwwDv/nNb/Dss8+iXC63rU8mk1hcXEQ6nWZAHhMMCGhPmJqacv6dSCScfyeTSaysrAAAT0xD1Gg0kMvlxi7vUVhZWUEymcTMzAyA3f75ne98BwBw5coVFAqFts/I/uzu13Fz+fJlXL58uWuamZkZPPTQQ84xSNFiQEB73tTUFJ5//nmUy+W2b5ryvq6iKEilUlhfX3eWFwoFZyi0XC47aba3t5vykJ/P5XKwLKtpiLdT/nHTaDRQKBScIWq5LQA8h65blxmG4XxLlMsty0K5XHb2YS6Xg6IoOH/+PLa2tgbKGwAymUzHYfe4sCwLCwsLOH78uOd6wzAwPz/vGRR46dZOQfrsKPvl3NwcFhYWOEIXB4IoBgCIYrE49DI6dXnbtgUAoWmas8w0TaGqqsjn80IIIdbW1gQAUa1WhaqqTn4bGxtCCCHq9XpbHoZhiHq97pSh67pTh275D0uxWOy4D7pRVVVks1khxN16q6oqbNsWpmm27Vu5L9zLOv3fvQ9t2xaapgkAYnNzs++8hRBC13Wh63rgbZX5Dbs/CiFEqVQSAJw+0loHIYTTZ1r7hVc7dmsnv3027H7Z7bhz16GWmOkKAAAEJUlEQVRUKvWVfxD99v+9gnuGYiHqgMBrfT6fb0sPwLnIeOXndaEyTdP5v7zA+cl/GPo5IcoLgns7NjY2BADnouF3X/RKI4QQ1WpVABCGYQyU9yBGFRC4A0SvOgghmi7mm5ubbeulsNop7H7Zq21kMC7be5gYEHTHPUOxEMeAwP2NqvWvU36ty+S33Xw+L2zbbkrbK/9h6OeEKLfBTZ7EVVUVQoQbELQun+SAoFu93ctlIKmqqnPBb/1cWO0Udr/089lh93uJAUF3nENABDiTCXVdd5bJ+9Li/08kuP/8euGFF6CqKubn53Ho0KGm58zDyH8UlpeX25bJiZles8cpfFNTU6hWqyiXyx0nv4bVTuPSLyl8DAiIAPzpT38CAM/JXXKCWz+mp6dRKpVQrVahaRoWFhbaXj4zSP6joKoqAHhO+tI0bWjlDjPvcZRMJlEqlVAul2EYRtv6sNsp7v2SwseAgPY8y7Lw8ssvQ1VVnDhxwlmezWYBAKurq843sqBvk1MUBY1GA8lkEq+++iqq1SoWFhZCy38Uzp49CwC4deuWs0zWd25uLvTy5IXo9OnToecdN/LC7vdxV1VVnXcUtAqrnaLql+7ROYpIBLcpiNpgyPds5b1UAE338uUTA+57s5J7hrv7r16vN62T+bnLcN/n1XXdmUVer9edyVPd8h+Wfu6hyklt7n2Uz+ebZqa7nwwQ4u5kNuDuDHZ5b9o0zbYJg3LSm3wSQ97zHiTvcX7KQPaN1j4peU1G7NVOfvtsr35pGIYA/D110Om4c+NTBvHBPUOxMMwTsNfJTf4ZhuE8guWlXq87J19N05yTYms+3ZbJi5Qsz0/+w9LvCdE0TZHNZpsu4O4TfL1edy7K8sQuH12TFxr59ICu600Bk7y4yM9ns9lQ8h6HgEBefN190KufenEHTe78OrWT3z4rRPd+qeu60DTNs3y3TsdcKxngdQp+wsSAoDtFCM4UoegpioJisYgzZ85EXZWJdu3aNTz55JOxmSAmXyIUl/pIo+yPcij+woULQy8rTKlUCqVSaeB8MpkMDh06NJLtj1v/jxvOISAiilA6ncbNmzdRqVSiropvlUoFi4uLA+dTq9VQq9WQTqdDqBUNigEBEUXCPRt+L7+2NpFIYGVlBVevXkWtVou6Oj2tr6/j8OHDzm8v9GtrawvLy8tYWVlp+n0Rig4DAiKKxJEjRzz/vRdNTU1hdXUVN27ciLoqPZ04cQLT09MD51Mul3Hp0qVY/0DTXnMg6goQ0d7E+7jNEonE2M0jGMRe2tZxwRECIiIiYkBAREREDAiIiIgIDAiIiIgIDAiIiIgIAN9USLEg31hHRDRsvOx542OHFAvFYjHqKhAR7WkcISAiIiLOISAiIiIGBERERAQGBERERITdSYXXo64EERERRet/WKCq0GZUNRkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "90db31fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T02:32:52.460568Z",
     "start_time": "2022-11-26T22:18:06.651795Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "executionInfo": {
     "elapsed": 63070,
     "status": "ok",
     "timestamp": 1669321222542,
     "user": {
      "displayName": "Rogério Delfim",
      "userId": "04235763959036945343"
     },
     "user_tz": 180
    },
    "id": "90db31fc",
    "outputId": "fa083b2d-f50b-4b43-c672-9ec27e779d99",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Tensorflow - 12359\n",
      "=========================================================================\n",
      "Fold 1 => L.Loss: 0.51951 - F1-score: 0.72177 - AUC:0.72900 - 0h 15m 21s\n",
      "Fold 2 => L.Loss: 0.50174 - F1-score: 0.74317 - AUC:0.74600 - 0h 19m 34s\n",
      "Fold 3 => L.Loss: 0.54221 - F1-score: 0.70480 - AUC:0.71100 - 0h 3m 49s\n",
      "Fold 4 => L.Loss: 0.51962 - F1-score: 0.72699 - AUC:0.73450 - 0h 11m 47s\n",
      "Fold 5 => L.Loss: 0.52711 - F1-score: 0.71392 - AUC:0.71950 - 0h 14m 4s\n",
      "Fold 6 => L.Loss: 0.52651 - F1-score: 0.70036 - AUC:0.71250 - 0h 9m 10s\n",
      "Fold 7 => L.Loss: 0.51841 - F1-score: 0.71270 - AUC:0.72750 - 0h 5m 43s\n",
      "Fold 8 => L.Loss: 0.52190 - F1-score: 0.72251 - AUC:0.73500 - 0h 9m 46s\n",
      "Fold 9 => L.Loss: 0.54299 - F1-score: 0.68958 - AUC:0.70200 - 0h 9m 41s\n",
      "Fold 10 => L.Loss: 0.54554 - F1-score: 0.69597 - AUC:0.70600 - 0h 10m 25s\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[32m\u001b[1m[Fold Mean] L.Loss: 0.52655 - 0.01295 +- \u001b[0m - 1h 49m 25s\n",
      "=========================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     10000\n",
      "           1       0.74      0.69      0.71     10000\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.72      0.72      0.72     20000\n",
      "weighted avg       0.72      0.72      0.72     20000\n",
      "\n",
      "[[7538 2462]\n",
      " [3092 6908]]\n",
      "\n",
      "=> Tensorflow - 12359\n",
      "=========================================================================\n",
      "Fold 1 => L.Loss: 0.52072 - F1-score: 0.71996 - AUC:0.72850 - 0h 8m 52s\n",
      "Fold 2 => L.Loss: 0.50369 - F1-score: 0.73931 - AUC:0.74400 - 0h 9m 12s\n",
      "Fold 3 => L.Loss: 0.53877 - F1-score: 0.71262 - AUC:0.71650 - 0h 8m 57s\n",
      "Fold 4 => L.Loss: 0.51816 - F1-score: 0.72182 - AUC:0.73100 - 0h 8m 32s\n",
      "Fold 5 => L.Loss: 0.53010 - F1-score: 0.71392 - AUC:0.71950 - 0h 5m 54s\n",
      "Fold 6 => L.Loss: 0.52690 - F1-score: 0.70270 - AUC:0.71400 - 0h 3m 22s\n",
      "Fold 7 => L.Loss: 0.51073 - F1-score: 0.72653 - AUC:0.73350 - 0h 6m 49s\n",
      "Fold 8 => L.Loss: 0.51743 - F1-score: 0.72868 - AUC:0.73750 - 0h 11m 16s\n",
      "Fold 9 => L.Loss: 0.53714 - F1-score: 0.68915 - AUC:0.70050 - 0h 5m 32s\n",
      "Fold 10 => L.Loss: 0.54511 - F1-score: 0.69112 - AUC:0.70100 - 0h 8m 23s\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[32m\u001b[1m[Fold Mean] L.Loss: 0.52488 - 0.01245 +- \u001b[0m - 1h 16m 55s\n",
      "=========================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     10000\n",
      "           1       0.74      0.69      0.71     10000\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.72      0.72      0.72     20000\n",
      "weighted avg       0.72      0.72      0.72     20000\n",
      "\n",
      "[[7505 2495]\n",
      " [3053 6947]]\n",
      "\n",
      "=> Tensorflow - 12359\n",
      "=========================================================================\n",
      "Fold 1 => L.Loss: 0.52107 - F1-score: 0.71339 - AUC:0.72600 - 0h 3m 7s\n",
      "Fold 2 => L.Loss: 0.50375 - F1-score: 0.74070 - AUC:0.73850 - 0h 5m 4s\n",
      "Fold 3 => L.Loss: 0.53934 - F1-score: 0.71183 - AUC:0.71500 - 0h 3m 51s\n",
      "Fold 4 => L.Loss: 0.52081 - F1-score: 0.71838 - AUC:0.72950 - 0h 4m 2s\n",
      "Fold 5 => L.Loss: 0.53090 - F1-score: 0.71109 - AUC:0.71600 - 0h 3m 38s\n",
      "Fold 6 => L.Loss: 0.52664 - F1-score: 0.70885 - AUC:0.71700 - 0h 3m 25s\n",
      "Fold 7 => L.Loss: 0.51327 - F1-score: 0.72523 - AUC:0.73100 - 0h 5m 41s\n",
      "Fold 8 => L.Loss: nan - F1-score: 0.72708 - AUC:0.73800 - 0h 4m 41s\n",
      "Fold 9 => L.Loss: 0.53778 - F1-score: 0.69403 - AUC:0.70550 - 0h 3m 47s\n",
      "Fold 10 => L.Loss: 0.54572 - F1-score: 0.68873 - AUC:0.69900 - 0h 4m 15s\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[32m\u001b[1m[Fold Mean] L.Loss: nan - nan +- \u001b[0m - 0h 41m 35s\n",
      "=========================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     10000\n",
      "           1       0.73      0.70      0.71     10000\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.72      0.72      0.72     20000\n",
      "weighted avg       0.72      0.72      0.72     20000\n",
      "\n",
      "[[7478 2522]\n",
      " [3047 6953]]\n",
      "\n",
      "=> Tensorflow - 12359\n",
      "=========================================================================\n",
      "Fold 1 => L.Loss: 0.52180 - F1-score: 0.71893 - AUC:0.72750 - 0h 3m 33s\n",
      "Fold 2 => L.Loss: 0.50747 - F1-score: 0.74092 - AUC:0.73950 - 0h 2m 48s\n",
      "Fold 3 => L.Loss: 0.54173 - F1-score: 0.71152 - AUC:0.71700 - 0h 2m 34s\n",
      "Fold 4 => L.Loss: 0.52522 - F1-score: 0.72004 - AUC:0.72550 - 0h 3m 35s\n",
      "Fold 5 => L.Loss: 0.52973 - F1-score: 0.71837 - AUC:0.72400 - 0h 2m 42s\n",
      "Fold 6 => L.Loss: 0.53116 - F1-score: 0.70758 - AUC:0.71650 - 0h 2m 17s\n",
      "Fold 7 => L.Loss: 0.51683 - F1-score: 0.72336 - AUC:0.73000 - 0h 3m 10s\n",
      "Fold 8 => L.Loss: 0.51933 - F1-score: 0.72396 - AUC:0.73500 - 0h 2m 17s\n",
      "Fold 9 => L.Loss: 0.54712 - F1-score: 0.68502 - AUC:0.69100 - 0h 0m 55s\n",
      "Fold 10 => L.Loss: 0.55028 - F1-score: 0.69207 - AUC:0.70100 - 0h 2m 46s\n",
      "-------------------------------------------------------------------------\n",
      "\u001b[32m\u001b[1m[Fold Mean] L.Loss: 0.52907 - 0.01311 +- \u001b[0m - 0h 26m 39s\n",
      "=========================================================================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73     10000\n",
      "           1       0.73      0.70      0.71     10000\n",
      "\n",
      "    accuracy                           0.72     20000\n",
      "   macro avg       0.72      0.72      0.72     20000\n",
      "weighted avg       0.72      0.72      0.72     20000\n",
      "\n",
      "[[7433 2567]\n",
      " [3019 6981]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tensorflow</th>\n",
       "      <td>0.52488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tensorflow</th>\n",
       "      <td>0.52655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tensorflow</th>\n",
       "      <td>0.52907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tensorflow</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "Tensorflow  0.52488\n",
       "Tensorflow  0.52655\n",
       "Tensorflow  0.52907\n",
       "Tensorflow      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: total: 23h 14min 42s\n",
      "Wall time: 4h 14min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#model_tensorflow, early_stopping, plateau = create_model(input_shape_=1100)\n",
    "\n",
    "kf     = jb.load(path+'Data/pkl/StratifiedKFold_2.pkl.z')\n",
    "models = [('Tensorflow', model, 3, 'nb_03_n2_02_tensorflow', early_stopping, plateau, pipeline_process, 1), \n",
    "          ('Tensorflow', model, 3, 'nb_03_n2_03_tensorflow', early_stopping, plateau, pipeline_process, 2), \n",
    "          ('Tensorflow', model, 3, 'nb_03_n2_04_tensorflow', early_stopping, plateau, pipeline_process, 3),\n",
    "          ('Tensorflow', model, 3, 'nb_03_n2_05_tensorflow', early_stopping, plateau, pipeline_process, 4)]\n",
    "\n",
    "df_pred_tr, df_pred_ts, df_score_mdl, df_history = \\\n",
    "    model_cv_fit(models_       = models, \n",
    "                 X_            = X[feature_selec_fsm],\n",
    "                 y_            = y, \n",
    "                 X_test_       = X_test[feature_selec_fsm],                  \n",
    "                 path_         = path, \n",
    "                 seed_         = seed,\n",
    "                 target_       = 'pred',\n",
    "                 create_sub_   = True, \n",
    "                 n_splits_     = 10,\n",
    "                 print_report_ = True, \n",
    "                 save_ensamble_= True,\n",
    "                 level_        = '2', \n",
    "                 kf_           = kf)\n",
    "\n",
    "# 0.51976 - nb_03_n2_01_tensorflow_0.52772_folds_10_seed_12359.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874a0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T21:41:06.384545Z",
     "start_time": "2022-11-21T21:41:06.370546Z"
    },
    "id": "9874a0b9"
   },
   "outputs": [],
   "source": [
    "log_loss(y_ts_final, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c7c07100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-27T21:45:03.344795Z",
     "start_time": "2022-11-27T21:45:03.175879Z"
    },
    "id": "c7c07100"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tensorflow_0.52655_seed_12359</th>\n",
       "      <th>tensorflow_0.52488_seed_12359</th>\n",
       "      <th>tensorflow_nan_seed_12359</th>\n",
       "      <th>tensorflow_0.52907_seed_12359</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.815910</td>\n",
       "      <td>0.797861</td>\n",
       "      <td>0.763539</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.338811</td>\n",
       "      <td>0.369323</td>\n",
       "      <td>0.358346</td>\n",
       "      <td>0.309045</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568062</td>\n",
       "      <td>0.572976</td>\n",
       "      <td>0.590848</td>\n",
       "      <td>0.445516</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.583380</td>\n",
       "      <td>0.566027</td>\n",
       "      <td>0.564726</td>\n",
       "      <td>0.662997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812788</td>\n",
       "      <td>0.856844</td>\n",
       "      <td>0.871899</td>\n",
       "      <td>0.857427</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.732088</td>\n",
       "      <td>0.773188</td>\n",
       "      <td>0.737158</td>\n",
       "      <td>0.687048</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.435541</td>\n",
       "      <td>0.424232</td>\n",
       "      <td>0.436139</td>\n",
       "      <td>0.536543</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.828020</td>\n",
       "      <td>0.825476</td>\n",
       "      <td>0.821142</td>\n",
       "      <td>0.832304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.383894</td>\n",
       "      <td>0.402236</td>\n",
       "      <td>0.380624</td>\n",
       "      <td>0.343494</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.961640</td>\n",
       "      <td>0.946286</td>\n",
       "      <td>0.990294</td>\n",
       "      <td>0.985727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tensorflow_0.52655_seed_12359  tensorflow_0.52488_seed_12359  \\\n",
       "0                           0.815910                       0.797861   \n",
       "1                           0.338811                       0.369323   \n",
       "2                           0.568062                       0.572976   \n",
       "3                           0.583380                       0.566027   \n",
       "4                           0.812788                       0.856844   \n",
       "...                              ...                            ...   \n",
       "19995                       0.732088                       0.773188   \n",
       "19996                       0.435541                       0.424232   \n",
       "19997                       0.828020                       0.825476   \n",
       "19998                       0.383894                       0.402236   \n",
       "19999                       0.961640                       0.946286   \n",
       "\n",
       "       tensorflow_nan_seed_12359  tensorflow_0.52907_seed_12359  fold  \n",
       "0                       0.763539                       0.748660     6  \n",
       "1                       0.358346                       0.309045     6  \n",
       "2                       0.590848                       0.445516     3  \n",
       "3                       0.564726                       0.662997     7  \n",
       "4                       0.871899                       0.857427     4  \n",
       "...                          ...                            ...   ...  \n",
       "19995                   0.737158                       0.687048     6  \n",
       "19996                   0.436139                       0.536543     5  \n",
       "19997                   0.821142                       0.832304     1  \n",
       "19998                   0.380624                       0.343494     5  \n",
       "19999                   0.990294                       0.985727     1  \n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36c6f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T03:02:50.772535Z",
     "start_time": "2022-11-22T03:02:46.150289Z"
    },
    "id": "fc36c6f1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_keras, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f16db",
   "metadata": {
    "id": "078f16db"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Lista com os modelos para gerar as previsões \n",
    "models_n3 = [\n",
    "    ('RForest', model_rf, 1, 'nb_02_n3_14_rf'), \n",
    "    #('XGB', model_xgb, 1, 'nb_02_n3_15_xgb'), \n",
    "    #('LGBM', model_lgbm, 1, 'nb_02_n3_16_lgbm'), \n",
    "    #('HBoosting', model_hbc, 1, 'nb_02_n3_17_hbc'), \n",
    "    #('LR', model_lr, 1, 'nb_02_n3_18_lr')\n",
    "]\n",
    "      \n",
    "# Dataset para armazenar as previsões\n",
    "df_pred_tr_n3   = pd.DataFrame() \n",
    "df_pred_ts_n3   = pd.DataFrame()\n",
    "df_score_mdl_n3 = pd.DataFrame()\n",
    "\n",
    "# Loop para treina cada modelo \n",
    "for mdl in models_n3: \n",
    "    \n",
    "    # Lista com o nome de cada modelo\n",
    "    cols = ['LR', 'KNN', 'MLP', 'XGB', 'ExTrees', 'LGBM', 'HBoosting', 'RForest']\n",
    "    \n",
    "    # remoção da colona, previsões do modelo, do treinamento. \n",
    "    cols.remove(mdl[0])\n",
    "    \n",
    "    # Chama uma função para treinar o modelo e retorna as previsões\n",
    "    _tr_n3, _ts_n3, _score_mdl_n3 = \\\n",
    "        model_cv_fit(models_          = [mdl], \n",
    "                     X_               = df_tr[cols],\n",
    "                     y_               = y, \n",
    "                     X_test_          = df_ts[cols],                  \n",
    "                     path_            = path, \n",
    "                     seed_            = seed,\n",
    "                     target_          = 'pred',\n",
    "                     create_sub_      = True, \n",
    "                     n_splits_        = 10,\n",
    "                     print_report_    = False, \n",
    "                     print_score_mdl_ = False, \n",
    "                     save_ensamble_   = True,\n",
    "                     level_           = '3'\n",
    "                    ) \n",
    "    \n",
    "    # Armazeno as previsões para o próximo nível \n",
    "    df_pred_tr_n3   = pd.concat([df_pred_tr_n3, _tr_n3], axis=1)\n",
    "    df_pred_ts_n3   = pd.concat([df_pred_ts_n3, _ts_n3], axis=1)\n",
    "    df_score_mdl_n3 = pd.concat([df_score_mdl_n3, _score_mdl_n3]) \n",
    "    \n",
    "del _tr_n3, _ts_n3, _score_mdl_n3 \n",
    "\n",
    "df_score_mdl_n3.sort_values(by='score',ascending=True)  \n",
    "\n",
    "# L.Loss: 0.52115 => 0.51405 -  nb_02_n3_14_rf_0.52115_folds_10_oof.csv.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59708c1",
   "metadata": {
    "id": "b59708c1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e4423",
   "metadata": {
    "id": "f68e4423"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13e0bf",
   "metadata": {
    "id": "bb13e0bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bef47b",
   "metadata": {
    "id": "33bef47b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d22d523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T23:52:02.645013Z",
     "start_time": "2022-11-15T23:52:02.624018Z"
    },
    "id": "4d22d523"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Nas submissões, o modelo com seleção de variáveis teve o melhor desempenho com score de 0.51742 contra 0.51753, sendo assim, vamos utilizar a seleção de recurso para criar novas variáveis. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31b045",
   "metadata": {
    "id": "bd31b045"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c9d48",
   "metadata": {
    "id": "824c9d48"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 2. FEATURE ENGINEERING </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3f59e",
   "metadata": {
    "id": "36e3f59e"
   },
   "source": [
    "\n",
    "Nesta parte do processo vamos criar alguns variáveis com o intuito de ajudar o modelo a identificar novos padrões e consequentemente melhor o desempenho, como padrão vamos criar todas as variáveis com inicial <b>fe_</b>, a cada criação nova variável vamos treinar o modelo <u>LGBM</u> e identificar se as novas variáveis ajudam a encontrar novos padrões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b16fa8",
   "metadata": {
    "id": "52b16fa8"
   },
   "source": [
    "## 2.1. Gerar PCA\n",
    "Nesta etapa vamos utilizar a PCA para gerar novas variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef233f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:21:59.132041Z",
     "start_time": "2022-11-20T00:21:59.118897Z"
    },
    "id": "22ef233f"
   },
   "outputs": [],
   "source": [
    "len(feature_selec_fsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4b70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:22:13.088512Z",
     "start_time": "2022-11-20T00:22:12.797833Z"
    },
    "id": "c0e4b70c"
   },
   "outputs": [],
   "source": [
    "X_21       = X[feature_selec_fsm].copy()\n",
    "X_21       = X[feature_selec_fsm].copy()\n",
    "X_test_21  = X_test[feature_selec_fsm].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BokmnwzG5pbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:22:35.046230Z",
     "start_time": "2022-11-20T00:22:30.798647Z"
    },
    "id": "BokmnwzG5pbb"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "pca           = ('pca', PCA(random_state=seed))\n",
    "pipeline_pca  = Pipeline(steps=[processar, pca])\n",
    "Xt            = pipeline_pca.fit_transform(X_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8394bb",
   "metadata": {
    "id": "ce8394bb"
   },
   "source": [
    "## 2.1.1. Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653458e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:22:44.331355Z",
     "start_time": "2022-11-20T00:22:42.157972Z"
    },
    "id": "b653458e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "features = range(pipeline_pca['pca'].n_components_)\n",
    "print(':', pipeline_pca['pca'].explained_variance_ratio_.cumsum()[:5].round(2))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(pipeline_pca['pca'].explained_variance_ratio_.cumsum())\n",
    "plt.title('Análise de componentes principais')\n",
    "plt.xlabel('Componentes')\n",
    "plt.ylabel('Razão de variância explicada cumulativa')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(features[:15], pipeline_pca['pca'].explained_variance_[:15], color='lightskyblue')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('Variância')\n",
    "plt.xticks(features[:15]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0d3ef",
   "metadata": {
    "id": "f8c0d3ef"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Podemos observar que as duas primeiras componentes explicam 83% da variância total dos dados, vamos dar uma olhada na distribuição dos dados:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XFV_tF0p95IM",
   "metadata": {
    "id": "XFV_tF0p95IM"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "n_components  = 2\n",
    "pca_feats     = [f'fe_pca_{i}' for i in range(n_components)]\n",
    "pca           = ('pca', PCA(n_components=n_components, random_state=seed))\n",
    "pipeline_pca  = Pipeline(steps=[processar, pca])\n",
    "\n",
    "pipeline_pca.fit(X_21)\n",
    "\n",
    "X_21[pca_feats]      = pipeline_pca.fit_transform(X_21)\n",
    "X_test_21[pca_feats] = pipeline_pca.fit_transform(X_test_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad85f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:25:03.969438Z",
     "start_time": "2022-11-20T00:25:02.758410Z"
    },
    "id": "3ad85f08"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "_ = X_21.copy() \n",
    "_[target] = y \n",
    "\n",
    "for i,feature in enumerate(pca_feats):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    sns.kdeplot(_[_[target]==0][feature],color='blue', alpha=0.5, label='0', shade=True)\n",
    "    sns.kdeplot(_[_[target]==1][feature],color='teal', alpha=0.5, label='1', shade=True)  \n",
    "    plt.xlabel(feature, fontsize=12)\n",
    "    plt.legend()\n",
    "         \n",
    "plt.suptitle('Variável PCA 1 e PCA 2', fontsize=20)\n",
    "plt.tight_layout(pad=3.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5991a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-18T00:35:45.021897Z",
     "start_time": "2022-11-18T00:35:45.011900Z"
    },
    "id": "7cc5991a"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Podemos observar no primeiro gráfico, áreas que não se sobrepÕe em relação as classes de classificações, quando olhamos para o segundo gráfico tem uma sobreposição das áreas das classes, isso torna a classificação dos modelos difícil, vamos dar uma olha na correlação dessas variáveis. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c453435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:27:51.746820Z",
     "start_time": "2022-11-20T00:27:51.126093Z"
    },
    "id": "9c453435"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "feature_corr = \\\n",
    "    utility.graf_feature_corr(df_         = _[pca_feats+[target]],                             \n",
    "                              annot_      = True, \n",
    "                              threshold_  = .8, \n",
    "                              print_var_  = False, \n",
    "                              print_graf_ = True, \n",
    "                              mask_       = False, \n",
    "                              method_     = 'spearman');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282b1ba",
   "metadata": {
    "id": "6282b1ba"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "No gráfico de correlação fica claro que a primeira PCA tem o maior porder preditivo <b>negativo</b>, isso pode ser um problema, pois a correlação negativo pode elevar o erro de predição,  em relação a segunda PCA tem um valor muito baixo.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bNbdu_T6wjjT",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:37:28.878886Z",
     "start_time": "2022-11-20T00:37:28.703182Z"
    },
    "id": "bNbdu_T6wjjT"
   },
   "outputs": [],
   "source": [
    "X_21[pca_feats].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b5b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:37:48.385765Z",
     "start_time": "2022-11-20T00:37:48.166185Z"
    },
    "id": "f17b5b45"
   },
   "outputs": [],
   "source": [
    "feature_drop = ['fe_pca_1']\n",
    "X_21.drop(feature_drop, axis=1, inplace=True)\n",
    "X_test_21.drop(feature_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a6461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:39:41.498573Z",
     "start_time": "2022-11-20T00:38:06.871195Z"
    },
    "id": "0f9a6461"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models = [('LGBM', model_pipeline_lgbm, 1, 'nb_02_n2_02_lgbm_nb_pca')]\n",
    "\n",
    "df_pred_tr, df_pred_ts, df_score_mdl = \\\n",
    "    model_cv_fit(models_          = models, \n",
    "                 X_               = X_21,\n",
    "                 y_               = y, \n",
    "                 X_test_          = X_test_21,                  \n",
    "                 path_            = path, \n",
    "                 seed_            = seed,\n",
    "                 target_          = 'pred',\n",
    "                 create_sub_      = True, \n",
    "                 n_splits_        = 10,\n",
    "                 print_report_    = False, \n",
    "                 print_score_mdl_ = False,\n",
    "                 save_ensamble_   = False,\n",
    "                 level_           = '2')\n",
    "\n",
    "# L.Loss: 0.52108 /  L.Loss: 0.51999\n",
    "# L.Loss: 0.52089 / L.Loss: 0.52004 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee7dd5",
   "metadata": {
    "id": "e7ee7dd5"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "Não teve melhoria na submissão, mas vou permanecer com a variável.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b1417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T23:53:03.751372Z",
     "start_time": "2022-11-14T23:53:03.649052Z"
    },
    "id": "145b1417"
   },
   "source": [
    "## 2.2. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8d0a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:40:24.113288Z",
     "start_time": "2022-11-20T00:40:23.999377Z"
    },
    "id": "75e8d0a6"
   },
   "outputs": [],
   "source": [
    "X_22      = X_21.copy()\n",
    "X_test_22 = X_test_21.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a552b0c",
   "metadata": {
    "id": "3a552b0c"
   },
   "source": [
    "### 2.2.1. Todas as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acef472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:40:31.900283Z",
     "start_time": "2022-11-20T00:40:31.894284Z"
    },
    "id": "4acef472"
   },
   "outputs": [],
   "source": [
    "feture_pca = X_22.columns.to_list()\n",
    "feture_pca.remove('fe_pca_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46219d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:42:45.330230Z",
     "start_time": "2022-11-20T00:41:06.828964Z"
    },
    "id": "e46219d5"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "sc1 = StandardScaler().fit(X_22[feture_pca])\n",
    "\n",
    "_ = pd.DataFrame(sc1.fit_transform(X_22[feture_pca].copy()), columns=feture_pca)\n",
    "\n",
    "f1, axs1 = plt.subplots(1,2,figsize=(20,6)) \n",
    "\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=seed), k=(2,10), timings=False, ax=axs1[0])\n",
    "visualizer.fit(_.values)\n",
    "visualizer.finalize() \n",
    "\n",
    "k       = visualizer.elbow_value_\n",
    "model_1 = KMeans(k, random_state=seed)\n",
    "sv      = SilhouetteVisualizer(model_1, ax=axs1[1])\n",
    "\n",
    "sv.fit(_)\n",
    "sv.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee4547",
   "metadata": {
    "id": "a5ee4547"
   },
   "source": [
    "### 2.2.2. Utilizando PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d7c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:44:07.562235Z",
     "start_time": "2022-11-20T00:43:56.653181Z"
    },
    "id": "b90d7c5a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "sc2 = StandardScaler() \n",
    "_   = pd.DataFrame(sc2.fit_transform(pd.DataFrame(X_21.copy()['fe_pca_0'])), columns=['fe_pca_0'])\n",
    "\n",
    "f1, axs1 = plt.subplots(1,2,figsize=(20,6)) \n",
    "\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=seed), k=(2,10), timings=False, ax=axs1[0])\n",
    "visualizer.fit(_.values)\n",
    "visualizer.finalize() \n",
    "\n",
    "k       = visualizer.elbow_value_\n",
    "model_2 = KMeans(k, random_state=seed)\n",
    "sv      = SilhouetteVisualizer(model_2, ax=axs1[1])\n",
    "\n",
    "sv.fit(_)\n",
    "sv.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c5265",
   "metadata": {
    "id": "553c5265"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Utilizando PCA temos os clusters com melhor silhjouette e melhor distribuições em relação ao utilizar todas as variáveis para gera os clusters. \n",
    "    \n",
    "Vamos gerar os clusters nos dados de treino e teste.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53deb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:45:32.131127Z",
     "start_time": "2022-11-20T00:45:21.150866Z"
    },
    "id": "0f53deb5"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "X_22['fe_cluster_kmeans']      = model_2.fit_predict(sc2.fit_transform(X_22))\n",
    "X_test_22['fe_cluster_kmeans'] = model_2.fit_predict(sc2.fit_transform(X_test_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a698cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:45:36.357785Z",
     "start_time": "2022-11-20T00:45:36.331467Z"
    },
    "id": "1a698cdc"
   },
   "outputs": [],
   "source": [
    "X_22.filter(regex=r'fe').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27bac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:46:12.905677Z",
     "start_time": "2022-11-20T00:46:08.294777Z"
    },
    "id": "1c27bac6"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "model_bgmm = BayesianGaussianMixture(n_components    = k, \n",
    "                                     covariance_type = 'full', \n",
    "                                     n_init          = 3,\n",
    "                                     init_params     = \"kmeans\",\n",
    "                                     random_state    = seed) \n",
    "\n",
    "X_22['fe_cluster_bgmm_pca']      = model_bgmm.fit_predict(X_22[['fe_pca_0']])\n",
    "X_test_22['fe_cluster_bgmm_pca'] = model_bgmm.fit_predict(X_test_22[['fe_pca_0']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec55fb",
   "metadata": {
    "id": "1dec55fb"
   },
   "source": [
    "### 2.2.3. Gráfico de análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25148a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:47:26.021405Z",
     "start_time": "2022-11-20T00:47:16.648210Z"
    },
    "id": "25148a22"
   },
   "outputs": [],
   "source": [
    "feature_sample = X_22.sample(27, axis='columns').columns.to_list()\n",
    "row            = int(len(feature_sample)/3) + 1\n",
    "\n",
    "f,ax = plt.subplots(figsize=(20,35))\n",
    "\n",
    "for i, feature in enumerate(feature_sample):\n",
    "    plt.subplot(row, 3 , i+1)\n",
    "    sns.kdeplot(data=X_22, x=feature, hue=\"fe_cluster_kmeans\", palette=sns.color_palette(\"hls\", k));\n",
    "    \n",
    "utility.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59257eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:47:44.136869Z",
     "start_time": "2022-11-20T00:47:35.559311Z"
    },
    "id": "59257eb0"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(20,35))\n",
    "\n",
    "for i, feature in enumerate(feature_sample):\n",
    "    plt.subplot(row, 3 , i+1)\n",
    "    sns.kdeplot(data=X_22, x=feature, hue=\"fe_cluster_bgmm_pca\", palette=sns.color_palette(\"hls\", k));\n",
    "    \n",
    "utility.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce148d",
   "metadata": {
    "id": "7dce148d"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Podemos observar que os clusters conseguem fazer a separação dos dados, vamos dar uma olhada na correlação das variáveis criadas. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0203c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:48:41.864001Z",
     "start_time": "2022-11-20T00:48:41.855985Z"
    },
    "id": "ce0203c5"
   },
   "outputs": [],
   "source": [
    "feature_corr = ['fe_pca_0','fe_cluster_kmeans', 'fe_cluster_bgmm_pca', target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79454b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T00:48:47.148551Z",
     "start_time": "2022-11-20T00:48:46.855221Z"
    },
    "id": "c79454b0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "_ = X_22.copy() \n",
    "_[target] = y\n",
    "\n",
    "feature_corr = \\\n",
    "    utility.graf_feature_corr(df_         = _[feature_corr],\n",
    "                              annot_      = True, \n",
    "                              threshold_  = .8, \n",
    "                              print_var_  = False, \n",
    "                              print_graf_ = True, \n",
    "                              mask_       = True, \n",
    "                              method_     = 'spearman');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bY4PqiohG8ac",
   "metadata": {
    "id": "bY4PqiohG8ac"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "    \n",
    "Temo uma alta correlação entre a PCA e o cluste gerado pelo kmeans, praticamente elas tem o mesmo pode preditivos em relação a variável alvo.\n",
    "\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19267d7d",
   "metadata": {
    "id": "19267d7d"
   },
   "source": [
    "### 2.2.4. Criar dammy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917b06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:13:10.167576Z",
     "start_time": "2022-11-20T01:13:08.047821Z"
    },
    "id": "7917b06d"
   },
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols           = ['fe_cluster_bgmm_pca', 'fe_cluster_kmeans'],\n",
    "                           handle_unknown = 'return_nan',\n",
    "                           return_df      = True,\n",
    "                           use_cat_names  = True)\n",
    "\n",
    "encoder.fit(X_22)\n",
    "\n",
    "_            = encoder.fit_transform(X_22)\n",
    "_[target]    = y\n",
    "feature_corr = _.filter(regex=r'fe_').columns.to_list()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "feature_corr = \\\n",
    "    utility.graf_feature_corr(df_         = _[feature_corr+ [target]],\n",
    "                              annot_      = True, \n",
    "                              threshold_  = .8, \n",
    "                              print_var_  = False, \n",
    "                              print_graf_ = True, \n",
    "                              mask_       = True, \n",
    "                              method_     = 'spearman');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f141ba",
   "metadata": {
    "id": "c6f141ba"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Me parece que criar variáveis <b>One Hot Encoding</b> da variável cluster seja  relevante, sendo assim, vamos implentar dentro de um pipeline a criação da variáveis dammies.   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fjfwItaDFZh0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:13:41.095715Z",
     "start_time": "2022-11-20T01:13:40.983608Z"
    },
    "id": "fjfwItaDFZh0"
   },
   "outputs": [],
   "source": [
    "X_22.drop('fe_cluster_kmeans', axis=1, inplace=True)\n",
    "X_test_22.drop('fe_cluster_kmeans', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HUd62JOR0HVK",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:13:45.214957Z",
     "start_time": "2022-11-20T01:13:45.201953Z"
    },
    "id": "HUd62JOR0HVK"
   },
   "outputs": [],
   "source": [
    "X_22.filter(regex=r'fe_').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1g76RrTk0VY5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:13:49.342240Z",
     "start_time": "2022-11-20T01:13:49.314211Z"
    },
    "id": "1g76RrTk0VY5"
   },
   "outputs": [],
   "source": [
    "X_test_22.filter(regex=r'fe_').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KVkg0CpiFw08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:13:54.446704Z",
     "start_time": "2022-11-20T01:13:54.439715Z"
    },
    "id": "KVkg0CpiFw08"
   },
   "outputs": [],
   "source": [
    "X_22.shape, X_test_22.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818fb8e",
   "metadata": {
    "id": "6818fb8e"
   },
   "source": [
    "### 2.2.5. Modelo sem dammy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d4460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:16:15.183750Z",
     "start_time": "2022-11-20T01:14:38.807181Z"
    },
    "id": "6e9d4460"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models = [('LGBM', model_pipeline_lgbm, 1, 'nb_02_n2_03_lgbm_nb_02_cluster_sem_dammy')]\n",
    "\n",
    "df_pred_tr, df_pred_ts, df_score_mdl = \\\n",
    "    model_cv_fit(models_          = models, \n",
    "                 X_               = X_22,\n",
    "                 y_               = y, \n",
    "                 X_test_          = X_test_22,                  \n",
    "                 path_            = path, \n",
    "                 seed_           = seed,\n",
    "                 target_          = 'pred',\n",
    "                 create_sub_      = True, \n",
    "                 n_splits_        = 10,\n",
    "                 print_report_    = False, \n",
    "                 print_score_mdl_ = False,\n",
    "                 save_ensamble_   = False,\n",
    "                 level_           = '2')\n",
    "\n",
    "# L.Loss: 0.52108 / L.Loss: 0.51999\n",
    "# L.Loss: 0.52089 / L.Loss: 0.52004 \n",
    "# L.Loss: 0.52109 / L.Loss: 0.52037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfa297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:16:19.660910Z",
     "start_time": "2022-11-20T01:16:19.439897Z"
    },
    "id": "6dcfa297"
   },
   "outputs": [],
   "source": [
    "_ =  X_22.copy()\n",
    "_['pred_proba'] =  y\n",
    "_ = _.groupby('fe_cluster_bgmm_pca')['pred_proba'].mean()\n",
    "f,ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(x=_.index, y=_.values, palette=sns.color_palette(\"hls\", 6) );\n",
    "ax.set_ylabel(\"Probabilidade média por cluster\");\n",
    "ax.set_ylim([0.,0.95]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88012cac",
   "metadata": {
    "id": "88012cac"
   },
   "source": [
    "### 2.2.6. Modelo com dammy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b70bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:21:52.533106Z",
     "start_time": "2022-11-20T01:21:52.514108Z"
    },
    "code_folding": [
     0
    ],
    "id": "b72b70bd"
   },
   "outputs": [],
   "source": [
    "param_lgbm  = {\n",
    "    'objective'         : 'binary',\n",
    "    'metric'            : 'binary_logloss',\n",
    "    'colsample_bytree'  : 0.5139258065278501,\n",
    "    'learning_rate'     : 0.02,\n",
    "    'max_depth'         : 6,\n",
    "    'min_child_samples' : 219,\n",
    "    'min_child_weight'  : 1e-05,\n",
    "    'n_estimators'      : 300,\n",
    "    'num_leaves'        : 128,\n",
    "    'reg_alpha'         : 1,\n",
    "    'reg_lambda'        : 0,\n",
    "    'subsample'         : 0.8116483602711031,         \n",
    "    #'device'            : 'gpu',    \n",
    "    'random_state'      : seed}\n",
    "\n",
    "model_lgbm = lgb.LGBMClassifier(**param_lgbm)\n",
    "\n",
    "# Processamento\n",
    "feature_encoder_bin = X_22.filter(regex='fe_c').columns.to_list()\n",
    "processar           = ('preprocessor', StandardScaler())\n",
    "variancethreshold   = ('variancethreshold', VarianceThreshold(threshold=1.0e-03)) \n",
    "selectpercentile    = ('selectpercentile', SelectPercentile(f_classif, percentile=98))\n",
    "selectKbest         = ('SelectKBest', SelectKBest(score_func=f_classif))\n",
    "encoder_bin         = ('encoder_binary', ce.BinaryEncoder(cols=feature_encoder_bin, return_df=True))\n",
    "mdl_lgbm            = ('model', model_lgbm)\n",
    "\n",
    "# Pipelne \n",
    "model_pipeline_lgbm = Pipeline(steps=[encoder_bin, processar, variancethreshold, selectpercentile, mdl_lgbm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e76ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T01:24:48.326965Z",
     "start_time": "2022-11-20T01:22:55.848166Z"
    },
    "id": "29e76ad4"
   },
   "outputs": [],
   "source": [
    "\n",
    "models = [('LGBM', model_pipeline_lgbm, 1, 'nb_02_n2_04_lgbm_nb_02_cluster_com_dammy')]\n",
    "\n",
    "df_pred_tr, df_pred_ts, df_score_mdl = \\\n",
    "    model_cv_fit(models_          = models, \n",
    "                 X_               = X_22,\n",
    "                 y_               = y, \n",
    "                 X_test_          = X_test_22,                  \n",
    "                 path_            = path, \n",
    "                 seed_            = seed,\n",
    "                 target_          = 'pred',\n",
    "                 create_sub_      = True, \n",
    "                 n_splits_        = 10,\n",
    "                 print_report_    = False, \n",
    "                 print_score_mdl_ = False,\n",
    "                 save_ensamble_   = False,\n",
    "                 level_           = '2')\n",
    "\n",
    "# L.Loss: 0.52108 / L.Loss: 0.51999\n",
    "# L.Loss: 0.52089 / L.Loss: 0.52004 \n",
    "# L.Loss: 0.52109 / L.Loss: 0.52037"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c6abe",
   "metadata": {
    "id": "226c6abe"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "A transformação da variável cluster em dammy não melhou o desempenho do modelo.   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0803f0",
   "metadata": {
    "id": "7c0803f0"
   },
   "source": [
    "# 3. Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41abee0",
   "metadata": {
    "id": "c41abee0"
   },
   "source": [
    "## 3.2. Definindo o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efaa8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T13:19:06.346769Z",
     "start_time": "2022-11-20T13:19:06.326737Z"
    },
    "code_folding": [
     2,
     19,
     35,
     43,
     50,
     62,
     67
    ],
    "id": "71efaa8f"
   },
   "outputs": [],
   "source": [
    "# Paremetros \n",
    "\n",
    "params_xgb  = {\n",
    "    'objective'        : 'binary:logistic',\n",
    "    'eval_metric'      : 'logloss',\n",
    "    'max_depth'        : 7,  \n",
    "    'colsample_bytree' : 0.8, \n",
    "    'max_leaves'       : 10,    # 0.52463    \n",
    "    'subsample'        : 0.95,  # 0.52460      \n",
    "    \n",
    "    #'lambda'           : 1.2,\n",
    "    #'alpha'            : 0.9,   # \n",
    "    #'min_child_weight' : 1e-3,\n",
    "    #'colsample_bylevel': 0.95,    \n",
    "    # 'learning_rate'    : 1e-1,\n",
    "     #'sampling_method'  : 'uniform',  # 0.52460   \n",
    "    'n_jobs'           : -1,\n",
    "    'seed'             : seed}\n",
    "\n",
    "param_lgbm  = {\n",
    "    'objective'         : 'binary',\n",
    "    'metric'            : 'binary_logloss',\n",
    "    'colsample_bytree'  : 0.5139258065278501,\n",
    "    'learning_rate'     : 0.02,\n",
    "    'max_depth'         : 6,\n",
    "    'min_child_samples' : 219,\n",
    "    'min_child_weight'  : 1e-05,\n",
    "    'n_estimators'      : 300,\n",
    "    'num_leaves'        : 128,\n",
    "    'reg_alpha'         : 1,\n",
    "    'reg_lambda'        : 0,\n",
    "    'subsample'         : 0.8116483602711031,         \n",
    "    #'device'            : 'gpu',    \n",
    "    'random_state'      : seed}\n",
    "\n",
    "param_rf    = {\n",
    "    'class_weight'      : 'balanced', \n",
    "    'n_estimators'      : 100,\n",
    "    'max_depth'         : 7,    # 0.52808\n",
    "    'min_samples_split' : 5,    # 0.52804    \n",
    "    'min_samples_leaf'  : 20,   #  0.52705\n",
    "    'random_state'      : seed}\n",
    "\n",
    "param_ext   = {\n",
    "    'n_estimators'     : 500,\n",
    "    'max_depth'        : 7, \n",
    "    'min_samples_leaf' : 12,         \n",
    "    'n_jobs'           : -1,\n",
    "    'random_state'     : seed}\n",
    "\n",
    "param_lr    = {\n",
    "    'max_iter'      : 1000, \n",
    "    'C'             : 0.0001, \n",
    "    'penalty'       : 'l2', \n",
    "    'fit_intercept' : True,\n",
    "    'solver'        : 'newton-cg'}\n",
    "\n",
    "param_mlp   = {\n",
    "    'learning_rate' : 'adaptive',\n",
    "    'alpha'         : 0.5,\n",
    "    'random_state'  : seed}\n",
    "\n",
    "param_hbc   = {\n",
    "    'max_iter'            : 100,\n",
    "    'validation_fraction' : 0.1,\n",
    "    'random_state'        : seed}\n",
    "\n",
    "if torch.cuda.is_available():           \n",
    "    params_xgb.update({'tree_method': 'gpu_hist','predictor': 'gpu_predictor'})\n",
    "\n",
    "# Classificadores\n",
    "model_lr   = LogisticRegression(**param_lr)\n",
    "model_knn  = KNeighborsClassifier(n_neighbors=225)\n",
    "model_mlp  = MLPClassifier(**param_mlp) \n",
    "model_xgb  = xgb.XGBClassifier(**params_xgb) \n",
    "model_ext  = ExtraTreesClassifier(**param_ext)\n",
    "model_lgbm = lgb.LGBMClassifier(**param_lgbm)\n",
    "model_rf   = RandomForestClassifier(**param_rf)\n",
    "model_hbc  = HistGradientBoostingClassifier(**param_hbc)\n",
    "\n",
    "pca    = ('pca', PCA(n_components=80, random_state=seed))\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Processamento\n",
    "encoder_bin       = ('encoder_binary', ce.BinaryEncoder(cols=feature_encoder_bin, return_df=True))\n",
    "processar         = ('preprocessor', scaler)\n",
    "variancethreshold = ('variancethreshold', VarianceThreshold(threshold=1.0e-03)) \n",
    "selectpercentile  = ('selectpercentile', SelectPercentile(f_classif, percentile=98))\n",
    "selectKbest       = ('SelectKBest', SelectKBest(score_func=f_classif))\n",
    "\n",
    "# Preciso normalizar as duas últimas colunas \n",
    "_ = X_22.columns.to_list()\n",
    "_.remove('fe_pca_0')\n",
    "_.remove('fe_cluster_bgmm_pca')\n",
    "\n",
    "pipeline_SimpleImputer  = Pipeline([('imputer', SimpleImputer(strategy=\"median\"))])\n",
    "pipeline_StandardScaler = Pipeline([('standard', scaler)])\n",
    "pipeline_MaxAbsScaler   = Pipeline([('cluster', MaxAbsScaler() )])\n",
    "\n",
    "# Compondo os pré-processadores\n",
    "pipiline_ColumnTransformer = ColumnTransformer(transformers=[    \n",
    "    ('SimpleImputer', pipeline_SimpleImputer, _),\n",
    "    ('StandardScaler', pipeline_StandardScaler, ['fe_pca_0']),\n",
    "    ('MaxAbsScaler', pipeline_MaxAbsScaler, ['fe_cluster_bgmm_pca'])\n",
    "])\n",
    "\n",
    "columntransf = ('ColumnTransformer', pipiline_ColumnTransformer)\n",
    "\n",
    "# Pipelne \n",
    "pipeline_lr   = Pipeline(steps=[variancethreshold, selectpercentile, ('model', model_lr)])\n",
    "pipeline_knn  = Pipeline(steps=[variancethreshold, selectpercentile, ('model', model_knn)])\n",
    "pipeline_mlp  = Pipeline(steps=[processar, variancethreshold, selectpercentile, ('model', model_mlp)])\n",
    "pipeline_xgb  = Pipeline(steps=[processar, variancethreshold, selectpercentile, ('model', model_xgb)])\n",
    "pipeline_ext  = Pipeline(steps=[processar, variancethreshold, selectpercentile, ('model', model_ext)])\n",
    "pipeline_lgbm = Pipeline(steps=[variancethreshold, selectpercentile, ('model', model_lgbm)])\n",
    "pipeline_rf   = Pipeline(steps=[variancethreshold, selectpercentile, ('model', model_rf)])\n",
    "pipeline_hbc  = Pipeline(steps=[variancethreshold, selectpercentile, ('model', model_hbc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b93c8",
   "metadata": {
    "id": "f53b93c8"
   },
   "source": [
    "## 3.3. Funções da modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d90f82",
   "metadata": {
    "id": "91d90f82"
   },
   "source": [
    "## 3.4. Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b3853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:34:59.308884Z",
     "start_time": "2022-11-20T16:34:59.296500Z"
    },
    "id": "961b3853"
   },
   "outputs": [],
   "source": [
    "X_22.shape, X_test_22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7944f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T14:09:39.470497Z",
     "start_time": "2022-11-20T13:19:22.752441Z"
    },
    "id": "c7944f50",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models = [ \n",
    "    ('LR', pipeline_lr, 1, 'nb_02_n2_05_lr_nb_01'), \n",
    "    ('KNN', pipeline_knn, 1, 'nb_02_n2_06_knn_nb_01'),     \n",
    "    ('MLP', pipeline_mlp, 1, 'nb_02_n2_07_mlp_nb_01' ),\n",
    "    ('XGB', pipeline_xgb, 1, 'nb_02_n2_08_xgb_nb_01'),    \n",
    "    ('ExTrees', pipeline_ext, 1, 'nb_02_n2_09_extrees_nb_01'),    \n",
    "    ('LGBM', pipeline_lgbm, 1, 'nb_02_n2_10_lgbm_nb_01'), \n",
    "    ('RForest', pipeline_rf, 1, 'nb_02_n2_11_rforest_nb_01'),\n",
    "    ('HBoosting', pipeline_hbc, 1,'nb_02_n2_12_hboosting_nb_01')]\n",
    "\n",
    "df_pred_tr, df_pred_ts, df_score_mdl = \\\n",
    "    model_cv_fit(models_       = models, \n",
    "                 X_            = X_22.copy(),\n",
    "                 y_            = y, \n",
    "                 X_test_       = X_test_22.copy(),                  \n",
    "                 path_         = path, \n",
    "                 seed_         = seed,\n",
    "                 target_       = 'pred',\n",
    "                 create_sub_   = True, \n",
    "                 n_splits_     = 10,\n",
    "                 print_report_ = True, \n",
    "                 save_ensamble_= True,\n",
    "                 level_        = '2')\n",
    "\n",
    "# L.Loss: 0.52108 / L.Loss: 0.51999\n",
    "# L.Loss: 0.52089 / L.Loss: 0.52004 \n",
    "# L.Loss: 0.52109 / L.Loss: 0.52020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7b90f",
   "metadata": {
    "id": "26f7b90f"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Nas submissões todos os modelos tiveram score melhor que no treinamento na LB pública, o melhor modelo foi <b>LGBM</b>, abaixo as submissÕes:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e99050b",
   "metadata": {
    "id": "3e99050b"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e063a7",
   "metadata": {
    "id": "d1e063a7"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 4. ANÁLISE DAS PREVISÕES </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e06c22",
   "metadata": {
    "id": "75e06c22"
   },
   "source": [
    "## 4.1. Distribuição e calibração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6420c4e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-19T20:22:55.045Z"
    },
    "id": "d6420c4e"
   },
   "outputs": [],
   "source": [
    "#df_pred_tr = jb.load(path+path_data +'pkl/df_pred_tr.pkl.z' )\n",
    "#df_pred_ts = jb.load(path+path_data +'pkl/df_pred_ts.pkl.z' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b205df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:07:09.558788Z",
     "start_time": "2022-11-20T15:07:02.479652Z"
    },
    "id": "a5b205df",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = df_pred_tr.columns\n",
    "row  = int(len(cols))\n",
    "\n",
    "fig, axs = plt.subplots(row, 2, figsize=(15, 20)) \n",
    "\n",
    "for i, col in enumerate(cols):     \n",
    "    axs[i][0].hist(df_pred_tr[col], range=(0, 1), bins=100, density=True, color='#ffd700', label='Traino')\n",
    "    axs[i][0].hist(df_pred_ts[col], range=(0, 1), bins=100, density=True, color='#0057b8', label='Teste')\n",
    "    axs[i][0].set_title(col, fontsize=16)\n",
    "    axs[i][0].legend()\n",
    "\n",
    "    CalibrationDisplay.from_predictions(y, df_pred_tr[col], ax=axs[i][1], n_bins=20, strategy='quantile', color='b')\n",
    "    axs[i][1].set_title('Probability calibration')\n",
    "    axs[i][1].set_xlabel('')\n",
    "    axs[i][1].set_ylabel('')\n",
    "        \n",
    "plt.suptitle('Distribuição e calibração dos modelos', fontsize=20)\n",
    "plt.tight_layout(pad=3.0);\n",
    "\n",
    "utility.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14118d6a",
   "metadata": {
    "id": "14118d6a"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "A maioria dos modelos tem um boa calibração, exceto a MLP, em relação a distribuição das previsões em ambos os datasets apresentam a mesma distribuição. Alguns modelo pondem ser melhorados com ajuste de parametros. \n",
    "    \n",
    "    \n",
    "</didv>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f749b3",
   "metadata": {
    "id": "b4f749b3"
   },
   "source": [
    "## 4.2. Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f397f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:07:23.276853Z",
     "start_time": "2022-11-20T15:07:22.257332Z"
    },
    "id": "0f397f32"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_ = df_pred_tr.copy() \n",
    "_[target] = y\n",
    "feature_corr = \\\n",
    "    utility.graf_feature_corr(df_         = _,                             \n",
    "                              annot_      = True, \n",
    "                              threshold_  = .8, \n",
    "                              print_var_  = False, \n",
    "                              print_graf_ = True, \n",
    "                              mask_       = True, \n",
    "                              method_     = 'spearman');\n",
    "utility.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edjBwLuSIRy",
   "metadata": {
    "id": "0edjBwLuSIRy"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "Todos os modelos tem uma baixa correlação com a variável alvo, porem entre as previsões temos uma autocorreção, não vou me preocupar neste momento com essa auto correlação, pois mais tarde vamos fazer uma seleção da melhores variáveis para o próximo nível.     \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8qUUAKhHS7Th",
   "metadata": {
    "id": "8qUUAKhHS7Th"
   },
   "source": [
    "## 4.3. Média ponderada\n",
    "\n",
    "Vamos fazer dos modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65QBHMIMSLBU",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:07:30.131000Z",
     "start_time": "2022-11-20T15:07:30.111994Z"
    },
    "code_folding": [
     0
    ],
    "id": "65QBHMIMSLBU"
   },
   "outputs": [],
   "source": [
    "def get_oof_roc_score(df_, y_, weight_, pred_model1_, pred_model2_):\n",
    "    blend_pred = (df_[pred_model1_]*weight_)+(df_[pred_model2_]*(1 - weight_))\n",
    "    score      = log_loss(y_, blend_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uMp7v1YKSLvQ",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:08:02.087478Z",
     "start_time": "2022-11-20T15:07:35.240456Z"
    },
    "code_folding": [
     0
    ],
    "id": "uMp7v1YKSLvQ"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "feature_mdl      = df_pred_tr.columns.to_list()\n",
    "myscores_mdl     = []\n",
    "best_mdl_score_1 = []\n",
    "\n",
    "for mdl_1 in feature_mdl:     \n",
    "    f = feature_mdl.copy() \n",
    "    f.remove(mdl_1)   \n",
    "    for mdl_2 in f: \n",
    "        myscores    = {}\n",
    "        best        = 1.\n",
    "        best_weight = 0.\n",
    "\n",
    "        for weight in range(100):            \n",
    "            weight /= 100.\n",
    "            score = get_oof_roc_score(df_          = df_pred_tr, \n",
    "                                      y_           = y,\n",
    "                                      weight_      = weight, \n",
    "                                      pred_model1_ = mdl_1,  \n",
    "                                      pred_model2_ = mdl_2)\n",
    "\n",
    "            if score < best:\n",
    "                best        = score\n",
    "                best_weight = weight                \n",
    "\n",
    "            myscores[weight] = score\n",
    "\n",
    "    best_mdl_score_1.append({'model_1' : mdl_1, \n",
    "                             'model_2' : mdl_2, \n",
    "                             'score'   : round(best, 5), \n",
    "                             'weight'  : best_weight})\n",
    "\n",
    "    msg = 'Best Weight: {:2.5f} - Score: {:2.5f} => {} - {}'\n",
    "    print(msg.format(best_weight, best, mdl_1, mdl_2))  \n",
    "    \n",
    "_ = pd.DataFrame(best_mdl_score_1).sort_values('score')\n",
    "\n",
    "print()\n",
    "display(_)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BJG4oZLeSQYD",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:09:35.394104Z",
     "start_time": "2022-11-20T15:09:35.329071Z"
    },
    "id": "BJG4oZLeSQYD"
   },
   "outputs": [],
   "source": [
    "mdl_1 = str(_[:1].values[:,:1]).replace(\"[\", '').replace(\"'\",'').replace(\"]\", '').replace(\"'\",'')\n",
    "mdl_2 = str(_[:1].values[:,1:2]).replace(\"[\", '').replace(\"'\",'').replace(\"]\", '').replace(\"'\",'')\n",
    "weight = np.float64(str(_[:1].values[:,3:4]).replace(\"[\", '').replace(\"'\",'').replace(\"]\", '').replace(\"'\",''))\n",
    "\n",
    "name = 'nb_02_n2_13_emsable_average_{}_{}.csv'.format(mdl_1, mdl_2)\n",
    "df_submission['pred'] = df_pred_ts[mdl_1]*weight + df_pred_ts[mdl_2]*(1-weight)\n",
    "df_submission.to_csv(path+'Data/submission/'+name, index=False)\n",
    "# 0.51598 - n2_01_emsable_average_LGBM_0.52022_HBoosting_0.52385.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8_fbmuGCd_sT",
   "metadata": {
    "id": "8_fbmuGCd_sT"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "Na submissão da media ponderada do HBoosting e RForest se mostrou promissor com score de 0.51669, passando a ser melhor que a maior dos modelos. \n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cdda9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T23:04:14.026397Z",
     "start_time": "2022-11-13T23:04:14.013363Z"
    },
    "id": "ed2cdda9"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bf418",
   "metadata": {
    "id": "e14bf418"
   },
   "source": [
    "# 5. Terceiro Nível\n",
    "Nesta parte do processo vamos pegar as previsões que foram geradas no segundo nível e fazer novas previsões com os modelos que foram utilizados, ao fazer as previsões vamos remover o modelo que faz a previsão do dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4FA3bpoeAa1B",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:10:16.912473Z",
     "start_time": "2022-11-20T15:10:16.897529Z"
    },
    "id": "4FA3bpoeAa1B"
   },
   "outputs": [],
   "source": [
    "df_pred_tr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf30b9",
   "metadata": {
    "id": "0ecf30b9"
   },
   "source": [
    "- Primeiro renomeamos as colunas dos datasets, com a renomeação temos facilidade para remover o modelo do dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WXrOTL8pwfin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:10:22.046532Z",
     "start_time": "2022-11-20T15:10:22.018587Z"
    },
    "id": "WXrOTL8pwfin"
   },
   "outputs": [],
   "source": [
    "df_tr = df_pred_tr.copy()\n",
    "df_ts = df_pred_ts.copy()\n",
    "\n",
    "cols_new = ['LR', 'KNN', 'MLP', 'XGB', 'ExTrees', \n",
    "            'LGBM', 'RForest','HBoosting']\n",
    "\n",
    "df_tr.columns= cols_new\n",
    "df_ts.columns= cols_new\n",
    "\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0aa6f",
   "metadata": {
    "id": "7ca0aa6f"
   },
   "source": [
    "- Nos passos abaixo temos a seguinte sequência: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c13e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T15:11:35.000643Z",
     "start_time": "2022-11-20T15:10:53.721327Z"
    },
    "id": "6d4c13e8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Lista com os modelos para gerar as previsões \n",
    "models_n3 = [\n",
    "    ('RForest', model_rf, 1, 'nb_02_n3_14_rf'), \n",
    "    ('XGB', model_xgb, 1, 'nb_02_n3_15_xgb'), \n",
    "    ('LGBM', model_lgbm, 1, 'nb_02_n3_16_lgbm'), \n",
    "    ('HBoosting', model_hbc, 1, 'nb_02_n3_17_hbc'), \n",
    "    ('LR', model_lr, 1, 'nb_02_n3_18_lr')\n",
    "]\n",
    "      \n",
    "# Dataset para armazenar as previsões\n",
    "df_pred_tr_n3   = pd.DataFrame() \n",
    "df_pred_ts_n3   = pd.DataFrame()\n",
    "df_score_mdl_n3 = pd.DataFrame()\n",
    "\n",
    "# Loop para treina cada modelo \n",
    "for mdl in models_n3: \n",
    "    \n",
    "    # Lista com o nome de cada modelo\n",
    "    cols = ['LR', 'KNN', 'MLP', 'XGB', 'ExTrees', 'LGBM', 'HBoosting', 'RForest']\n",
    "    \n",
    "    # remoção da colona, previsões do modelo, do treinamento. \n",
    "    cols.remove(mdl[0])\n",
    "    \n",
    "    # Chama uma função para treinar o modelo e retorna as previsões\n",
    "    _tr_n3, _ts_n3, _score_mdl_n3 = \\\n",
    "        model_cv_fit(models_          = [mdl], \n",
    "                     X_               = df_tr[cols],\n",
    "                     y_               = y, \n",
    "                     X_test_          = df_ts[cols],                  \n",
    "                     path_            = path, \n",
    "                     seed_            = seed,\n",
    "                     target_          = 'pred',\n",
    "                     create_sub_      = True, \n",
    "                     n_splits_        = 10,\n",
    "                     print_report_    = False, \n",
    "                     print_score_mdl_ = False, \n",
    "                     save_ensamble_   = True,\n",
    "                     level_           = '3'\n",
    "                    ) \n",
    "    \n",
    "    # Armazeno as previsões para o próximo nível \n",
    "    df_pred_tr_n3   = pd.concat([df_pred_tr_n3, _tr_n3], axis=1)\n",
    "    df_pred_ts_n3   = pd.concat([df_pred_ts_n3, _ts_n3], axis=1)\n",
    "    df_score_mdl_n3 = pd.concat([df_score_mdl_n3, _score_mdl_n3]) \n",
    "    \n",
    "del _tr_n3, _ts_n3, _score_mdl_n3 \n",
    "\n",
    "df_score_mdl_n3.sort_values(by='score',ascending=True)  \n",
    "\n",
    "# L.Loss: 0.52115 => 0.51405 -  nb_02_n3_14_rf_0.52115_folds_10_oof.csv.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77886822",
   "metadata": {
    "id": "77886822"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "\n",
    "O melhor modelo foi <b>R. Forest</b> tando no treinamento e na LB, batendo o score anterior. Vamos fazer algumas análise e gerar uma média ponderada.     \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i89RmLhe2MC1",
   "metadata": {
    "id": "i89RmLhe2MC1"
   },
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bfec3",
   "metadata": {
    "id": "0d0bfec3"
   },
   "source": [
    "## 5.1. Distribuição e calibração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dMSPgTn0f5-",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-19T20:23:05.995Z"
    },
    "id": "4dMSPgTn0f5-"
   },
   "outputs": [],
   "source": [
    "cols = df_pred_tr_n3.columns\n",
    "row  = int(len(cols))\n",
    "\n",
    "fig, axs = plt.subplots(row, 2, figsize=(15, 15)) \n",
    "\n",
    "for i, col in enumerate(cols):     \n",
    "    axs[i][0].hist(df_pred_tr_n3[col], range=(0, 1), bins=100, density=True, color='#ffd700', label='Traino')\n",
    "    axs[i][0].hist(df_pred_ts_n3[col], range=(0, 1), bins=100, density=True, color='#0057b8', label='Teste')\n",
    "    axs[i][0].set_title(col, fontsize=16)\n",
    "    axs[i][0].legend()\n",
    "\n",
    "    CalibrationDisplay.from_predictions(y, df_pred_tr_n3[col], ax=axs[i][1], n_bins=20, strategy='quantile', color='b')\n",
    "    axs[i][1].set_title('Probability calibration')\n",
    "    axs[i][1].set_xlabel('')\n",
    "    axs[i][1].set_ylabel('')\n",
    "        \n",
    "plt.suptitle('Distribuição e calibração dos modelos', fontsize=20)\n",
    "plt.tight_layout(pad=3.0);\n",
    "\n",
    "utility.free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1224e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T16:35:39.383613Z",
     "start_time": "2022-11-20T16:35:39.073989Z"
    },
    "id": "43a1224e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "_ = df_pred_tr_n3.copy() \n",
    "_[target] = y\n",
    "feature_corr = \\\n",
    "    utility.graf_feature_corr(df_         = _,                             \n",
    "                              annot_      = True, \n",
    "                              threshold_  = .8, \n",
    "                              print_var_  = False, \n",
    "                              print_graf_ = True, \n",
    "                              mask_       = True, \n",
    "                              method_     = 'spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M_XPht8i1wOU",
   "metadata": {
    "id": "M_XPht8i1wOU"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "<p style=\"color: black; font-family: Arial Black\">NOTA:</p>\n",
    "   \n",
    "Observamos que a distribuição dos datasets(treino/teste) seguem a mesma distribuição, porém com a maioria das probabilidade entre 0.2 e 0.8, ainda temos um espaço para melhoria. Em relação a calibração a maioria dos modelos tem uma boa calibragem, exceto LR e XGB. <p>\n",
    "\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9oEewgDfFiD3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-19T20:23:07.600Z"
    },
    "id": "9oEewgDfFiD3"
   },
   "outputs": [],
   "source": [
    "cols_n3 = ['RForest', 'XGB', 'LGBM', 'HBoosting', 'LR' ] \n",
    "df_pred_tr_n3.columns= cols_n3\n",
    "df_pred_ts_n3.columns= cols_n3\n",
    "df_pred_ts_n3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1reGSZuC2DEm",
   "metadata": {
    "id": "1reGSZuC2DEm"
   },
   "outputs": [],
   "source": [
    "w1 = .7\n",
    "w2 = .3\n",
    "name = 'nb_02_n4_19_emsable_average_RForest_LGBM_w1_{}_w2_{}.csv'.format(w1, w2)\n",
    "name = 'nb_02_n4_22_emsable_average.csv'\n",
    "df_submission['pred'] = df_pred_ts_n3['RForest']*w1 + df_pred_ts_n3['HBoosting']*w2\n",
    "df_submission.to_csv(path+'Data/submission/'+name, index=False)\n",
    "# 0.51404 - nb_02_n4_22_emsable_average.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6cfad",
   "metadata": {
    "id": "f3b6cfad"
   },
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4e539",
   "metadata": {
    "id": "0fa4e539"
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 6. CONCLUSÃO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ead6a",
   "metadata": {
    "id": "6a0ead6a"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius:15px\">\n",
    "\n",
    "Com esse notebook, consegui superar o score do notebook anterior, podemos destacar os seguintes pontos: <br>\n",
    "    \n",
    "- A remoção das variáveis irrelevantes com a utilização do <b>SelectFromModel do sklearn</b> deve efeito relevante para as previsões;\n",
    "    \n",
    "- As duas variáveis (PCA e cluster) criadas também ajudaram significativamente na melhoria do score;\n",
    "    \n",
    "- Foram criadas variáveis estatísca, mas não teve bom desempenho, sendo removido;  \n",
    "        \n",
    "- Foram geradas diversas previsões no segundo nível, no terceiro nível foi utilizado as previsões do segundo nível com a utilização de alguns classificadores do segundo nível, o melhor modelo fo <b>R. Forest</b>.  \n",
    "   \n",
    "<p style=\"color: black; font-family: Arial Black\">PRÓXIMOS PASSOS:</p> <br>\n",
    "- Ajuste de parametros; \n",
    "- Seleção de variáveis com permutação;\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f53b93c8"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
