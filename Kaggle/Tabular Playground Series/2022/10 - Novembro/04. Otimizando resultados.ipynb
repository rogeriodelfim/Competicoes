{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54555c2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-19T20:02:13.544Z"
    }
   },
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;\n",
    "            background-color:#a7d5ed;font-size:170%;\n",
    "            font-family:Nexa;letter-spacing:4.5px;\">    \n",
    "    <h1 style=\"padding:15px;color:black;text-align: center\"> Otimizando resultados </h1> \n",
    "</div>\n",
    "\n",
    "![](img/header.png?t=2021-04-09-00-57-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47160732",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-19T20:02:51.304Z"
    }
   },
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> OBJETIVO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8dd42",
   "metadata": {},
   "source": [
    "Neste notebook, vou utilizar os resultados de outros notebooks. Mas no final a pontuação deste notebook será melhor que a pontuação de cada notebook utilizado. É claro que esse tipo de método funciona apenas para alguns desafios e não é um método geral.\n",
    "\n",
    " Nas etapas de um a seis, usei \"ensembling\" e na etapa sete, usei o \"Método Comparativo\". O \"Método Comparativo\" é novo para você porque é uma ideia minha. Claro, fora do Kaggle, usei o \"Método Comparativo\" muitas vezes, e esse método sempre funcionou muito bem. Por isso resolvi compartilhar esse método com você nesse desafio. Como você verá neste caderno, o efeito positivo do \"Método Comparativo\" é ainda maior do que o efeito de todas as etapas do \"ensemble\".\n",
    "\n",
    "Por exemplo, suponha que você tenha um projeto real (não um desafio Kaggle). Você obteve sete resultados medíocres com sete métodos simples e três bons resultados com três métodos avançados. Você geralmente perde sete resultados medíocres, mas minha sugestão é que mesmo os resultados medíocres são importantes. Você pode melhorar bons resultados por \"conjunto\" e usar resultados medíocres para o \"Método Comparativo\".\n",
    "\n",
    "Até o momento, usei os resultados de doze kernels. Claro que pontuações melhores têm um impacto maior na pontuação deste notebook. Porém, cada kernel tem me ajudado na votação (Método Comparativo). Obrigado a todos e novamente mencionarei os endereços de alguns desses kernels abaixo. Certamente o mérito deste caderno é de todos nós.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76acda37",
   "metadata": {},
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649437a",
   "metadata": {},
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 1. IMPORTAÇÕES </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251883d",
   "metadata": {},
   "source": [
    "## 1.1. Instalações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7f0c43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:13:46.350198Z",
     "start_time": "2022-11-19T20:13:46.332198Z"
    }
   },
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython()) \n",
    "\n",
    "if COLAB:        \n",
    "    !pip install --q scikit-plot\n",
    "    !pip install --q category_encoders\n",
    "    !pip install --q shap\n",
    "    !pip install --q inflection    \n",
    "    !pip install --q catboost\n",
    "    !pip install --q colorama\n",
    "    #!pip install --q optbinning\n",
    "    #!pip install --q catboost\n",
    "    #!pip install --q pandas-profiling\n",
    "    #!pip install --q pycaret\n",
    "        \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b07582",
   "metadata": {},
   "source": [
    "## 1.2. Bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70310389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:04.114778Z",
     "start_time": "2022-11-19T20:10:53.803749Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import sklearn.exceptions\n",
    "import multiprocessing\n",
    "import glob\n",
    "import scipy.optimize \n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d293685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:25:09.986285Z",
     "start_time": "2022-11-19T20:25:09.980283Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas                    as pd\n",
    "import numpy                     as np\n",
    "import matplotlib.pyplot         as plt \n",
    "import seaborn                   as sns\n",
    "import joblib                    as jb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9052e204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:59:21.823448Z",
     "start_time": "2022-11-19T20:59:19.861002Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook             import tqdm, trange\n",
    "from matplotlib.axes._axes     import _log as matplotlib_axes_logger\n",
    "from sklearn.metrics           import roc_auc_score, f1_score, log_loss, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d62d0c",
   "metadata": {},
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6138",
   "metadata": {},
   "source": [
    "## 1.3. Funções\n",
    "Aqui centralizamos todas as funções desenvolvidas durante o projeto para melhor organização do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "588b6908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:29.258403Z",
     "start_time": "2022-11-19T20:11:29.242407Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def delete_files(namefile):\n",
    "\n",
    "        path = ['model/train', 'model/test', 'model/valid', 'model/params', 'model/score',\n",
    "                'model/test_f', 'model/cv_model', 'model/preds', 'model/optuna', \n",
    "                'model/preds/train', 'model/preds/test', 'model/preds/test/n1', \n",
    "                'model/preds/test/n2', 'model/preds/test/n3', 'model/preds/train/n1', \n",
    "                'model/preds/train/n2', 'model/preds/train/n3','model/preds/param', \n",
    "                'Data/submission/tunning', 'Data/submission', 'model/mdl'\n",
    "                \n",
    "               ]\n",
    "\n",
    "        for path_ in path:\n",
    "            for raiz, diretorios, arquivos in os.walk(path_):\n",
    "                for arquivo in arquivos:\n",
    "                    if arquivo.startswith(namefile):                    \n",
    "                        os.remove(os.path.join(raiz, arquivo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dd5c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:29.742214Z",
     "start_time": "2022-11-19T20:11:29.722213Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def save_data_model(model_, model_name_, path_, y_pred_train_prob_, y_pred_test_prob_, y_pred_test_submission_, \n",
    "                    score_, seed_, level_='1', target_='target', cutoff_value_=.6, gera_submission_=True):    \n",
    "    \n",
    "    level = 'n' + level_ + '/'\n",
    "\n",
    "    if score_>cutoff_value_:    \n",
    "        \n",
    "        path_name_param = path_ + 'model/preds/param/' + model_name_.format(score_, seed_) + '.pkl.z'\n",
    "        path_name_train = path_ + 'model/preds/train/' + level + model_name_.format(score_, seed_)  + '.pkl.z'\n",
    "        path_name_test  = path_ + 'model/preds/test/'  + level + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        path_name_model = path_ + 'model/mdl/'         + model_name_.format(score_, seed_)  + '.pkl.z'   \n",
    "        \n",
    "        delete_files(model_name_)\n",
    "        \n",
    "        jb.dump(y_pred_train_prob_, path_name_train)\n",
    "        jb.dump(y_pred_test_prob_, path_name_test)\n",
    "        jb.dump(model_, path_name_model)\n",
    "                \n",
    "        if gera_submission_:\n",
    "            df_submission[target_] = y_pred_test_submission_\n",
    "            df_submission.to_csv(path_ + 'Data/submission/' + model_name_+ '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c045ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:30.329548Z",
     "start_time": "2022-11-19T20:11:30.306540Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_cv_fit(models_, X_, y_, X_test_, path_, target_='pred', seed_=12359, print_report_=False, \n",
    "                 print_score_mdl_=True, n_splits_=5, create_sub_=False, #print_hist_=False, \n",
    "                 var_th_=1.0e-03, save_ensamble_=True, level_='1'):\n",
    "    \n",
    "    cols        = []\n",
    "    cols_score  = []\n",
    "    oof_train   = np.zeros((len(X_), len(models_)))\n",
    "    score_mdl   = np.zeros(len(models_),)\n",
    "    oof_test    = np.zeros((len(X_test_), len(models_)))\n",
    "    kf          = StratifiedKFold(shuffle=True, n_splits=n_splits_, random_state=seed_)        \n",
    "    X_ts        = scipy.special.logit(X_test_.clip(1e-6, 1-1e-6))\n",
    "    \n",
    "    for i, m in enumerate(models_):\n",
    "        \n",
    "        time_start  = datetime.now()        \n",
    "        model       = m[1]\n",
    "        type_model  = m[2]\n",
    "        name_sub    = m[3]\n",
    "        score_list  = []\n",
    "        y_ts_pred   = 0 \n",
    "        \n",
    "        delete_files(name_sub)\n",
    "        \n",
    "        print()\n",
    "        print('=> {}'.format(m[0]))\n",
    "        print('='*73)\n",
    "\n",
    "        for fold, (idx_tr, idx_va) in enumerate(kf.split(X_, y_)):\n",
    "            \n",
    "            time_fold_start = datetime.now()\n",
    "            \n",
    "            X_tr = scipy.special.logit(X_.iloc[idx_tr].clip(1e-6, 1-1e-6))\n",
    "            X_va = scipy.special.logit(X_.iloc[idx_va].clip(1e-6, 1-1e-6))\n",
    "            y_tr = y_.iloc[idx_tr]\n",
    "            y_va = y_.iloc[idx_va]\n",
    "            \n",
    "            if type_model==1:\n",
    "                model.fit(X_tr, y_tr)\n",
    "\n",
    "            if type_model==2:\n",
    "                model.fit(X_tr, y_tr, \n",
    "                          model__eval_set=[(X_va, y_va)], \n",
    "                          model__eval_metric ='binary_logloss', \n",
    "                          model__callbacks=[early_stopping(100)]\n",
    "                          )\n",
    "\n",
    "\n",
    "            y_va_pred  = model.predict_proba(X_va)[:,1]\n",
    "            y_ts_pred += model.predict_proba(X_ts)[:,1]/kf.n_splits                      \n",
    "            logloss    = log_loss(y_va, y_va_pred) \n",
    "            f1         = f1_score(y_va, (y_va_pred>.5).astype(int))\n",
    "            roc_auc    = roc_auc_score(y_va, (y_va_pred>.5).astype(int))            \n",
    "            \n",
    "            oof_train[idx_va, i] = y_va_pred\n",
    "            \n",
    "            time_fold_end = utility.diff(time_fold_start, datetime.now())\n",
    "            \n",
    "            msg = \"Fold {} => L.Loss: {:2.5f} - F1-score: {:2.5f} - AUC:{:2.5f} - {}\"            \n",
    "            print(msg.format(fold+1,logloss,f1,roc_auc, time_fold_end))\n",
    "            \n",
    "            score_list.append(logloss)\n",
    "\n",
    "        oof_test[:,i] = y_ts_pred\n",
    "        score_mean    = np.mean(score_list).round(5)\n",
    "        \n",
    "        #if print_hist_: \n",
    "        #    plot_oof_histogram(m[0], oof_train)\n",
    "        \n",
    "        cols.append(m[0])\n",
    "        cols_score.append(m[0]+'_'+str(score_mean))\n",
    "                \n",
    "        if create_sub_:\n",
    "            if target_ is None: target_=target\n",
    "            name_sub = name_sub+'_{:2.5f}_folds_{}_oof.csv'.format(score_mean, n_splits_)\n",
    "\n",
    "            save_data_model(model_                  = model, \n",
    "                            model_name_             = name_sub, \n",
    "                            path_                   = path_, \n",
    "                            y_pred_train_prob_      = oof_train[:, i], \n",
    "                            y_pred_test_prob_       = oof_test[:,i], \n",
    "                            y_pred_test_submission_ = oof_test[:,i], \n",
    "                            score_                  = score_mean, \n",
    "                            seed_                   = seed_, \n",
    "                            level_                  = level_, \n",
    "                            target_                 = target_, \n",
    "                            cutoff_value_           = .1, \n",
    "                            gera_submission_        = True)  \n",
    "        \n",
    "        score_mdl[i] = score_mean\n",
    "        \n",
    "        time_end = utility.diff(time_start, datetime.now()) \n",
    "        \n",
    "        print('-'*73)\n",
    "        print(f'{Fore.GREEN}{Style.BRIGHT}[Fold Mean] L.Loss: {score_mean:.5f}{Style.RESET_ALL} - {time_end}') \n",
    "        print('='*73)\n",
    "        \n",
    "        if print_report_: \n",
    "            y_pred = (oof_train[:, i]>.5).astype(int)\n",
    "            print()\n",
    "            print(classification_report(y_, y_pred))\n",
    "            print(confusion_matrix(y_, y_pred))    \n",
    "\n",
    "        utility.free_gpu_cache()\n",
    "           \n",
    "    df_oof_tr    = pd.DataFrame(oof_train, columns=cols_score) \n",
    "    df_oof_ts    = pd.DataFrame(oof_test, columns=cols_score) \n",
    "    df_score_mdl = pd.DataFrame(score_mdl, columns= ['score'])\n",
    "    \n",
    "    df_score_mdl.index = cols    \n",
    "    df_score_mdl       = df_score_mdl.sort_values(by='score',ascending=True)  \n",
    "    \n",
    "    if save_ensamble_:\n",
    "        jb.dump(df_oof_tr, path_ + 'Data/pkl/df_pred_tr_n{}.pkl.z'.format(level_))\n",
    "        jb.dump(df_oof_ts, path_ + 'Data/pkl/df_pred_ts_n{}.pkl.z'.format(level_));\n",
    "\n",
    "    if print_score_mdl_: display(df_score_mdl)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    return df_oof_tr, df_oof_ts, df_score_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30e2d6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:30.914259Z",
     "start_time": "2022-11-19T20:11:30.659225Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Utility():\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.name_ =''\n",
    "       \n",
    "    def jupyter_setting():\n",
    "    \n",
    "        %matplotlib inline\n",
    "\n",
    "        #os.environ[\"WANDB_SILENT\"] = \"true\" \n",
    "        #plt.style.use('bmh') \n",
    "        #plt.rcParams['figure.figsize'] = [20,15]\n",
    "        #plt.rcParams['font.size']      = 13\n",
    "\n",
    "        matplotlib_axes_logger.setLevel('ERROR')\n",
    "\n",
    "        pd.options.display.max_columns = None\n",
    "        #pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        warnings.simplefilter('ignore')\n",
    "        warnings.filterwarnings('ignore')\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category= sklearn.exceptions.UndefinedMetricWarning)\n",
    "        warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "        pd.options.mode.chained_assignment = None \n",
    "        pd.set_option('display.max_rows', 200)\n",
    "        pd.set_option('display.max_columns', 500)\n",
    "        pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "        icecream = [\"#00008b\", \"#960018\",\"#008b00\", \"#00468b\", \"#8b4500\", \"#582c00\"]\n",
    "        #sns.palplot(sns.color_palette(icecream))\n",
    "\n",
    "        colors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n",
    "              \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n",
    "              \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n",
    "              \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]\n",
    "\n",
    "        # Colors\n",
    "        dark_red   = \"#b20710\"\n",
    "        black      = \"#221f1f\"\n",
    "        green      = \"#009473\"\n",
    "        myred      = '#CD5C5C'\n",
    "        myblue     = '#6495ED'\n",
    "        mygreen    = '#90EE90'    \n",
    "        color_cols = [myred, myblue,mygreen]\n",
    "\n",
    "        return icecream, colors, color_cols\n",
    "\n",
    "    def missing_zero_values_table(self, df):\n",
    "        \n",
    "        mis_val         = df.isnull().sum()\n",
    "        mis_val_percent = round(df.isnull().mean().mul(100), 2)\n",
    "        mz_table        = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table        = mz_table.rename(columns = {df.index.name:'col_name', \n",
    "                                                     0 : 'Valores ausentes', \n",
    "                                                     1 : '% de valores totais'})\n",
    "        \n",
    "        mz_table['Tipo de dados'] = df.dtypes\n",
    "        mz_table                  = mz_table[mz_table.iloc[:,1] != 0 ]. \\\n",
    "                                     sort_values('% de valores totais', ascending=False)\n",
    "        \n",
    "        msg = \"Seu dataframe selecionado tem {} colunas e {} \" + \\\n",
    "              \"linhas. \\nExistem {} colunas com valores ausentes.\"\n",
    "            \n",
    "        print (msg.format(df.shape[1], df.shape[0], mz_table.shape[0]))\n",
    "        \n",
    "        return mz_table.reset_index()\n",
    "    \n",
    "    def reduce_memory_usage(self, df, verbose=True):\n",
    "    \n",
    "        numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "        start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            col_type = df[col].dtypes\n",
    "\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "        end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                    end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def graf_label(self, ax, total):\n",
    "\n",
    "         for i in ax.patches:\n",
    "            # get_width pulls left or right; get_y pushes up or down\n",
    "            width, height = i.get_width() -.2 , i.get_height()\n",
    "\n",
    "            x, y  = i.get_xy()  \n",
    "            color = 'white'\n",
    "            alt   = .5\n",
    "            soma  = 0 \n",
    "\n",
    "            if height < 70:\n",
    "                color = 'black'\n",
    "                alt   = 1\n",
    "                soma  = 10\n",
    "\n",
    "            ax.annotate(str(round((i.get_height() * 100.0 / total), 1) )+'%', \n",
    "                        (i.get_x()+.55*width, \n",
    "                         i.get_y()+soma + alt*height),\n",
    "                         color   = color,\n",
    "                         weight = 'bold',\n",
    "                         size   = 14)\n",
    "            \n",
    "    def graf_bar(self, df, col, title, xlabel, ylabel, tol = 0):\n",
    "    \n",
    "        #ax    = df.groupby(['churn_cat'])['churn_cat'].count()\n",
    "        ax     = df    \n",
    "        colors = col\n",
    "\n",
    "        if tol == 0: \n",
    "            total  = sum(ax)\n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           color   = colors, \n",
    "                           grid    = False)\n",
    "        else:\n",
    "            total  = tol     \n",
    "            ax = (ax).plot(kind    ='bar',\n",
    "                           stacked = True,\n",
    "                           width   = .5,\n",
    "                           rot     = 0,\n",
    "                           figsize = (10,6),\n",
    "                           color   = colors,\n",
    "                           grid    = False)\n",
    "\n",
    "        title   = title #+ ' \\n'\n",
    "        xlabel  = '\\n ' + xlabel \n",
    "        ylabel  = ylabel + ' \\n'\n",
    "\n",
    "        ax.set_title(title  , fontsize=22)\n",
    "        ax.set_xlabel(xlabel, fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)    \n",
    "\n",
    "        min = [0,23000000]\n",
    "        #ax.set_ylim(min)\n",
    "        self.graf_label(ax, total)\n",
    "\n",
    "    def correlation(self, df_, threshold_):\n",
    "        col_corr    = set()  \n",
    "        corr_matrix = df_.corr()\n",
    "        \n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > threshold_: \n",
    "                    colname = corr_matrix.columns[i]  \n",
    "                    col_corr.add(colname)\n",
    "                    \n",
    "        return col_corr\n",
    "\n",
    "    def __graf_fature_corr(df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                         print_graf_=True, mask_=True, title_='', method_='pearson'):\n",
    "        \n",
    "        msg_title = '\\n Correlação das variável {} -{} \\n'.format(title_, 'method_')\n",
    "        \n",
    "        df = df_.copy().corr(method =method_).round(5)\n",
    "        \n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "            \n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot=annot_, \n",
    "                             mask=mask, \n",
    "                             cmap=\"RdBu\", \n",
    "                             annot_kws={\"weight\": \"bold\", \"fontsize\":13}                              \n",
    "                            )\n",
    "\n",
    "            ax.set_title(msg_title, fontsize=17)\n",
    "            \n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\", style = 'whitegrid', palette= 'pastel')\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\", style = 'whitegrid', palette= 'pastel')\n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.show();\n",
    "            \n",
    "            \n",
    "            \n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "        \n",
    "        #sns.set(style=\"darkgrid\")\n",
    "        plt.show();\n",
    "                        \n",
    "    def describe(self, df):\n",
    "        var = df.columns\n",
    "\n",
    "        # Medidas de tendência central, média e mediana \n",
    "        ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "        ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "        # Dispensão - str, min , max range skew, kurtosis\n",
    "        d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "        d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "        d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "        d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "        d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "        d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "        d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "        # concatenete \n",
    "        m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "        m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "\n",
    "        return m\n",
    "\n",
    "    def graf_outlier(self, df, feature):\n",
    "        col = [(0,4), (5,9)]\n",
    "\n",
    "        df_plot = ((df[feature] - df[feature].min())/\n",
    "                   (df[feature].max() - df[feature].min()))\n",
    "\n",
    "        fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "        for i, (x) in enumerate(col): \n",
    "            sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); \n",
    "\n",
    "    def diff(self, t_a, t_b):\n",
    "        from dateutil.relativedelta import relativedelta\n",
    "        t_diff = relativedelta(t_b, t_a)  # later/end time comes first!\n",
    "        return '{h}h {m}m {s}s'.format(h=t_diff.hours, m=t_diff.minutes, s=t_diff.seconds)\n",
    "    \n",
    "    def free_gpu_cache(self):\n",
    "\n",
    "        # https://www.kaggle.com/getting-started/140636\n",
    "        #print(\"Initial GPU Usage\")\n",
    "        #gpu_usage()                             \n",
    "\n",
    "        #cuda.select_device(0)\n",
    "        #cuda.close()\n",
    "        #cuda.select_device(0)   \n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def graf_eval(self):\n",
    "\n",
    "        results     = model.evals_result()\n",
    "        ntree_limit = model.best_ntree_limit\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "\n",
    "        for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "\n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "            plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "            plt.axvline(ntree_limit, \n",
    "                        color=\"gray\", \n",
    "                        label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "\n",
    "\n",
    "            title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "            plt.title(title_name)\n",
    "            plt.xlabel(\"Número de árvores\")\n",
    "            plt.ylabel(error)\n",
    "            plt.legend();\n",
    "\n",
    "    def linear_fit_slope(self, y):\n",
    "        \"\"\"Return the slope of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return slope\n",
    "\n",
    "    def linear_fit_intercept(self, y):\n",
    "        \"\"\"Return the intercept of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return intercept\n",
    "\n",
    "    def cromer_v(self, x, y):\n",
    "        cm       = pd.crosstab(x, y).to_numpy()        \n",
    "        n        = cm.sum()\n",
    "        r, k     = cm.shape\n",
    "        chi2     = stats.chi2_contingency(cm)[0]\n",
    "        chi2corr = max(0, chi2 - (k-1) * (r-1) /(n-1))\n",
    "        kcorr    = k - (k-1) **2/(n-1)\n",
    "        rcorr    = r - (r-1) **2/(n-1)    \n",
    "        v        = np.sqrt((chi2corr/n) / (min(kcorr-1, rcorr-1)))        \n",
    "        return v  \n",
    "\n",
    "    def generate_category_table(self, data):\n",
    "\n",
    "        cols    = data.select_dtypes(include='object').columns\n",
    "        dataset = pd.DataFrame()\n",
    "\n",
    "        for i in cols:\n",
    "            corr = []\n",
    "            for x in cols: \n",
    "                corr.append(self.cromer_v(data[i],data[x]))\n",
    "\n",
    "            aux     = pd.DataFrame({i:corr})\n",
    "            dataset = pd.concat([dataset, aux], axis=1) \n",
    "\n",
    "        return dataset.set_index(dataset.columns)\n",
    "            \n",
    "    def graf_feature_corr(self, df_, annot_=False, threshold_=.8, print_var_=False, \n",
    "                          print_graf_=True, mask_=True, title_='', method_='pearson'):\n",
    "\n",
    "        df = df_.corr(method=method_).round(5)\n",
    "\n",
    "        if print_graf_: \n",
    "            # Máscara para ocultar a parte superior direita do gráfico, pois é uma duplicata\n",
    "            mask = np.zeros_like(df)\n",
    "            mask[np.triu_indices_from(mask)] = mask_\n",
    "\n",
    "            sns.set(style=\"whitegrid\", palette=\"pastel\") \n",
    "            \n",
    "            # Making a plot\n",
    "            ax = sns.heatmap(df, annot = annot_, \n",
    "                             mask      = mask, \n",
    "                             cmap      = \"RdBu\", \n",
    "                             fmt       = \".2f\",\n",
    "                             annot_kws = {\"weight\": \"bold\", \"fontsize\":10}\n",
    "                            )\n",
    "            \n",
    "            ax.set_title(\"\\n Correlação das variável {} - {} \\n\".format(title_, method_.upper()), fontsize=17)\n",
    "\n",
    "            plt.setp(ax.get_xticklabels(), \n",
    "                     rotation      = 90, \n",
    "                     ha            = \"right\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     weight        = \"normal\")\n",
    "\n",
    "            plt.setp(ax.get_yticklabels(), \n",
    "                     weight        = \"normal\",\n",
    "                     rotation_mode = \"anchor\", \n",
    "                     rotation      = 0, \n",
    "                     ha            = \"right\")\n",
    "            \n",
    "            sns.set(style=\"darkgrid\")\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "        if print_var_:         \n",
    "            df_corr = df[abs(df)>threshold_][df!=1.0].unstack().dropna().reset_index()\n",
    "            if len(df_corr)>0:            \n",
    "                print('Variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                df_corr.columns =  ['var_1', 'var_2', 'corr']\n",
    "                display(df_corr)\n",
    "            else: \n",
    "                print('Não tem variáveis autocorrelacionadas threshold={:2.2f}'.format(threshold_))\n",
    "                \n",
    "        return self.correlation(df_, threshold_)\n",
    "\n",
    "    def plot_roc_curve(self, fpr, tpr, label=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(fpr, tpr, \"r-\", label=label)\n",
    "        ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.rcParams['font.size'] = 12\n",
    "        plt.title('ROC curve for FLAI 08')\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "\n",
    "    def feature_engineering(self, df_):\n",
    "\n",
    "        var_f27 = ''\n",
    "        for col in df_['f_27']: \n",
    "            var_f27 +=col\n",
    "\n",
    "        var_f27 = list(set(var_f27))\n",
    "        var_f27.sort()\n",
    "\n",
    "        df_[\"fe_f_27_unique\"] = df_[\"f_27\"].apply(lambda x: len(set(x)))\n",
    "\n",
    "        for letra in var_f27:             \n",
    "            df_['fe_' + letra.lower() + '_count'] = df2_train[\"f_27\"].str.count(letra)\n",
    "\n",
    "        return df_ \n",
    "\n",
    "    def identifies_outliers(self, df):\n",
    "\n",
    "        cols_num = df.select_dtypes(np.number).columns\n",
    "\n",
    "        for col in cols_num: \n",
    "            if col != 'unnamed':            \n",
    "                Q1  = df[col].quantile(0.25)\n",
    "                Q3  = df[col].quantile(0.75)\n",
    "                IQR = Q3-Q1\n",
    "                lowqe_bound=Q1 - 1.5 * IQR\n",
    "                upper_bound=Q3 + 1.5 * IQR\n",
    "\n",
    "                df['outliers_'+ col] = 0\n",
    "                df['outliers_'+ col][(df[col]<=lowqe_bound)|(df[col]>=upper_bound)] = 1    \n",
    "\n",
    "                df[col] = np.where(df[col] > df[col].quantile(0.95),\n",
    "                                                df[col].median(),\n",
    "                                                df[col])\n",
    "\n",
    "    def evaluation(self, y_, predictions_, smape_base_=100):\n",
    "        from sklearn import metrics\n",
    "        mae   = metrics.mean_absolute_error(y_, predictions_)\n",
    "        mse   = metrics.mean_squared_error(y_, predictions_)\n",
    "        rmse  = metrics.mean_squared_error(y_, predictions_, squared=False) \n",
    "        mape  = metrics.mean_absolute_percentage_error(y_, predictions_)\n",
    "        smape = self.smape(y_, predictions_)\n",
    "        r2    = metrics.r2_score(y_, predictions_)    \n",
    "        return rmse, mae, mse, mape, r2, smape\n",
    "    \n",
    "    def feature_statistic(self, df, feature_float, feature_cat=None):\n",
    "        df['fe_mean']        = df[feature_float].mean(axis=1)   \n",
    "        df['fe_std']         = df[feature_float].std(axis=1)   \n",
    "        df['fe_median']      = df[feature_float].median(axis=1)   \n",
    "        df['fe_var']         = df[feature_float].var(axis=1) \n",
    "        df['fe_min']         = df[feature_float].min(axis=1)   \n",
    "        df['fe_max']         = df[feature_float].max(axis=1)   \n",
    "        df['fe_skew']        = df[feature_float].skew(axis=1)   \n",
    "        df['fe_quantile_25'] = df[feature_float].quantile(q=.25, axis=1)\n",
    "        df['fe_quantile_50'] = df[feature_float].quantile(q=.5, axis=1)\n",
    "        df['fe_quantile_75'] = df[feature_float].quantile(q=.75, axis=1)\n",
    "        \n",
    "        if feature_cat is not None:\n",
    "            df['fe_dammy_count'] = df[feature_cat].sum(axis=1)   \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def gridSearchCV(self, model_, params_, X_train_, y_train_):\n",
    "        \"\"\"\n",
    "        @param    model: sklearn estimator\n",
    "        @param    params (dict): Dictionary of possible parameters\n",
    "\n",
    "        @return   cv_results (DataFrame)\n",
    "        \"\"\"\n",
    "        model_cv = GridSearchCV(model_, param_grid=params_, scoring='roc_auc', cv=5)\n",
    "        model_cv.fit(X_train_, y_train_)\n",
    "        cv_results = pd.DataFrame(model_cv.cv_results_)[['params', 'mean_test_score']]\n",
    "\n",
    "        return cv_results\n",
    "    \n",
    "    def evaluate(self, model,X_train_, y_train_, X_test_, plotROC=False):\n",
    "\n",
    "        model.fit(X_train_, y_train_)\n",
    "        probs = model.predict_proba(X_train_)\n",
    "        preds = probs[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(y_train_, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(f'AUC: {roc_auc:.4f}')\n",
    "\n",
    "        rocDf = pd.DataFrame({'fpr': fpr, 'tpr':tpr, 'threshold':threshold})\n",
    "        rocDf['tpr - fpr'] = rocDf.tpr - rocDf.fpr\n",
    "        optimalThreshold = rocDf.threshold[rocDf['tpr - fpr'].idxmax()]\n",
    "\n",
    "        y_pred = np.where(preds >= optimalThreshold, 1, 0)\n",
    "\n",
    "        # Plot ROC AUC\n",
    "        if plotROC:\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.plot([0, 1], [0, 1],'r--')\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.show()    \n",
    "\n",
    "    def iqr_outliers(self, df,ft):\n",
    "\n",
    "        q1  = df[ft].quantile(0.25)\n",
    "        q3  = df[ft].quantile(0.75)\n",
    "        iqr = q3-q1\n",
    "        c   = 0 \n",
    "\n",
    "        Lower_tail = q1 - 1.5 * iqr\n",
    "        Upper_tail = q3 + 1.5 * iqr\n",
    "\n",
    "        for i in range(len(df[ft])):\n",
    "            if df[ft][i] > Upper_tail or df[ft][i] < Lower_tail:\n",
    "                c+=1\n",
    "        return c\n",
    "    \n",
    "    def outlier_create_feature_check(self, df_tr_, df_ts_, cols_=[], qt_inferior_=.25, qt_superior_=.75, \n",
    "                                     flg_ts_=True, input_limete_=False, verbose_=True):\n",
    "    \n",
    "        col_oltlier         = 'fe_outlier'\n",
    "        df_tr_[col_oltlier] = 0 \n",
    "        df_ts_[col_oltlier] = 0 \n",
    "\n",
    "        for c in cols_:\n",
    "\n",
    "            percentil25 = df_tr_[c].quantile(qt_inferior_)\n",
    "            percentil75 = df_tr_[c].quantile(qt_superior_)\n",
    "\n",
    "            iqr= percentil75 - percentil25 \n",
    "\n",
    "            limite_inferior = percentil25 - 1.5 * iqr\n",
    "            limite_superior = percentil75 + 1.5 * iqr\n",
    "\n",
    "            df_tr_[col_oltlier][df_tr_[c]>limite_superior] = -1\n",
    "            df_tr_[col_oltlier][df_tr_[c]<limite_inferior] = -1\n",
    "\n",
    "            if input_limete_:\n",
    "                df_tr_[c][df_tr_[c]>limite_superior] = limite_superior\n",
    "                df_tr_[c][df_tr_[c]<limite_inferior] = limite_inferior\n",
    "\n",
    "            if flg_ts_:\n",
    "                df_ts_[col_oltlier][df_ts_[c]>limite_superior] = -1\n",
    "                df_ts_[col_oltlier][df_ts_[c]<limite_inferior] = -1\n",
    "                \n",
    "                if input_limete_:\n",
    "                    df_ts_[c][df_ts_[c]>limite_superior] = limite_superior\n",
    "                    df_ts_[c][df_ts_[c]<limite_inferior] = limite_inferior\n",
    "\n",
    "            if verbose_:\n",
    "                print('Com a variável {}'.format(c))\n",
    "                print(df_tr_[col_oltlier].value_counts())\n",
    "                print()\n",
    "\n",
    "        return df_tr_, df_ts_\n",
    "        \n",
    "    def calibrated_classifier_graf_model(self, mdl_list_, X_, y_, seed_=12359, figsize_=(10, 10), verbose_=False): \n",
    "\n",
    "        fig = plt.figure(1, figsize=figsize_)\n",
    "        ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "        \n",
    "        if verbose_: ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "        ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfeitamente calibrado\")\n",
    "\n",
    "        for name, mdl1 in mdl_list_:  \n",
    "            model_pipeline  = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor_1),\n",
    "                #('sampler_over', over), \n",
    "                #('sampler_under', under),    \n",
    "                ('variancethreshold', VarianceThreshold(threshold=0.1)),    \n",
    "                ('selectpercentile', SelectPercentile(f_classif, percentile=90)), \n",
    "                ('model', mdl1)\n",
    "                ])\n",
    "\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_, y_, test_size=0.5, random_state=seed_)\n",
    "\n",
    "            model_calibrated = CalibratedClassifierCV(model_pipeline, method='isotonic', cv=2) \n",
    "            # method='isotonic' sigmoid\n",
    "\n",
    "            model_calibrated.fit(X_train, y_train)\n",
    "\n",
    "            if hasattr(model_calibrated, \"predict_proba\"):\n",
    "                prob_pos = model_calibrated.predict_proba(X_val)[:, 1]\n",
    "            else:  \n",
    "                prob_pos = model_calibrated.decision_function(X_val)\n",
    "                prob_pos = (prob_pos-prob_pos.min()) / (prob_pos.max()-prob_pos.min())\n",
    "\n",
    "            score = brier_score_loss(y_val, prob_pos, pos_label=y_val.max())\n",
    "\n",
    "            frac_of_pos, mean_pred_value = calibration_curve(y_val, prob_pos, n_bins=15, normalize=True)      \n",
    "\n",
    "            ax1.plot(mean_pred_value, frac_of_pos, \"s-\", label=\"%s (%1.3f)\" % (name, score))\n",
    "\n",
    "            ax1.set_ylabel('Fração de positivos')\n",
    "            ax1.set_ylim([-0.05, 1.05])\n",
    "            ax1.legend(loc='upper left' )\n",
    "            ax1.set_title('\\nGráficos de calibração (curva de confiabilidade)\\n', fontsize=18)\n",
    "\n",
    "            if verbose_: \n",
    "                ax2.hist(prob_pos, range=(0, 1), bins=100, label=name, histtype=\"step\", lw=2)    \n",
    "                ax2.set_xlabel('Valor médio previsto')\n",
    "                ax2.set_ylabel('Quantidade')\n",
    "                ax2.legend(loc=\"upper left\", ncol=1)\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                msg = 'AUC: {:2.5f} - F1: {:2.5f} - Perda: {:2.3f} -> {}'\n",
    "                auc = roc_auc_score(y_val, prob_pos)\n",
    "                f1  = f1_score(y_val, (prob_pos>.5).astype(int))\n",
    "                print(msg.format(auc,f1, score, name))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def describe(df):\n",
    "        var = df.columns\n",
    "\n",
    "        # Medidas de tendência central, média e mediana \n",
    "        ct1 = pd.DataFrame(df[var].apply(np.mean)).T\n",
    "        ct2 = pd.DataFrame(df[var].apply(np.median)).T\n",
    "\n",
    "        # Dispensão - str, min , max range skew, kurtosis\n",
    "        d1 = pd.DataFrame(df[var].apply(np.std)).T\n",
    "        d2 = pd.DataFrame(df[var].apply(min)).T\n",
    "        d3 = pd.DataFrame(df[var].apply(max)).T\n",
    "        d4 = pd.DataFrame(df[var].apply(lambda x: x.max() - x.min())).T\n",
    "        d5 = pd.DataFrame(df[var].apply(lambda x: x.skew())).T\n",
    "        d6 = pd.DataFrame(df[var].apply(lambda x: x.kurtosis())).T\n",
    "        d7 = pd.DataFrame(df[var].apply(lambda x: (3 *( np.mean(x) - np.median(x)) / np.std(x) ))).T\n",
    "\n",
    "        # concatenete \n",
    "        m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6, d7]).T.reset_index()\n",
    "        m.columns = ['attrobutes', 'min', 'max', 'range', 'mean', 'median', 'std','skew', 'kurtosis','coef_as']\n",
    "        \n",
    "        return m\n",
    "        \n",
    "    def smape(self, a, f):\n",
    "        return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)\n",
    "\n",
    "    def smape_(self, y_true, y_pred, base_=100.):\n",
    "        denominator          = (np.abs(y_true)+np.abs(y_pred))/base_\n",
    "        diff                 = np.abs(y_true-y_pred)/denominator\n",
    "        diff[denominator==0] = 0.0\n",
    "        return np.nanmean(diff)\n",
    "    \n",
    "    def smape_loss(y_true, y_pred):\n",
    "        \"\"\"SMAPE Loss\"\"\"\n",
    "        return np.abs(y_true - y_pred) / (y_true + np.abs(y_pred)) * 200\n",
    "    \n",
    "    def calc_erro(y, y_pred, outros=True, ruturn_score=False):\n",
    "        erro   = smape(y, y_pred)    \n",
    "        \n",
    "        \n",
    "        if outros:        \n",
    "            rmse = metrics.mean_squared_error(y, y_pred, squared=False)\n",
    "            mape = metrics.mean_absolute_percentage_error(y, y_pred)\n",
    "            mae  = metrics.mean_absolute_error(y, y_pred)\n",
    "            \n",
    "            print('RMSE : {:2.5f}'.format(rmse))\n",
    "            print('MAE  : {:2.5f}'.format(mae))\n",
    "            print('MAPE : {:2.5f}'.format(mape))\n",
    "            \n",
    "            \n",
    "        if ruturn_score: \n",
    "            return erro\n",
    "        else: \n",
    "            print('SMAPE: {:2.5f}'.format(erro))\n",
    "            \n",
    "    def graf_outlier(df, feature):\n",
    "        col = [(0,4), (5,9)]\n",
    "\n",
    "        df_plot = ((df[feature] - df[feature].min())/\n",
    "                (df[feature].max() - df[feature].min()))\n",
    "\n",
    "        fig, ax = plt.subplots(len(col), 1, figsize=(15,7))\n",
    "\n",
    "        for i, (x) in enumerate(col): \n",
    "            sns.boxplot(data = df_plot.iloc[:, x[0]:x[1] ], ax = ax[i]); \n",
    "                    \n",
    "    def graf_eval():\n",
    "\n",
    "        results     = model.evals_result()\n",
    "        ntree_limit = model.best_ntree_limit\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "\n",
    "        for i, error in  enumerate(['mlogloss', 'merror']):#\n",
    "            \n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.plot(results[\"validation_0\"][error], label=\"Treinamento\")\n",
    "            plt.plot(results[\"validation_1\"][error], label=\"Validação\")\n",
    "\n",
    "            plt.axvline(ntree_limit, \n",
    "                        color=\"gray\", \n",
    "                        label=\"N. de árvore ideal {}\".format(ntree_limit))\n",
    "                        \n",
    "            \n",
    "            title_name ='\\n' + error.upper() + ' PLOT \\n'\n",
    "            plt.title(title_name)\n",
    "            plt.xlabel(\"Número de árvores\")\n",
    "            plt.ylabel(error)\n",
    "            plt.legend();\n",
    "        \n",
    "    def linear_fit_slope(y):\n",
    "        \"\"\"Return the slope of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return slope\n",
    "        \n",
    "    def linear_fit_intercept(y):\n",
    "        \"\"\"Return the intercept of a linear fit to a series.\"\"\"\n",
    "        y_pure = y.dropna()\n",
    "        length = len(y_pure)\n",
    "        x = np.arange(0, length)\n",
    "        slope, intercept = np.polyfit(x, y_pure.values, deg=1)\n",
    "        return intercept\n",
    "    \n",
    "    def create_fold(self, path_): \n",
    "\n",
    "        paths = ['img', 'Data', 'Data/pkl', 'Data/submission', 'Data/tunning', \n",
    "                 'model', 'model/preds', 'model/optuna','model/preds/test', 'Data/shap',\n",
    "                 'model/preds/test/n1', 'model/preds/test/n2', 'model/preds/test/n3', \n",
    "                 'model/preds/train', 'model/preds/train/n1', 'model/preds/train/n2', \n",
    "                 'model/preds/train/n3', 'model/preds/param', 'model/mdl', 'model/preds/folds' ]\n",
    "\n",
    "        for p in paths:\n",
    "            try:\n",
    "                os.mkdir(path_+p)       \n",
    "            except:\n",
    "                #print('Erro ao criar pasta: {} '.format(path+p))\n",
    "                pass \n",
    "        \n",
    "utility = Utility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1905caee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:11:31.196970Z",
     "start_time": "2022-11-19T20:11:31.177918Z"
    }
   },
   "outputs": [],
   "source": [
    "icecream, colors, color_cols = Utility.jupyter_setting()\n",
    "n_threads = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224f3c7",
   "metadata": {},
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0c42b",
   "metadata": {},
   "source": [
    "## 1.4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7386194b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:19:54.224553Z",
     "start_time": "2022-11-19T20:19:54.204554Z"
    }
   },
   "outputs": [],
   "source": [
    "path        =  '/content/drive/MyDrive/kaggle/Tabular Playground Series/2022/10 - Novembro/' if COLAB else ''      \n",
    "path_data   = 'Data/'  # Results\n",
    "path_automl = 'automl/'\n",
    "target      = 'label'\n",
    "\n",
    "utility.create_fold(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab3f23",
   "metadata": {},
   "source": [
    "### 1.4.4. Carrega dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17d6e74b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:01:03.128540Z",
     "start_time": "2022-11-19T21:01:03.091539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      0\n",
       "1   1      1\n",
       "2   2      1\n",
       "3   3      1\n",
       "4   4      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train data: Rows=20000, Columns=2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.640707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>0.636904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>0.392496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>0.588658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>0.783603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      pred\n",
       "0  20000  0.640707\n",
       "1  20001  0.636904\n",
       "2  20002  0.392496\n",
       "3  20003  0.588658\n",
       "4  20004  0.783603"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1_train     = pd.read_csv(path + path_data + \"train_labels.csv\")\n",
    "df_submission = pd.read_csv(path + path_data + \"sample_submission.csv\")\n",
    "y             = df1_train[target]\n",
    "\n",
    "display(df1_train.head())\n",
    "print(f\" train data: Rows={df1_train.shape[0]}, Columns={df1_train.shape[1]}\")\n",
    "display(df_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c75bbf5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:42:14.150779Z",
     "start_time": "2022-11-19T20:42:13.795777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a126d86b5e47d79cc363ffb070505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 336 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM_0.51988_HBoosting_0.52438</th>\n",
       "      <th>extrees_0.52861</th>\n",
       "      <th>hbc_0.52478</th>\n",
       "      <th>hboosting</th>\n",
       "      <th>knn_0.53639</th>\n",
       "      <th>lgbm_0.51988</th>\n",
       "      <th>lgbm_0.51999</th>\n",
       "      <th>lgbm_0.52004</th>\n",
       "      <th>lgbm_0.52037</th>\n",
       "      <th>lgbm_0.52332</th>\n",
       "      <th>lr_0.52670</th>\n",
       "      <th>lr_0.52825</th>\n",
       "      <th>mlp_0.60907</th>\n",
       "      <th>rf_0.52115</th>\n",
       "      <th>rforest_0.52404</th>\n",
       "      <th>xgb0.52265</th>\n",
       "      <th>xgb_0.52157</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>0.548843</td>\n",
       "      <td>0.585168</td>\n",
       "      <td>0.509119</td>\n",
       "      <td>0.537545</td>\n",
       "      <td>0.618222</td>\n",
       "      <td>0.550837</td>\n",
       "      <td>0.540377</td>\n",
       "      <td>0.543999</td>\n",
       "      <td>0.548438</td>\n",
       "      <td>0.572351</td>\n",
       "      <td>0.567470</td>\n",
       "      <td>0.544412</td>\n",
       "      <td>0.560365</td>\n",
       "      <td>0.518106</td>\n",
       "      <td>0.577371</td>\n",
       "      <td>0.570877</td>\n",
       "      <td>0.515994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>0.687285</td>\n",
       "      <td>0.632355</td>\n",
       "      <td>0.605727</td>\n",
       "      <td>0.680203</td>\n",
       "      <td>0.584444</td>\n",
       "      <td>0.688535</td>\n",
       "      <td>0.695913</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.689898</td>\n",
       "      <td>0.615514</td>\n",
       "      <td>0.672638</td>\n",
       "      <td>0.587383</td>\n",
       "      <td>0.475287</td>\n",
       "      <td>0.640746</td>\n",
       "      <td>0.668888</td>\n",
       "      <td>0.677540</td>\n",
       "      <td>0.637975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20002</th>\n",
       "      <td>0.254128</td>\n",
       "      <td>0.254955</td>\n",
       "      <td>0.225538</td>\n",
       "      <td>0.240589</td>\n",
       "      <td>0.245778</td>\n",
       "      <td>0.256517</td>\n",
       "      <td>0.248506</td>\n",
       "      <td>0.248475</td>\n",
       "      <td>0.250720</td>\n",
       "      <td>0.213055</td>\n",
       "      <td>0.245844</td>\n",
       "      <td>0.320378</td>\n",
       "      <td>0.313449</td>\n",
       "      <td>0.225798</td>\n",
       "      <td>0.235138</td>\n",
       "      <td>0.257691</td>\n",
       "      <td>0.233197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20003</th>\n",
       "      <td>0.393717</td>\n",
       "      <td>0.373809</td>\n",
       "      <td>0.386632</td>\n",
       "      <td>0.409098</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.391002</td>\n",
       "      <td>0.394445</td>\n",
       "      <td>0.397829</td>\n",
       "      <td>0.398680</td>\n",
       "      <td>0.396297</td>\n",
       "      <td>0.356794</td>\n",
       "      <td>0.401716</td>\n",
       "      <td>0.270752</td>\n",
       "      <td>0.389684</td>\n",
       "      <td>0.384318</td>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.391016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>0.047704</td>\n",
       "      <td>0.109414</td>\n",
       "      <td>0.054091</td>\n",
       "      <td>0.046739</td>\n",
       "      <td>0.101333</td>\n",
       "      <td>0.047874</td>\n",
       "      <td>0.045278</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>0.045657</td>\n",
       "      <td>0.065152</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.103823</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.054272</td>\n",
       "      <td>0.077303</td>\n",
       "      <td>0.041673</td>\n",
       "      <td>0.062738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GBM_0.51988_HBoosting_0.52438  extrees_0.52861  hbc_0.52478  hboosting  \\\n",
       "id                                                                              \n",
       "20000                       0.548843         0.585168     0.509119   0.537545   \n",
       "20001                       0.687285         0.632355     0.605727   0.680203   \n",
       "20002                       0.254128         0.254955     0.225538   0.240589   \n",
       "20003                       0.393717         0.373809     0.386632   0.409098   \n",
       "20004                       0.047704         0.109414     0.054091   0.046739   \n",
       "\n",
       "       knn_0.53639  lgbm_0.51988  lgbm_0.51999  lgbm_0.52004  lgbm_0.52037  \\\n",
       "id                                                                           \n",
       "20000     0.618222      0.550837      0.540377      0.543999      0.548438   \n",
       "20001     0.584444      0.688535      0.695913      0.693985      0.689898   \n",
       "20002     0.245778      0.256517      0.248506      0.248475      0.250720   \n",
       "20003     0.384000      0.391002      0.394445      0.397829      0.398680   \n",
       "20004     0.101333      0.047874      0.045278      0.045359      0.045657   \n",
       "\n",
       "       lgbm_0.52332  lr_0.52670  lr_0.52825  mlp_0.60907  rf_0.52115  \\\n",
       "id                                                                     \n",
       "20000      0.572351    0.567470    0.544412     0.560365    0.518106   \n",
       "20001      0.615514    0.672638    0.587383     0.475287    0.640746   \n",
       "20002      0.213055    0.245844    0.320378     0.313449    0.225798   \n",
       "20003      0.396297    0.356794    0.401716     0.270752    0.389684   \n",
       "20004      0.065152    0.096710    0.103823     0.009690    0.054272   \n",
       "\n",
       "       rforest_0.52404  xgb0.52265  xgb_0.52157  \n",
       "id                                               \n",
       "20000         0.577371    0.570877     0.515994  \n",
       "20001         0.668888    0.677540     0.637975  \n",
       "20002         0.235138    0.257691     0.233197  \n",
       "20003         0.384318    0.395592     0.391016  \n",
       "20004         0.077303    0.041673     0.062738  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df_pred_result       = pd.DataFrame(np.zeros(20000), columns=['id'])\n",
    "df_pred_result['id'] = df_pred[20000:].index\n",
    "\n",
    "file_list = sorted(glob.glob(os.path.join(path + path_data, 'submission/result/*.csv')))\n",
    "\n",
    "for idx, file in enumerate(tqdm(file_list)):\n",
    "    col = file.replace('Data/submission/result\\\\', '').replace('.csv', '')    \n",
    "    df_pred_result[col] = pd.read_csv(file)[\"pred\"].to_numpy()  \n",
    "\n",
    "df_pred_result.set_index('id', inplace=True)\n",
    "utility.free_gpu_cache()\n",
    "\n",
    "df_pred_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "414ddc7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:04:28.973034Z",
     "start_time": "2022-11-19T21:04:28.884033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GBM_0.51988_HBoosting_0.52438</th>\n",
       "      <th>extrees_0.52861</th>\n",
       "      <th>hbc_0.52478</th>\n",
       "      <th>hboosting</th>\n",
       "      <th>knn_0.53639</th>\n",
       "      <th>lgbm_0.51988</th>\n",
       "      <th>lgbm_0.51999</th>\n",
       "      <th>lgbm_0.52004</th>\n",
       "      <th>lgbm_0.52037</th>\n",
       "      <th>lgbm_0.52332</th>\n",
       "      <th>lr_0.52670</th>\n",
       "      <th>lr_0.52825</th>\n",
       "      <th>mlp_0.60907</th>\n",
       "      <th>rf_0.52115</th>\n",
       "      <th>rforest_0.52404</th>\n",
       "      <th>xgb0.52265</th>\n",
       "      <th>xgb_0.52157</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.497850</td>\n",
       "      <td>0.497785</td>\n",
       "      <td>0.495961</td>\n",
       "      <td>0.497677</td>\n",
       "      <td>0.490136</td>\n",
       "      <td>0.497880</td>\n",
       "      <td>0.497929</td>\n",
       "      <td>0.497847</td>\n",
       "      <td>0.497878</td>\n",
       "      <td>0.496655</td>\n",
       "      <td>0.497652</td>\n",
       "      <td>0.497502</td>\n",
       "      <td>0.501397</td>\n",
       "      <td>0.497668</td>\n",
       "      <td>0.497856</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.497815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.269020</td>\n",
       "      <td>0.258127</td>\n",
       "      <td>0.269862</td>\n",
       "      <td>0.270063</td>\n",
       "      <td>0.251140</td>\n",
       "      <td>0.268954</td>\n",
       "      <td>0.268911</td>\n",
       "      <td>0.268812</td>\n",
       "      <td>0.268933</td>\n",
       "      <td>0.268749</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.313505</td>\n",
       "      <td>0.272791</td>\n",
       "      <td>0.265509</td>\n",
       "      <td>0.270117</td>\n",
       "      <td>0.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.012190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.009159</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.004180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.297329</td>\n",
       "      <td>0.314173</td>\n",
       "      <td>0.281444</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>0.307111</td>\n",
       "      <td>0.297267</td>\n",
       "      <td>0.297880</td>\n",
       "      <td>0.297813</td>\n",
       "      <td>0.297482</td>\n",
       "      <td>0.287151</td>\n",
       "      <td>0.312719</td>\n",
       "      <td>0.347623</td>\n",
       "      <td>0.233941</td>\n",
       "      <td>0.278097</td>\n",
       "      <td>0.303817</td>\n",
       "      <td>0.303388</td>\n",
       "      <td>0.276889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.463946</td>\n",
       "      <td>0.468401</td>\n",
       "      <td>0.454290</td>\n",
       "      <td>0.465208</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.463889</td>\n",
       "      <td>0.464262</td>\n",
       "      <td>0.464226</td>\n",
       "      <td>0.463819</td>\n",
       "      <td>0.451540</td>\n",
       "      <td>0.469017</td>\n",
       "      <td>0.472127</td>\n",
       "      <td>0.468380</td>\n",
       "      <td>0.454568</td>\n",
       "      <td>0.461832</td>\n",
       "      <td>0.464969</td>\n",
       "      <td>0.458654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.717844</td>\n",
       "      <td>0.695691</td>\n",
       "      <td>0.717054</td>\n",
       "      <td>0.718717</td>\n",
       "      <td>0.682667</td>\n",
       "      <td>0.717675</td>\n",
       "      <td>0.717942</td>\n",
       "      <td>0.717430</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.725808</td>\n",
       "      <td>0.700250</td>\n",
       "      <td>0.657214</td>\n",
       "      <td>0.789022</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.708673</td>\n",
       "      <td>0.716691</td>\n",
       "      <td>0.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.994314</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.994668</td>\n",
       "      <td>0.990821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995027</td>\n",
       "      <td>0.994972</td>\n",
       "      <td>0.994941</td>\n",
       "      <td>0.994863</td>\n",
       "      <td>0.995826</td>\n",
       "      <td>0.997017</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999787</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.997946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GBM_0.51988_HBoosting_0.52438  extrees_0.52861   hbc_0.52478  \\\n",
       "count                   20000.000000     20000.000000  20000.000000   \n",
       "mean                        0.497850         0.497785      0.495961   \n",
       "std                         0.269020         0.258127      0.269862   \n",
       "min                         0.009626         0.006127      0.008510   \n",
       "25%                         0.297329         0.314173      0.281444   \n",
       "50%                         0.463946         0.468401      0.454290   \n",
       "75%                         0.717844         0.695691      0.717054   \n",
       "max                         0.994314         0.998806      0.994668   \n",
       "\n",
       "          hboosting   knn_0.53639  lgbm_0.51988  lgbm_0.51999  lgbm_0.52004  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       0.497677      0.490136      0.497880      0.497929      0.497847   \n",
       "std        0.270063      0.251140      0.268954      0.268911      0.268812   \n",
       "min        0.012190      0.000000      0.009093      0.008918      0.009159   \n",
       "25%        0.296882      0.307111      0.297267      0.297880      0.297813   \n",
       "50%        0.465208      0.466667      0.463889      0.464262      0.464226   \n",
       "75%        0.718717      0.682667      0.717675      0.717942      0.717430   \n",
       "max        0.990821      1.000000      0.995027      0.994972      0.994941   \n",
       "\n",
       "       lgbm_0.52037  lgbm_0.52332    lr_0.52670    lr_0.52825   mlp_0.60907  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       0.497878      0.496655      0.497652      0.497502      0.501397   \n",
       "std        0.268933      0.268749      0.263489      0.228184      0.313505   \n",
       "min        0.009049      0.006070      0.001505      0.009005      0.000007   \n",
       "25%        0.297482      0.287151      0.312719      0.347623      0.233941   \n",
       "50%        0.463819      0.451540      0.469017      0.472127      0.468380   \n",
       "75%        0.716867      0.725808      0.700250      0.657214      0.789022   \n",
       "max        0.994863      0.995826      0.997017      0.995994      0.999999   \n",
       "\n",
       "         rf_0.52115  rforest_0.52404    xgb0.52265   xgb_0.52157  \n",
       "count  20000.000000     20000.000000  20000.000000  20000.000000  \n",
       "mean       0.497668         0.497856      0.497816      0.497815  \n",
       "std        0.272791         0.265509      0.270117      0.271400  \n",
       "min        0.002503         0.003428      0.004514      0.004180  \n",
       "25%        0.278097         0.303817      0.303388      0.276889  \n",
       "50%        0.454568         0.461832      0.464969      0.458654  \n",
       "75%        0.721893         0.708673      0.716691      0.719100  \n",
       "max        0.999787         0.998980      0.996964      0.997946  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e3c85",
   "metadata": {},
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31666bd0",
   "metadata": {},
   "source": [
    "<div style=\"color:white;border-radius:8px;background-color:#a7d5ed\">    \n",
    "    <h1 style=\"padding:12px;color:black;\"> 2. MODELAGEM DE OTIMIZAÇÃO DO RESULTADO </h1>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1437c",
   "metadata": {},
   "source": [
    "## 2.1. Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ca01009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:35:56.113314Z",
     "start_time": "2022-11-19T20:35:56.093319Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate(main, support, coeff):\n",
    "    \n",
    "    g = main.copy()    \n",
    "    \n",
    "    for i in main.columns[1:]:        \n",
    "        res     = []\n",
    "        lm, Is  = [], []        \n",
    "        lm      = main[i].tolist()\n",
    "        ls      = support[i].tolist()  \n",
    "        \n",
    "        for j in range(len(main)):\n",
    "            res.append((lm[j] * coeff) + (ls[j] * (1.- coeff)))            \n",
    "            \n",
    "        g[i] = res\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cef083f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:36:12.192281Z",
     "start_time": "2022-11-19T20:36:12.179278Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def drawing(main, support, generated):\n",
    "    \n",
    "    X  = main.iloc[:, 1]\n",
    "    Y1 = support.iloc[:, 1]\n",
    "    Y2 = generated.iloc[:, 1]\n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid') \n",
    "    plt.figure(figsize=(8, 8), facecolor='lightgray')\n",
    "    plt.title(f'\\nNo eixo X >>> principal\\nNo eixo Y >>> suporte\\n')           \n",
    "    plt.scatter(X, Y1, s=0.1)\n",
    "    plt.show() \n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid') \n",
    "    plt.figure(figsize=(8, 8), facecolor='lightgray')\n",
    "    plt.title(f'\\nNo eixo X >>> principal\\nNo eixo Y >>> gerado\\n')           \n",
    "    plt.scatter(X, Y2, s=0.1)\n",
    "    plt.show()     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d616eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:36:27.246888Z",
     "start_time": "2022-11-19T20:36:27.226796Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def drawing1(main, support, generated):\n",
    "    \n",
    "    X  = main.iloc[:, 1]\n",
    "    Y1 = support.iloc[:, 1]\n",
    "    Y2 = generated.iloc[:, 1]\n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid') \n",
    "    plt.figure(figsize=(8, 8), facecolor='lightgray')\n",
    "    plt.title(f'\\nBlue | X axis >> main | Y axis >> support\\n\\nOrange | X axis >> main | Y axis >> generated\\n') \n",
    "    #plt.title(f'\\nAzul | Eixo X >> principal | Eixo Y >> suporte \\n n\\Laranja | Eixo X >> principal | Eixo Y >> gerado \\n')\n",
    "    plt.scatter(X, Y1, s=0.1)    \n",
    "    plt.scatter(X, Y2, s=0.1)\n",
    "    \n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00209dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:36:46.706667Z",
     "start_time": "2022-11-19T20:36:46.692669Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def drawing2(pxy, mxy):\n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid') \n",
    "    plt.figure(figsize=(8, 8), facecolor='lightgray')\n",
    "    plt.title(f'\\nComparative Method\\n\\nBlue | X(main) | Y(average - smaller result)\\n\\nOrange | X(main) | Y(generated)\\n') \n",
    "    plt.scatter(pxy[0], pxy[1], s=0.1)\n",
    "    plt.scatter(pxy[0], pxy[2], s=0.1)\n",
    "    plt.show() \n",
    "\n",
    "    plt.style.use('seaborn-whitegrid') \n",
    "    plt.figure(figsize=(8, 8), facecolor='lightgray')\n",
    "    plt.title(f'\\nComparative Method\\n\\nBlue | X(main) | Y(average - bigger results)\\n\\nOrange | X(main) | Y(generated)\\n') \n",
    "    plt.scatter(mxy[0], mxy[1], s=0.1)\n",
    "    plt.scatter(mxy[0], mxy[2], s=0.1)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a64d9a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T20:37:11.415649Z",
     "start_time": "2022-11-19T20:37:11.395645Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def comparison(main, majority, pcoeff, mcoeff):\n",
    "    '''\n",
    "    majority: Must be greater than half the total number of kernels. \n",
    "              In this example it must be greater than six.(Hyper parameter)\n",
    "    \n",
    "    pcoeff:   More than one (Hyper parameter)\n",
    "    mcoeff:   Less than one (Hyper parameter)\n",
    "    \n",
    "              First you can assume: (mcoeff = 2 - pcoeff)\n",
    "              Then update the numbers based on the results.    \n",
    "    '''    \n",
    "    comp = main.copy()\n",
    "    for i in main.columns[1:]:\n",
    "        \n",
    "        res = []\n",
    "        pxy = [[],[],[]]\n",
    "        mxy = [[],[],[]]        \n",
    "        lm  = main[i].tolist() \n",
    "        ls  = [[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "        \n",
    "        for n in range (12):       \n",
    "            csv   = pd.read_csv(dfk.iloc[n, 2])  \n",
    "            ls[n] = csv[i].tolist() \n",
    "            \n",
    "        for j in range(len(main)):\n",
    "            pcount = 0\n",
    "            pvalue = 0.0        \n",
    "            mcount = 0\n",
    "            mvalue = 0.0 \n",
    "    \n",
    "            for k in range (12):            \n",
    "                if lm[j] > ls[k][j]:\n",
    "                    pcount += 1\n",
    "                    pvalue += ls[k][j]                 \n",
    "                else: \n",
    "                    mcount += 1\n",
    "                    mvalue += ls[k][j] \n",
    "                    \n",
    "            if (pcount > majority): \n",
    "                res.append(lm[j] * pcoeff)\n",
    "                pxy[2].append(lm[j] * pcoeff)                \n",
    "                pxy[1].append(pvalue / pcount)\n",
    "                pxy[0].append(lm[j])\n",
    "                        \n",
    "            elif (mcount > majority): \n",
    "                res.append(lm[j] * mcoeff)\n",
    "                mxy[2].append(lm[j] * mcoeff)                \n",
    "                mxy[1].append(mvalue / mcount)\n",
    "                mxy[0].append(lm[j])\n",
    "                        \n",
    "            else: \n",
    "                res.append(lm[j])       \n",
    "    \n",
    "        comp[i] = res    \n",
    "\n",
    "    drawing2(pxy, mxy)    \n",
    "    return comp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ea2cd",
   "metadata": {},
   "source": [
    "<p style=\"border-bottom: 2px solid #256B5D\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9324879",
   "metadata": {},
   "source": [
    "## 2.2. Passo 1\n",
    "Nesta etapa, usamos os resultados dos kernels \"A, B, C, D, E, F, G\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a3e18584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:38:19.285940Z",
     "start_time": "2022-11-19T21:38:19.276941Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(main, support, coeff):\n",
    "    y_pred = (main*coeff)+(support*(1.- coeff))    \n",
    "    return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "082bd4e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:41:52.017945Z",
     "start_time": "2022-11-19T21:41:52.010945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBM_0.51988_HBoosting_0.52438',\n",
       " 'extrees_0.52861',\n",
       " 'hbc_0.52478',\n",
       " 'hboosting',\n",
       " 'knn_0.53639',\n",
       " 'lgbm_0.51988',\n",
       " 'lgbm_0.52004',\n",
       " 'lgbm_0.52037',\n",
       " 'lgbm_0.52332',\n",
       " 'lr_0.52670',\n",
       " 'lr_0.52825',\n",
       " 'mlp_0.60907',\n",
       " 'rf_0.52115',\n",
       " 'rforest_0.52404',\n",
       " 'xgb0.52265',\n",
       " 'xgb_0.52157']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7d7b0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:43:22.724510Z",
     "start_time": "2022-11-19T21:43:22.122712Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [107], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m main \u001b[38;5;241m=\u001b[39m df_pred_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_0.52670\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m sub2 \u001b[38;5;241m=\u001b[39m generate(main, sub1, \u001b[38;5;241m0.65\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdrawing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [60], line 3\u001b[0m, in \u001b[0;36mdrawing\u001b[1;34m(main, support, generated)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrawing\u001b[39m(main, support, generated):\n\u001b[1;32m----> 3\u001b[0m     X  \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m     Y1 \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m     Y2 \u001b[38;5;241m=\u001b[39m generated\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1458\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1458\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:765\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tuple_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m    Check the key for valid keys across my indexer.\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 765\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    766\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(key)\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:812\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(_one_ellipsis_message)\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "main = df_pred_result['lr_0.52670']\n",
    "\n",
    "sub2 = generate(main, sub1, 0.65)\n",
    "\n",
    "drawing(main, sub1, sub2)\n",
    "\n",
    "#drawing1(main, sub1, sub2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2cb1ddb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:47:34.829278Z",
     "start_time": "2022-11-19T21:47:34.803277Z"
    }
   },
   "outputs": [],
   "source": [
    "main    = df_pred_result['lgbm_0.51999']\n",
    "\n",
    "coeff   = 0.99 \n",
    "feature = df_pred_result.columns.to_list() \n",
    "feature.remove('lgbm_0.51999')\n",
    "\n",
    "for col in feature: \n",
    "    support = df_pred_result[col] \n",
    "    main = generate(main, support, coeff) \n",
    "    \n",
    "sub1= main.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fead3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:48:55.755511Z",
     "start_time": "2022-11-19T21:48:55.692510Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot reset_index inplace on a Series to create a DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [124], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msub2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py:1481\u001b[0m, in \u001b[0;36mSeries.reset_index\u001b[1;34m(self, level, drop, name, inplace)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(\n\u001b[0;32m   1478\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mcopy(), index\u001b[38;5;241m=\u001b[39mnew_index\n\u001b[0;32m   1479\u001b[0m         )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreset_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inplace:\n\u001b[1;32m-> 1481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot reset_index inplace on a Series to create a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1483\u001b[0m     )\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;66;03m# For backwards compatibility, keep columns as [0] instead of\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;66;03m#  [None] when self.name is None\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot reset_index inplace on a Series to create a DataFrame"
     ]
    }
   ],
   "source": [
    "sub2 = sub2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1df1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = df_pred_result['lr_0.52670']\n",
    "\n",
    "sub2 = generate(main, sub1, 0.65)\n",
    "sub2 \n",
    "\n",
    "drawing(main, sub1, sub2)\n",
    "\n",
    "#drawing1(main, sub1, sub2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d9c3563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-19T21:43:22.724510Z",
     "start_time": "2022-11-19T21:43:22.122712Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [107], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m main \u001b[38;5;241m=\u001b[39m df_pred_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_0.52670\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m sub2 \u001b[38;5;241m=\u001b[39m generate(main, sub1, \u001b[38;5;241m0.65\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdrawing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [60], line 3\u001b[0m, in \u001b[0;36mdrawing\u001b[1;34m(main, support, generated)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrawing\u001b[39m(main, support, generated):\n\u001b[1;32m----> 3\u001b[0m     X  \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m     Y1 \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m     Y2 \u001b[38;5;241m=\u001b[39m generated\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1458\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1458\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:765\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tuple_indexer\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m    Check the key for valid keys across my indexer.\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 765\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    766\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(key)\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:812\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(_one_ellipsis_message)\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key_length(key)\n\u001b[1;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "main = df_pred_result['lr_0.52670']\n",
    "\n",
    "sub2 = generate(main, sub1, 0.65)\n",
    "\n",
    "drawing(main, sub1, sub2)\n",
    "\n",
    "#drawing1(main, sub1, sub2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79044458",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Lista com os modelos para gerar as previsões \n",
    "models_n3 = [\n",
    "    ('RForest', model_rf, 1, 'nb_02_n3_14_rf'), \n",
    "    ('XGB', model_xgb, 1, 'nb_02_n3_15_xgb'), \n",
    "    ('LGBM', model_lgbm, 1, 'nb_02_n3_16_lgbm'), \n",
    "    ('HBoosting', model_hbc, 1, 'nb_02_n3_17_hbc'), \n",
    "    ('LR', model_lr, 1, 'nb_02_n3_18_lr')\n",
    "]\n",
    "      \n",
    "# Dataset para armazenar as previsões\n",
    "df_pred_tr_n3   = pd.DataFrame() \n",
    "df_pred_ts_n3   = pd.DataFrame()\n",
    "df_score_mdl_n3 = pd.DataFrame()\n",
    "\n",
    "# Loop para treina cada modelo \n",
    "for mdl in models_n3: \n",
    "    \n",
    "    # Lista com o nome de cada modelo\n",
    "    cols = ['LR', 'KNN', 'MLP', 'XGB', 'ExTrees', 'LGBM', 'HBoosting', 'RForest']\n",
    "    \n",
    "    # remoção da colona, previsões do modelo, do treinamento. \n",
    "    cols.remove(mdl[0])\n",
    "    \n",
    "    # Chama uma função para treinar o modelo e retorna as previsões\n",
    "    _tr_n3, _ts_n3, _score_mdl_n3 = \\\n",
    "        model_cv_fit(models_          = [mdl], \n",
    "                     X_               = df_tr[cols],\n",
    "                     y_               = y, \n",
    "                     X_test_          = df_ts[cols],                  \n",
    "                     path_            = path, \n",
    "                     seed_            = seed,\n",
    "                     target_          = 'pred',\n",
    "                     create_sub_      = True, \n",
    "                     n_splits_        = 10,\n",
    "                     print_report_    = False, \n",
    "                     print_score_mdl_ = False, \n",
    "                     save_ensamble_   = True,\n",
    "                     level_           = '3'\n",
    "                    ) \n",
    "    \n",
    "    # Armazeno as previsões para o próximo nível \n",
    "    df_pred_tr_n3   = pd.concat([df_pred_tr_n3, _tr_n3], axis=1)\n",
    "    df_pred_ts_n3   = pd.concat([df_pred_ts_n3, _ts_n3], axis=1)\n",
    "    df_score_mdl_n3 = pd.concat([df_score_mdl_n3, _score_mdl_n3]) \n",
    "    \n",
    "del _tr_n3, _ts_n3, _score_mdl_n3 \n",
    "\n",
    "df_score_mdl_n3.sort_values(by='score',ascending=True)  \n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
